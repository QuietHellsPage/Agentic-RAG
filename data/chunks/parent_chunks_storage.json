[
    {
        "document_id": "0",
        "parent_id": 0,
        "parent_text": "STEVEN PINKER\n\n###### T H E L A N G U A G E I N S T I N C T\n\n\n_The New Science of Language and Mind_\n\n\nPENGUIN BOOKS\n\n\n_for_\n_Harry and Roslyn Pinker_\nwho gave me language"
    },
    {
        "document_id": "0",
        "parent_id": 1,
        "parent_text": "### Preface\n\nI have never met a person who is not interested in language.\nI wrote this book to try to satisfy that curiosity. Language is beginning\nto submit to that uniquely satisfying kind of understanding that we\ncall science, but the news has been kept a secret.\n\nFor the language lover, I hope to show that there is a world of\nelegance and richness in quotidian speech that far outshines the local\ncuriosities of etymologies, unusual words, and fine points of usage.\n\nFor the reader of popular science, I hope to explain what is behind\nthe recent discoveries (or, in many cases, nondiscoveries) reported in\nthe press: universal deep structures, brainy babies, grammar genes,\nartificially intelligent computers, neural networks, signing chimps,\ntalking Neanderthals, idiot savants, feral children, paradoxical brain\ndamage, identical twins separated at birth, color pictures of the thinking brain, and the search for the mother of all languages. I also hope\nto answer many natural questions about languages, like why there are\nso many of them, why they are so hard for adults to learn, and why\nno one seems to know the plural of _Walkman._\n\nFor students unaware of the science of language and mind, or\nworse, burdened with memorizing word frequency effects on lexical\ndecision reaction time or the fine points of the Empty Category\nPrinciple, I hope to convey the grand intellectual excitement that\nlaunched the modern study of language several decades ago.\n\nFor my professional colleagues, scattered across so many disciplines\nand studying so many seemingly unrelated topics, I hope to offer a\nsemblance of an integration of this vast territory. Although I am an\n\n\n**7**\n\n\n**8** Preface"
    },
    {
        "document_id": "0",
        "parent_id": 2,
        "parent_text": "For my professional colleagues, scattered across so many disciplines\nand studying so many seemingly unrelated topics, I hope to offer a\nsemblance of an integration of this vast territory. Although I am an\n\n\n**7**\n\n\n**8** Preface\n\n\nopinionated, obsessional researcher who dislikes insipid compromises\nthat fuzz up the issues, many academic controversies remind me of\nthe blind men palpating the elephant. If my personal synthesis seems\nto embrace both sides of debates like \"formalism versus functionalism\" or \"syntax versus semantics versus pragmatics,\" perhaps it is\nbecause there was never an issue there to begin with.\n\nFor the general nonfiction reader, interested in language and human beings in the broadest sense, I hope to offer something different\nfrom the airy platitudes—Language Lite—that typify discussions of\nlanguage (generally by people who have never studied it) in the\nhumanities and sciences alike. For better or worse, I can write in only\none way, with a passion for powerful, explanatory ideas, and a torrent\nof relevant detail. Given this last habit, I am lucky to be explaining\na subject whose principles underlie wordplay, poetry, rhetoric, wit,\nand good writing. I have not hesitated to show off my favorite examples of language in action from pop culture, ordinary children and\nadults, the more flamboyant academic writers in my field, and some\nof the finest stylists in English.\n\nThis book, then, is intended for everyone who uses language, and\nthat means everyone!\n\nI owe thanks to many people. First, to Leda Cosmides, Nancy\nEtcoff, Michael Gazzaniga, Laura Ann Petitto, Harry Pinker, Robert\nPinker, Roslyn Pinker, Susan Pinker, John Tooby, and especially\nIlavenil Subbiah, for commenting on the manuscript and generously\noffering advice and encouragement."
    },
    {
        "document_id": "0",
        "parent_id": 3,
        "parent_text": "This book, then, is intended for everyone who uses language, and\nthat means everyone!\n\nI owe thanks to many people. First, to Leda Cosmides, Nancy\nEtcoff, Michael Gazzaniga, Laura Ann Petitto, Harry Pinker, Robert\nPinker, Roslyn Pinker, Susan Pinker, John Tooby, and especially\nIlavenil Subbiah, for commenting on the manuscript and generously\noffering advice and encouragement.\n\nMy home institution, the Massachusetts Institute of Technology, is\na special environment for the study of language, and I am grateful\nto the colleagues, students, and former students who shared their\nexpertise. Noam Chomsky made penetrating criticisms and helpful\nsuggestions, and Ned Block, Paul Bloom, Susan Carey, Ted Gibson,\nMorris Halle, and Michael Jordan helped me think through the issues\nin several chapters. Thanks go also to Hilary Bromberg, Jacob Feldman, John Houde, Samuel Jay Keyser, John J. Kim, Gary Marcus,\nNeal Perlmutter, David Pesetsky, David Poppel, Annie Senghas,\nKarin Stromswold, Michael Tarr, Marianne Teuber, Michael Ullman,\nKenneth Wexler, and Karen Wynn for erudite answers to questions\nranging from sign language to obscure ball players and guitarists. The\nDepartment of Brain and Cognitive Sciences' librarian, Pat Claffey,\nand computer system manager, Stephen G. Wadlow, those most\n\n\nPreface **9**\n\n\nadmirable prototypes of their professions, offered dedicated, expert\nhelp at many stages."
    },
    {
        "document_id": "0",
        "parent_id": 4,
        "parent_text": "Preface **9**\n\n\nadmirable prototypes of their professions, offered dedicated, expert\nhelp at many stages.\n\nSeveral chapters benefited from the scrutiny of real mavens, and I\nam grateful for their technical and stylistic comments: Derek Bickerton, David Caplan, Richard Dawkins, Nina Dronkers, Jane Grimshaw, Misia Landau, Beth Levin, Alan Prince, and Sarah G.\nThomason. I also thank my colleagues in cyberspace who indulged\nmy impatience by replying, sometimes in minutes, to my electronic\nqueries: Mark Aronoff, Kathleen Baynes, Ursula Bellugi, Dorothy\nBishop, Helena Cronin, Lila Gleitman, Myrna Gopnik, Jacques Guy,\nHenry Kucera, Sigrid Lipka, Jacques Mehler, Elissa Newport, Alex\nRudnicky, Jenny Singleton, Virginia Valian, and Heather Van der\nLely. A final thank you to Alta Levenson of Bialik High School for\nher help with the Latin.\n\nI am happy to acknowledge the special care lavished by John\nBrockman, my agent, Ravi Mirchandani, my editor at Penguin Books,\nand Maria Guarnaschelli, my editor at William Morrow; Maria's wise\nand detailed advice vastly improved the final manuscript. Katarina\nRice copy-edited my first two books, and I am delighted that she\nagreed to my request to work with me on this one, especially considering some of the things I say in Chapter 12.\n\nMy own research on language has been supported by the National\nInstitutes of Health (grant HD 18381) and the National Science\nFoundation (grant BNS 91-09766), and by the McDonnell-Pew Center for Cognitive Neuroscience at MIT."
    },
    {
        "document_id": "0",
        "parent_id": 5,
        "parent_text": "## Contents\n\n**1. An Instinct to Acquire an Art** 15\n\n**2. Chatterboxes** 25\n\n**3. Mentalese** 55\n\n**4 . How Language Works** 8 3\n\n**5. Words, Words, Words** 126\n\n**6. The Sounds of Silence** 158\n\n**7. Talking Heads** 192\n\n**8. The Tower of Babel** 231\n\n**9. Baby Born Talking—Describes Heaven** 2 6 2\n\n**10. Language Organs and Grammar Genes** 297\n\n**11. The Big Bang** 332\n\n**12. The Language Mavens** 370\n\n**13. Mind Design** 4 0 4\n\n\n**Glossary** 431\n\n\n**1 1**\n\n\n### 1"
    },
    {
        "document_id": "0",
        "parent_id": 6,
        "parent_text": "#### An Instinct to Acquire an Art\n\nAs you are reading these words, you are taking part in one\nof the wonders of the natural world. For you and I belong to a species\nwith a remarkable ability: we can shape events in each other's brains\nwith exquisite precision. I am not referring to telepathy or mind\ncontrol or the other obsessions of fringe science; even in the depictions of believers these are blunt instruments compared to an ability\nthat is uncontroversially present in every one of us. That ability is\nlanguage. Simply by making noises with our mouths, we can reliably\ncause precise new combinations of ideas to arise in each other's\nminds. The ability comes so naturally that we are apt to forget what\na miracle it is. So let me remind you with some simple demonstrations.\nAsking you only to surrender your imagination to my words for a few\nmoments, I can cause you to think some very specific thoughts:\n\n\nWhen a male octopus spots a female, his normally grayish body\nsuddenly becomes striped. He swims above the female and begins\ncaressing her with seven of his arms. If she allows this, he will\nquickly reach toward her and slip his eighth arm into her breathing\ntube. A series of sperm packets moves slowly through a groove in\nhis arm, finally to slip into the mantle cavity of the female.\n\nCherries jubilee on a white suit? Wine on an altar cloth? Apply club\nsoda immediately. It works beautifully to remove the stains from\nfabrics.\n\nWhen Dixie opens the door to Tad, she is stunned, because she\nthought he was dead. She slams it in his face and then tries to\n\n\n**15**\n\n\n**1 6** THE LANGUAGE INSTINCT\n\n\nescape. However, when Tad says, \"I love you,\" she lets him in. Tad\ncomforts her, and they become passionate. When Brian interrupts,\nDixie tells a stunned Tad that she and Brian were married earlier\nthat day. With much difficulty, Dixie informs Brian that things are\nnowhere near finished between her and Tad. Then she spills the\nnews that Jamie is Tad's son. \"My what?\" says a shocked Tad."
    },
    {
        "document_id": "0",
        "parent_id": 7,
        "parent_text": "**15**\n\n\n**1 6** THE LANGUAGE INSTINCT\n\n\nescape. However, when Tad says, \"I love you,\" she lets him in. Tad\ncomforts her, and they become passionate. When Brian interrupts,\nDixie tells a stunned Tad that she and Brian were married earlier\nthat day. With much difficulty, Dixie informs Brian that things are\nnowhere near finished between her and Tad. Then she spills the\nnews that Jamie is Tad's son. \"My what?\" says a shocked Tad.\n\n\nThink about what these words have done. I did not simply remind\nyou of octopuses; in the unlikely event that you ever see one develop\nstripes, you now know what will happen next. Perhaps the next time\nyou are in a supermarket you will look for club soda, one out of the\ntens of thousands of items available, and then not touch it until\nmonths later when a particular substance and a particular object\naccidentally come together. You now share with millions of other\npeople the secrets of protagonists in a world that is the product of\nsome stranger's imagination, the daytime drama _All My Children._\nTrue, my demonstrations depended on our ability to read and write,\nand this makes our communication even more impressive by bridging\ngaps of time, space, and acquaintanceship. But writing is clearly an\noptional accessory; the real engine of verbal communication is the\nspoken language we acquired as children."
    },
    {
        "document_id": "0",
        "parent_id": 8,
        "parent_text": "In any natural history of the human species, language would stand\nout as the preeminent trait. To be sure, a solitary human is an impressive problem-solver and engineer. But a race of Robinson Crusoes\nwould not give an extraterrestrial observer all that much to remark\non. What is truly arresting about our kind is better captured in the\nstory of the Tower of Babel, in which humanity, speaking a single\nlanguage, came so close to reaching heaven that God himself felt\nthreatened. A common language connects the members of a community into an information-sharing network with formidable collective\npowers. Anyone can benefit from the strokes of genius, lucky accidents, and trial-and-error wisdom accumulated by anyone else, present or past. And people can work in teams, their efforts coordinated\nby negotiated agreements. As a result, _Homo sapiens_ is a species,\nlike blue-green algae and earthworms, that has wrought far-reaching\nchanges on the planet. Archeologists have discovered the bones of\nten thousand wild horses at the bottom of a cliff in France, the\nremains of herds stampeded over the clifftop by groups of paleolithic\nhunters seventeen thousand years ago. These fossils of ancient cooper\n\nAn Instinct to Acquire an Art **1 7**\n\n\nation and shared ingenuity may shed light on why saber-tooth tigers,\nmastodons, giant woolly rhinoceroses, and dozens of other large mammals went extinct around the time that modern humans arrived in\ntheir habitats. Our ancestors, apparently, killed them off."
    },
    {
        "document_id": "0",
        "parent_id": 9,
        "parent_text": "An Instinct to Acquire an Art **1 7**\n\n\nation and shared ingenuity may shed light on why saber-tooth tigers,\nmastodons, giant woolly rhinoceroses, and dozens of other large mammals went extinct around the time that modern humans arrived in\ntheir habitats. Our ancestors, apparently, killed them off.\n\nLanguage is so tightly woven into human experience that it is\nscarcely possible to imagine life without it. Chances are that if you\nfind two or more people together anywhere on earth, they will soon\nbe exchanging words. When there is no one to talk with, people talk\nto themselves, to their dogs, even to their plants. In our social relations, the race is not to the swift but to the verbal—the spellbinding\norator, the silver-tongued seducer, the persuasive child who wins the\nbattle of wills against a brawnier parent. Aphasia, the loss of language\nfollowing brain injury, is devastating, and in severe cases family members may feel that the whole person is lost forever."
    },
    {
        "document_id": "0",
        "parent_id": 10,
        "parent_text": "This book is about human language. Unlike most books with \"language\" in the title, it will not chide you about proper usage, trace the\norigins of idioms and slang, or divert you with palindromes, anagrams,\neponyms, or those precious names for groups of animals like \"exaltation of larks.\" For I will be writing not about the English language\nor any other language, but about something much more basic: the\ninstinct to learn, speak, and understand language. For the first time\nin history, there is something to write about it. Some thirty-five years\nago a new science was born. Now called \"cognitive science,\" it combines tools from psychology, computer science, linguistics, philosophy, and neurobiology to explain the workings of human intelligence.\nThe science of language, in particular, has seen spectacular advances\nin the years since. There are many phenomena of language that we\nare coming to understand nearly as well as we understand how a\ncamera works or what the spleen is for. I hope to communicate these\nexciting discoveries, some of them as elegant as anything in modern\nscience, but I have another agenda as well.\n\nThe recent illumination of linguistic abilities has revolutionary implications for our understanding of language and its role in human\naffairs, and for our view of humanity itself. Most educated people\nalready have opinions about language. They know that it is man's\nmost important cultural invention, the quintessential example of his\ncapacity to use symbols, and a biologically unprecedented event irrevocably separating him from other animals. They know that language\npervades thought, with different languages causing their speakers to\n\n\n**1 8** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 11,
        "parent_text": "**1 8** THE LANGUAGE INSTINCT\n\n\nconstrue reality in different ways. They know that children learn to\ntalk from role models and caregivers. They know that grammatical\nsophistication used to be nurtured in the schools, but sagging educational standards and the debasements of popular culture have led to\na frightening decline in the ability of the average person to construct\na grammatical sentence. They also know that English is a zany, logicdefying tongue, in which one drives on a parkway and parks in a\ndriveway, plays at a recital and recites at a play. They know that\nEnglish spelling takes such wackiness to even greater heights—\nGeorge Bernard Shaw complained that _fish_ could just as sensibly be\nspelled _ghoti (gh_ as in _tough, o_ as in _women, ti_ as in _nation)_ —and\nthat only institutional inertia prevents the adoption of a more rational,\nspell-it-like-it-sounds system."
    },
    {
        "document_id": "0",
        "parent_id": 12,
        "parent_text": "In the pages that follow, I will try to convince you that every one\nof these common opinions is wrong! And they are all wrong for a\nsingle reason. Language is not a cultural artifact that we learn the way\nwe learn to tell time or how the federal government works. Instead,\nit is a distinct piece of the biological makeup of our brains. Language\nis a complex, specialized skill, which develops in the child spontaneously, without conscious effort or formal instruction, is deployed\nwithout awareness of its underlying logic, is qualitatively the same in\nevery individual, and is distinct from more general abilities to process\ninformation or behave intelligently. For these reasons some cognitive\nscientists have described language as a psychological faculty, a mental\norgan, a neural system, and a computational module. But I prefer the\nadmittedly quaint term \"instinct.\" It conveys the idea that people\nknow how to talk in more or less the sense that spiders know how to\nspin webs. Web-spinning was not invented by some unsung spider\ngenius and does not depend on having had the right education or on\nhaving an aptitude for architecture or the construction trades. Rather,\nspiders spin spider webs because they have spider brains, which give\nthem the urge to spin and the competence to succeed. Although there\nare differences between webs and words, I will encourage you to see\nlanguage in this way, for it helps to make sense of the phenomena we\nwill explore.\n\nThinking of language as an instinct inverts the popular wisdom,\nespecially as it has been passed down in the canon of the humanities\nand social sciences. Language is no more a cultural invention than is\nupright posture. It is not a manifestation of a general capacity to use\n\n\nAn Instinct to Acquire an Art **1 9**"
    },
    {
        "document_id": "0",
        "parent_id": 13,
        "parent_text": "Thinking of language as an instinct inverts the popular wisdom,\nespecially as it has been passed down in the canon of the humanities\nand social sciences. Language is no more a cultural invention than is\nupright posture. It is not a manifestation of a general capacity to use\n\n\nAn Instinct to Acquire an Art **1 9**\n\n\nsymbols: a three-year-old, we shall see, is a grammatical genius, but\nis quite incompetent at the visual arts, religious iconography, traffic\nsigns, and the other staples of the semiotics curriculum. Though\nlanguage is a magnificent ability unique to _Homo sapiens_ among living\nspecies, it does not call for sequestering the study of humans from\nthe domain of biology, for a magnificent ability unique to a particular\nliving species is far from unique in the animal kingdom. Some kinds\nof bats home in on flying insects using Doppler sonar. Some kinds of\nmigratory birds navigate thousands of miles by calibrating the positions of the constellations against the time of day and year. In nature's\ntalent show we are simply a species of primate with our own act, a\nknack for communicating information about who did what to whom\nby modulating the sounds we make when we exhale."
    },
    {
        "document_id": "0",
        "parent_id": 14,
        "parent_text": "Once you begin to look at language not as the ineffable essence of\nhuman uniqueness but as a biological adaptation to communicate\ninformation, it is no longer as tempting to see language as an insidious\nshaper of thought, and, we shall see, it is not. Moreover, seeing\nlanguage as one of nature's engineering marvels—an organ with \"that\nperfection of structure and co-adaptation which justly excites our\nadmiration,\" in Darwin's words—gives us a new respect for your\nordinary Joe and the much-maligned English language (or any language). The complexity of language, from the scientist's point of view,\nis part of our biological birthright; it is not something that parents\nteach their children or something that must be elaborated in school—\nas Oscar Wilde said, \"Education is an admirable thing, but it is well\nto remember from time to time that nothing that is worth knowing\ncan be taught.\" A preschooler's tacit knowledge of grammar is more\nsophisticated than the thickest style manual or the most state-of-theart computer language system, and the same applies to all healthy\nhuman beings, even the notorious syntax-fracturing professional athlete and the, you know, like, inarticulate teenage skateboarder. Finally, since language is the product of a well-engineered biological\ninstinct, we shall see that it is not the nutty barrel of monkeys that\nentertainer-columnists make it out to be. I will try to restore some\ndignity to the English vernacular, and will even have some nice things\nto say about its spelling system.\n\nThe conception of language as a kind of instinct was first articulated\nin 1871 by Darwin himself. In _The Descent of Man_ he had to contend\nwith language because its confinement to humans seemed to present\n\n\n**2 0** THE LANGUAGE INSTINCT\n\n\na challenge to his theory. As in all matters, his observations are\nuncannily modern:"
    },
    {
        "document_id": "0",
        "parent_id": 15,
        "parent_text": "The conception of language as a kind of instinct was first articulated\nin 1871 by Darwin himself. In _The Descent of Man_ he had to contend\nwith language because its confinement to humans seemed to present\n\n\n**2 0** THE LANGUAGE INSTINCT\n\n\na challenge to his theory. As in all matters, his observations are\nuncannily modern:\n\n\nAs . . . one of the founders of the noble science of philology observes, language is an art, like brewing or baking; but writing would\nhave been a better simile. It certainly is not a true instinct, for every\nlanguage has to be learned. It differs, however, widely from all\nordinary arts, for man has an instinctive tendency to speak, as we\nsee in the babble of our young children; while no child has an\ninstinctive tendency to brew, bake, or write. Moreover, no philologist now supposes that any language has been deliberately invented;\nit has been slowly and unconsciously developed by many steps.\n\n\nDarwin concluded that language ability is \"an instinctive tendency to\nacquire an art,\" a design that is not peculiar to humans but seen in\nother species such as song-learning birds.\n\nA language instinct may seem jarring to those who think of language\nas the zenith of the human intellect and who think of instincts as\nbrute impulses that compel furry or feathered zombies to build a dam\nor up and fly south. But one of Darwin's followers, William James,\nnoted that an instinct possessor need not act as a \"fatal automaton.\"\nHe argued that we have all the instincts that animals do, and many\nmore besides; our flexible intelligence comes from the interplay of\nmany instincts competing. Indeed, the instinctive nature of human\nthought is just what makes it so hard for us to see that it is an instinct:"
    },
    {
        "document_id": "0",
        "parent_id": 16,
        "parent_text": "It takes . . . a mind debauched by learning to carry the process of\nmaking the natural seem strange, so far as to ask for the _why_ of\nany instinctive human act. To the metaphysician alone can such\nquestions occur as: Why do we smile, when pleased, and not scowl?\nWhy are we unable to talk to a crowd as we talk to a single friend?\nWhy does a particular maiden turn our wits so upside-down? The\ncommon man can only say, _\"Of course_ we smile, _of course_ our heart\npalpitates at the sight of the crowd, _of course_ we love the maiden,\nthat beautiful soul clad in that perfect form, so palpably and flagrandy made for all eternity to be loved!\"\n\nAnd so, probably, does each animal feel about the particular\nthings it tends to do in presence of particular objects. . . . To the\nlion it is the lioness which is made to be loved; to the bear, the she\n\nAn Instinct to Acquire an Art **2 1**\n\n\nbear. To the broody hen the notion would probably seem monstrous\nthat there should be a creature in the world to whom a nestful of\neggs was not the utterly fascinating and precious and never-to-betoo-much-sat-upon object which it is to her.\n\nThus we may be sure that, however mysterious some animals'\ninstincts may appear to us, our instincts will appear no less mysterious to them. And we may conclude that, to the animal which obeys\nit, every impulse and every step of every instinct shines with its own\nsufficient light, and seems at the moment the only eternally right\nand proper thing to do. What voluptuous thrill may not shake a fly,\nwhen she at last discovers the one particular leaf, or carrion, or bit\nof dung, that out of all the world can stimulate her ovipositor to its\ndischarge? Does not the discharge then seem to her the only fitting\nthing? And need she care or know anything about the future maggot\nand its food?"
    },
    {
        "document_id": "0",
        "parent_id": 17,
        "parent_text": "I can think of no better statement of my main goal. The workings\nof language are as far from our awareness as the rationale for egglaying is from the fly's. Our thoughts come out of our mouths so\neffortlessly that they often embarrass us, having eluded our mental\ncensors. When we are comprehending sentences, the stream of words\nis transparent; we see through to the meaning so automatically that\nwe can forget that a movie is in a foreign language and subtitled. We\nthink children pick up their mother tongue by imitating their mothers,\nbut when a child says _Don't giggle me!_ or _We holded the baby rabbits,_\nit cannot be an act of imitation. I want to debauch your mind with\nlearning, to make these natural gifts seem strange, to get you to ask\nthe \"why\" and \"how\" of these seemingly homely abilities. Watch an\nimmigrant struggling with a second language or a stroke patient with\na first one, or deconstruct a snatch of baby talk, or try to program a\ncomputer to understand English, and ordinary speech begins to look\ndifferent. The effortlessness, the transparency, the automaticity are\nillusions, masking a system of great richness and beauty.\n\nIn this century, the most famous argument that language is like an\ninstinct comes from Noam Chomsky, the linguist who first unmasked\nthe intricacy of the system and perhaps the person most responsible\nfor the modern revolution in language and cognitive science. In the\n1950s the social sciences were dominated by behaviorism, the school\nof thought popularized by John Watson and B. F. Skinner. Mental\n\n\n**2 2** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 18,
        "parent_text": "In this century, the most famous argument that language is like an\ninstinct comes from Noam Chomsky, the linguist who first unmasked\nthe intricacy of the system and perhaps the person most responsible\nfor the modern revolution in language and cognitive science. In the\n1950s the social sciences were dominated by behaviorism, the school\nof thought popularized by John Watson and B. F. Skinner. Mental\n\n\n**2 2** THE LANGUAGE INSTINCT\n\n\nterms like \"know\" and \"think\" were branded as unscientific; \"mind\"\nand \"innate\" were dirty words. Behavior was explained by a few laws\nof stimulus-response learning that could be studied with rats pressing\nbars and dogs salivating to tones. But Chomsky called attention to\ntwo fundamental facts about language. First, virtually every sentence\nthat a person utters or understands is a brand-new combination of\nwords, appearing for the first time in the history of the universe.\nTherefore a language cannot be a repertoire of responses; the brain\nmust contain a recipe or program that can build an unlimited set of\nsentences out of a finite list of words. That program may be called a\nmental grammar (not to be confused with pedagogical or stylistic\n\"grammars,\" which are just guides to the etiquette of written prose).\nThe second fundamental fact is that children develop these complex\ngrammars rapidly and without formal instruction and grow up to give\nconsistent interpretations to novel sentence constructions that they\nhave never before encountered. Therefore, he argued, children must\ninnately be equipped with a plan common to the grammars of all\nlanguages, a Universal Grammar, that tells them how to distill the\nsyntactic patterns out of the speech of their parents. Chomsky put it\nas follows:"
    },
    {
        "document_id": "0",
        "parent_id": 19,
        "parent_text": "It is a curious fact about the intellectual history of the past few\ncenturies that physical and mental development have been approached in quite different ways. No one would take seriously the\nproposal that the human organism learns through experience to\nhave arms rather than wings, or that the basic structure of particular\norgans results from accidental experience. Rather, it is taken for\ngranted that the physical structure of the organism is genetically\ndetermined, though of course variation along such dimensions as\nsize, rate of development, and so forth will depend in part on\nexternal factors....\n\nThe development of personality, behavior patterns, and cognitive\nstructures in higher organisms has often been approached in a very\ndifferent way. It is generally assumed that in these domains, social\nenvironment is the dominant factor. The structures of mind that\ndevelop over time are taken to be arbitrary and accidental; there is\nno \"human nature\" apart from what develops as a specific historical\nproduct....\n\nBut human cognitive systems, when seriously investigated, prove\n\n\nAn Instinct to Acquire an Art **2 3**\n\n\nto be no less marvelous and intricate than the physical structures\nthat develop in the life of the organism. Why, then, should we not\nstudy the acquisition of a cognitive structure such as language more\nor less as we study some complex bodily organ?"
    },
    {
        "document_id": "0",
        "parent_id": 20,
        "parent_text": "But human cognitive systems, when seriously investigated, prove\n\n\nAn Instinct to Acquire an Art **2 3**\n\n\nto be no less marvelous and intricate than the physical structures\nthat develop in the life of the organism. Why, then, should we not\nstudy the acquisition of a cognitive structure such as language more\nor less as we study some complex bodily organ?\n\nAt first glance, the proposal may seem absurd, if only because of\nthe great variety of human languages. But a closer consideration\ndispels these doubts. Even knowing very little of substance about\nlinguistic universals, we can be quite sure that the possible variety of\nlanguage is sharply limited. . . . The language each person acquires is\na rich and complex construction hopelessly underdetermined by\nthe fragmentary evidence available [to the child]. Nevertheless individuals in a speech community have developed essentially the same\nlanguage. This fact can be explained only on the assumption that\nthese individuals employ highly restrictive principles that guide the\nconstruction of grammar.\n\n\nBy performing painstaking technical analyses of the sentences ordinary people accept as part of their mother tongue, Chomsky and\nother linguists developed theories of the mental grammars underlying\npeople's knowledge of particular languages and of the Universal\nGrammar underlying the particular grammars. Early on, Chomsky's\nwork encouraged other scientists, among them Eric Lenneberg,\nGeorge Miller, Roger Brown, Morris Halle, and Alvin Liberman, to\nopen up whole new areas of language study, from child development\nand speech perception to neurology and genetics. By now, the community of scientists studying the questions, he raised numbers in the\nthousands. Chomsky is currently among the ten most-cited writers in\nall of the humanities (beating out Hegel and Cicero and trailing only\nMarx, Lenin, Shakespeare, the Bible, Aristotle, Plato, and Freud) and\nthe only living member of the top ten."
    },
    {
        "document_id": "0",
        "parent_id": 21,
        "parent_text": "What those citations _say_ is another matter. Chomsky gets people\nexercised. Reactions range from the awe-struck deference ordinarily\nreserved for gurus of weird religious cults to the withering invective that\nacademics have developed into a high art. In part this is because Chomsky attacks what is still one of the foundations of twentieth-century\nintellectual life—the \"Standard Social Science Model,\" according to\nwhich the human psyche is molded by the surrounding culture. But it\nis also because no thinker can afford to ignore him. As one of his severest\ncritics, the philosopher Hilary Putnam, acknowledges,\n\n\n**2 4** THE LANGUAGE INSTINCT\n\n\nWhen one reads Chomsky, one is struck by a sense of great intellectual power; one knows one is encountering an extraordinary mind.\nAnd this is as much a matter of the spell of his powerful personality\nas it is of his obvious intellectual virtues: originality, scorn for the\nfaddish and the superficial; willingness to revive (and the ability to\nrevive) positions (such as the \"doctrine of innate ideas\") that had\nseemed passe; concern with topics, such as the structure of the\nhuman mind, that are of central and perennial importance."
    },
    {
        "document_id": "0",
        "parent_id": 22,
        "parent_text": "The story I will tell in this book has, of course, been deeply influenced by Chomsky. But it is not his story exactly, and I will not tell\nit as he would. Chomsky has puzzled many readers with his skepticism\nabout whether Darwinian natural selection (as opposed to other evolutionary processes) can explain the origins of the language organ\nthat he argues for; I think it is fruitful to consider language as an\nevolutionary adaptation, like the eye, its major parts designed to carry\nout important functions. And Chomsky's arguments about the nature\nof the language faculty are based on technical analyses of word and\nsentence structure, often couched in abstruse formalisms. His discussions of flesh-and-blood speakers are perfunctory and highly idealized. Though I happen to agree with many of his arguments, I think\nthat a conclusion about the mind is convincing only if many kinds of\nevidence converge on it. So the story in this book is highly eclectic,\nranging from how DNA builds brains to the pontifications of newspaper language columnists. The best place to begin is to ask why anyone\nshould believe that human language is a part of human biology—an\ninstinct—at all."
    },
    {
        "document_id": "0",
        "parent_id": 23,
        "parent_text": "### 2"
    },
    {
        "document_id": "0",
        "parent_id": 24,
        "parent_text": "#### Chatterboxes\n\n**By** the 1920s it was thought that no corner of the earth fit\nfor human habitation had remained unexplored. New Guinea, the\nworld's second largest island, was no exception. The European missionaries, planters, and administrators clung to its coastal lowlands,\nconvinced that no one could live in the treacherous mountain range\nthat ran in a solid line down the middle of the island. But the mountains visible from each coast in fact belonged to two ranges, not one,\nand between them was a temperate plateau crossed by many fertile\nvalleys. A million Stone Age people lived in those highlands, isolated\nfrom the rest of the world for forty thousand years. The veil would\nnot be lifted until gold was discovered in a tributary of one of the main\nrivers. The ensuing gold rush attracted Michael Leahy, a footloose\nAustralian prospector, who on May 26, 1930, set out to explore the\nmountains with a fellow prospector and a group of indigenous lowland people hired as carriers. After scaling the heights, Leahy was\namazed to see grassy open country on the other side. By nightfall his\namazement turned to alarm, because there were points of light in the\ndistance, obvious signs that the valley was populated. After a sleepless\nnight in which Leahy and his party loaded their weapons and assembled a crude bomb, they made their first contact with the highlanders.\nThe astonishment was mutual. Leahy wrote in his diary:\n\n\nIt was a relief when the [natives] came in sight, the men . . . in front,\narmed with bows and arrows, the women behind bringing stalks of\nsugarcane. When he saw the women, Ewunga told me at once that\n\n\n**2 6** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 25,
        "parent_text": "It was a relief when the [natives] came in sight, the men . . . in front,\narmed with bows and arrows, the women behind bringing stalks of\nsugarcane. When he saw the women, Ewunga told me at once that\n\n\n**2 6** THE LANGUAGE INSTINCT\n\n\nthere would be no fight. We waved to them to come on, which they\ndid cautiously, stopping every few yards to look us over. When a\nfew of them finally got up courage to approach, we could see that\nthey were utterly thunderstruck by our appearance. When I took\noff my hat, those nearest to me backed away in terror. One old\nchap came forward gingerly with open mouth, and touched me to\nsee if I was real. Then he knelt down, and rubbed his hands over\nmy bare legs, possibly to find if they were painted, and grabbed me\naround the knees and hugged them, rubbing his bushy head against\nme. . . . The women and children gradually got up courage to approach also, and presently the camp was swarming with the lot of\nthem, all running about and jabbering at once, pointing to .. .\neverything that was new to them.\n\n\nThat \"jabbering\" was language—an unfamiliar language, one of\neight hundred different ones that would be discovered among the\nisolated highlanders right up through the 1960s. Leahy's first contact\nrepeated a scene that must have taken place hundreds of times in\nhuman history, whenever one people first encountered another. All\nof them, as far as we know, already had language. Every Hottentot,\nevery Eskimo, every Yanomamo. No mute tribe has ever been discovered, and there is no record that a region has served as a \"cradle\" of\nlanguage from which it spread to previously languageless groups."
    },
    {
        "document_id": "0",
        "parent_id": 26,
        "parent_text": "As in every other case, the language spoken by Leahy's hosts turned\nout to be no mere jabber but a medium that could express abstract\nconcepts, invisible entities, and complex trains of reasoning. The\nhighlanders conferred intensively, trying to agree upon the nature of\nthe pallid apparitions. The leading conjecture was that they were\nreincarnated ancestors or other spirits in human form, perhaps ones\nthat turned back into skeletons at night. They agreed upon an empirical test that would settle the matter. \"One of the people hid,\" recalls\nthe highlander Kirupano Eza'e, \"and watched them going to excrete.\nHe came back and said, 'Those men from heaven went to excrete\nover there.' Once they had left many men went to take a look. When\nthey saw that it smelt bad, they said, 'Their skin might be different,\nbut their shit smells bad like ours.' \"\n\nThe universality of complex language is a discovery that fills linguists with awe, and is the first reason to suspect that language is not\njust any cultural invention but the product of a special human instinct.\n\n\nChatterboxes **2 7**\n\n\nCultural inventions vary widely in their sophistication from society to\nsociety; within a society, the inventions are generally at the same level\nof sophistication. Some groups count by carving notches on bones\nand cook on fires ignited by spinning sticks in logs; others use computers and microwave ovens. Language, however, ruins this correlation.\nThere are Stone Age societies, but there is no such thing as a Stone\nAge language. Earlier in this century the anthropological linguist\nEdward Sapir wrote, \"When it comes to linguistic form, Plato walks\nwith the Macedonian swineherd, Confucius with the head-hunting\nsavage of Assam.\""
    },
    {
        "document_id": "0",
        "parent_id": 27,
        "parent_text": "To pick an example at random of a sophisticated linguistic form\nin a nonindustrialized people, the linguist Joan Bresnan recently wrote\na technical article comparing a construction in Kivunjo, a Bantu\nlanguage spoken in several villages on the slopes of Mount Kilimanjaro in Tanzania, with its counterpart construction in English, which\nshe describes as \"a West Germanic language spoken in England and\nits former colonies.\" The English construction is called the dative*\nand is found in sentences like _She baked me a brownie_ and _He prom-_\n_ised her Arpege,_ where an indirect object like _me_ or _her_ is placed after\nthe verb to indicate the beneficiary of an act. The corresponding\nKivunjo construction is called the applicative, whose resemblance to\nthe English dative, Bresnan notes, \"can be likened to that of the game\nof chess to checkers.\" The Kivunjo construction fits entirely inside\nthe verb, which has seven prefixes and suffixes, two moods, and\nfourteen tenses; the verb agrees with its subject, its object, and its\nbenefactive nouns, each of which comes in sixteen genders. (In case\nyou are wondering, these \"genders\" do not pertain to things like\ncross-dressers, transsexuals, hermaphrodites, androgynous people,\nand so on, as one reader of this chapter surmised. To a linguist, the\nterm _gender_ retains its original meaning of \"kind,\" as in the related\nwords _generic, genus,_ and _genre._ The Bantu \"genders\" refer to kinds\nlike humans, animals, extended objects, clusters of objects, and body\nparts. It just happens that in many European languages the genders\ncorrespond to the sexes, at least in pronouns. For this reason the\nlinguistic term _gender_ has been pressed into service by nonlinguists\n\n\n*** All the technical terms from linguistics, biology, and cognitive science that I use in**\n**this book are defined i n the G** **l** **o** **s** **s** **a** **r** **y** **.**\n\n\n**2 8** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 28,
        "parent_text": "*** All the technical terms from linguistics, biology, and cognitive science that I use in**\n**this book are defined i n the G** **l** **o** **s** **s** **a** **r** **y** **.**\n\n\n**2 8** THE LANGUAGE INSTINCT\n\n\nas a convenient label for sexual dimorphism; the more accurate term\n_sex_ seems now to be reserved as the polite way to refer to copulation.)\nAmong the other clever gadgets I have glimpsed in the grammars of\nso-called primitive groups, the complex Cherokee pronoun system\nseems especially handy. It distinguishes among \"you and I,\" \"another\nperson and I,\" \"several other people and I,\" and \"you, one or more\nother persons, and I,\" which English crudely collapses into the allpurpose pronoun _we._\n\nActually, the people whose linguistic abilities are most badly underestimated are right here in our society. Linguists repeatedly run up\nagainst the myth that working-class people and the less educated\nmembers of the middle class speak a simpler or coarser language. This\nis a pernicious illusion arising from the effortlessness of conversation.\nOrdinary speech, like color vision or walking, is a paradigm of engineering excellence—a technology that works so well that the user\ntakes its outcome for granted, unaware of the complicated machinery\nhidden behind the panels. Behind such \"simple\" sentences as _Where_\n_did he go?_ and or _The guy I met killed himself,_ used automatically by\nany English speaker, are dozens of subroutines that arrange the words\nto express the meaning. Despite decades of effort, no artificially engineered language system comes close to duplicating the person in the\nstreet, HAL and C3PO notwithstanding."
    },
    {
        "document_id": "0",
        "parent_id": 29,
        "parent_text": "But though the language engine is invisible to the human user, the\ntrim packages and color schemes are attended to obsessively. Trifling\ndifferences between the dialect of the mainstream and the dialect of\nother groups, like _isn't any_ versus _ain't no, those books_ versus _them_\n_books,_ and _dragged him away_ versus _drug him away,_ are dignified as\nbadges of \"proper grammar.\" But they have no more to do with\ngrammatical sophistication than the fact that people in some regions\nof the United States refer to a certain insect as a _dragonfly_ and people\nin other regions refer to it as a _darning needle,_ or that English speakers\ncall canines _dogs_ whereas French speakers call them _chiens._ It is even\na bit misleading to call Standard English a \"language\" and these\nvariations \"dialects,\" as if there were some meaningful difference\nbetween them. The best definition comes from the linguist Max Weinreich: a language is a dialect with an army and a navy.\n\nThe myth that nonstandard dialects of English are grammatically\ndeficient is widespread. In the 1960s some well-meaning educational\npsychologists announced that American black children had been so\n\n\nChatterboxes **2 9**"
    },
    {
        "document_id": "0",
        "parent_id": 30,
        "parent_text": "The myth that nonstandard dialects of English are grammatically\ndeficient is widespread. In the 1960s some well-meaning educational\npsychologists announced that American black children had been so\n\n\nChatterboxes **2 9**\n\n\nculturally deprived that they lacked true language and were confined\ninstead to a \"non-logical mode of expressive behavior.\" The conclusions were based on the students' shy or sullen reactions to batteries\nof standardized tests. If the psychologists had listened to spontaneous\nconversations, they would have rediscovered the commonplace fact\nthat American black culture is everywhere highly verbal; the subculture of street youths in particular is famous in the annals of anthropology for the value placed on linguistic virtuosity. Here is an example,\nfrom an interview conducted by the linguist William Labov on a\nstoop in Harlem. The interviewee is Larry, the roughest member of\na teenage gang called the Jets. (Labov observes in his scholarly article\nthat \"for most readers of this paper, first contact with Larry would\nproduce some fairly negative reactions on both sides.\")\n\n\nYou know, like some people say if you're good an' shit, your spirit\ngoin' t'heaven . . . 'n' if you bad, your spirit goin' to hell. Well,\nbullshit! Your spirit goin' to hell anyway, good or bad.\n\n[Why?]\n\nWhy? I'll tell you why. 'Cause, you see, doesn' nobody really know\nthat it's a God, y'know, 'cause I mean I have seen black gods, white\ngods, all color gods, and don't nobody know it's really a God. An'\nwhen they be sayin' if you good, you goin' t'heaven, tha's bullshit,\n'cause you ain't goin' to no heaven, 'cause it ain't no heaven for you\nto go to.\n\n[. .. jus' suppose that there is a God, would he be white or black?]\n\nHe'd be white, man.\n\n[Why?]\n\nWhy? I'll tell you why. 'Cause the average whitey out here got\neverything, you dig? And the nigger ain't got shit, y'know? Y'understan'? So—um—for—in order for _that_ to happen, you know it ain't\nno black God that's doin' that bullshit."
    },
    {
        "document_id": "0",
        "parent_id": 31,
        "parent_text": "[. .. jus' suppose that there is a God, would he be white or black?]\n\nHe'd be white, man.\n\n[Why?]\n\nWhy? I'll tell you why. 'Cause the average whitey out here got\neverything, you dig? And the nigger ain't got shit, y'know? Y'understan'? So—um—for—in order for _that_ to happen, you know it ain't\nno black God that's doin' that bullshit.\n\n\nFirst contact with Larry's grammar may produce negative reactions\nas well, but to a linguist it punctiliously conforms to the rules of the\ndialect called Black English Vernacular (BEV). The most linguistically\ninteresting thing about the dialect is how linguistically uninteresting\nit is: if Labov did not have to call attention to it to debunk the claim\n\n\n**3 0** THE LANGUAGE INSTINCT\n\n\nthat ghetto children lack true linguistic competence, it would have\nbeen filed away as just another language. Where Standard American\nEnglish (SAE) uses _there_ as a meaningless dummy subject for the\ncopula, BEV uses _it_ as a meaningless dummy subject for the copula\n(compare SAE's _There's really a God_ with Larry's _It's really a God)._\nLarry's negative concord _(You ain't goin' to no heaven)_ is seen in\nmany languages, such as French _(ne . . . pas)._ Like speakers of SAE,\nLarry inverts subjects and auxiliaries in nondeclarative sentences, but\nthe exact set of the sentence types allowing inversion differs slightly.\nLarry and other BEV speakers invert subjects and auxiliaries in negative main clauses like _Don't nobody know;_ SAE speakers invert them\nonly in questions like _Doesn't anybody know?_ and a few other sentence\ntypes. BEV allows its speakers the option of deleting copulas _(If you_\n_bad);_ this is not random laziness but a systematic rule that is virtually\nidentical to the contraction rule in SAE that reduces _He is_ to _He's,_\n_You are_ to _You're,_ and _I am_ to _I'm._ In both dialects, _be_ can erode\nonly in certain kinds of sentences. No SAE speaker would try the\nfollowing contractions:"
    },
    {
        "document_id": "0",
        "parent_id": 32,
        "parent_text": "Yes he is! —> Yes he's!\nI don't care what you are. —> I don't care what you're.\nWho is it? Who's it?\n\n\nFor the same reasons, no BEV speaker would try the following deletions:\n\n\nYes he is! —> Yes he!\nI don't care what you are. —> I don't care what you.\nWho is it? —> Who it?\n\n\nNote, too, that BEV speakers are not just more prone to eroding\nwords. BEV speakers use the full forms of certain auxiliaries ( _I have_\n_seen),_ whereas SAE speakers usually contract them ( _I've seen_ ) _._ And\nas we would expect from comparisons between languages, there are\nareas in which BEV is more precise than standard English. _He be_\n_working_ means that he generally works, perhaps that he has a regular\njob; _He working_ means only that he is working at the moment that\nthe sentence is uttered. In SAE, _He is working_ fails to make that\ndistinction. Moreover, sentences like _In order for that to happen, you_\n\n\nChatterboxes **3 l**\n\n\n_know it ain't no black God that's doin' that bullshit_ show that Larry's\nspeech uses the full inventory of grammatical paraphernalia that computer scientists struggle unsuccessfully to duplicate (relative clauses,\ncomplement structures, clause subordination, and so on), not to mention some fairly sophisticated theological argumentation."
    },
    {
        "document_id": "0",
        "parent_id": 33,
        "parent_text": "Chatterboxes **3 l**\n\n\n_know it ain't no black God that's doin' that bullshit_ show that Larry's\nspeech uses the full inventory of grammatical paraphernalia that computer scientists struggle unsuccessfully to duplicate (relative clauses,\ncomplement structures, clause subordination, and so on), not to mention some fairly sophisticated theological argumentation.\n\nAnother project of Labov's involved tabulating the percentage of\ngrammatical sentences in tape recordings of speech in a variety of\nsocial classes and social settings. \"Grammatical,\" for these purposes,\nmeans \"well-formed according to consistent rules in the dialect of the\nspeakers.\" For example, if a speaker asked the question _Where are_\n_you going?,_ the respondent would not be penalized for answering To\n_the store,_ even though it is in some sense not a complete sentence.\nSuch ellipses are obviously part of the grammar of conversational\nEnglish; the alternative, _I am going to the store,_ sounds stilted and is\nalmost never used. \"Ungrammatical\" sentences, by this definition,\ninclude randomly broken-off sentence fragments, tongue-tied hemming and hawing, slips of the tongue, and other forms of word salad.\nThe results of Labov's tabulation are enlightening. The great majority\nof sentences were grammatical, especially in casual speech, with\nhigher percentages of grammatical sentences in working-class speech\nthan in middle-class speech. The highest percentage of ungrammatical\nsentences was found in the proceedings of learned academic conferences."
    },
    {
        "document_id": "0",
        "parent_id": 34,
        "parent_text": "The ubiquity of complex language among human beings is a gripping discovery and, for many observers, compelling proof that language is innate. But to tough-minded skeptics like the philosopher\nHilary Putnam, it is no proof at all. Not everything that is universal\nis innate. Just as travelers in previous decades never encountered a\ntribe without a language, nowadays anthropologists have trouble\nfinding a people beyond the reach of VCR's, Coca-Cola, and Bart\nSimpson T-shirts. Language was universal before Coca-Cola was, but\nthen, language is more useful than Coca-Cola. It is more like eating\nwith one's hands rather than one's feet, which is also universal, but\nwe need not invoke a special hand-to-mouth instinct to explain why.\nLanguage is invaluable for all the activities of daily living in a community of people: preparing food and shelter, loving, arguing, negotiating, teaching. Necessity being the mother of invention, language could\n\n\n**3 2** THE LANGUAGE INSTINCT\n\n\nhave been invented by resourceful people a number of times long\nago. (Perhaps, as Lily Tomlin said, man invented language to satisfy\nhis deep need to complain.) Universal grammar would simply reflect\nthe universal exigencies of human experience and the universal limitations on human information processing. All languages have words for\n\"water\" and \"foot\" because all people need to refer to water and\nfeet; no language has a word a million syllables long because no\nperson would have time to say it. Once invented, language would\nentrench itself within a culture as parents taught their children and\nchildren imitated their parents. From cultures that had language, it\nwould spread like wildfire to other, quieter cultures. At the heart of\nthis process is wondrously flexible human intelligence, with its general\nmultipurpose learning strategies."
    },
    {
        "document_id": "0",
        "parent_id": 35,
        "parent_text": "So the universality of language does not lead to an innate language\ninstinct as night follows day. To convince you that there is a language\ninstinct, I will have to fill in an argument that leads from the jabbering\nof modern peoples to the putative genes for grammar. The crucial\nintervening steps come from my own professional specialty, the study\nof language development in children. The crux of the argument is\nthat complex language is universal because _children actually reinvent_\n_it,_ generation after generation—not because they are taught, not\nbecause they are generally smart, not because it is useful to them, but\nbecause they just can't help it. Let me now take you down this trail\nof evidence.\n\n\nThe trail begins with the study of how the particular languages we\nfind in the world today arose. Here, one would think, linguistics runs\ninto the problem of any historical science: no one recorded the crucial\nevents at the time they happened. Although historical linguists can\ntrace modern complex languages back to earlier ones, this just pushes\nthe problem back a step; we need to see how people create a complex\nlanguage from scratch. Amazingly, we can.\n\nThe first cases were wrung from two of the more sorrowful episodes\nof world history, the Atlantic slave trade and indentured servitude in\nthe South Pacific. Perhaps mindful of the Tower of Babel, some of the\nmasters of tobacco, cotton, coffee, and sugar plantations deliberately\nmixed slaves and laborers from different language backgrounds; others preferred specific ethnicities but had to accept mixtures because\n\n\nChatterboxes **3 3**"
    },
    {
        "document_id": "0",
        "parent_id": 36,
        "parent_text": "The first cases were wrung from two of the more sorrowful episodes\nof world history, the Atlantic slave trade and indentured servitude in\nthe South Pacific. Perhaps mindful of the Tower of Babel, some of the\nmasters of tobacco, cotton, coffee, and sugar plantations deliberately\nmixed slaves and laborers from different language backgrounds; others preferred specific ethnicities but had to accept mixtures because\n\n\nChatterboxes **3 3**\n\n\nthat was all that was available. When speakers of different languages\nhave to communicate to carry out practical tasks but do not have the\nopportunity to learn one another's languages, they develop a makeshift jargon called a pidgin. Pidgins are choppy strings of words\nborrowed from the language of the colonizers or plantation owners,\nhighly variable in order and with little in the way of grammar. Sometimes a pidgin can become a lingua franca and gradually increase in\ncomplexity over decades, as in the \"Pidgin English\" of the modern\nSouth Pacific. (Prince Philip was delighted to learn on a visit to New\nGuinea that he is referred to in that language as _fella belong Mrs._\n_Queen.)_\n\nBut the linguist Derek Bickerton has presented evidence that in\nmany cases a pidgin can be transmuted into a full complex language\nin one fell swoop: all it takes is for a group of children to be exposed\nto the pidgin at the age when they acquire their mother tongue. That\nhappened, Bickerton has argued, when children were isolated from\ntheir parents and were tended collectively by a worker who spoke to\nthem in the pidgin. Not content to reproduce the fragmentary word\nstrings, the children injected grammatical complexity where none\nexisted before, resulting in a brand-new, richly expressive language.\nThe language that results when children make a pidgin their native\ntongue is called a creole."
    },
    {
        "document_id": "0",
        "parent_id": 37,
        "parent_text": "Bickerton's main evidence comes from a unique historical circumstance. Though the slave plantations that spawned most creoles are,\nfortunately, a thing of the remote past, one episode of creolization\noccurred recently enough for us to study its principal players. Just\nbefore the turn of the century there was a boom in Hawaiian sugar\nplantations, whose demands for labor quickly outstripped the native\npool. Workers were brought in from China, Japan, Korea, Portugal,\nthe Philippines, and Puerto Rico, and a pidgin quickly developed.\nMany of the immigrant laborers who first developed that pidgin were\nalive when Bickerton interviewed them in the 1970s. Here are some\ntypical examples of their speech:\n\n\nMe cape buy, me check make.\nBuilding—high place—wall pat—time—nowtime—an' den\n\n—a new tempecha eri time show you.\nGood, dis one. Kaukau any-kin' dis one. Pilipine islan' no\n\ngood. No mo money.\n\n\n**3 4** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 38,
        "parent_text": "Me cape buy, me check make.\nBuilding—high place—wall pat—time—nowtime—an' den\n\n—a new tempecha eri time show you.\nGood, dis one. Kaukau any-kin' dis one. Pilipine islan' no\n\ngood. No mo money.\n\n\n**3 4** THE LANGUAGE INSTINCT\n\n\nFrom the individual words and the context, it was possible for the\nlistener to infer that the first speaker, a ninety-two-year-old Japanese\nimmigrant talking about his earlier days as a coffee farmer, was trying\nto say \"He bought my coffee; he made me out a check.\" But the\nutterance itself could just as easily have meant \"I bought coffee; I made\nhim out a check,\" which would have been appropriate if he had been\nreferring to his current situation as a store owner. The second speaker,\nanother elderly Japanese immigrant, had been introduced to the wonders\nof civilization in Los Angeles by one of his many children, and was\nsaying that there was an electric sign high up on the wall of the building\nwhich displayed the time and temperature. The third speaker, a sixtynine-year-old Filipino, was saying \"It's better here than in the Philippines; here you can get all kinds of food, but over there there isn't any\nmoney to buy food with.\" (One of the kinds of food was \"pfrawg,\"\nwhich he caught for himself in the marshes by the method of \"kank da\nhead.\") In all these cases, the speaker's intentions had to be filled in by\nthe listener. The pidgin did not offer the speakers the ordinary grammatical resources to convey these messages—no consistent word order, no\nprefixes or suffixes, no tense or other temporal and logical markers, no\nstructure more complex than a simple clause, and no consistent way to\nindicate who did what to whom."
    },
    {
        "document_id": "0",
        "parent_id": 39,
        "parent_text": "But the children who had grown up in Hawaii beginning in the\n1890s and were exposed to the pidgin ended up speaking quite\ndifferently. Here are some sentences from the language they invented,\nHawaiian Creole. The first two are from a Japanese papaya grower\nborn in Maui; the next two, from a Japanese/Hawaiian ex-plantation\nlaborer born on the big island; the last, from a Hawaiian motel\nmanager, formerly a farmer, born in Kauai:\n\n\nDa firs japani came ran away from japan come.\n\"The first Japanese who arrived ran away from Japan to\nhere.\"\n\nSome filipino wok o'he-ah dey wen' couple ye-ahs in filipin\nislan'.\n\"Some Filipinos who worked over here went back to the\nPhilippines for a couple of years.\"\n\nPeople no like t'come fo' go wok.\n\"People don't want to have him go to work [for them].\"\n\n\nChatterboxes **3 5**\n\n\nOne time when we go home inna night dis ting stay fly up.\n\"Once when we went home at night this thing was flying\nabout.\"\n\nOne day had pleny of dis mountain fish come down.\n\"One day there were a lot of these fish from the mountains\nthat came down [the river].\"\n\n\nDo not be misled by what look like crudely placed English verbs,\nsuch as _go, stay,_ and _came,_ or phrases like _one time._ They are not\nhaphazard uses of English words but systematic uses of Hawaiian\nCreole grammar: the words have been converted by the Creole speakers into auxiliaries, prepositions, case markers, and relative pronouns.\nIn fact, this is probably how many of the grammatical prefixes and\nsuffixes in established languages arose. For example, the English pasttense ending _-ed_ may have evolved from the verb _do: He hammered_\nwas originally something like _He hammer-did._ Indeed, Creoles _are_\nbona fide languages, with standardized word orders and grammatical\nmarkers that were lacking in the pidgin of the immigrants and, aside\nfrom the sounds of words, not taken from the language of the colonizers."
    },
    {
        "document_id": "0",
        "parent_id": 40,
        "parent_text": "Bickerton notes that if the grammar of a creole is largely the product\nof the minds of children, unadulterated by complex language input\nfrom their parents, it should provide a particularly clear window on\nthe innate grammatical machinery of the brain. He argues that Creoles\nfrom unrelated language mixtures exhibit uncanny resemblances—\nperhaps even the same basic grammar. This basic grammar also shows\nup, he suggests, in the errors children make when acquiring more\nestablished and embellished languages, like some underlying design\nbleeding through a veneer of whitewash. When English-speaking\nchildren say\n\n\nWhy he is leaving?\nNobody don't likes me.\nI'm gonna full Angela's bucket.\nLet Daddy hold it hit it,\n\n\nthey are unwittingly producing sentences that are grammatical in\nmany of the world's Creoles.\nBickerton's particular claims are controversial, depending as\n\n\n**3 6** THE LANGUAGE INSTINCT\n\n\nthey do on his reconstruction of events that occurred decades\nor centuries in the past. But his basic idea has been stunningly\ncorroborated by two recent natural experiments in which creolization by children can be observed in real time. These fascinating\ndiscoveries are among many that have come from the study of the\nsign languages of the deaf. Contrary to popular misconceptions,\nsign languages are not pantomimes and gestures, inventions of\neducators, or ciphers of the spoken language of the surrounding\ncommunity. They are found wherever there is a community of deaf\npeople, and each one is a distinct, full language, using the same\nkinds of grammatical machinery found worldwide in spoken languages. For example, American Sign Language, used by the deaf\ncommunity in the United States, does not resemble English, or\nBritish Sign Language, but relies on agreement and gender systems\nin a way that is reminiscent of Navajo and Bantu."
    },
    {
        "document_id": "0",
        "parent_id": 41,
        "parent_text": "Until recently there were no sign languages at all in Nicaragua,\nbecause its deaf people remained isolated from one another. When\nthe Sandinista government took over in 1979 and reformed the educational system, the first schools for the deaf were created. The schools\nfocused on drilling the children in lip reading and speech, and as in\nevery case where that is tried, the results were dismal. But it did\nnot matter. On the playgrounds and schoolbuses the children were\ninventing their own sign system, pooling the makeshift gestures that\nthey used with their families at home. Before long the system congealed into what is now called the Lenguaje de Signos Nicaraguense\n(LSN). Today LSN is used, with varying degrees of fluency, by young\ndeaf adults, aged seventeen to twenty-five, who developed it when\nthey were ten or older. Basically, it is a pidgin. Everyone uses it\ndifferently, and the signers depend on suggestive, elaborate circumlocutions rather than on a consistent grammar.\n\nBut children like Mayela, who joined the school around the age of\nfour, when LSN was already around, and all the pupils younger than\nher, are quite different. Their signing is more fluid and compact, and\nthe gestures are more stylized and less like a pantomime. In fact,\nwhen their signing is examined close up, it is so different from LSN\nthat it is referred to by a different name, Idioma de Signos Nicaraguense (ISN). LSN and ISN are currently being studied by the psycholinguists Judy Kegl, Miriam Hebe Lopez, and Annie Senghas. ISN\nappears to be a creole, created in one leap when the younger children\n\n\nChatterboxes **3 7**"
    },
    {
        "document_id": "0",
        "parent_id": 42,
        "parent_text": "Chatterboxes **3 7**\n\n\nwere exposed to the pidgin signing of the older children—just as\nBickerton would have predicted. ISN has spontaneously standardized\nitself; all the young children sign it in the same way. The children\nhave introduced many grammatical devices that were absent in LSN,\nand hence they rely far less on circumlocutions. For example, an LSN\n(pidgin) signer might make the sign for \"talk to\" and then point from\nthe position of the talker to the position of the hearer. But an ISN\n(creole) signer modifies the sign itself, sweeping it in one motion from\na point representing the talker to a point representing the hearer.\nThis is a common device in sign languages, formally identical to\ninflecting a verb for agreement in spoken languages. Thanks to such\nconsistent grammar, ISN is very expressive. A child can watch a\nsurrealistic cartoon and describe its plot to another child. The children use it in jokes, poems, narratives, and life histories, and it is\ncoming to serve as the glue that holds the community together. A\nlanguage has been born before our eyes.\n\nBut ISN was the collective product of many children communicating with one another. If we are to attribute the richness of language\nto the mind of the child, we really want to see a single child adding\nsome increment of grammatical complexity to the input the child has\nreceived. Once again the study of the deaf grants our wish."
    },
    {
        "document_id": "0",
        "parent_id": 43,
        "parent_text": "But ISN was the collective product of many children communicating with one another. If we are to attribute the richness of language\nto the mind of the child, we really want to see a single child adding\nsome increment of grammatical complexity to the input the child has\nreceived. Once again the study of the deaf grants our wish.\n\nWhen deaf infants are raised by signing parents, they learn sign\nlanguage in the same way that hearing infants learn spoken language.\nBut deaf children who are not born to deaf parents—the majority of\ndeaf children—often have no access to sign language users as they\ngrow up, and indeed are sometimes deliberately kept from them by\neducators in the \"oralist\" tradition who want to force them to master\nlip reading and speech. (Most deaf people deplore these authoritarian\nmeasures.) When deaf children become adults, they tend to seek out\ndeaf communities and begin to acquire the sign language that takes\nproper advantage of the communicative media available to them. But\nby then it is usually too late; they must then struggle with sign language as a difficult intellectual puzzle, much as a hearing adult does\nin foreign language classes. Their proficiency is notably below that of\ndeaf people who acquired sign language as infants, just as adult\nimmigrants are often permanently burdened with accents and conspicuous grammatical errors. Indeed, because the deaf are virtually\nthe only neurologically normal people who make it to adulthood\nwithout having acquired a language, their difficulties offer particularly\n\n\n**3 8** THE LANGUAGE INSTINCT\n\n\ngood evidence that successful language acquisition must take place\nduring a critical window of opportunity in childhood."
    },
    {
        "document_id": "0",
        "parent_id": 44,
        "parent_text": "The psycholinguists Jenny Singleton and Elissa Newport have studied a nine-year-old profoundly deaf boy, to whom they gave the\npseudonym Simon, and his parents, who are also deaf. Simon's parents did not acquire sign language until the late ages of fifteen and\nsixteen, and as a result they acquired it badly. In ASL, as in many\nlanguages, one can move a phrase to the front of a sentence and mark\nit with a prefix or suffix (in ASL, raised eyebrows and a lifted chin)\nto indicate that it is the topic of the sentence. The English sentence\n_Elvis I really like_ is a rough equivalent. But Simon's parents rarely\nused this construction and mangled it when they did. For example,\nSimon's father once tried to sign the thought _My friend, he thought_\n_my second child was deaf._ It came out as _My friend thought, my second_\n_child, he thought he was deaf_ —a bit of sign salad that violates not\nonly ASL grammar but, according to Chomsky's theory, the Universal\nGrammar that governs all naturally acquired human languages (later\nin this chapter we will see why). Simon's parents had also failed to\ngrasp the verb inflection system of ASL. In ASL, the verb _to blow_ is\nsigned by opening a fist held horizontally in front of the mouth (like\na puff of air). Any verb in ASL can be modified to indicate that the\naction is being done continuously: the signer superimposes an arclike\nmotion on the sign and repeats it quickly. A verb can also be modified\nto indicate that the action is being done to more than one object\n(for example, several candles): the signer terminates the sign in one\nlocation in space, then repeats it but terminates it at another location.\nThese inflections can be combined in either of two orders: _blow_\ntoward the left and then toward the right and repeat, or _blow_ toward\nthe left twice and then _blow_ toward the right twice. The first order\nmeans \"to blow out the candles on one cake, then another cake, then\nthe first cake again, then the second cake again\"; the second means"
    },
    {
        "document_id": "0",
        "parent_id": 45,
        "parent_text": "(for example, several candles): the signer terminates the sign in one\nlocation in space, then repeats it but terminates it at another location.\nThese inflections can be combined in either of two orders: _blow_\ntoward the left and then toward the right and repeat, or _blow_ toward\nthe left twice and then _blow_ toward the right twice. The first order\nmeans \"to blow out the candles on one cake, then another cake, then\nthe first cake again, then the second cake again\"; the second means\n\"to blow out the candles on one cake continuously, and then blow\nout the candles on another cake continuously.\" This elegant set of\nrules was lost on Simon's parents. They used the inflections inconsistently and never combined them onto a verb two at a time, though\nthey would occasionally use the inflections separately, crudely linked\nwith signs like _then._ In many ways Simon's parents were like pidgin\nspeakers."
    },
    {
        "document_id": "0",
        "parent_id": 46,
        "parent_text": "Chatterboxes 39\n\n\nAstoundingly, though Simon saw no ASL but his parents' defective\nversion, his own signing was far better ASL than theirs. He understood sentences with moved topic phrases without difficulty, and\nwhen he had to describe complex videotaped events, he used the\nASL verb inflections almost perfectly, even in sentences requiring two\nof them in particular orders. Simon must somehow have shut out his\nparents' ungrammatical \"noise.\" He must have latched on to the\ninflections that his parents used inconsistently, and reinterpreted\nthem as mandatory. And he must have seen the logic that was implicit,\nthough never realized, in his parents' use of two kinds of verb inflection, and reinvented the ASL system of superimposing both of them\nonto a single verb in a specific order. Simon's superiority to his\nparents is an example of creolization by a single living child.\n\nActually, Simon's achievements are remarkable only because he is\nthe first one who showed them to a psycholinguist. There must be\nthousands of Simons: ninety to ninety-five percent of deaf children\nare born to hearing parents. Children fortunate enough to be exposed\nto ASL at all often get it from hearing parents who themselves learned\nit, incompletely, to communicate with their children. Indeed, as the\ntransition from LSN to ISN shows, sign languages themselves are\nsurely products of creolization. Educators at various points in history\nhave tried to invent sign systems, sometimes based on the surrounding\nspoken language. But these crude codes are always unlearnable, and\nwhen deaf children learn from them at all, they do so by converting\nthem into much richer natural languages.\n\n\nExtraordinary acts of creation by children do not require the extraordinary circumstances of deafness or plantation Babels. The same\nkind of linguistic genius is involved every time a child learns his or\nher mother tongue."
    },
    {
        "document_id": "0",
        "parent_id": 47,
        "parent_text": "Extraordinary acts of creation by children do not require the extraordinary circumstances of deafness or plantation Babels. The same\nkind of linguistic genius is involved every time a child learns his or\nher mother tongue.\n\nFirst, let us do away with the folklore that parents teach their\nchildren language. No one supposes that parents provide explicit\ngrammar lessons, of course, but many parents (and some child psychologists who should know better) think that mothers provide children with implicit lessons. These lessons take the form of a special\nspeech variety called Motherese (or, as the French call it, Mamanaise):\nintensive sessions of conversational give-and-take, with repetitive\n\n\n**4 0** THE LANGUAGE INSTINCT\n\n\ndrills and simplified grammar. (\"Look at the _doggie!_ See the _doggie?_\nThere's a _doggie!\")_ In contemporary middle-class American culture,\nparenting is seen as an awesome responsibility, an unforgiving vigil\nto keep the helpless infant from falling behind in the great race of\nlife. The belief that Motherese is essential to language development\nis part of the same mentality that sends yuppies to \"learning centers\"\nto buy little mittens with bull's-eyes to help their babies find their\nhands sooner."
    },
    {
        "document_id": "0",
        "parent_id": 48,
        "parent_text": "drills and simplified grammar. (\"Look at the _doggie!_ See the _doggie?_\nThere's a _doggie!\")_ In contemporary middle-class American culture,\nparenting is seen as an awesome responsibility, an unforgiving vigil\nto keep the helpless infant from falling behind in the great race of\nlife. The belief that Motherese is essential to language development\nis part of the same mentality that sends yuppies to \"learning centers\"\nto buy little mittens with bull's-eyes to help their babies find their\nhands sooner.\n\nOne gets some perspective by examining the folk theories about\nparenting in other cultures. The !Kung San of the Kalahari Desert in\nsouthern Africa believe that children must be drilled to sit, stand,\nand walk. They carefully pile sand around their infants to prop them\nupright, and sure enough, every one of these infants soon sits up on\nits own. We find this amusing because we have observed the results\nof the experiment that the San are unwilling to chance: we don't\nteach our children to sit, stand, and walk, and they do it anyway, on\ntheir own schedule. But other groups enjoy the same condescension\ntoward us. In many communities of the world, parents do not indulge\ntheir children in Motherese. In fact, they do not speak to their prelinguistic children at all, except for occasional demands and rebukes.\nThis is not unreasonable. After all, young children plainly can't understand a word you say. So why waste your breath in soliloquies? Any\nsensible person would surely wait until a child has developed speech\nand more gratifying two-way conversations become possible. As Aunt\nMae, a woman living in the South Carolina Piedmont, explained to\nthe anthropologist Shirley Brice Heath: \"Now just how crazy is dat?\nWhite folks uh hear dey kids say sump'n, dey say it back to 'em, dey\naks 'em 'gain and 'gain 'bout things, like they 'posed to be born\nknowin'.\" Needless to say, the children in these communities, overhearing adults and other children, learn to talk, as we see in Aunt\nMae's fully grammatical BEV."
    },
    {
        "document_id": "0",
        "parent_id": 49,
        "parent_text": "Children deserve most of the credit for the language they acquire.\nIn fact, we can show that they know things they could not have been\ntaught. One of Chomsky's classic illustrations of the logic of language\ninvolves the process of moving words around to form questions.\nConsider how you might turn the declarative sentence _A unicorn is_\n_in the garden_ into the corresponding question, _Is a unicorn in the_\n_garden?_ You could scan the declarative sentence, take the auxiliary\n_is,_ and move it to the front of the sentence:\n\n\nChatterboxes **4 1**\n\n\na unicorn is in the garden. —>\nis a unicorn in the garden?\n\n\nNow take the sentence _A unicorn that is eating a flower is in the_\n_garden._ There are two _is's._ Which gets moved? Obviously, not the\nfirst one hit by the scan; that would give you a very odd sentence:\n\n\na unicorn that is eating a flower is in the garden. —>\nis a unicorn that eating a flower is in the garden?\n\n\nBut why can't you move that _is)_ Where did the simple procedure go\nwrong? The answer, Chomsky noted, comes from the basic design of\nlanguage. Though sentences are strings of words, our mental algorithms for grammar do not pick out words by their linear positions,\nsuch as \"first word,\" \"second word,\" and so on. Rather, the algorithms group words into phrases, and phrases into even bigger\nphrases, and give each one a mental label, like \"subject noun phrase\"\nor \"verb phrase.\" The real rule for forming questions does not look\nfor the first occurrence of the auxiliary word as one goes from left to\nright in the string; it looks for the auxiliary that comes after the phrase\nlabeled as the subject. This phrase, containing the entire string of\nwords _a unicorn that is eating a flower,_ behaves as a single unit. The\nfirst _is_ sits deeply buried in it, invisible to the question-forming rule.\nThe second _is,_ coming immediately after this subject noun phrase, is\nthe one that is moved:\n\n\n[a unicorn that is eating a flower] is in the garden. —>\nis [a unicorn that is eating a flower] in the garden?"
    },
    {
        "document_id": "0",
        "parent_id": 50,
        "parent_text": "[a unicorn that is eating a flower] is in the garden. —>\nis [a unicorn that is eating a flower] in the garden?\n\n\nChomsky reasoned that if the logic of language is wired into children, then the first time they are confronted with a sentence with two\nauxiliaries they should be capable of turning it into a question with\nthe proper wording. This should be true even though the wrong rule,\nthe one that scans the sentence as a linear string of words, is simpler\nand presumably easier to learn. And it should be true even though\nthe sentences that would teach children that the linear rule is wrong\nand the structure-sensitive rule is right—questions with a second\nauxiliary embedded inside the subject phrase—are so rare as to be\nnonexistent in Motherese. Surely not every child learning English has\n\n\n**4 2** THE LANGUAGE INSTINCT\n\n\nheard Mother say _Is the doggie that is eating the flower in the garden?_\nFor Chomsky, this kind of reasoning, which he calls \"the argument\nfrom the poverty of the input,\" is the primary justification for saying\nthat the basic design of language is innate.\n\nChomsky's claim was tested in an experiment with three-, four-,\nand five-year-olds at a daycare center by the psycholinguists Stephen\nCrain and Mineharu Nakayama. One of the experimenters controlled\na doll of Jabba the Hutt, of _Star Wars_ fame. The other coaxed the\nchild to ask a set of questions, by saying, for example, \"Ask Jabba if\nthe boy who is unhappy is watching Mickey Mouse.\" Jabba would\ninspect a picture and answer yes or no, but it was really the child who\nwas being tested, not Jabba. The children cheerfully provided the\nappropriate questions, and, as Chomsky would have predicted, not a\nsingle one of them came up with an ungrammatical string like _Is the_\n_boy who unhappy is watching Mickey Mouse?,_ which the simple linear\nrule would have produced."
    },
    {
        "document_id": "0",
        "parent_id": 51,
        "parent_text": "Now, you may object that this does not show that children's brains\nregister the subject of a sentence. Perhaps the children were just going\nby the meanings of the words. _The man who is running_ refers to a\nsingle actor playing a distinct role in the picture, and children could\nhave been keeping track of which words are about particular actors,\nnot which words belong to the subject noun phrase. But Crain and\nNakayama anticipated the objection. Mixed into their list were commands like \"Ask Jabba if it is raining in this picture.\" The _it_ of the\nsentence, of course, does not refer to anything; it is a dummy element\nthat is there only to satisfy the rules of syntax, which demand a\nsubject. But the English question rule treats it just like any other\nsubject: _Is it raining?_ Now, how do children cope with this meaningless placeholder? Perhaps they are as literal-minded as the Duck in\n_Alice's Adventures in Wonderland:_\n\n\n\"I proceed [said the Mouse]. 'Edwin and Morcar, the earls of\nMercia and Northumbria, declared for him; and even Stigand, the\npatriotic archbishop of Canterbury, found it advisable—' \"\n\"Found _what?\"_ said the Duck.\n\"Found _it,\"_ the Mouse replied rather crossly: \"of course you\nknow what 'it' means.\"\n\n\"I know what 'it' means well enough, when _I_ find a thing,\" said\n\n\n**Chatterboxes** **4 3**\n\n\nthe Duck: \"it's generally a frog, or a worm. The question is, what\ndid the archbishop find?\"\n\n\nBut children are not ducks. Crain and Nakayama's children replied,\n_Is it raining in this picture?_ Similarly, they had no trouble forming questions with other dummy subjects, as in \"Ask Jabba if there\nis a snake in this picture,\" or with subjects that are not things,\nas in \"Ask Jabba if running is fun\" and \"Ask Jabba if love is good\nor bad.\""
    },
    {
        "document_id": "0",
        "parent_id": 52,
        "parent_text": "**Chatterboxes** **4 3**\n\n\nthe Duck: \"it's generally a frog, or a worm. The question is, what\ndid the archbishop find?\"\n\n\nBut children are not ducks. Crain and Nakayama's children replied,\n_Is it raining in this picture?_ Similarly, they had no trouble forming questions with other dummy subjects, as in \"Ask Jabba if there\nis a snake in this picture,\" or with subjects that are not things,\nas in \"Ask Jabba if running is fun\" and \"Ask Jabba if love is good\nor bad.\"\n\nThe universal constraints on grammatical rules also show that the\nbasic form of language cannot be explained away as the inevitable\noutcome of a drive for usefulness. Many languages, widely scattered\nover the globe, have auxiliaries, and like English, many languages\nmove the auxiliary to the front of the sentence to form questions and\nother constructions, always in a structure-dependent way. But this is\nnot the only way one could design a question rule. One could just as\neffectively move the leftmost auxiliary in the string to the front, or\nflip the first and last words, or utter the entire sentence in mirrorreversed order (a trick that the human mind is capable of; some\npeople learn to talk backwards to amuse themselves and amaze their\nfriends). The particular ways that languages do form questions are\narbitrary, species-wide conventions; we don't find them in artificial\nsystems like computer programming languages or the notation of\nmathematics. The universal plan underlying languages, with auxiliaries and inversion rules, nouns and verbs, subjects and objects,\nphrases and clauses, case and agreement, and so on, seems to suggest\na commonality in the brains of speakers, because many other plans\nwould have been just as useful. It is as if isolated inventors miraculously came up with identical standards for typewriter keyboards or\nMorse code or traffic signals."
    },
    {
        "document_id": "0",
        "parent_id": 53,
        "parent_text": "Evidence corroborating the claim that the mind contains blueprints\nfor grammatical rules comes, once again, out of the mouths of babes\nand sucklings. Take the English agreement suffix _-s_ as in _He walks._\nAgreement is an important process in many languages, but in modern\nEnglish it is superfluous, a remnant of a richer system that flourished\nin Old English. If it were to disappear entirely, we would not miss it,\nany more than we miss the similar _-est_ suffix in _Thou sayest._ But\npsychologically speaking, this frill does not come cheap. Any speaker\n\n\n**4 4** THE LANGUAGE INSTINCT\n\n\ncommitted to using it has to keep track of four details in every\nsentence uttered:\n\n\n   - whether the subject is in the third person or not: _He walks_\n\nversus _I walk._\n\n   - whether the subject is singular or plural: _He walks_ versus\n\n_They walk._\n\n   - whether the action is present tense or not: _He walks_ versus\n\n_He walked._\n\n   - whether the action is habitual or going on at the moment\n\nof speaking (its \"aspect\"): _He walks to school_ versus _He_\n_is walking to school._\n\n\nAnd all this work is needed just to use the suffix once one has learned\nit. To learn it in the first place, a child must (1) notice that verbs end\nin _-s_ in some sentences but appear bare-ended in others, (2) begin a\nsearch for the grammatical causes of this variation (as opposed to just\naccepting it as part of the spice of life), and (3) not rest until those\ncrucial factors—tense, aspect, and the number and person of the\nsubject of the sentence—have been sifted out of the ocean of conceivable but irrelevant factors (like the number of syllables of the final\nword in the sentence, whether the object of a preposition is natural\nor man-made, and how warm it is when the sentence is uttered). Why\nwould anyone bother?"
    },
    {
        "document_id": "0",
        "parent_id": 54,
        "parent_text": "But little children do bother. By the age of three and a half or\nearlier, they use the _-s_ agreement suffix in more than ninety percent\nof the sentences that require it, and virtually never use it in the\nsentences that forbid it. This mastery is part of their grammar explosion, a period of several months in the third year of life during which\nchildren suddenly begin to speak in fluent sentences, respecting most\nof the fine points of their community's spoken language. For example,\na preschooler with the pseudonym Sarah, whose parents had only a\nhigh school education, can be seen obeying the English agreement\nrule, useless though it is, in complex sentences like the following:\n\n\nWhen my mother _hangs_ clothes, do you let 'em rinse out in\nrain?\nDonna _teases_ all the time and Donna has false teeth.\nI know what a big chicken _looks_ like.\n\n\n**Chatterboxes** **4 5**\n\n\nAnybody _knows_ how to scribble.\nHey, this part _goes_ where this one is, stupid.\nWhat _comes_ after \"C\"?\nIt _looks_ like a donkey face.\nThe person _takes_ care of the animals in the barn.\nAfter it _dries_ off then you can make the bottom.\nWell, someone _hurts_ hisself and everything.\nHis tail _sticks_ out like this.\nWhat _happens_ if ya press on this hard?\nDo you have a real baby that _says_ googoo gaga?\n\n\nJust as interestingly, Sarah could not have been simply imitating her\nparents, memorizing verbs with the _-s'_ s pre-attached. Sarah sometimes\nuttered word forms that she could not possibly have heard from her\nparents:\n\n\nWhen she _he's_ in the kindergarten . . .\nHe's a boy so he _gots_ a scary one. [costume]\nShe _do's_ what her mother tells her.\n\n\nShe must, then, have created these forms herself, using an unconscious version of the English agreement rule. The very concept of\nimitation is suspect to begin with (if children are general imitators,\nwhy don't they imitate their parents' habit of sitting quietly in airplanes?), but sentences like these show clearly that language acquisition cannot be explained as a kind of imitation."
    },
    {
        "document_id": "0",
        "parent_id": 55,
        "parent_text": "She must, then, have created these forms herself, using an unconscious version of the English agreement rule. The very concept of\nimitation is suspect to begin with (if children are general imitators,\nwhy don't they imitate their parents' habit of sitting quietly in airplanes?), but sentences like these show clearly that language acquisition cannot be explained as a kind of imitation.\n\n\nOne step remains to complete the argument that language is a\nspecific instinct, not just the clever solution to a problem thought up\nby a generally brainy species. If language is an instinct, it should have\nan identifiable seat in the brain, and perhaps even a special set of\ngenes that help wire it into place. Disrupt these genes or neurons,\nand language should suffer while the other parts of intelligence carry\non; spare them in an otherwise damaged brain, and you should have\na retarded individual with intact language, a linguistic idiot savant.\nIf, on the other hand, language is just the exercise of human smarts,\nwe might expect that injuries and impairments would make people\nstupider across the board, including their language. The only pattern\n\n\n**4 6** THE LANGUAGE INSTINCT\n\n\nwe would expect is that the more brain tissue that is damaged, the\nduller and less articulate the person should be.\n\nNo one has yet located a language organ or a grammar gene, but\nthe search is on. There are several kinds of neurological and genetic\nimpairments that compromise language while sparing cognition and\nvice versa. One of them has been known for over a century, perhaps\nfor millennia. When there is damage to certain circuits in the lower\nparts of the frontal lobe of the brain's left hemisphere—say, from a\nstroke or bullet wound—the person often suffers from a syndrome\ncalled Broca's aphasia. One of these victims, who eventually recovered\nhis language ability, recalls the event, which he experienced with\ncomplete lucidity:"
    },
    {
        "document_id": "0",
        "parent_id": 56,
        "parent_text": "When I woke up I had a bit of a headache and thought I must have\nbeen sleeping with my right arm under me because it felt all pinsand-needly and numb and I couldn't make it do what I wanted. I\ngot out of bed but I couldn't stand; as a matter of fact I actually\nfell on the floor because my right leg was too weak to take my\nweight. I called out to my wife in the next room and no sound\ncame—I couldn't speak. . . . I was astonished, horrified. I couldn't\nbelieve that this was happening to me and I began to feel bewildered\nand frightened and then I suddenly realized that I must have had a\nstroke. In a way this rationalization made me feel somewhat relieved\nbut not for long because I had always thought that the effects of a\nstroke were permanent in every case. . . . I found I could speak a\nlittle but even to me the words seemed wrong and not what I meant\nto say.\n\n\nAs this writer noted, most stroke victims are not as lucky. Mr. Ford\nwas a Coast Guard radio operator when he suffered a stroke at the\nage of thirty-nine. The neuropsychologist Howard Gardner interviewed him three months later. Gardner asked him about his work\nbefore he entered the hospital.\n\n\n\"I'm a sig .. . no .. . man . . . uh, well,. . . again.\" These words\nwere emitted slowly, and with great effort. The sounds were not\nclearly articulated; each syllable was uttered harshly, explosively, in\na throaty voice....\n\n\nChatterboxes **4 7**\n\n\n\"Let me help you,\" I interjected. \"You were a signal . . . \"\n\"A sig-nal man . . . right,\" Ford completed my phrase triumphantly.\n\n\"Were you in the Coast Guard?\"\n\"No, er, yes, yes . . . ship . . . Massachu . . . chusetts . . . Coastguard . . . years.\" He raised his hands twice, indicating the number\n\"nineteen.\""
    },
    {
        "document_id": "0",
        "parent_id": 57,
        "parent_text": "Chatterboxes **4 7**\n\n\n\"Let me help you,\" I interjected. \"You were a signal . . . \"\n\"A sig-nal man . . . right,\" Ford completed my phrase triumphantly.\n\n\"Were you in the Coast Guard?\"\n\"No, er, yes, yes . . . ship . . . Massachu . . . chusetts . . . Coastguard . . . years.\" He raised his hands twice, indicating the number\n\"nineteen.\"\n\n\"Oh, you were in the Coast Guard for nineteen years.\"\n\"Oh . . . boy . . . right . . . right,\" he replied.\n\"Why are you in the hospital, Mr. Ford?\"\nFord looked at me a bit strangely, as if to say, Isn't it patently\nobvious? He pointed to his paralyzed arm and said, \"Arm no good,\"\nthen to his mouth and said, \"Speech . . . can't say . . . talk, you see.\"\n\n\"What happened to you to make you lose your speech?\"\n\"Head, fall, Jesus Christ, me no good, str, str . . . oh Jesus . . .\nstroke.\"\n\n\"I see. Could you tell me, Mr. Ford, what you've been doing in\nthe hospital?\"\n\n\"Yes, sure. Me go, er, uh, P.T. nine o'cot, speech . . . two times\n. . . read . . . wr . . . ripe, er, rike, er, write . . . practice . . . get-ting\nbetter.\"\n\n\"And have you been going home on weekends?\"\n\"Why, yes . . . Thursday, er, er, er, no, er, Friday . . . Bar-ba-ra\n.. . wife . . . and, oh, car . . . drive . . . purnpike . . . you know . . .\nrest and . . . tee-vee.\"\n\n\"Are you able to understand everything on television?\"\n\"Oh, yes, yes .. . well . . . al-most.\""
    },
    {
        "document_id": "0",
        "parent_id": 58,
        "parent_text": "\"Yes, sure. Me go, er, uh, P.T. nine o'cot, speech . . . two times\n. . . read . . . wr . . . ripe, er, rike, er, write . . . practice . . . get-ting\nbetter.\"\n\n\"And have you been going home on weekends?\"\n\"Why, yes . . . Thursday, er, er, er, no, er, Friday . . . Bar-ba-ra\n.. . wife . . . and, oh, car . . . drive . . . purnpike . . . you know . . .\nrest and . . . tee-vee.\"\n\n\"Are you able to understand everything on television?\"\n\"Oh, yes, yes .. . well . . . al-most.\"\n\n\nObviously Mr. Ford had to struggle to get speech out, but his\nproblems were not in controlling his vocal muscles. He could blow\nout a candle and clear his throat, and he was as linguistically hobbled\nwhen he wrote as when he spoke. Most of his handicaps centered\naround grammar itself. He omitted endings like _-ed_ and _-s_ and grammatical function words like _or, be,_ and _the,_ despite their high frequency in the language. When reading aloud, he skipped over the\nfunction words, though he successfully read content words like _bee_\nand _oar_ that had the same sounds. He named objects and recognized\ntheir names extremely well. He understood questions when their gist\ncould be deduced from their content words, such as \"Does a stone\n\n\n**4 8** THE LANGUAGE INSTINCT\n\n\nfloat on water?\" or \"Do you use a hammer for cutting?,\" but not\nones that required grammatical analysis, like \"The lion was killed by\nthe tiger; which one is dead?\"\n\nDespite Mr. Ford's grammatical impairment, he was clearly in\ncommand of his other faculties. Gardner notes: \"He was alert, attentive, and fully aware of where he was and why he was there. Intellectual functions not closely tied to language, such as knowledge of right\nand left, ability to draw with the left (unpracticed) hand, to calculate,\nread maps, set clocks, make constructions, or carry out commands,\nwere all preserved. His Intelligence Quotient in nonverbal areas was\nin the high average range.\" Indeed, the dialogue shows that Mr. Ford,\nlike many Broca's aphasics, showed an acute understanding of his\nhandicap."
    },
    {
        "document_id": "0",
        "parent_id": 59,
        "parent_text": "Injuries in adulthood are not the only ways that the circuitry underlying language can be compromised. A few otherwise healthy children\njust fail to develop language on schedule. When they do begin to talk,\nthey have difficulty articulating words, and though their articulation\nimproves with age, the victims persist in a variety of grammatical\nerrors, often into adulthood. When obvious nonlinguistic causes are\nruled out—cognitive disorders like retardation, perceptual disorders\nlike deafness, and social disorders like autism—the children are given\nthe accurate but not terribly helpful diagnostic label Specific Language Impairment (SLI).\n\nLanguage therapists, who are often called upon to treat several\nmembers in a family, have long been under the impression that SLI\nis hereditary. Recent statistical studies show that the impression may\nbe correct. SLI runs in families, and if one member of a set of identical\ntwins has it, the odds are very high that the other will, too. Particularly\ndramatic evidence comes from one British family, the K's, recently\nstudied by the linguist Myrna Gopnik and several geneticists. The\ngrandmother of the family is language-impaired. She has five adult\nchildren. One daughter is linguistically normal, as are this daughter's\nchildren. The other four adults, like the grandmother, are impaired.\nTogether these four had twenty-three children; of them, eleven were\nlanguage-impaired, twelve were normal. The language-impaired children were randomly distributed among the families, the sexes, and\nthe birth orders.\n\nOf course, the mere fact that some behavioral pattern runs in\nfamilies does not show that it is genetic. Recipes, accents, and lullabies\n\n\n**4 9**"
    },
    {
        "document_id": "0",
        "parent_id": 60,
        "parent_text": "Of course, the mere fact that some behavioral pattern runs in\nfamilies does not show that it is genetic. Recipes, accents, and lullabies\n\n\n**4 9**\n\n\nrun in families, but they have nothing to do with DNA. In this\ncase, though, a genetic cause is plausible. If the cause were in the\nenvironment—poor nutrition, hearing the defective speech of an\nimpaired parent or sibling, watching too much TV, lead contamination from old pipes, whatever—then why would the syndrome capriciously strike some family members while leaving their near age-mates\n(in one case, a fraternal twin) alone? In fact, the geneticists working\nwith Gopnik noted that the pedigree suggests a trait controlled by a\nsingle dominant gene, just like pink flowers on Gregor Mendel's pea\nplants.\n\nWhat does this hypothetical gene do? It does not seem to impair\noverall intelligence; most of the afflicted family members score in the\nnormal range in the nonverbal parts of IQ tests. (Indeed, Gopnik\nstudied one unrelated child with the syndrome who routinely received\nthe best grade in his mainstream math class.) It is their language that\nis impaired, but they are not like Broca's aphasics; the impression is\nmore of a tourist struggling in a foreign city. They speak somewhat\nslowly and deliberately, carefully planning what they will say and\nencouraging their interlocutors to come to their aid by completing\nsentences for them. They report that ordinary conversation is strenuous mental work and that when possible they avoid situations in\nwhich they must speak. Their speech contains frequent grammatical\nerrors, such as misuse of pronouns and of suffixes like the plural and\npast tense:\n\n\nIt's a flying finches, they are.\nShe remembered when she hurts herself the other day.\nThe neighbors phone the ambulance because the man fall\n\noff the tree.\nThe boys eat four cookie.\nCarol is cry in the church."
    },
    {
        "document_id": "0",
        "parent_id": 61,
        "parent_text": "It's a flying finches, they are.\nShe remembered when she hurts herself the other day.\nThe neighbors phone the ambulance because the man fall\n\noff the tree.\nThe boys eat four cookie.\nCarol is cry in the church.\n\n\nIn experimental tests they have difficulty with tasks that normal\nfour-year-olds breeze through. A classic example is the _wug_ -test _,_\nanother demonstration that normal children do not learn language\nby imitating their parents. The testee is shown a line drawing of a\nbirdlike creature and told that it is a _wug._ Then a picture of two of\nthem is shown, and the child is told, \"Now there are two of them;\nthere are two .\" Your typical four-year-old will blurt out _wugs,_\n\n\n**5 0** THE LANGUAGE INSTINCT\n\n\nbut the language-impaired adult is stymied. One of the adults Gopnik\nstudied laughed nervously and said, \"Oh, dear, well carry on.\" When\npressed, she responded, \"Wug . . . wugness, isn't it? No. I see. You\nwant to pair . . . pair it up. OK.\" For the next animal, _zat,_ she said,\n\"Za . . . ka . . . za . . . zackle.\" For the next, _sas,_ she deduced that it\nmust be \"sasses.\" Flushed with success, she proceeded to generalize\ntoo literally, converting _zoop_ to \"zoop-es\" and _tob_ to \"tob-ye-es,\"\nrevealing that she hadn't really grasped the English rule. Apparently\nthe defective gene in this family somehow affects the development of\nthe rules that normal children use unconsciously. The adults do their\nbest to compensate by consciously reasoning the rules out, with predictably clumsy results."
    },
    {
        "document_id": "0",
        "parent_id": 62,
        "parent_text": "Broca's aphasia and SLI are cases where language is impaired and\nthe rest of intelligence seems more or less intact. But this does not\nshow that language is separate from intelligence. Perhaps language\nimposes greater demands on the brain than any other problem the\nmind has to solve. For the other problems, the brain can limp along\nat less than its full capacity; for language, all systems have to be one\nhundred percent. To clinch the case, we need to find the opposite\ndissociation, linguistic idiot savants—that is, people with good language and bad cognition.\n\nHere is another interview, this one between a fourteen-year-old\ngirl called Denyse and the late psycholinguist Richard Cromer; the\ninterview was transcribed and analyzed by Cromer's colleague Sigrid\nLipka.\n\n\nI like opening cards. I had a pile of post this morning and not one\nof them was a Christmas card. A bank statement I got this morning!\n\n[A bank statement? I hope it was good news.]\n\nNo it wasn't good news.\n\n[Sounds like mine.]\n\nI hate . . ., My mum works over at the, over on the ward and she\nsaid \"not another bank statement.\" I said \"it's the second one in\ntwo days.\" And she said \"Do you want me to go to the bank for\nyou at lunchtime?\" and I went \"No, I'll go this time and explain it\nmyself.\" I tell you what, my bank are awful. They've lost my bank\nbook, you see, and I can't find it anywhere. I belong to the TSB\nBank and I'm thinking of changing my bank 'cause they're so awful.\n\n\nChatterboxes **5 1**\n\n\nThey keep, they keep losing . . . [someone comes in to bring some\ntea] Oh, isn't that nice.\n\n[Uhm. Very good.]\n\nThey've got the habit of doing that. They lose, they've lost my bank\nbook twice, in a month, and I think I'll scream. My mum went\nyesterday to the bank for me. She said \"They've lost your bank\nbook again.\" I went \"Can I scream?\" and I went, she went \"Yes,\ngo on.\" So I hollered. But it is annoying when they do things like\nthat. TSB, Trustees aren't. . . uh the best ones to be with actually.\nThey're hopeless."
    },
    {
        "document_id": "0",
        "parent_id": 63,
        "parent_text": "[Uhm. Very good.]\n\nThey've got the habit of doing that. They lose, they've lost my bank\nbook twice, in a month, and I think I'll scream. My mum went\nyesterday to the bank for me. She said \"They've lost your bank\nbook again.\" I went \"Can I scream?\" and I went, she went \"Yes,\ngo on.\" So I hollered. But it is annoying when they do things like\nthat. TSB, Trustees aren't. . . uh the best ones to be with actually.\nThey're hopeless.\n\n\nI have seen Denyse on videotape, and she comes across as a loquacious, sophisticated conversationalist—all the more so, to American\nears, because of her refined British accent. _(My bank are awful,_ by\nthe way, is grammatical in British, though not American, English.) It\ncomes as a surprise to learn that the events she relates so earnestly\nare figments of her imagination. Denyse has no bank account, so she\ncould not have received any statements in the mail, nor could her\nbank have lost her bankbook. Though she would talk about a joint\nbank account she shared with her boyfriend, she had no boyfriend,\nand obviously had only the most tenuous grasp of the concept \"joint\nbank account\" because she complained about the boyfriend taking\nmoney out of her side of the account. In other conversations Denyse\nwould engage her listeners with lively tales about the wedding of her\nsister, her holiday in Scotland with a boy named Danny, and a happy\nairport reunion with a long-estranged father. But Denyse's sister is\nunmarried, Denyse has never been to Scotland, she does not know\nanyone named Danny, and her father has never been away for any\nlength of time. In fact, Denyse is severely retarded. She never learned\nto read or write and cannot handle money or any of the other demands\nof everyday functioning."
    },
    {
        "document_id": "0",
        "parent_id": 64,
        "parent_text": "Denyse was born with spina bifida (\"split spine\"), a malformation\nof the vertebrae that leaves the spinal cord unprotected. Spina bifida\noften results in hydrocephalus, an increase in pressure in the cerebrospinal fluid filling the ventricles (large cavities) of the brain, distending\nthe brain from within. For reasons no one understands, hydrocephalic\nchildren occasionally end up like Denyse, significantly retarded but\nwith unimpaired—indeed, overdeveloped—language skills. (Perhaps\nthe ballooning ventricles crush much of the brain tissue necessary for\n\n\n**5 2** THE LANGUAGE INSTINCT\n\n\neveryday intelligence but leave intact some other portions that can\ndevelop language circuitry.) The various technical terms for the condition include \"cocktail party conversation,\" \"chatterbox syndrome,\"\nand \"blathering.\"\n\nFluent grammatical language can in fact appear in many kinds\nof people with severe intellectual impairments, like schizophrenics,\nAlzheimer's patients, some autistic children, and some aphasics. One\nof the most fascinating syndromes recently came to light when the\nparents of a retarded girl with chatterbox syndrome in San Diego read\nan article about Chomsky's theories in a popular science magazine and\ncalled him at MIT, suggesting that their daughter might be of interest\nto him. Chomsky is a paper-and-pencil theoretician who wouldn't\nknow Jabba the Hutt from the Cookie Monster, so he suggested that\nthe parents bring their child to the laboratory of the psycholinguist\nUrsula Bellugi in La Jolla."
    },
    {
        "document_id": "0",
        "parent_id": 65,
        "parent_text": "Bellugi, working with colleagues in molecular biology, neurology,\nand radiology, found that the child (whom they called Crystal), and\na number of others they have subsequently tested, had a rare form of\nretardation called Williams syndrome. The syndrome seems to be\nassociated with a defective gene on chromosome 11 involved in the\nregulation of calcium, and it acts in complex ways on the brain, skull,\nand internal organs during development, though no one knows why\nit has the effects it does. The children have an unusual appearance:\nthey are short and slight, with narrow faces and broad foreheads, flat\nnasal bridges, sharp chins, star-shaped patterns in their irises, and\nfull lips. They are sometimes called \"elfin-faced\" or \"pixie people,\"\nbut to me they look more like Mick Jagger. They are significantly\nretarded, with an IQ of about 50, and are incompetent at ordinary\ntasks like tying their shoes, finding their way, retrieving items from a\ncupboard, telling left from right, adding two numbers, drawing a\nbicycle, and suppressing their natural tendency to hug strangers. But\nlike Denyse they are fluent, if somewhat prim, conversationalists.\nHere are two transcripts from Crystal when she was eighteen:\n\n\nAnd what an elephant is, it is one of the animals. And what the\nelephant does, it lives in the jungle. It can also live in the zoo. And\nwhat it has, it has long, gray ears, fan ears, ears that can blow in the\nwind. It has a long trunk that can pick up grass or pick up hay . . .\nIf they're in a bad mood, it can be terrible . . . If the elephant gets\n\n\nChatterboxes **5 3**\n\n\nmad, it could stomp; it could charge. Sometimes elephants can\ncharge, like a bull can charge. They have big, long, tusks. They can\ndamage a car . . . It could be dangerous. When they're in a pinch,\nwhen they're in a bad mood, it can be terrible. You don't want an\nelephant as a pet. You want a cat or a dog or a bird."
    },
    {
        "document_id": "0",
        "parent_id": 66,
        "parent_text": "Chatterboxes **5 3**\n\n\nmad, it could stomp; it could charge. Sometimes elephants can\ncharge, like a bull can charge. They have big, long, tusks. They can\ndamage a car . . . It could be dangerous. When they're in a pinch,\nwhen they're in a bad mood, it can be terrible. You don't want an\nelephant as a pet. You want a cat or a dog or a bird.\n\nThis is a story about chocolates. Once upon a time, in Chocolate\nWorld there used to be a Chocolate Princess. She was such a yummy\nprincess. She was on her chocolate throne and then some chocolate\nman came to see her. And the man bowed to her and he said these\nwords to her. The man said to her, \"Please, Princess Chocolate. I\nwant you to see how I do my work. And it's hot outside in Chocolate\nWorld, and you might melt to the ground like melted butter. And\nif the sun changes to a different color, then the Chocolate World—\nand you—won't melt. You can be saved if the sun changes to a\ndifferent color. And if it doesn't change to a different color, you\nand Chocolate World are doomed.\n\n\nLaboratory tests confirm the impression of competence at grammar;\nthe children understand complex sentences, and fix up ungrammatical sentences, at normal levels. And they have an especially charming\nquirk: they are fond of unusual words. Ask a normal child to name\nsome animals, and you will get the standard inventory of pet store\nand barnyard: dog, cat, horse, cow, pig. Ask a Williams syndrome\nchild, and you get a more interesting menagerie: unicorn, pteranodon,\nyak, ibex, water buffalo, sea lion, saber-tooth tiger, vulture, koala,\ndragon, and one that should be especially interesting to paleontologists, \"brontosaurus rex.\" One eleven-year-old poured a glass of milk\ninto the sink and said, \"I'll have to evacuate it\"; another handed\nBellugi a drawing and announced, \"Here, Doc, this is in remembrance\nof you.\""
    },
    {
        "document_id": "0",
        "parent_id": 67,
        "parent_text": "People like Kirupano, Larry, the Hawaiian-born papaya grower,\nMayela, Simon, Aunt Mae, Sarah, Mr. Ford, the K's, Denyse, and\nCrystal constitute a field guide to language users. They show that\ncomplex grammar is displayed across the full range of human habitats.\nYou don't need to have left the Stone Age; you don't need to be\nmiddle class; you don't need to do well in school; you don't even\nneed to be old enough for school. Your parents need not bathe\n\n\n**5 4** THE LANGUAGE INSTINCT\n\n\nyou in language or even command a language. You don't need the\nintellectual wherewithal to function in society, the skills to keep house\nand home together, or a particularly firm grip on reality. Indeed, you\ncan possess all these advantages and still not be a competent language\nuser, if you lack just the right genes or just the right bits of brain."
    },
    {
        "document_id": "0",
        "parent_id": 68,
        "parent_text": "### 3"
    },
    {
        "document_id": "0",
        "parent_id": 69,
        "parent_text": "#### Mentalese\n\n**The** year 1984 has come and gone, and it is losing its connotation of the totalitarian nightmare of George Orwell's 1949 novel.\nBut relief may **be** premature. In an appendix to _Nineteen Eighty-four,_\nOrwell wrote of an even more ominous date. In 1984, the infidel\nWinston Smith had to be converted with imprisonment, degradation,\ndrugs, and torture; by 2050, there would be no Winston Smiths. For\nin that year the ultimate technology for thought control would be in\nplace: the language Newspeak.\n\n\nThe purpose of Newspeak was not only to provide a medium of\nexpression for the world-view and mental habits proper to the\ndevotees of Ingsoc [English Socialism], but to make all other modes\nof thought impossible. It was intended that when Newspeak had\nbeen adopted once and for all and Oldspeak forgotten, a heretical\nthought—that is, a thought diverging from the principles of Ingsoc—should be literally unthinkable, at least so far as thought is\ndependent on words. Its vocabulary was so constructed as to give\nexact and often very subtle expression to every meaning that a Party\nmember could properly wish to express, while excluding all other\nmeanings and also the possibility of arriving at them by indirect\nmethods. This was done partly by the invention of new words, but\nchiefly by eliminating undesirable words and by stripping such\nwords as remained of unorthodox meanings, and so far as possible\nof all secondary meanings whatever. To give a single example. The\nword _free_ still existed in Newspeak, but it could only be used in\n\n\n**55**\n\n\n**5 6** THE LANGUAGE INSTINCT\n\n\nsuch statements as \"This dog is free from lice\" or \"This field is free\nfrom weeds.\" It could not be used in its old sense of \"politically\nfree\" or \"intellectually free,\" since political and intellectual freedom\nno longer existed even as concepts, and were therefore of necessity\nnameless."
    },
    {
        "document_id": "0",
        "parent_id": 70,
        "parent_text": "**55**\n\n\n**5 6** THE LANGUAGE INSTINCT\n\n\nsuch statements as \"This dog is free from lice\" or \"This field is free\nfrom weeds.\" It could not be used in its old sense of \"politically\nfree\" or \"intellectually free,\" since political and intellectual freedom\nno longer existed even as concepts, and were therefore of necessity\nnameless.\n\n. . . A person growing up with Newspeak as his sole language\nwould no more know that _equal_ had once had the secondary meaning of \"politically equal,\" or that _free_ had once meant \"intellectually\nfree,\" than, for instance, a person who had never heard of chess\nwould be aware of the secondary meanings attaching to _queen_ and\n_rook._ There would be many crimes and errors which it would be\nbeyond his power to commit, simply because they were nameless\nand therefore unimaginable.\n\n\nBut there is a straw of hope for human freedom: Orwell's caveat \"at\nleast so far as thought is dependent on words.\" Note his equivocation:\nat the end of the first paragraph, a concept is unimaginable and\ntherefore nameless; at the end of the second, a concept is nameless\nand therefore unimaginable. _Is_ thought dependent on words? Do\npeople literally think in English, Cherokee, Kivunjo, or, by 2050,\nNewspeak? Or are our thoughts couched in some silent medium of\nthe brain—a language of thought, or \"mentalese\"—and merely\nclothed in words whenever we need to communicate them to a listener? No question could be more central to understanding the language instinct."
    },
    {
        "document_id": "0",
        "parent_id": 71,
        "parent_text": "In much of our social and political discourse, people simply assume\nthat words determine thoughts. Inspired by Orwell's essay \"Politics\nand the English Language,\" pundits accuse governments of manipulating our minds with euphemisms like _pacification_ (bombing), _reve-_\n_nue enhancement_ (taxes), and _nonretention_ (firing). Philosophers\nargue that since animals lack language, they must also lack consciousness—Wittgenstein wrote, \"A dog could not have the thought 'perhaps it will rain tomorrow' \"—and therefore they do not possess the\nrights of conscious beings. Some feminists blame sexist thinking on\nsexist language, like the use of _he_ to refer to a generic person. Inevitably, reform movements have sprung up. Many replacements for _he_\nhave been suggested over the years, including _E, hesh, po, tey, co, jhe,_\n_ve, xe, he'er, thon,_ and _na._ The most extreme of these movements is\nGeneral Semantics, begun in 1933 by the engineer Count Alfred\n\n\nMentalese **5 7**\n\n\nKorzybski and popularized in long-time best-sellers by his disciples\nStuart Chase and S. I. Hayakawa. (This is the same Hayakawa who\nlater achieved notoriety as the protest-defying college president and\nsnoozing U.S. senator.) General Semantics lays the blame for human\nfolly on insidious \"semantic damage\" to thought perpetrated by the\nstructure of language. Keeping a forty-year-old in prison for a theft\nhe committed as a teenager assumes that the forty-year-old John and\nthe eighteen-year-old John are \"the same person,\" a cruel logical\nerror that would be avoided if we referred to them not as _John_ but\nas _John1972_ and _John1994,_ respectively. The verb _to be_ is a particular\nsource of illogic, because it identifies individuals with abstractions, as\nin _Mary is a woman,_ and licenses evasions of responsibility, like\nRonald Reagan's famous nonconfession _Mistakes were made._ One\nfaction seeks to eradicate the verb altogether."
    },
    {
        "document_id": "0",
        "parent_id": 72,
        "parent_text": "And supposedly there is a scientific basis for these assumptions:\nthe famous Sapir-Whorf hypothesis of linguistic determinism, stating\nthat people's thoughts are determined by the categories made available by their language, and its weaker version, linguistic relativity,\nstating that differences among languages cause differences in the\nthoughts of their speakers. People who remember little else from their\ncollege education can rattle off the factoids: the languages that carve\nthe spectrum into color words at different places, the fundamentally\ndifferent Hopi concept of time, the dozens of Eskimo words for snow.\nThe implication is heavy: the foundational categories of reality are\nnot \"in\" the world but are imposed by one's culture (and hence can\nbe challenged, perhaps accounting for the perennial appeal of the\nhypothesis to undergraduate sensibilities).\n\nBut it is wrong, all wrong. The idea that thought is the same thing\nas language is an example of what can be called a conventional\nabsurdity: a statement that goes against all common sense but that\neveryone believes because they dimly recall having heard it somewhere and because it is so pregnant with implications. (The \"fact\"\nthat we use only five percent of our brains, that lemmings commit\nmass suicide, that the _Boy Scout Manual_ annually outsells all other\nbooks, and that we can be coerced into buying by subliminal messages\nare other examples.) Think about it. We have all had the experience\nof uttering or writing a sentence, then stopping and realizing that it\nwasn't exactly what we meant to say. To have that feeling, there has\nto be a \"what we meant to say\" that is different from what we said.\n\n\n**5 8** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 73,
        "parent_text": "**5 8** THE LANGUAGE INSTINCT\n\n\nSometimes it is not easy to find _any_ words that properly convey a\nthought. When we hear or read, we usually remember the gist, not\nthe exact words, so there has to be such a thing as a gist that is not\nthe same as a bunch of words. And if thoughts depended on words,\nhow could a new word ever be coined? How could a child learn a\nword to begin with? How could translation from one language to\nanother be possible?\n\nThe discussions that assume that language determines thought\ncarry on only by a collective suspension of disbelief. A dog, Bertrand\nRussell noted, may not be able to tell you that its parents were honest\nthough poor, but can anyone really conclude from this that the dog\nis _unconscious?_ (Out cold? A zombie?) A graduate student once\nargued with me using the following deliciously backwards logic: language must affect thought, because if it didn't, we would have no\nreason to fight sexist usage (apparently, the fact that it is offensive is\nnot reason enough). As for government euphemism, it is contemptible\nnot because it is a form of mind control but because it is a form of\nlying. (Orwell was quite clear about this in his masterpiece essay.)\nFor example, \"revenue enhancement\" has a much broader meaning\nthan \"taxes,\" and listeners naturally assume that if a politician had\nmeant \"taxes\" he would have said \"taxes.\" Once a euphemism is\npointed out, people are not so brainwashed that they have trouble\nunderstanding the deception. The National Council of Teachers of\nEnglish annually lampoons government doublespeak in a widely reproduced press release, and calling attention to euphemism is a popular form of humor, like the speech from the irate pet store customer\nin _Monty Python's Flying Circus:_"
    },
    {
        "document_id": "0",
        "parent_id": 74,
        "parent_text": "This parrot is no more. It has ceased to be. It's expired and gone\nto meet its maker. This is a late parrot. It's a stiff. Bereft of life, it\nrests in peace. If you hadn't nailed it to the perch, it would be\npushing up the daisies. It's rung down the curtain and joined the\nchoir invisible. This is an ex-parrot.\n\n\nAs we shall see in this chapter, there is no scientific evidence that\nlanguages dramatically shape their speakers' ways of thinking. But I\nwant to do more than review the unintentionally comical history of\nattempts to prove that they do. The idea that language shapes thinking\nseemed plausible when scientists were in the dark about how thinking\n\n\nMentalese **5 9**\n\n\nworks or even how to study it. Now that cognitive scientists know\nhow to think about thinking, there is less of a temptation to equate\nit with language just because words are more palpable than thoughts.\nBy understanding _why_ linguistic determinism is wrong, we will be in\na better position to understand how language itself works when we\nturn to it in the next chapters."
    },
    {
        "document_id": "0",
        "parent_id": 75,
        "parent_text": "Mentalese **5 9**\n\n\nworks or even how to study it. Now that cognitive scientists know\nhow to think about thinking, there is less of a temptation to equate\nit with language just because words are more palpable than thoughts.\nBy understanding _why_ linguistic determinism is wrong, we will be in\na better position to understand how language itself works when we\nturn to it in the next chapters.\n\n\nThe linguistic determinism hypothesis is closely linked to the names\nEdward Sapir and Benjamin Lee Whorf. Sapir, a brilliant linguist,\nwas a student of the anthropologist Franz Boas. Boas and his students\n(who also include Ruth Benedict and Margaret Mead) were important\nintellectual figures in this century, because they argued that nonindustrial peoples were not primitive savages but had systems of language,\nknowledge, and culture as complex and valid in their world view as\nour own. In his study of Native American languages Sapir noted that\nspeakers of different languages have to pay attention to different\naspects of reality simply to put words together into grammatical\nsentences. For example, when English speakers decide whether or\nnot to put _-ed_ onto the end of a verb, they must pay attention to\ntense, the relative time of occurrence of the event they are referring\nto and the moment of speaking. Wintu speakers need not bother with\ntense, but when they decide which suffix to put on their verbs, they\nmust pay attention to whether the knowledge they are conveying was\nlearned through direct observation or by hearsay.\n\nSapir's interesting observation was soon taken much farther. Whorf\nwas an inspector for the Hartford Fire Insurance Company and an\namateur scholar of Native American languages, which led him to take\ncourses from Sapir at Yale. In a much-quoted passage, he wrote:"
    },
    {
        "document_id": "0",
        "parent_id": 76,
        "parent_text": "Sapir's interesting observation was soon taken much farther. Whorf\nwas an inspector for the Hartford Fire Insurance Company and an\namateur scholar of Native American languages, which led him to take\ncourses from Sapir at Yale. In a much-quoted passage, he wrote:\n\n\nWe dissect nature along lines laid down by our native languages.\nThe categories and types that we isolate from the world of phenomena we do not find there because they stare every observer in the\nface; on the contrary, the world is presented in a kaleidoscopic flux\nof impressions which has to be organized by our minds—and this\nmeans largely by the linguistic systems in our minds. We cut nature\nup, organize it into concepts, and ascribe significances as we do,\nlargely because we are parties to an agreement to organize it in this\nway—an agreement that holds throughout our speech community\n\n\n**6 0** THE LANGUAGE INSTINCT\n\n\nand is codified in the patterns of our language. The agreement is,\nof course, an implicit and unstated one, _but its terms are absolutely_\n_obligatory;_ we cannot talk at all except by subscribing to the organization and classification of data which the agreement decrees.\n\n\nWhat led Whorf to this radical position? He wrote that the idea\nfirst occurred to him in his work as a fire prevention engineer when\nhe was struck by how language led workers to misconstrue dangerous\nsituations. For example, one worker caused a serious explosion by\ntossing a cigarette into an \"empty\" drum that in fact was full of\ngasoline vapor. Another lit a blowtorch near a \"pool of water\" that\nwas really a basin of decomposing tannery waste, which, far from\nbeing \"watery,\" was releasing inflammable gases. Whorf's studies of\nAmerican languages strengthened his conviction. For example, in\nApache, _It is a dripping spring_ must be expressed \"As water, or\nsprings, whiteness moves downward.\" \"How utterly unlike our way\nof thinking!\" he wrote."
    },
    {
        "document_id": "0",
        "parent_id": 77,
        "parent_text": "But the more you examine Whorf's arguments, the less sense they\nmake. Take the story about the worker and the \"empty\" drum. The\nseeds of disaster supposedly lay in the semantics of _empty,_ which,\nWhorf claimed, means both \"without its usual contents\" and \"null\nand void, empty, inert.\" The hapless worker, his conception of reality\nmolded by his linguistic categories, did not distinguish between the\n\"drained\" and \"inert\" senses, hence, flick . . . boom! But wait. Gasoline vapor is invisible. A drum with nothing but vapor in it looks just\nlike a drum with nothing in it at all. Surely this walking catastrophe\nwas fooled by his eyes, not by the English language.\n\nThe example of whiteness moving downward is supposed to show\nthat the Apache mind does not cut up events into distinct objects and\nactions. Whorf presented many such examples from Native American\nlanguages. The Apache equivalent of _The boat is grounded on the_\n_beach_ is \"It is on the beach pointwise as an event of canoe motion.\"\n_He invites people to a feast_ becomes \"He, or somebody, goes for\neaters of cooked food.\" _He cleans a gun with a ramrod_ is translated\nas \"He directs a hollow moving dry spot by movement of tool.\" All\nthis, to be sure, is utterly unlike our way of talking. But do we know\nthat it is utterly unlike our way of thinking?\n\nAs soon as Whorf's articles appeared, the psycholinguists Eric\nLenneberg and Roger Brown pointed out two non sequiturs in his\n\n\nMentalese **6 1**\n\n\nargument. First, Whorf did not actually study any Apaches; it is not\nclear that he ever met one. His assertions about Apache psychology\nare based entirely on Apache grammar—making his argument circular. Apaches speak differently, so they must think differently. How\ndo we know that they think differently? Just listen to the way they\nspeak!"
    },
    {
        "document_id": "0",
        "parent_id": 78,
        "parent_text": "As soon as Whorf's articles appeared, the psycholinguists Eric\nLenneberg and Roger Brown pointed out two non sequiturs in his\n\n\nMentalese **6 1**\n\n\nargument. First, Whorf did not actually study any Apaches; it is not\nclear that he ever met one. His assertions about Apache psychology\nare based entirely on Apache grammar—making his argument circular. Apaches speak differently, so they must think differently. How\ndo we know that they think differently? Just listen to the way they\nspeak!\n\nSecond, Whorf rendered the sentences as clumsy, word-for-word\ntranslations, designed to make the literal meanings seem as odd as\npossible. But looking at the actual glosses that Whorf provided, I\ncould, with equal grammatical justification, render the first sentence\nas the mundane \"Clear stuff—water—is falling.\" Turning the tables,\nI could take the English sentence \"He walks\" and render it \"As\nsolitary masculinity, leggedness proceeds.\" Brown illustrates how\nstrange the German mind must be, according to Whorf's logic, by\nreproducing Mark Twain's own translation of a speech he delivered\nin flawless German to the Vienna Press Club:\n\n\nI am indeed the truest friend of the German language—and not\nonly now, but from long since—yes, before twenty years already. . . .\nI would only some changes effect. I would only the language\nmethod—the luxurious, elaborate construction compress, the eternal parenthesis suppress, do away with, annihilate; the introduction\nof more than thirteen subjects in one sentence forbid; the verb so\nfar to the front pull that one it without a telescope discover can.\nWith one word, my gentlemen, I would your beloved language\nsimplify so that, my gentlemen, when you her for prayer need, One\nher yonder-up understands."
    },
    {
        "document_id": "0",
        "parent_id": 79,
        "parent_text": ". . . I might gladly the separable verb also a little bit reform. I\nmight none do let what Schiller did: he has the whole history of the\nThirty Years' War between the two members of a separate verb inpushed. That has even Germany itself aroused, and one has Schiller\nthe permission refused the History of the Hundred Years' War to\ncompose—God be it thanked! After all these reforms established\nbe will, will the German language the noblest and the prettiest on\nthe world be.\n\n\nAmong Whorf's \"kaleidoscopic flux of impressions,\" color is surely\nthe most eye-catching. He noted that we see objects in different\nhues, depending on the wavelengths of the light they reflect, but that\n\n\n62 THE LANGUAGE INSTINCT\n\n\nphysicists tell us that wavelength is a continuous dimension with\nnothing delineating red, yellow, green, blue, and so on. Languages\ndiffer in their inventory of color words: Latin lacks generic \"gray\"\nand \"brown\"; Navajo collapses blue and green into one word; Russian\nhas distinct words for dark blue and sky blue; Shona speakers use\none word for the yellower greens and the greener yellows, and a\ndifferent one for the bluer greens and the nonpurplish blues. You\ncan fill in the rest of the argument. It is language that puts the frets\nin the spectrum; Julius Caesar would not know shale from Shinola.\n\nBut although physicists see no basis for color boundaries, physiologists do. Eyes do not register wavelength the way a thermometer\nregisters temperature. They contain three kinds of cones, each with\na different pigment, and the cones are wired to neurons in a way\nthat makes the neurons respond best to red patches against a green\nbackground or vice versa, blue against yellow, black against white.\nNo matter how influential language might be, it would seem preposterous to a physiologist that it could reach down into the retina and\nrewire the ganglion cells."
    },
    {
        "document_id": "0",
        "parent_id": 80,
        "parent_text": "Indeed, humans the world over (and babies and monkeys, for that\nmatter) color their perceptual worlds using the same palette, and this\nconstrains the vocabularies they develop. Although languages may\ndisagree about the wrappers in the sixty-four crayon box—the burnt\numbers, the turquoises, the fuchsias—they agree much more on the\nwrappers in the eight-crayon box—the fire-engine reds, grass greens,\nlemon yellows. Speakers of different languages unanimously pick\nthese shades as the best examples of their color words, as long as the\nlanguage has a color word in that general part of the spectrum. And\nwhere languages do differ in their color words, they differ predictably,\nnot according to the idiosyncratic tastes of some word-coiner. Languages are organized a bit like the Crayola product line, the fancier\nones adding colors to the more basic ones. If a language has only two\ncolor words, they are for black and white (usually encompassing dark\nand light, respectively). If it has three, they are for black, white, and\nred; if four, black, white, red, and either yellow or green. Five adds\nin both yellow and green; six, blue; seven, brown; more than seven,\npurple, pink, orange, or gray. But the clinching experiment was carried out in the New Guinea highlands with the Grand Valley Dani,\na people speaking one of the black-and-white languages. The psychologist Eleanor Rosch found that the Dani were quicker at learning a\n\n\nMentalese **6 3**\n\n\nnew color category that was based on fire-engine red than a category\nbased on an off-red. The way we see colors determines how we learn\nwords for them, not vice versa."
    },
    {
        "document_id": "0",
        "parent_id": 81,
        "parent_text": "Mentalese **6 3**\n\n\nnew color category that was based on fire-engine red than a category\nbased on an off-red. The way we see colors determines how we learn\nwords for them, not vice versa.\n\nThe fundamentally different Hopi concept of time is one of the\nmore startling claims about how minds can vary. Whorf wrote that\nthe Hopi language contains \"no words, grammatical forms, constructions, or expressions that refer directly to what we call 'time,' or to\npast, or future, or to enduring or lasting.\" He suggested, too, that\nthe Hopi had \"no general notion or intuition of TIME as a smooth\nflowing continuum in which everything in the universe proceeds at\nan equal rate, out of a future, through a present, into a past.\" According to Whorf, they did not conceptualize events as being like\npoints, or lengths of time like days as countable things. Rather, they\nseemed to focus on change and process itself, and on psychological\ndistinctions between presently known, mythical, and conjecturally\ndistant. The Hopi also had little interest in \"exact sequences, dating,\ncalendars, chronology.\"\n\nWhat, then, are we to make of the following sentence translated\nfrom Hopi?\n\n\nThen indeed, the following day, quite early in the morning at the\nhour when people pray to the sun, around that time then he woke\nup the girl again."
    },
    {
        "document_id": "0",
        "parent_id": 82,
        "parent_text": "What, then, are we to make of the following sentence translated\nfrom Hopi?\n\n\nThen indeed, the following day, quite early in the morning at the\nhour when people pray to the sun, around that time then he woke\nup the girl again.\n\n\nPerhaps the Hopi are not as oblivious to time as Whorf made them\nout to be. In his extensive study of the Hopi, the anthropologist\nEkkehart Malotki, who reported this sentence, also showed that Hopi\nspeech contains tense, metaphors for time, units of time (including\ndays, numbers of days, parts of the day, yesterday and tomorrow,\ndays of the week, weeks, months, lunar phases, seasons, and the year),\nways to quantify units of time, and words like \"ancient,\" \"quick,\"\n\"long time,\" and \"finished.\" Their culture keeps records with sophisticated methods of dating, including a horizon-based sun calendar,\nexact ceremonial day sequences, knotted calendar strings, notched\ncalendar sticks, and several devices for timekeeping using the principle of the sundial. No one is really sure how Whorf came up with his\noutlandish claims, but his limited, badly analyzed sample of Hopi\nspeech and his long-time leanings toward mysticism must have contributed.\n\n\n**6 4** THE LANGUAGE INSTINCT\n\n\nSpeaking of anthropological canards, no discussion of language\nand thought would be complete without the Great Eskimo Vocabulary Hoax. Contrary to popular belief, the Eskimos do not have more\nwords for snow than do speakers of English. They do not have four\nhundred words for snow, as it has been claimed in print, or two\nhundred, or one hundred, or forty-eight, or even nine. One dictionary\nputs the figure at two. Counting generously, experts can come up\nwith about a dozen, but by such standards English would not be far\nbehind, with _snow, sleet, slush, blizzard, avalanche, hail, hardpack,_\n_powder, flurry, dusting,_ and a coinage of Boston's WBZ-TV meteorologist Bruce Schwoegler, _snizzling._"
    },
    {
        "document_id": "0",
        "parent_id": 83,
        "parent_text": "Where did the myth come from? Not from anyone who has actually\nstudied the Yupik and Inuit-Inupiaq families of polysynthetic languages spoken from Siberia to Greenland. The anthropologist Laura\nMartin has documented how the story grew like an urban legend,\nexaggerated with each retelling. In 1911 Boas casually mentioned that\nEskimos used four unrelated word roots for snow. Whorf embellished\nthe count to seven and implied that there were more. His article\nwas widely reprinted, then cited in textbooks and popular books\non language, which led to successively inflated estimates in other\ntextbooks, articles, and newspaper columns of Amazing Facts.\n\nThe linguist Geoffrey Pullum, who popularized Martin's article in\nhis essay \"The Great Eskimo Vocabulary Hoax,\" speculates about\nwhy the story got so out of control: \"The alleged lexical extravagance\nof the Eskimos comports so well with the many other facets of their\npolysynthetic perversity: rubbing noses; lending their wives to strangers; eating raw seal blubber; throwing Grandma out to be eaten by\npolar bears.\" It is an ironic twist. Linguistic relativity came out of the\nBoas school, as part of a campaign to show that nonliterate cultures\nwere as complex and sophisticated as European ones. But the supposedly mind-broadening anecdotes owe their appeal to a patronizing\nwillingness to treat other cultures' psychologies as weird and exotic\ncompared to our own. As Pullum notes,\n\n\nAmong the many depressing things about this credulous transmission and elaboration of a false claim is that even if there _were_ a large\nnumber of roots for different snow types in some Arctic language,\nthis would _not,_ objectively, be intellectually interesting; it would be a\nmost mundane and unremarkable fact. Horsebreeders have various\n\n\n**Mentalese** **6 5**"
    },
    {
        "document_id": "0",
        "parent_id": 84,
        "parent_text": "Among the many depressing things about this credulous transmission and elaboration of a false claim is that even if there _were_ a large\nnumber of roots for different snow types in some Arctic language,\nthis would _not,_ objectively, be intellectually interesting; it would be a\nmost mundane and unremarkable fact. Horsebreeders have various\n\n\n**Mentalese** **6 5**\n\n\nnames for breeds, sizes, and ages of horses; botanists have names\nfor leaf shapes; interior decorators have names for shades of mauve;\nprinters have many different names for fonts (Carlson, Garamond,\nHelvetica, Times Roman, and so on), naturally enough. . . . Would\nanyone think of writing about printers the same kind of slop we\nfind written about Eskimos in bad linguistics textbooks? Take [the\nfollowing] random textbook . . ., with its earnest assertion \"It is\nquite obvious that in the culture of the Eskimos . . . snow is of\ngreat enough importance to split up the conceptual sphere that\ncorresponds to one word and one thought in English into several\ndistinct classes . . .\" Imagine reading: \"It is quite obvious that in\nthe culture of printers . . . fonts are of great enough importance to\nsplit up the conceptual sphere that corresponds to one word and\none thought among non-printers into several distinct classes . . .\"\nUtterly boring, even if true. Only the link to those legendary, promiscuous, blubber-gnawing hunters of the ice-packs could permit\nsomething this trite to be presented to us for contemplation."
    },
    {
        "document_id": "0",
        "parent_id": 85,
        "parent_text": "If the anthropological anecdotes are bunk, what about controlled\nstudies? The thirty-five years of research from the psychology laboratory is distinguished by how little it has shown. Most of the experiments have tested banal \"weak\" versions of the Whorfian hypothesis,\nnamely that words can have some effect on memory or categorization.\nSome of these experiments have actually worked, but that is hardly\nsurprising. In a typical experiment, subjects have to commit paint\nchips to memory and are tested with a multiple-choice procedure. In\nsome of these studies, the subjects show slightly better memory for\ncolors that have readily available names in their language. But even\ncolors without names are remembered fairly well, so the experiment\ndoes not show that the colors are remembered by verbal labels alone.\nAll it shows is that subjects remembered the chips in two forms, a\nnonverbal visual image and a verbal label, presumably because two\nkinds of memory, each one fallible, are better than one. In another\ntype of experiment subjects have to say which two out of three color\nchips go together; they often put the ones together that have the same\nname in their language. Again, no surprise. I can imagine the subjects\nthinking to themselves, \"Now how on earth does this guy expect me\nto pick two chips to put together? He didn't give me any hints, and\nthey're all pretty similar. Well, I'd probably call those two 'green' and\n\n\n**6 6** THE LANGUAGE INSTINCT\n\n\nthat one 'blue,' and that seems as good a reason to put them together\nas any.\" In these experiments, language is, technically speaking, influencing a form of thought in some way, but so what? It is hardly\nan example of incommensurable world views, or of concepts that are\nnameless and therefore unimaginable, or of dissecting nature along\nlines laid down by our native languages according to terms that are\nabsolutely obligatory."
    },
    {
        "document_id": "0",
        "parent_id": 86,
        "parent_text": "**6 6** THE LANGUAGE INSTINCT\n\n\nthat one 'blue,' and that seems as good a reason to put them together\nas any.\" In these experiments, language is, technically speaking, influencing a form of thought in some way, but so what? It is hardly\nan example of incommensurable world views, or of concepts that are\nnameless and therefore unimaginable, or of dissecting nature along\nlines laid down by our native languages according to terms that are\nabsolutely obligatory.\n\nThe only really dramatic finding comes from the linguist and now\nSwarthmore College president Alfred Bloom in his book _The Linguis-_\n_tic Shaping of Thought._ English grammar, says Bloom, provides its\nspeakers with the subjunctive construction: _If John were to go to the_\n_hospital, he would meet Mary._ The subjunctive is used to express\n\"counterfactual\" situations, events that are known to be false but\nentertained as hypotheticals. (Anyone familiar with Yiddish knows\na better example, the ultimate riposte to someone reasoning from\nimprobable premises: _Az di bobe volt gehat beytsim volt zi geven_\n_mayn zeyde,_ \"If my grandmother had balls, she'd be my grandfather.\")\nChinese, in contrast, lacks a subjunctive and any other simple grammatical construction that directly expresses a counterfactual. The\nthought must be expressed circuitously, something like \"If John is\ngoing to the hospital . . . but he is not going to the hospital . . . but\nif he is going, he meets Mary.\""
    },
    {
        "document_id": "0",
        "parent_id": 87,
        "parent_text": "Bloom wrote stories containing sequences of implications from\na counterfactual premise and gave them to Chinese and American\nstudents. For example, one story said, in outline, \"Bier was an eighteenth-century European philosopher. There was some contact between the West arid China at that time, but very few works of Chinese\nphilosophy had been translated. Bier could not read Chinese, but if\nhe had been able to read Chinese, he would have discovered B; what\nwould have most influenced him would have been C; once influenced\nby that Chinese perspective, Bier would then have done D,\" and so\non. The subjects were then asked to check off whether B, C, and D\nactually occurred. The American students gave the correct answer,\nno, ninety-eight percent of the time; the Chinese students gave the\ncorrect answer only seven percent of the time! Bloom concluded\nthat the Chinese language renders its speakers unable to entertain\nhypothetical false worlds without great mental effort. (As far as I\nknow, no one has tested the converse prediction on speakers of\nYiddish.)\n\n\nMentalese **6 7**\n\n\nThe cognitive psychologists Terry Au, Yohtaro Takano, and Lisa\nLiu were not exactly enchanted by these tales of the concreteness\nof the Oriental mind. Each one identified serious flaws in Bloom's\nexperiments. One problem was that his stories were written in stilted\nChinese. Another was that some of the science stories turned out,\nupon careful rereading, to be genuinely ambiguous. Chinese college\nstudents tend to have more science training than American students,\nand thus they were _better_ at detecting the ambiguities that Bloom\nhimself missed. When these flaws were fixed, the differences vanished."
    },
    {
        "document_id": "0",
        "parent_id": 88,
        "parent_text": "People can be forgiven for overrating language. Words make noise,\nor sit on a page, for all to hear and see. Thoughts are trapped inside\nthe head of the thinker. To know what someone else is thinking, or\nto talk to each other about the nature of thinking, we have to use—\nwhat else, words! It is no wonder that many commentators have\ntrouble even conceiving of thought without words—or is it that they\njust don't have the language to talk about it?\n\nAs a cognitive scientist I can afford to be smug about common\nsense being true (thought is different from language) and linguistic\ndeterminism being a conventional absurdity. For two sets of tools\nnow make it easier to think clearly about the whole problem. One is\na body of experimental studies that break the word barrier and assess\nmany kinds of nonverbal thought. The other is a theory of how\nthinking might work that formulates the questions in a satisfyingly\nprecise way.\n\nWe have already seen an example of thinking without language:\nMr. Ford, the fully intelligent aphasic discussed in Chapter 2. (One\ncould, however, argue that his thinking abilities had been constructed\nbefore his stroke on the scaffolding of the language he then possessed.) We have also met deaf children who lack a language and\nsoon invent one. Even more pertinent are the deaf adults occasionally\ndiscovered who lack any form of language whatsoever—no sign language, no writing, no lip reading, no speech. In her recent book _A_\n_Man Without Words,_ Susan Schaller tells the story of Ildefonso, a\ntwenty-seven-year-old illegal immigrant from a small Mexican village\nwhom she met while working as a sign language interpreter in Los\nAngeles. Ildefonso's animated eyes conveyed an unmistakable intelligence and curiosity, and Schaller became his volunteer teacher and\n\n\n**6 8** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 89,
        "parent_text": "**6 8** THE LANGUAGE INSTINCT\n\n\ncompanion. He soon showed her that he had a full grasp of number:\nhe learned to do addition on paper in three minutes and had little\ntrouble understanding the base-ten logic behind two-digit numbers.\nIn an epiphany reminiscent of the story of Helen Keller, Ildefonso\ngrasped the principle of naming when Schaller tried to teach him the\nsign for \"cat.\" A dam burst, and he demanded to be shown the signs\nfor all the objects he was familiar with. Soon he was able to convey\nto Schaller parts of his life story: how as a child he had begged his\ndesperately poor parents to send him to school, the kinds of crops\nhe had picked in different states, his evasions of immigration authorities. He led Schaller to other languageless adults in forgotten corners\nof society. Despite their isolation from the verbal world, they displayed many abstract forms of thinking, like rebuilding broken locks,\nhandling money, playing card games, and entertaining each other\nwith long pantomimed narratives.\n\nOur knowledge of the mental life of Ildefonso and other languageless adults must remain impressionistic for ethical reasons: when\nthey surface, the first priority is to teach them language, not to study\nhow they manage without it. But there are other languageless beings\nwho have been studied experimentally, and volumes have been written about how they reason about space, time, objects, number, rate,\ncausality, and categories. Let me recount three ingenious examples.\nOne involves babies, who cannot think in words because they have\nnot yet learned any. One involves monkeys, who cannot think in\nwords because they are incapable of learning them. The third involves\nhuman adults, who, whether or not they think in words, claim their\nbest thinking is done without them."
    },
    {
        "document_id": "0",
        "parent_id": 90,
        "parent_text": "The developmental psychologist Karen Wynn has recently shown\nthat five-month-old babies can do a simple form of mental arithmetic.\nShe used a technique common in infant perception research. Show a\nbaby a bunch of objects long enough, and the baby gets bored and\nlooks away; change the scene, and if the baby notices the difference,\nhe or she will regain interest. The methodology has shown that babies\nas young as five days old are sensitive to number. In one experiment,\nan experimenter bores a baby with an object, then occludes the object\nwith an opaque screen. When the screen is removed, if the same\nobject is present, the babies look for a little while, then get bored\nagain. But if, through invisible subterfuge, two or three objects have\nended up there, the surprised babies stare longer.\n\n\n**Mentalese** 6 9\n\n\nIn Wynn's experiment, the babies were shown a rubber Mickey\nMouse doll on a stage until their little eyes wandered. Then a screen\ncame up, and a prancing hand visibly reached out from behind a\ncurtain and placed a second Mickey Mouse behind the screen. When\nthe screen was removed, if there were two Mickey Mouses visible\n(something the babies had never actually seen), the babies looked for\nonly a few moments. But if there was only one doll, the babies were\ncaptivated—even though this was exactly the scene that had bored\nthem before the screen was put in place. Wynn also tested a second\ngroup of babies, and this time, after the screen came up to obscure\na _pair_ of dolls, a hand visibly reached behind the screen and removed\none of them. If the screen fell to reveal a single Mickey, the babies\nlooked briefly; if it revealed the old scene with two, the babies had\nmore trouble tearing themselves away. The babies must have been\nkeeping track of how many dolls were behind the screen, updating\ntheir counts as dolls were added or subtracted. If the number inexplicably departed from what they expected, they scrutinized the scene,\nas if searching for some explanation."
    },
    {
        "document_id": "0",
        "parent_id": 91,
        "parent_text": "Vervet monkeys live in stable groups of adult males and females\nand their offspring. The primatologists Dorothy Cheney and Robert\nSeyfarth have noticed that extended families form alliances like the\nMontagues and Capulets. In a typical interaction they observed in\nKenya, one juvenile monkey wrestled another to the ground screaming. Twenty minutes later the victim's sister approached the perpetrator's sister and without provocation bit her on the tail. For the\nretaliator to have identified the proper target, she would have had to\nsolve the following analogy problem: A (victim) is to B (myself) as C\n(perpetrator) is to X, using the correct relationship \"sister of (or\nperhaps merely \"relative of; there were not enough vervets in the\npark for Cheney and Seyfarth to tell).\n\nBut do monkeys really know how their groupmates are related to\neach other, and, more impressively, do they realize that different pairs\nof individuals like brothers and sisters can be related in the same\nway? Cheney and Seyfarth hid a loudspeaker behind a bush and\nplayed tapes of a two-year-old monkey screaming. The females in the\narea reacted by looking at the mother of the infant who had been\nrecorded—showing that they not only recognized the infant by its\nscream but recalled who its mother was. Similar abilities have been\nshown in the longtailed macaques that Verena Dasser coaxed into a\n\n\n**7 0** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 92,
        "parent_text": "**7 0** THE LANGUAGE INSTINCT\n\n\nlaboratory adjoining a large outdoor enclosure. Three slides were\nprojected: a mother at the center, one of her offspring on one side,\nand an unrelated juvenile of the same age and sex on the other. Each\nscreen had a button under it. After the monkey had been trained to\npress a button under the offspring slide, it was tested on pictures of\nother mothers in the group, each one flanked by a picture of that\nmother's offspring and a picture of another juvenile. More than ninety\npercent of the time the monkey picked the offspring. In another test,\nthe monkey was shown two slides, each showing a pair of monkeys,\nand was trained to press a button beneath the slide showing a particular mother and her juvenile daughter. When presented with slides of\nnew monkeys in the group, the subject monkey always picked the\nmother-and-offspring pair, whether the offspring was male, female,\ninfant, juvenile, or adult. Moreover, the monkeys appeared to be\nrelying not only on physical resemblance between a given pair of\nmonkeys, or on the sheer number of hours they had previously spent\ntogether, as the basis for recognizing they were kin, but on something\nmore subtle in the history of their interaction. Cheney and Seyfarth,\nwho work hard at keeping track of who is related to whom in what\nway in the groups of animals they study, note that monkeys would\nmake excellent primatologists."
    },
    {
        "document_id": "0",
        "parent_id": 93,
        "parent_text": "Many creative people insist that in their most inspired moments\nthey think not in words but in mental images. Samuel Taylor Coleridge wrote that visual images of scenes and words once appeared\ninvoluntarily before him in a dreamlike state (perhaps opium-induced). He managed to copy the first forty lines onto paper, resulting\nin the poem we know as \"Kubla Khan,\" before a knock on the door\nshattered the images and obliterated forever what would have been\nthe rest of the poem. Many contemporary novelists, like Joan Didion,\nreport that their acts of creation begin not with any notion of a\ncharacter or a plot but with vivid mental pictures that dictate their\nchoice of words. The modern sculptor James Surls plans his projects\nlying on a couch listening to music; he manipulates the sculptures in\nhis mind's eye, he says, putting an arm on, taking an arm off, watching\nthe images roll and tumble.\n\nPhysical scientists are even more adamant that their thinking is\ngeometrical, not verbal. Michael Faraday, the originator of our modern conception of electric and magnetic fields, had no training in\n\n\nMentalese **7 1**"
    },
    {
        "document_id": "0",
        "parent_id": 94,
        "parent_text": "Physical scientists are even more adamant that their thinking is\ngeometrical, not verbal. Michael Faraday, the originator of our modern conception of electric and magnetic fields, had no training in\n\n\nMentalese **7 1**\n\n\nmathematics but arrived at his insights by visualizing lines of force as\nnarrow tubes curving through space. James Clerk Maxwell formalized\nthe concepts of electromagnetic fields in a set of mathematical equations and is considered the prime example of an abstract theoretician,\nbut he set down the equations only after mentally playing with elaborate imaginary models of sheets and fluids. Nikola Tesla's idea for the\nelectrical motor and generator, Friedrich Kekule's discovery of the\nbenzene ring that kicked off modern organic chemistry, Ernest Lawrence's conception of the cyclotron, James Watson and Francis\nCrick's discovery of the DNA double helix—all came to them in\nimages. The most famous self-described visual thinker is Albert Einstein, who arrived at some of his insights by imagining himself riding\na beam of light and looking back at a clock, or dropping a coin while\nstanding in a plummeting elevator. He wrote:\n\n\nThe psychical entities which seem to serve as elements in thought\nare certain signs and more or less clear images which can be \"voluntarily\" reproduced and combined. . . . This combinatory play seems\nto be the essential feature in productive thought—before there is\nany connection with logical construction in words or other kinds of\nsigns which can be communicated to others. The above-mentioned\nelements are, in my case, of visual and some muscular type. Conventional words or other signs have to be sought for laboriously only in\na secondary state, when the mentioned associative play is sufficiently\nestablished and can be reproduced at will."
    },
    {
        "document_id": "0",
        "parent_id": 95,
        "parent_text": "Another creative scientist, the cognitive psychologist Roger Shepard, had his own moment of sudden visual inspiration, and it led to\na classic laboratory demonstration of mental imagery in mere mortals.\nEarly one morning, suspended between sleep and awakening in a\nstate of lucid consciousness, Shepard experienced \"a spontaneous\nkinetic image of three-dimensional structures majestically turning in\nspace.\" Within moments and before fully awakening, Shepard had a\nclear idea for the design of an experiment. A simple variant of his\nidea was later carried out with his then-student Lynn Cooper. Cooper\nand Shepard flashed thousands of slides, each showing a single letter\nof the alphabet, to their long-suffering student volunteers. Sometimes\n\n\n**7 2** THE LANGUAGE INSTINCT\n\n\nthe letter was upright, but sometimes it was tilted or mirror-reversed\nor both. As an example, here are the sixteen versions of the letter F:\n\n\n0 +45 +90 +135 180 -135 -90 -45"
    },
    {
        "document_id": "0",
        "parent_id": 96,
        "parent_text": "**7 2** THE LANGUAGE INSTINCT\n\n\nthe letter was upright, but sometimes it was tilted or mirror-reversed\nor both. As an example, here are the sixteen versions of the letter F:\n\n\n0 +45 +90 +135 180 -135 -90 -45\n\n\nThe subjects were asked to press one button if the letter was normal\n(that is, like one of the letters in the top row of the diagram), another\nif it was a mirror image (like one of the letters in the bottom row).\nTo do the task, the subjects had to compare the letter in the slide\nagainst some memory record of what the normal version of the letter\nlooks like right-side up. Obviously, the right-side-up slide (0 degrees)\nis the quickest, because it matches the letter in memory exactly, but\nfor the other orientations, some mental transformation to the upright\nis necessary first. Many subjects reported that they, like the famous\nsculptors and scientists, \"mentally rotated\" an image of the letter to\nthe upright. By looking at the reaction times, Shepard and Cooper\nshowed that this introspection was accurate. The upright letters\nwere fastest, followed by the 45 degree letters, the 90 degree letters, and the 135 degree letters, with the 180 degree (upside-down)\nletters the slowest. In other words, the farther the subjects had to\nmentally rotate the letter, the longer they took. From the data, Cooper\nand Shepard estimated that letters revolve in the mind at a rate of\n56 RPM."
    },
    {
        "document_id": "0",
        "parent_id": 97,
        "parent_text": "Note that if the subjects had been manipulating something resembling _verbal descriptions_ of the letters, such as \"an upright spine with\none horizontal segment that extends rightwards from the top and\nanother horizontal segment that extends rightwards from the middle,\" the results would have been very different. Among all the topsyturvy letters, the upside-down versions (180 degrees) should be fastest: one simply switches all the \"top\"s to \"bottom\"s and vice versa,\nand the \"left\"s to \"right\"s and vice versa, and one has a new description of the shape as it would appear right-side up, suitable for matching against memory. Sideways letters (90 degrees) should be slower,\n\n\nMentalese **7 3**\n\n\nbecause \"top\" gets changed either to \"right\" or to \"left,\" depending\non whether it lies clockwise (+ 90 degrees) or counterclockwise (— 90\ndegrees) from the upright. Diagonal letters (45 and 135 degrees)\nshould be slowest, because every word in the description has to be\nreplaced: \"top\" has to be replaced with either \"top right\" or \"top\nleft,\" and so on. So the order of difficulty should be 0, 180, 90, 45,\n135, not the majestic rotation of 0, 45, 90, 135, 180 that Cooper and\nShepard saw in the data. Many other experiments have corroborated\nthe idea that visual thinking uses not language but a mental graphics\nsystem, with operations that rotate, scan, zoom, pan, displace, and\nfill in patterns of contours."
    },
    {
        "document_id": "0",
        "parent_id": 98,
        "parent_text": "What sense, then, can we make of the suggestion that images,\nnumbers, kinship relations, or logic can be represented in the brain\nwithout being couched in words? In the first half of this century,\nphilosophers had an answer: none. Reifying thoughts as things in\nthe head was a logical error, they said. A picture or family tree or\nnumber in the head would require a little man, a homunculus, to\nlook at it. And what would be inside _his_ head—even smaller pictures, with an even smaller man looking at them? But the argument\nwas unsound. It took Alan Turing, the brilliant British mathematician\nand philosopher, to make the idea of a mental representation scientifically respectable. Turing described a hypothetical machine that\ncould be said to engage in reasoning. In fact this simple device, named\na Turing Machine in his honor, is powerful enough to solve any\nproblem that any computer, past, present, or future, can solve. And\nit clearly uses an internal symbolic representation—a kind of mentalese—without requiring a little man or any occult processes. By\nlooking at how a Turing machine works, we can get a grasp of what\nit would mean for a human mind to think in mentalese as opposed\nto English.\n\nIn essence, to reason is to deduce new pieces of knowledge from\nold ones. A simple example is the old chestnut from introductory\nlogic: if you know that Socrates is a man and that all men are mortal,\nyou can figure out that Socrates is mortal. But how could a hunk\nof matter like a brain accomplish this feat? The first key idea is a\n_representation:_ a physical object whose parts and arrangement corre\n\n**7 4** THE LANGUAGE INSTINCT\n\n\nspond piece for piece to some set of ideas or facts. For example, the\npattern of ink on this page\n\n```\n          Socrates isa man\n\n```"
    },
    {
        "document_id": "0",
        "parent_id": 99,
        "parent_text": "**7 4** THE LANGUAGE INSTINCT\n\n\nspond piece for piece to some set of ideas or facts. For example, the\npattern of ink on this page\n\n```\n          Socrates isa man\n\n```\n\nis a representation of the idea that Socrates is a man. The shape of\none group of ink marks, `Socrates`, is a symbol that stands for the\nconcept of Socrates. The shape of another set of ink marks, `isa`,\nstands for the concept of being an instance of, and the shape of the\nthird, `man`, stands for the concept of man. Now, it is crucial to keep\none thing in mind. I have put these ink marks in the shape of English\nwords as a courtesy to you, the reader, so that you can keep them\nstraight as we work through the example. But all that really matters\nis that they have different shapes. I could have used a star of David,\na smiley face, and the Mercedes-Benz logo, as long as I used them\nconsistently.\n\nSimilarly, the fact that the `Socrates` ink marks are to the left of\nthe `isa` ink marks on the page, and the `man` ink marks are to the\nright, stands for the idea that Socrates is a man. If I change any\npart of the representation, like replacing `isa` with `isasonofa`, or\nflipping the positions of `Socrates` and `man`, we would have a\nrepresentation of a different idea. Again, the left-to-right English\norder is just a mnemonic device for your convenience. I could have\ndone it right-to-left or up-and-down, as long as I used that order\nconsistently.\n\nKeeping these conventions in mind, now imagine that the page has\na second set of ink marks, representing the proposition that every\nman is mortal:\n\n\nMentalese **7 5**\n\n```\n          Socrates isa man\n          Every man ismortal\n\n```"
    },
    {
        "document_id": "0",
        "parent_id": 100,
        "parent_text": "Keeping these conventions in mind, now imagine that the page has\na second set of ink marks, representing the proposition that every\nman is mortal:\n\n\nMentalese **7 5**\n\n```\n          Socrates isa man\n          Every man ismortal\n\n```\n\nTo get reasoning to happen, we now need a _processor._ A processor\nis not a little man (so one needn't worry about an infinite regress of\nhomunculi inside homunculi) but something much stupider: a gadget\nwith a fixed number of reflexes. A processor can react to different\npieces of a representation and do something in response, including\naltering the representation or making new ones. For example, imagine\na machine that can move around on a printed page. It has a cutout\nin the shape of the letter sequence `isa,` and a light sensor that can\ntell when the cutout is superimposed on a set of ink marks in the\nexact shape of the cutout. The sensor is hooked up to a little pocket\ncopier, which can duplicate any set of ink marks, either by printing\nidentical ink marks somewhere else on the page or by burning them\ninto a new cutout.\n\nNow imagine that this sensor-copier-creeper machine is wired up\nwith four reflexes. First, it rolls down the page, and whenever it\ndetects some `isa` ink marks, it moves to the left, and copies the ink\nmarks it finds there onto the bottom left corner of the page. Let loose\non our page, it would create the following:\n\n```\n          Socrates isa man\n          Every man ismortal\n\n          Socrates\n\n```\n\n**7 6** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 101,
        "parent_text": "Now imagine that this sensor-copier-creeper machine is wired up\nwith four reflexes. First, it rolls down the page, and whenever it\ndetects some `isa` ink marks, it moves to the left, and copies the ink\nmarks it finds there onto the bottom left corner of the page. Let loose\non our page, it would create the following:\n\n```\n          Socrates isa man\n          Every man ismortal\n\n          Socrates\n\n```\n\n**7 6** THE LANGUAGE INSTINCT\n\n\nIts second reflex, also in response to finding an i s a, is to get itself\nto the right of that i s a and copy any ink marks it finds there into\nthe holes of a new cutout. In our case, this forces the processor to\nmake a cutout in the shape of man. Its third reflex is to scan down\nthe page checking for ink marks shaped like `Every,` and if it finds\nsome, seeing if the ink marks to the right align with its new cutout.\nIn our example, it finds one: the man in the middle of the second\nline. Its fourth reflex, upon finding such a match, is to move to the\nright and copy the ink marks it finds there onto the bottom center of\nthe page. In our example, those are the ink marks i s m o r t a l . If you\nare following me, you'll see that our page now looks like this:\n\n```\n          Socrates isa man\n          Every man ismortal\n\n          Socrates ismortal\n\n```"
    },
    {
        "document_id": "0",
        "parent_id": 102,
        "parent_text": "```\n          Socrates isa man\n          Every man ismortal\n\n          Socrates ismortal\n\n```\n\nA primitive kind of reasoning has taken place. Crucially, although\nthe gadget and the page it sits on collectively display a kind of intelligence, there is nothing in either of them that is itself intelligent.\nGadget and page are just a bunch of ink marks, cutouts, photocells,\nlasers, and wires. What makes the whole device smart is the exact\n_correspondence_ between the logician's rule \"If X is a Y and all Y's\nare Z, then X is Z\" and the way the device scans, moves, and prints.\nLogically speaking, \"X is a Y\" means that what is true of Y is also\ntrue of X, and mechanically speaking, `X isa Y` causes what is printed\nnext to the `Y` to be also printed next to the `X` . The machine, blindly\nfollowing the laws of physics, just responds to the shape of the ink\nmarks `isa` (without understanding what it means to us) and copies\nother ink marks in a way that ends up mimicking the operation of\nthe logical rule. What makes it \"intelligent\" is that the sequence of\nsensing and moving and copying results in its printing a representation\nof a conclusion that is true if and only if the page contains representa\n\nMentalese **7 7**\n\n\ntions of premises that are true. If one gives the device as much paper\nas it needs, Turing showed, the machine can do anything that any\ncomputer can do—and perhaps, he conjectured, anything that any\nphysically embodied mind can do."
    },
    {
        "document_id": "0",
        "parent_id": 103,
        "parent_text": "Now, this example uses ink marks on paper as its representation\nand a copying-creeping-sensing machine as its processor. But the\nrepresentation can be in any physical medium at all, as long as the\npatterns are used consistently. In the brain, there might be three\ngroups of neurons, one used to represent the individual that the\nproposition is about (Socrates, Aristotle, Rod Stewart, and so on),\none to represent the logical relationship in the proposition (is a, is\nnot, is like, and so on), and one to represent the class or type that\nthe individual is being categorized as (men, dogs, chickens, and so\non). Each concept would correspond to the firing of a particular\nneuron; for example, in the first group of neurons, the fifth neuron\nmight fire to represent Socrates and the seventeenth might fire to\nrepresent Aristotle; in the third group, the eighth neuron might fire\nto represent men, the twelfth neuron might fire to represent dogs.\nThe processor might be a network of other neurons feeding into these\ngroups, connected together in such a way that it reproduces the firing\npattern in one group of neurons in some other group (for example,\nif the eighth neuron is firing in group 3, the processor network would\nturn on the eighth neuron in some fourth group, elsewhere in the\nbrain). Or the whole thing could be done in silicon chips. But in all\nthree cases the principles are the same. The way the elements in the\nprocessor are wired up would cause them to sense and copy pieces\nof a representation, and to produce new representations, in a way\nthat mimics the rules of reasoning. With many thousands of representations and a set of somewhat more sophisticated processors (perhaps\ndifferent kinds of representations and processors for different kinds\nof thinking), you might have a genuinely intelligent brain or computer.\nAdd an eye that can detect certain contours in the world and turn on\nrepresentations that symbolize them, and muscles that can act on the\nworld whenever certain representations symbolizing goals are turned"
    },
    {
        "document_id": "0",
        "parent_id": 104,
        "parent_text": "that mimics the rules of reasoning. With many thousands of representations and a set of somewhat more sophisticated processors (perhaps\ndifferent kinds of representations and processors for different kinds\nof thinking), you might have a genuinely intelligent brain or computer.\nAdd an eye that can detect certain contours in the world and turn on\nrepresentations that symbolize them, and muscles that can act on the\nworld whenever certain representations symbolizing goals are turned\non, and you have a behaving organism (or add a TV camera and set\nof levers and wheels, and you have a robot)."
    },
    {
        "document_id": "0",
        "parent_id": 105,
        "parent_text": "This, in a nutshell, is the theory of thinking called \"the physical\nsymbol system hypothesis\" or the \"computational\" or \"representa\n\n**7 8** THE LANGUAGE INSTINCT\n\n\ntional\" theory of mind. It is as fundamental to cognitive science as the\ncell doctrine is to biology and plate tectonics is to geology. Cognitive\npsychologists and neuroscientists are trying to figure out what kinds\nof representations and processors the brain has. But there are ground\nrules that must be followed at all times: no little men inside, and no\npeeking. The representations that one posits in the mind have to be\narrangements of symbols, and the processor has to be a device with\na fixed set of reflexes, period. The combination, acting all by itself,\nhas to produce the intelligent conclusions. The theorist is forbidden\nto peer inside and \"read\" the symbols, \"make sense\" of them, and\npoke around to nudge the device in smart directions like some deus\nex machina."
    },
    {
        "document_id": "0",
        "parent_id": 106,
        "parent_text": "Now we are in a position to pose the Whorfian question in a precise\nway. Remember that a representation does not have to look like\nEnglish or any other language; it just has to use symbols to represent\nconcepts, and arrangements of symbols to represent the logical relations among them, according to some consistent scheme. But though\ninternal representations in an English speaker's mind don't _have_ to\nlook like English, they _could,_ in principle, look like English—or\nlike whatever language the person happens to speak. So here is the\nquestion: Do they in fact? For example, if we know that Socrates is\na man, is it because we have neural patterns that correspond one-toone to the English words _Socrates, is, a,_ and _man,_ and groups of\nneurons in the brain that correspond to the subject of an English\nsentence, the verb, and the object, laid out in that order? Or do we\nuse some other code for representing concepts and their relations in\nour heads, a language of thought or mentalese that is not the same\nas any of the world's languages? We can answer this question by\nseeing whether English sentences embody the information that a\nprocessor would need to perform valid sequences of reasoning—\nwithout requiring any fully intelligent homunculus inside doing the\n\"understanding.\"\n\nThe answer is a clear no. English (or any other language people\nspeak) is hopelessly unsuited to serve as our internal medium of\ncomputation. Consider some of the problems.\n\nThe first is ambiguity. These headlines actually appeared in newspapers:\n\n\nMentalese **7 9**\n\n\nChild's Stool Great for Use in Garden\nStud Tires Out\nStiff Opposition Expected to Casketless Funeral Plan\nDrunk Gets Nine Months in Violin Case\nIraqi Head Seeks Arms\nQueen Mary Having Bottom Scraped\nColumnist Gets Urologist in Trouble with His Peers"
    },
    {
        "document_id": "0",
        "parent_id": 107,
        "parent_text": "The first is ambiguity. These headlines actually appeared in newspapers:\n\n\nMentalese **7 9**\n\n\nChild's Stool Great for Use in Garden\nStud Tires Out\nStiff Opposition Expected to Casketless Funeral Plan\nDrunk Gets Nine Months in Violin Case\nIraqi Head Seeks Arms\nQueen Mary Having Bottom Scraped\nColumnist Gets Urologist in Trouble with His Peers\n\n\nEach headline contains a word that is ambiguous. But surely the\nthought underlying the word is _not_ ambiguous; the writers of the\nheadlines surely knew which of the two senses of the words _stool,_\n_stud,_ and _stiff_ they themselves had in mind. And if there can be two\nthoughts corresponding to one word, thoughts can't be words.\n\nThe second problem with English is its lack of logical explicitness.\nConsider the following example, devised by the computer scientist\nDrew McDermott:\n\n\nRalph is an elephant.\nElephants live in Africa.\nElephants have tusks.\n\n\nOur inference-making device, with some minor modifications to handle the English grammar of the sentences, would deduce \"Ralph lives\nin Africa\" and \"Ralph has tusks.\" This sounds fine but isn't. Intelligent you, the reader, knows that the Africa that Ralph lives in is the\nsame Africa that all the other elephants live in, but that Ralph's tusks\nare his own. But the symbol-copier-creeper-sensor that is supposed\nto be a model of you _doesn't_ know that, because the distinction is\nnowhere to be found in any of the statements. If you object that this\nis just common sense, you would be right—but it's common sense\nthat we're trying to account for, and English sentences do not embody\nthe information that a processor needs to carry out common sense."
    },
    {
        "document_id": "0",
        "parent_id": 108,
        "parent_text": "A third problem is called \"co-reference.\" Say you start talking\nabout an individual by referring to him as _the tall blond man with_\n_one black shoe._ The second time you refer to him in the conversation\nyou are likely to call him _the man;_ the third time, just _him._ But the\nthree expressions do not refer to three people or even to three ways\nof thinking about a single person; the second and third are just ways\n\n\n**8 0** THE LANGUAGE INSTINCT\n\n\nof saving breath. Something in the brain must treat them as the same\nthing; English isn't doing it.\n\nA fourth, related problem comes from those aspects of language\nthat can only be interpreted in the context of a conversation or text—\nwhat linguists call \"deixis.\" Consider articles like _a_ and _the._ What is\nthe difference between _killed a policeman_ and _killed the policeman?_\nOnly that in the second sentence, it is assumed that some specific\npoliceman was mentioned earlier or is salient in the context. Thus in\nisolation the two phrases are synonymous, but in the following contexts (the first from an actual newspaper article) their meanings are\ncompletely different:\n\n\nA policeman's 14-year-old son, apparently enraged after\nbeing disciplined for a bad grade, opened fire from his\nhouse, _killing a policeman_ and wounding three people\nbefore he was shot dead.\nA policeman's 14-year-old son, apparently enraged after\nbeing disciplined for a bad grade, opened fire from his\nhouse, _killing the policeman_ and wounding three people\nbefore he was shot dead.\n\n\nOutside of a particular conversation or text, then, the words _a_ and\n_the_ are quite meaningless. They have no place in one's permanent\nmental database. Other conversation-specific words like _here, there,_\n_this, that, now, then, I, me, my, her, we,_ and _you_ pose the same\nproblems, as the following old joke illustrates:\n\n\nFirst guy: I didn't sleep with my wife before we were married, did\nyou?\n\n\nSecond guy: I don't know. What was her maiden name?\n\n\nA fifth problem is synonymy. The sentences"
    },
    {
        "document_id": "0",
        "parent_id": 109,
        "parent_text": "Outside of a particular conversation or text, then, the words _a_ and\n_the_ are quite meaningless. They have no place in one's permanent\nmental database. Other conversation-specific words like _here, there,_\n_this, that, now, then, I, me, my, her, we,_ and _you_ pose the same\nproblems, as the following old joke illustrates:\n\n\nFirst guy: I didn't sleep with my wife before we were married, did\nyou?\n\n\nSecond guy: I don't know. What was her maiden name?\n\n\nA fifth problem is synonymy. The sentences\n\n\nSam sprayed paint onto the wall.\nSam sprayed the wall with paint.\nPaint was sprayed onto the wall by Sam.\nThe wall was sprayed with paint by Sam.\n\n\nMentalese **8 1**\n\n\nrefer to the same event and therefore license many of the same inferences. For example, in all four cases, one may conclude that the wall\nhas paint on it. But they are four distinct arrangements of words. You\nknow that they mean the same thing, but no simple processor, crawling over them as marks, would know that. Something else that is not\none of those arrangements of words must be representing the single\nevent that you know is common to all four. For example, the event\nmight be represented as something like\n\n```\n  (Sam spray paint i) cause (painti go to (on wall))\n\n```\n\n—which, assuming we don't take the English words seriously, is not\ntoo far from one of the leading proposals about what mentalese looks\nlike."
    },
    {
        "document_id": "0",
        "parent_id": 110,
        "parent_text": "```\n  (Sam spray paint i) cause (painti go to (on wall))\n\n```\n\n—which, assuming we don't take the English words seriously, is not\ntoo far from one of the leading proposals about what mentalese looks\nlike.\n\nThese examples (and there are many more) illustrate a single important point. The representations underlying thinking, on the one\nhand, and the sentences in a language, on the other, are in many ways\nat cross-purposes. Any particular thought in our head embraces a\nvast amount of information. But when it comes to communicating a\nthought to someone else, attention spans are short and mouths are\nslow. To get information into a listener's head in a reasonable amount\nof time, a speaker can encode only a fraction of the message into\nwords and must count on the listener to fill in the rest. But _inside a_\n_single bead,_ the demands are different. Air time is not a limited\nresource: different parts of the brain are connected to one another\ndirectly with thick cables that can transfer huge amounts of information quickly. Nothing can be left to the imagination, though, because\nthe internal representations _are_ the imagination.\n\nWe end up with the following picture. People do not think in\nEnglish or Chinese or Apache; they think in a language of thought.\nThis language of thought probably looks a bit like all these languages;\npresumably it has symbols for concepts, and arrangements of symbols\nthat correspond to who did what to whom, as in the paint-spraying\nrepresentation shown above. But compared with any given language,\nmentalese must be richer in some ways and simpler in others. It\nmust be richer, for example, in that several concept symbols must\ncorrespond to a given English word like _stool_ or _stud._ There must\nbe extra paraphernalia that differentiate logically distinct kinds of\nconcepts, like Ralph's tusks versus tusks in general, and that link\n\n\n**8 2** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 111,
        "parent_text": "**8 2** THE LANGUAGE INSTINCT\n\n\ndifferent symbols that refer to the same thing, like _the tall blond man_\n_with one black shoe_ and _the man._ On the other hand, mentalese must\nbe simpler than spoken languages; conversation-specific words and\nconstructions (like _a_ and _the)_ are absent, and information about\npronouncing words, or even ordering them, is unnecessary. Now, it\ncould be that English speakers think in some kind of simplified and\nannotated quasi-English, with the design I have just described, and\nthat Apache speakers think in a simplified and annotated quasiApache. But to get these languages of thought to subserve reasoning\nproperly, they would have to look much more like each other than\neither one does to its spoken counterpart, and it is likely that they\nare the same: a universal mentalese.\n\nKnowing a language, then, is knowing how to translate mentalese\ninto strings of words and vice versa. People without a language would\nstill have mentalese, and babies and many nonhuman animals presumably have simpler dialects. Indeed, if babies did not have a mentalese\nto translate to and from English, it is not clear how learning English\ncould take place, or even what learning English would mean.\n\nSo where does all this leave Newspeak? Here are my predictions\nfor the year 2050. First, since mental life goes on independently of\nparticular languages, concepts of freedom and equality will be thinkable even if they are nameless. Second, since there are far more\nconcepts than there are words, and listeners must always charitably\nfill in what the speaker leaves unsaid, existing words will quickly gain\nnew senses, perhaps even regain their original senses. Third, since\nchildren are not content to reproduce any old input from adults but\ncreate a complex grammar that can go beyond it, they would creolize\nNewspeak into a natural language, possibly in a single generation.\nThe twenty-first-century toddler may be Winston Smith's revenge."
    },
    {
        "document_id": "0",
        "parent_id": 112,
        "parent_text": "### 4"
    },
    {
        "document_id": "0",
        "parent_id": 113,
        "parent_text": "#### How Language Works\n\nJournalists say that when a dog bites a man that is not news,\nbut when a man bites a dog that is news. This is the essence of the\nlanguage instinct: language conveys news. The streams of words called\n\"sentences\" are not just memory prods, reminding you of man and\nman's best friend and letting you fill in the rest; they tell you who in\nfact did what to whom. Thus we get more from most stretches of\nlanguage than Woody Allen got from _War and Peace,_ which he read\nin two hours after taking speed-reading lessons: \"It was about some\nRussians.\" Language allows us to know how octopuses make love\nand how to remove cherry stains and why Tad was heartbroken, and\nwhether the Red Sox will win the World Series without a good relief\npitcher and how to build an atom bomb in your basement and how\nCatherine the Great died, among other things.\n\nWhen scientists see some apparent magic trick in nature, like bats\nhoming in on insects in pitch blackness or salmon returning to breed\nin their natal stream, they look for the engineering principles behind\nit. For bats, the trick turned out to be sonar; for salmon, it was locking\nin to a faint scent trail. What is the trick behind the ability of _Homo_\n_sapiens_ to convey that man bites dog?\nIn fact there is not one trick but two, and they are associated with\nthe names of two European scholars who wrote in the nineteenth\ncentury. The first principle, articulated by the Swiss linguist Ferdinand de Saussure, is \"the arbitrariness of the sign,\" the wholly conventional pairing of a sound with a meaning. The word _dog_ does not\nlook like a dog, walk like a dog, or woof like a dog, but it means\n\n\n**83**\n\n\n**8 4** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 114,
        "parent_text": "**83**\n\n\n**8 4** THE LANGUAGE INSTINCT\n\n\n\"dog\" just the same. It does so because every English speaker has\nundergone an identical act of rote learning in childhood that links\nthe sound to the meaning. For the price of this standardized memorization, the members of a language community receive an enormous\nbenefit: the ability to convey a concept from mind to mind virtually\ninstantaneously. Sometimes the gunshot marriage between sound and\nmeaning can be amusing. As Richard Lederer points out in _Crazy_\n_English,_ we drive on a parkway but park in a driveway, there is no\nham in hamburger or bread in sweetbreads, and blueberries are blue\nbut cranberries are not cran. But think about the \"sane\" alternative\nof depicting a concept so that receivers can apprehend the meaning in\nthe form. The process is so challenging to the ingenuity, so comically\nunreliable, that we have made it into party games like Pictionary and\ncharades.\n\nThe second trick behind the language instinct is captured in a\nphrase from Wilhelm Von Humboldt that presaged Chomsky: language \"makes infinite use of finite media.\" We know the difference\nbetween the forgettable _Dog bites man_ and the newsworthy _Man bites_\n_dog_ because of the order in which _dog, man,_ and _bites_ are combined.\nThat is, we use a code to translate between orders of words and\ncombinations of thoughts. That code, or set of rules, is called a\ngenerative grammar; as I have mentioned, it should not be confused\nwith the pedagogical and stylistic grammars we encountered in school."
    },
    {
        "document_id": "0",
        "parent_id": 115,
        "parent_text": "The principle underlying grammar is unusual in the natural world.\nA grammar is an example of a \"discrete combinatorial system.\" A\nfinite number of discrete elements (in this case, words) are sampled,\ncombined, and permuted to create larger structures (in this case,\nsentences) with properties that are quite distinct from those of their\nelements. For example, the meaning of _Man bites dog_ is different\nfrom the meaning of any of the three words inside it, and different\nfrom the meaning of the same words combined in the reverse order.\nIn a discrete combinatorial system like language, there can be an\nunlimited number of completely distinct combinations with an infinite\nrange of properties. Another noteworthy discrete combinatorial system in the natural world is the genetic code in DNA, where four\nkinds of nucleotides are combined into sixty-four kinds of codons,\nand the codons can be strung into an unlimited number of different\ngenes. Many biologists have capitalized on the close parallel between\nthe principles of grammatical combination and the principles of ge\n\nHow Language Works **8 5**\n\n\nnetic combination. In the technical language of genetics, sequences\nof DNA are said to contain \"letters\" and \"punctuation\"; may be\n\"palindromic,\" \"meaningless,\" or \"synonymous\"; are \"transcribed\"\nand \"translated\"; and are even stored in \"libraries.\" The immunologist Niels Jerne entitled his Nobel Prize address \"The Generative\nGrammar of the Immune System.\""
    },
    {
        "document_id": "0",
        "parent_id": 116,
        "parent_text": "How Language Works **8 5**\n\n\nnetic combination. In the technical language of genetics, sequences\nof DNA are said to contain \"letters\" and \"punctuation\"; may be\n\"palindromic,\" \"meaningless,\" or \"synonymous\"; are \"transcribed\"\nand \"translated\"; and are even stored in \"libraries.\" The immunologist Niels Jerne entitled his Nobel Prize address \"The Generative\nGrammar of the Immune System.\"\n\nMost of the complicated systems we see in the world, in contrast,\nare _blending systems,_ like geology, paint mixing, cooking, sound, light,\nand weather. In a blending system the properties of the combination\nlie _between_ the properties of its elements, and the properties of the\nelements are lost in the average or mixture. For example, combining\nred paint and white paint results in pink paint. Thus the range of\nproperties that can be found in a blending system are highly circumscribed, and the only way to differentiate large numbers of combinations is to discriminate tinier and tinier differences. It may not be a\ncoincidence that the two systems in the universe that most impress\nus with their open-ended complex design—life and mind—are based\non discrete combinatorial systems. Many biologists believe that if\ninheritance were not discrete, evolution as we know it could not have\ntaken place.\n\nThe way language works, then, is that each person's brain contains\na lexicon of words and the concepts they stand for (a mental dictionary) and a set of rules that combine the words to convey relationships\namong concepts (a mental grammar). We will explore the world\nof words in the next chapter; this one is devoted to the design of\ngrammar."
    },
    {
        "document_id": "0",
        "parent_id": 117,
        "parent_text": "The way language works, then, is that each person's brain contains\na lexicon of words and the concepts they stand for (a mental dictionary) and a set of rules that combine the words to convey relationships\namong concepts (a mental grammar). We will explore the world\nof words in the next chapter; this one is devoted to the design of\ngrammar.\n\nThe fact that grammar is a discrete combinatorial system has two\nimportant consequences. The first is the sheer vastness of language.\nGo into the Library of Congress and pick a sentence at random from\nany volume, and chances are you would fail to find an exact repetition\nno matter how long you continued to search. Estimates of the number\nof sentences that an ordinary person is capable of producing are\nbreathtaking. If a speaker is interrupted at a random point in a\nsentence, there are on average about ten different words that could\nbe inserted at that point to continue the sentence in a grammatical\nand meaningful way. (At some points in a sentence, only one word can\nbe inserted, and at others, there is a choice from among thousands; ten\nis the average.) Let's assume that a person is capable of producing\nsentences up to twenty words long. Therefore the number of senten\n\n**8 6** THE LANGUAGE INSTINCT\n\n\nces that a speaker can deal with in principle is at least 10 2 0 (a one\nwith twenty zeros after it, or a hundred million trillion). At a rate of\nfive seconds a sentence, a person would need a childhood of about a\nhundred trillion years (with no time for eating or sleeping) to memorize them all. In fact, a twenty-word limitation is far too severe. The\nfollowing comprehensible sentence from George Bernard Shaw, for\nexample, is 110 words long:"
    },
    {
        "document_id": "0",
        "parent_id": 118,
        "parent_text": "**8 6** THE LANGUAGE INSTINCT\n\n\nces that a speaker can deal with in principle is at least 10 2 0 (a one\nwith twenty zeros after it, or a hundred million trillion). At a rate of\nfive seconds a sentence, a person would need a childhood of about a\nhundred trillion years (with no time for eating or sleeping) to memorize them all. In fact, a twenty-word limitation is far too severe. The\nfollowing comprehensible sentence from George Bernard Shaw, for\nexample, is 110 words long:\n\n\nStranger still, though Jacques-Dalcroze, like all these great teachers,\nis the completest of tyrants, knowing what is right and that he must\nand will have the lesson just so or else break his heart (not somebody\nelse's, observe), yet his school is so fascinating that every woman\nwho sees it exclaims: \"Oh why was I not taught like this!\" and\nelderly gentlemen excitedly enroll themselves as students and distract classes of infants by their desperate endeavours to beat two in\na bar with one hand and three with the other, and start off on earnest\nwalks around the room, taking two steps backward whenever M.\nDalcroze calls out \"Hop!\"\n\n\nIndeed, if you put aside the fact that the days of our age are\nthreescore and ten, each of us is capable of uttering an _infinite_ number\nof different sentences. By the same logic that shows that there are an\ninfinite number of integers—if you ever think you have the largest\ninteger, just add 1 to it and you will have another—there must be an\ninfinite number of sentences. The _Guinness Book of World Records_\nonce claimed to recognize the longest English sentence: a 1,300-word\nstretch in William Faulkner's novel _Absalom, Absalom!_ that begins:\n\n\nThey both bore it as though in deliberate flagellant exaltation . . .\n\n\nI am tempted to achieve immortality by submitting the following\nrecord-breaker:\n\n\nFaulkner wrote, \"They both bore it as though in deliberate\nflagellant exaltation . . . \"\n\n\nBut it would be only the proverbial fifteen minutes of fame, for soon\nI could be bested by:\n\n\nHow Language Works **8 7**"
    },
    {
        "document_id": "0",
        "parent_id": 119,
        "parent_text": "They both bore it as though in deliberate flagellant exaltation . . .\n\n\nI am tempted to achieve immortality by submitting the following\nrecord-breaker:\n\n\nFaulkner wrote, \"They both bore it as though in deliberate\nflagellant exaltation . . . \"\n\n\nBut it would be only the proverbial fifteen minutes of fame, for soon\nI could be bested by:\n\n\nHow Language Works **8 7**\n\n\nPinker wrote that Faulkner wrote, \"They both bore it as\nthough in deliberate flagellant exaltation . . . \"\n\n\nAnd that record, too, would fall when someone submitted:\n\n\nWho cares that Pinker wrote that Faulkner wrote, \"They\nboth bore it as though in deliberate flagellant exaltation . . .\"?\n\n\nAnd so on, ad infinitum. The infinite use of finite media distinguishes\nthe human brain from virtually all the artificial language devices we\ncommonly come across, like pull-string dolls, cars that nag you to\nclose the door, and cheery voice-mail instructions (\"Press the pound\nkey for more options\"), all of which use a fixed list of prefabricated\nsentences.\n\nThe second consequence of the design of grammar is that it is a\ncode that is _autonomous_ from cognition. A grammar specifies how\nwords may combine to express meanings; that specification is independent of the particular meanings we typically convey or expect\nothers to convey to us. Thus we all sense that some strings of words\nthat can be given common-sense interpretations do not conform to\nthe grammatical code of English. Here are some strings that we can\neasily interpret but that we sense are not properly formed:\n\n\nWelcome to Chinese Restaurant. Please try your Nice Chinese Food with Chopsticks: the traditional and typical of\nChinese glorious history and cultual.\nIt's a flying finches, they are.\nThe child seems sleeping.\nIs raining.\nSally poured the glass with water.\nWho did a book about impress you?\n\nSkid crash hospital.\nDrum vapor worker cigarette flick boom.\n\nThis sentence no verb.\nThis sentence has contains two verbs.\nThis sentence has cabbage six words.\nThis is not a complete. This either."
    },
    {
        "document_id": "0",
        "parent_id": 120,
        "parent_text": "Welcome to Chinese Restaurant. Please try your Nice Chinese Food with Chopsticks: the traditional and typical of\nChinese glorious history and cultual.\nIt's a flying finches, they are.\nThe child seems sleeping.\nIs raining.\nSally poured the glass with water.\nWho did a book about impress you?\n\nSkid crash hospital.\nDrum vapor worker cigarette flick boom.\n\nThis sentence no verb.\nThis sentence has contains two verbs.\nThis sentence has cabbage six words.\nThis is not a complete. This either.\n\n\n**8 8** THE LANGUAGE INSTINCT\n\n\nThese sentences are \"ungrammatical,\" not in the sense of split\ninfinitives, dangling participles, and the other hobgoblins of the\nschoolmarm, but in the sense that every ordinary speaker of the casual\nvernacular has a gut feeling that something is wrong with them,\ndespite their interpretability. Ungrammaticality is simply a consequence of our having a fixed code for interpreting sentences. For\nsome strings a meaning can be guessed, but we lack confidence that\nthe speaker has used the same code in producing the sentence as we\nused in interpreting it. For similar reasons, computers, which are less\nforgiving of ungrammatical input than human listeners, express their\ndispleasure in all-too-familiar dialogues like this one:\n\n\n`> PRINT` (x + 1\n```\n*****SYNTAX ERROR*****\n\n```\n\nThe opposite can happen as well. Sentences can make no sense but\ncan still be recognized as grammatical. The classic example is a sentence from Chomsky, his only entry in _Bartlett's Familiar Quotations:_\n\n\nColorless green ideas sleep furiously.\n\n\nThe sentence was contrived to show that syntax and sense can be\nindependent of each other, but the point was made long before\nChomsky; the genre of nonsense verse and prose, popular in the\nnineteenth century, depends on it. Here is an example from Edward\nLear, the acknowledged master of nonsense:\n\n\nIt's a fact the whole world knows,\nThat Pobbles are happier without their toes."
    },
    {
        "document_id": "0",
        "parent_id": 121,
        "parent_text": "Colorless green ideas sleep furiously.\n\n\nThe sentence was contrived to show that syntax and sense can be\nindependent of each other, but the point was made long before\nChomsky; the genre of nonsense verse and prose, popular in the\nnineteenth century, depends on it. Here is an example from Edward\nLear, the acknowledged master of nonsense:\n\n\nIt's a fact the whole world knows,\nThat Pobbles are happier without their toes.\n\n\nMark Twain once parodied the romantic description of nature written\nmore for its mellifluousness than its content:\n\n\nIt was a crisp and spicy morning in early October. The lilacs and\nlaburnums, lit with the glory-fires of autumn, hung burning and\nflashing in the upper air, a fairy bridge provided by kind Nature\nfor the wingless wild things that have their homes in the tree-tops\nand would visit together; the larch and the pomegranate flung\ntheir purple and yellow flames in brilliant broad splashes along\n\n\nHow Language Works **8 9**\n\n\nthe slanting sweep of the woodland; the sensuous fragrance of\ninnumerable deciduous flowers rose upon the swooning atmosphere; far in the empty sky a solitary esophagus slept upon motionless wing; everywhere brooded stillness, serenity, and the peace\nof God.\n\n\nAnd almost everyone knows the poem in Lewis Carroll's _Through the_\n_Looking-Glass_ that ends:\n\n\nAnd, as in uffish thought he stood,\n\nThe Jabberwock, with eyes of flame,\nCame whiffling through the tulgey wood,\nAnd burbled as it came!\n\n\nOne, two! One, two! And through and through\n\nThe vorpal blade went snicker-snack!\nHe left it dead, and with its head\nHe went galumphing back.\n\n\n\"And hast thou slain the Jabberwock?\n\nCome to my arms, my beamish boy!\nO frabjous day! Callooh! Callay!\"\nHe chortled in his joy.\n\n\n'Twas brillig, and the slithy toves\n\nDid gyre and gimble in the wabe:\nAll mimsy were the borogoves,\n\nAnd the mome raths outgrabe."
    },
    {
        "document_id": "0",
        "parent_id": 122,
        "parent_text": "The Jabberwock, with eyes of flame,\nCame whiffling through the tulgey wood,\nAnd burbled as it came!\n\n\nOne, two! One, two! And through and through\n\nThe vorpal blade went snicker-snack!\nHe left it dead, and with its head\nHe went galumphing back.\n\n\n\"And hast thou slain the Jabberwock?\n\nCome to my arms, my beamish boy!\nO frabjous day! Callooh! Callay!\"\nHe chortled in his joy.\n\n\n'Twas brillig, and the slithy toves\n\nDid gyre and gimble in the wabe:\nAll mimsy were the borogoves,\n\nAnd the mome raths outgrabe.\n\n\nAs Alice said, \"Somehow it seems to fill my head with ideas—only I\ndon't exactly know what they are!\" But though common sense and\ncommon knowledge are of no help in understanding these passages,\nEnglish speakers recognize that they are grammatical, and their mental rules allow them to extract precise, though abstract, frameworks\nof meaning. Alice deduced, _\"Somebody_ killed _something:_ that's clear,\nat any rate—.\" And after reading Chomsky's entry in _Bartlett's,_ anyone can answer questions like \"What slept? How? Did one thing\nsleep, or several? What kind of ideas were they?\"\n\n\nHow might the combinatorial grammar underlying human language work? The most straightforward way to combine words in\n\n\n**9 0** THE LANGUAGE INSTINCT\n\n\norder is explained in Michael Frayn's novel _The Tin Men._ The protagonist, Goldwasser, is an engineer working at an institute for automation. He must devise a computer system that generates the standard\nkinds of stories found in the daily papers, like \"Paralyzed Girl Determined to Dance Again.\" Here he is hand-testing a program that\ncomposes stories about royal occasions:"
    },
    {
        "document_id": "0",
        "parent_id": 123,
        "parent_text": "**9 0** THE LANGUAGE INSTINCT\n\n\norder is explained in Michael Frayn's novel _The Tin Men._ The protagonist, Goldwasser, is an engineer working at an institute for automation. He must devise a computer system that generates the standard\nkinds of stories found in the daily papers, like \"Paralyzed Girl Determined to Dance Again.\" Here he is hand-testing a program that\ncomposes stories about royal occasions:\n\n\nHe opened the filing cabinet and picked out the first card in the\nset. _Traditionally,_ it read. Now there was a random choice between\ncards reading _coronations, engagements, funerals, weddings, comings_\n_of age, births, deaths,_ or _the churching of women._ The day before he\nhad picked _funerals,_ and been directed on to a card reading with\nsimple perfection _are occasions for mourning._ Today he closed his\neyes, drew _weddings,_ and was signposted on to _are occasions for_\n_rejoicing._\n\n_The wedding of X and Y_ followed in logical sequence, and brought\nhim a choice between _is no exception_ and _is a case in point._ Either\nway there followed _indeed._ Indeed, whichever occasion one had\nstarted off with, whether coronations, deaths, or births, Goldwasser\nsaw with intense mathematical pleasure, one now reached this same\nelegant bottleneck. He paused on _indeed,_ then drew in quick succession _it is a particularly happy occasion, rarely,_ and _can there have_\n_been a more popular young couple._\n\nFrom the next selection, Goldwasser drew _X has won himself/_\n_herself a special place in the nation's affections,_ which forced him to\ngo on to _and the British people have clearly taken Y to their hearts_\n_already._\n\nGoldwasser was surprised, and a little disturbed, to realise that\nthe word \"fitting\" had still not come up. But he drew it with the\nnext card— _it is especially fitting that._"
    },
    {
        "document_id": "0",
        "parent_id": 124,
        "parent_text": "From the next selection, Goldwasser drew _X has won himself/_\n_herself a special place in the nation's affections,_ which forced him to\ngo on to _and the British people have clearly taken Y to their hearts_\n_already._\n\nGoldwasser was surprised, and a little disturbed, to realise that\nthe word \"fitting\" had still not come up. But he drew it with the\nnext card— _it is especially fitting that._\n\nThis gave him _the bride/bridegroom should be,_ and an open choice\nbetween _of such a noble and illustrious line, a commoner in these_\n_democratic times, from a nation with which this country has long_\n_enjoyed a particularly close and cordial relationship,_ and _from a nation_\n_with which this country's relations have not in the past been always_\n_happy._\n\nFeeling that he had done particularly well with \"fitting\" last time,\nGoldwasser now deliberately selected it again. _It is also fitting that,_\nread the card, to be quickly followed by _we should remember,_ and\n\n\nHow Language Works **9 1**\n\n\nX _and Y are not merely symbols—they are a lively young man and_\n_a very lovely young woman._\n\nGoldwasser shut his eyes to draw the next card. It turned out to\nread _in these days when._ He pondered whether to select _it is fashion-_\n_able to scoff at the traditional morality of marriage and family life_ or\n_it is no longer fashionable to scoff at the traditional morality of_\n_marriage and family life._ The latter had more of the form's authentic\nbaroque splendour, he decided."
    },
    {
        "document_id": "0",
        "parent_id": 125,
        "parent_text": "X _and Y are not merely symbols—they are a lively young man and_\n_a very lovely young woman._\n\nGoldwasser shut his eyes to draw the next card. It turned out to\nread _in these days when._ He pondered whether to select _it is fashion-_\n_able to scoff at the traditional morality of marriage and family life_ or\n_it is no longer fashionable to scoff at the traditional morality of_\n_marriage and family life._ The latter had more of the form's authentic\nbaroque splendour, he decided.\n\n\nLet's call this a word-chain device (the technical name is a \"finitestate\" or \"Markov\" model). A word-chain device is a bunch of lists\nof words (or prefabricated phrases) and a set of directions for going\nfrom list to list. A processor builds a sentence by selecting a word\nfrom one list, then a word from another list, and so on. (To recognize\na sentence spoken by another person, one just checks the words\nagainst each list in order.) Word-chain systems are commonly used\nin satires like Frayn's, usually as do-it-yourself recipes for composing\nexamples of a kind of verbiage. For example, here is a Social Science\nJargon Generator, which the reader may operate by picking a word\nat random from the first column, then a word from the second, then\none from the third, and stringing them together to form an impressivesounding term like _inductive aggregating interdependence:_\n\n\ndialectical participatory interdependence\ndefunctionalized degenerative diffusion\npositivistic aggregating periodicity\npredicative appropriative synthesis\nmultilateral simulated sufficiency\nquantitative homogeneous equivalence\ndivergent transfigurative expectancy\nsynchronous diversifying plasticity\ndifferentiated cooperative epigenesis\ninductive progressive constructivism\nintegrated complementary deformation\ndistributive eliminative solidification\n\n\nRecently I saw a word-chain device that generates breathless book\njacket blurbs, and another for Bob Dylan song lyrics.\n\n\n**9 2** THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 126,
        "parent_text": "Recently I saw a word-chain device that generates breathless book\njacket blurbs, and another for Bob Dylan song lyrics.\n\n\n**9 2** THE LANGUAGE INSTINCT\n\n\nA word-chain device is the simplest example of a discrete combinatorial system, since it is capable of creating an unlimited number of\ndistinct combinations from a finite set of elements. Parodies notwithstanding, a word-chain device can generate infinite sets of grammatical English sentences. For example, the extremely simple scheme\n\n\nassembles many sentences, such as _A girl eats ice cream_ and _The happy_\n_dog eats candy._ It can assemble an infinite number because of the loop\nat the top that can take the device from the _happy_ list back to itself\nany number of times: _The happy dog eats ice cream, The happy happy_\n_dog eats ice cream,_ and so on."
    },
    {
        "document_id": "0",
        "parent_id": 127,
        "parent_text": "assembles many sentences, such as _A girl eats ice cream_ and _The happy_\n_dog eats candy._ It can assemble an infinite number because of the loop\nat the top that can take the device from the _happy_ list back to itself\nany number of times: _The happy dog eats ice cream, The happy happy_\n_dog eats ice cream,_ and so on.\n\nWhen an engineer has to build a system to combine words in\nparticular orders, a word-chain device is the first thing that comes to\nmind. The recorded voice that gives you a phone number when you\ndial directory assistance is a good example. A human speaker is\nrecorded uttering the ten digits, each in seven different sing-song\npatterns (one for the first position in a phone number, one for the\nsecond position, and so on). With just these seventy recordings, ten\nmillion phone numbers can be assembled; with another thirty recordings for three-digit area codes, ten billion numbers are possible\n(in practice, many are never used because of restrictions like the\nabsence of 0 and 1 from the beginning of a phone number). In fact\nthere have been serious efforts to model the English language as a\nvery large word chain. To make it as realistic as possible, the transitions from one word list to another can reflect the actual probabilities\nthat those kinds of words follow one another in English (for example,\nthe word _that_ is much more likely to be followed by _is_ than by\n_indicates)._ Huge databases of these \"transition probabilities\" have\nbeen compiled by having a computer analyze bodies of English text\nor by asking volunteers to name the words that first come to mind\nafter a given word or series of words. Some psychologists have suggested that human language is based on a huge word chain stored in\nthe brain. The idea is congenial to stimulus-response theories: a stimu\n\nHow Language Works **9 3**\n\n\nlus elicits a spoken word as a response, then the speaker perceives\nhis or her own response, which serves as the next stimulus, eliciting\none out of several words as the next response, and so on."
    },
    {
        "document_id": "0",
        "parent_id": 128,
        "parent_text": "How Language Works **9 3**\n\n\nlus elicits a spoken word as a response, then the speaker perceives\nhis or her own response, which serves as the next stimulus, eliciting\none out of several words as the next response, and so on.\n\nBut the fact that word-chain devices seem ready-made for parodies\nlike Frayn's raises suspicions. The point of the various parodies is\nthat the genre being satirized is so mindless and cliche-ridden that a\nsimple mechanical method can churn out an unlimited number of\nexamples that can almost pass for the real thing. The humor works\nbecause of the discrepancy between the two: we all assume that\npeople, even sociologists and reporters, are not really word-chain\ndevices; they only seem that way.\n\nThe modern study of grammar began when Chomsky showed that\nword-chain devices are not just a bit suspicious; they are deeply,\nfundamentally, the wrong way to think about how human language\nworks. They are discrete combinatorial systems, but they are the\nwrong kind. There are three problems, and each one illuminates some\naspect of how language really does work."
    },
    {
        "document_id": "0",
        "parent_id": 129,
        "parent_text": "The modern study of grammar began when Chomsky showed that\nword-chain devices are not just a bit suspicious; they are deeply,\nfundamentally, the wrong way to think about how human language\nworks. They are discrete combinatorial systems, but they are the\nwrong kind. There are three problems, and each one illuminates some\naspect of how language really does work.\n\nFirst, a sentence of English is a completely different thing from a\nstring of words chained together according to the transition probabilities of English. Remember Chomsky's sentence _Colorless green ideas_\n_sleep furiously._ He contrived it not only to show that nonsense can\nbe grammatical but also to show that improbable word sequences\ncan be grammatical. In English texts the probability that the word\n_colorless_ is followed by the word _green_ is surely zero. So is the probability that _green_ is followed by _ideas, ideas_ by _sleep,_ and _sleep_ by\n_furiously._ Nonetheless, the string is a well-formed sentence of English.\nConversely, when one actually assembles word chains using probability tables, the resulting word strings are very far from being wellformed sentences. For example, say you take estimates of the set of\nwords most likely to come after every four-word sequence, and use\nthose estimates to grow a string word by word, always looking at the\nfour most recent words to determine the next one. The string will be\neerily Englishy, but not English, like _House to ask for is to earn our_\n_living by working towards a goal for his team in old New-York was a_\n_wonderful place wasn't it even pleasant to talk about and laugh hard_\n_when he tells lies he should not tell me the reason why you are is_\n_evident._\n\nThe discrepancy between English sentences and Englishy word\nchains has two lessons. When people learn a language, they are learn\n\n9 4 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 130,
        "parent_text": "The discrepancy between English sentences and Englishy word\nchains has two lessons. When people learn a language, they are learn\n\n9 4 THE LANGUAGE INSTINCT\n\n\ning how to put words in order, but not by recording which word\nfollows which other word. They do it by recording which word _cate-_\n_gory_ —noun, verb, and so on—follows which other category. That is,\nwe can recognize _colorless green ideas_ because it has the same order\nof adjectives and nouns that we learned from more familiar sequences\nlike _strapless black dresses._ The second lesson is that the nouns and\nverbs and adjectives are not just hitched end to end in one long chain;\nthere is some overarching blueprint or plan for the sentence that puts\neach word in a specific slot.\n\nIf a word-chain device is designed with sufficient cleverness, it can\ndeal with these problems. But Chomsky had a definitive refutation of\nthe very idea that a human language is a word chain. He proved that\ncertain sets of English sentences could not, even in principle, be\nproduced by a word-chain device, no matter how big or how faithful to probability tables the device is. Consider sentences like the\nfollowing:\n\n\nEither the girl eats ice cream, or the girl eats candy.\nIf the girl eats ice cream, then the boy eats hot dogs.\n\n\nAt first glance it seems easy to accommodate these sentences:\n\n\nBut the device does not work. _Either_ must be followed later in a\nsentence by or; no one says _Either the girl eats ice cream, then the girl_\n_likes candy._ Similarly, _if_ requires _then;_ no one says _If the girl eats ice_\n_cream, or the girl likes candy._ But to satisfy the desire of a word early\nin a sentence for some other word late in the sentence, the device has\nto remember the early word while it is churning out all the words in\nbetween. And that is the problem: a word-chain device is an amnesiac,\nremembering only which word list it has just chosen from, nothing\n\n\nHow Language Works **9 5**"
    },
    {
        "document_id": "0",
        "parent_id": 131,
        "parent_text": "How Language Works **9 5**\n\n\nearlier. By the time it reaches the _or/then_ list, it has no means of\nremembering whether it said _if_ or _either_ way back at the beginning.\nFrom our vantage point, peering down at the entire road map, we\ncan remember which choice the device made at the first fork in the\nroad, but the device itself, creeping antlike from list to list, has no\nway of remembering.\n\nNow, you might think it would be a simple matter to redesign the\ndevice so that it does not have to remember early choices at late\npoints in the sentence. For example, one could join up _either_ and _or_\nand all the possible word sequences in between into one giant sequence, and _if_ and _then_ and all the sequences in between as a second\ngiant sequence, before returning to a third copy of the sequence—\nyielding a chain so long I have to print it sideways (see page 96).\nThere is something immediately disturbing about this solution: there\nare three identical subnetworks. Clearly, whatever people can say\nbetween an _either_ and an _or,_ they can say between an _if_ and a _then,_\nand also after the _or_ or the _then._ But this ability should come naturally\nout of the design of whatever the device is in people's heads that\nallows them to speak. It shouldn't depend on the designer's carefully\nwriting down three identical sets of instructions (or, more plausibly,\non the child's having to learn the structure of the English sentence\nthree different times, once between _if_ and _then,_ once between _either_\nand _or,_ and once after a _then_ or an _or)._\n\nBut Chomsky showed that the problem is even deeper. Each of\nthese sentences can be embedded in any of the others, including\nitself:\n\n\nIf either the girl eats ice cream or the girl eats candy, then\n\nthe boy eats hot dogs.\nEither if the girl eats ice cream then the boy eats ice cream,\n\nor if the girl eats ice cream then the boy eats candy."
    },
    {
        "document_id": "0",
        "parent_id": 132,
        "parent_text": "But Chomsky showed that the problem is even deeper. Each of\nthese sentences can be embedded in any of the others, including\nitself:\n\n\nIf either the girl eats ice cream or the girl eats candy, then\n\nthe boy eats hot dogs.\nEither if the girl eats ice cream then the boy eats ice cream,\n\nor if the girl eats ice cream then the boy eats candy.\n\n\nFor the first sentence, the device has to remember _if_ and _either_ so\nthat it can continue later with _or_ and _then,_ in that order. For the\nsecond sentence, it has to remember _either_ and _if_ so that it can\ncomplete the sentence with _then_ and _or._ And so on. Since there's no\nlimit in principle to the number of _if_ 's and _either_ 's that can begin a\nsentence, each requiring its own order of _then's_ and _or's_ to complete\nit, it does no good to spell out each memory sequence as its own\n\n\nchain of lists; you'd need an infinite number of chains, which won't\nfit inside a finite brain.\n\nThis argument may strike you as scholastic. No real person ever\nbegins a sentence with _Either either if either if if,_ so who cares whether\na putative model of that person can complete it with _then . . . then_\n_. . . or . . . then . . . or . . . or?_ But Chomsky was just adopting the\nesthetic of the mathematician, using the interaction between _either-_\n_or_ and _if-then_ as the simplest possible example of a property of\nlanguage—its use of \"long-distance dependencies\" between an early\nword and a later one—to prove mathematically that word-chain devices cannot handle these dependencies.\n\n\nHow Language Works **9 7**"
    },
    {
        "document_id": "0",
        "parent_id": 133,
        "parent_text": "How Language Works **9 7**\n\n\nThe dependencies, in fact, abound in languages, and mere mortals\nuse them all the time, over long distances, often handling several at\nonce—just what a word-chain device cannot do. For example, there\nis an old grammarian's saw about how a sentence can end in five\nprepositions. Daddy trudges upstairs to Junior's bedroom to read\nhim a bedtime story. Junior spots the book, scowls, and asks, \"Daddy,\nwhat did you bring that book that I don't want to be read to out of\nup for?\" By the point at which he utters _read,_ Junior has committed\nhimself to holding four dependencies in mind: _to be read_ demands\n_to, that book that_ requires _out of, bring_ requires _up,_ and _what_ requires\n_for._ An even better, real-life example comes from a letter to _TV Guide:_\n\n\nHow Ann Salisbury can claim that Pam Dawber's anger at not\nreceiving her fair share of acclaim for _Mork and Mindy's_ success\nderives from a fragile ego escapes me."
    },
    {
        "document_id": "0",
        "parent_id": 134,
        "parent_text": "How Ann Salisbury can claim that Pam Dawber's anger at not\nreceiving her fair share of acclaim for _Mork and Mindy's_ success\nderives from a fragile ego escapes me.\n\n\nAt the point just after the word _not,_ the letter-writer had to keep four\ngrammatical commitments in mind: (1) _not_ requires _-ing_ (her anger\nat _not_ receiv _ing_ acclaim); (2) _at_ requires some kind of noun or gerund\n(her anger _at_ not _receiving acclaim);_ (3) the singular subject _Pam_\n_Dawber's anger_ requires the verb fourteen words downstream to agree\nwith it in number (Dawber's _anger . . . derives_ from); (4) the singular\nsubject beginning with _How_ requires the verb twenty-seven words\ndownstream to agree with it in number _(How . . . escapes_ me). Similarly, a reader must keep these dependencies in mind while interpreting the sentence. Now, technically speaking, one could rig up a wordchain model to handle even these sentences, as long as there is some\nactual limit on the number of dependencies that the speaker need\nkeep in mind (four, say). But the degree of redundancy in the device\nwould be absurd; for each of the thousands of _combinations_ of dependencies, an identical chain must be duplicated inside the device.\nIn trying to fit such a superchain in a person's memory, one quickly\nruns out of brain.\n\n\nThe difference between the artificial combinatorial system we see\nin word-chain devices and the natural one we see in the human brain\nis summed up in a line from the Joyce Kilmer poem: \"Only God can\nmake a tree.\" A sentence is not a chain but a tree. In a human\n\n\n**9 8** THE LANGUAGE INSTINCT\n\n\n**grammar, words are grouped into phrases, like twigs joined in a**\n**branch. The phrase is given a name—a mental symbol—and little**\n**phrases can be joined into bigger ones.**"
    },
    {
        "document_id": "0",
        "parent_id": 135,
        "parent_text": "The difference between the artificial combinatorial system we see\nin word-chain devices and the natural one we see in the human brain\nis summed up in a line from the Joyce Kilmer poem: \"Only God can\nmake a tree.\" A sentence is not a chain but a tree. In a human\n\n\n**9 8** THE LANGUAGE INSTINCT\n\n\n**grammar, words are grouped into phrases, like twigs joined in a**\n**branch. The phrase is given a name—a mental symbol—and little**\n**phrases can be joined into bigger ones.**\n\n**Take the sentence** _The happy boy eats ice cream._ **It begins with**\n**three words that hang together as a unit, the noun phrase** _the happy_\n_boy._ **In English a noun phrase (NP) is composed of a noun (N),**\n**sometimes preceded by an article or \"determiner\" (abbreviated**\n**\"det\") and any number of adjectives (A). All this can be captured in**\n**a rule that defines what English noun phrases look like in general. In**\n**the standard notation of linguistics, an arrow means \"consists of,\"**\n**parentheses mean \"optional,\" and an asterisk means \"as many of**\n**them as you want,\" but I provide the rule just to show that all of its**\n**information can be captured precisely in a few symbols; you can**\n**ignore the notation and just look at the translation into ordinary**\n**words below it:**\n\n\n**NP —> (det) A* N**\n**\"A noun phrase consists of an optional determiner, followed**\n**by any number of adjectives, followed by a noun.\"**\n\n\n**The rule defines an upside-down tree branch:**\n\n\n**Here are two other rules, one defining the English sentence** (S), **the**\n**other defining the predicate or verb phrase (VP); both use the NP**\n**symbol as an ingredient:**\n\n\nS — **> NP VP**\n**\"A sentence consists of a noun phrase followed by a verb**\n**phrase.\"**\n\n**VP—> V NP**\n**\"A verb phrase consists of a verb followed by a noun**\n**phrase.\"**\n\n\nHow Language Works **9 9**\n\n\nWe now need a mental dictionary that specifies which words belong\nto which part-of-speech categories (noun, verb, adjective, preposition,\ndeterminer):"
    },
    {
        "document_id": "0",
        "parent_id": 136,
        "parent_text": "S — **> NP VP**\n**\"A sentence consists of a noun phrase followed by a verb**\n**phrase.\"**\n\n**VP—> V NP**\n**\"A verb phrase consists of a verb followed by a noun**\n**phrase.\"**\n\n\nHow Language Works **9 9**\n\n\nWe now need a mental dictionary that specifies which words belong\nto which part-of-speech categories (noun, verb, adjective, preposition,\ndeterminer):\n\n\nN —> boy, girl, dog, cat, ice cream, candy, hot dogs\n\"Nouns may be drawn from the following list: _boy,_\n_girl, . . .\"_\n\nV —> eats, likes, bites\n\"Verbs may be drawn from the following list: _eats, likes,_\n_bites.\"_\n\nA —> happy, lucky, tall\n\"Adjectives may be drawn from the following list: _happy,_\n_lucky, tall.\"_\n\ndet —> a, the, one\n\"Determiners may be drawn from the following list: _a, the,_\n_one.\"_\n\n\nA set of rules like the ones I have listed—a \"phrase structure\ngrammar\"—defines a sentence by linking the words to branches on\nan inverted tree:\n\n\nThe invisible superstructure holding the words in place is a powerful invention that eliminates the problems of word-chain devices. The\nkey insight is that a tree is _modular,_ like telephone jacks or garden\nhose couplers. A symbol like \"NP\" is like a connector or fitting of a\ncertain shape. It allows one component (a phrase) to snap into any\nof several positions inside other components (larger phrases). Once\na kind of phrase is defined by a rule and given its connector symbol,\nit never has to be defined again; the phrase can be plugged in any\n\n100 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 137,
        "parent_text": "100 THE LANGUAGE INSTINCT\n\n\nwhere there is a corresponding socket. For example, in the little\ngrammar I have listed, the symbol \"NP\" is used both as the subject\nof a sentence (S —> NP VP) and as the object of a verb phrase (VP\n—> V NP). In a more realistic grammar, it would also be used as the\nobject of a preposition _(near the boy),_ in a possessor phrase _(the boy's_\n_hat),_ as an indirect object _(give the boy a cookie),_ and in several other\npositions. This plug-and-socket arrangement explains how people can\nuse the same kind of phrase in many different positions in a sentence,\nincluding:\n\n\n[The happy happy boy] eats ice cream.\nI like [the happy happy boy].\nI gave [the happy happy boy] a cookie.\n\n[The happy happy boy]'s cat eats ice cream.\n\n\nThere is no need to learn that the adjective precedes the noun (rather\nthan vice versa) for the subject, and then have to learn the same thing\nfor the object, and again for the indirect object, and yet again for the\npossessor.\n\nNote, too, that the promiscuous coupling of any phrase with any\nslot makes grammar autonomous from our common-sense expectations involving the meanings of the words. It thus explains why we\ncan write and appreciate grammatical nonsense. Our little grammar\ndefines all kinds of colorless green sentences, like _The happy happy_\n_candy likes the tall ice cream,_ as well as conveying such newsworthy\nevents as _The girl bites the dog._\n\nMost interestingly, the labeled branches of a phrase structure\ntree act as an overarching memory or plan for the whole sentence.\nThis allows nested long-distance dependencies, like _if_ . . . _then_\nand _either . . . or,_ to be handled with ease. All you need is a rule\ndefining a phrase that contains a copy of the very same kind of\nphrase, such as:\n\n\nS —> either S or S\n\"A sentence can consist of the word _either,_ followed by a\nsentence, followed by the word _or,_ followed by another\nsentence.\"\n\n\nHow Language Works 101"
    },
    {
        "document_id": "0",
        "parent_id": 138,
        "parent_text": "S —> either S or S\n\"A sentence can consist of the word _either,_ followed by a\nsentence, followed by the word _or,_ followed by another\nsentence.\"\n\n\nHow Language Works 101\n\n\nS —> if S then S\n\"A sentence can consist of the word _if_, followed by a sentence, followed by the word _then,_ followed by another\nsentence.\"\n\n\nThese rules embed one instance of a symbol inside another instance\nof the same symbol (here, a sentence inside a sentence), a neat trick—\nlogicians call it \"recursion\"—for generating an infinite number of\nstructures. The pieces of the bigger sentence are held together, in\norder, as a set of branches growing out of a common node. That node\nholds together each _either_ with its _or,_ each _if_ with its _then,_ as in\nthe following diagram (the triangles are abbreviations for lots of\nunderbrush that would only entangle us if shown in full):\n\n\nThere is another reason to believe that a sentence is held together by\na mental tree. So far **I** have been talking about stringing words into a\ngrammatical order, ignoring what they mean. But grouping words into\nphrases is also necessary to connect grammatical sentences with their\nproper meanings, chunks of mentalese. We know that the sentence shown\nabove is about a girl, not a boy, eating ice cream, and a boy, not a girl,\neating hot dogs, and we know that the boy's snack is contingent on the\ngirl's, not vice versa. That is because _girl_ and _ice cream_ are connected\ninside their own phrase, as are _boy_ and _hot dogs,_ as are the two sentences\ninvolving the girl. With a chaining device it's just one damn word after\nanother, but with a phrase structure grammar the connectedness of\nwords in the tree reflects the relatedness of ideas in mentalese. Phrase\nstructure, then, is one solution to the engineering problem of taking an\n\n\n102 THE LANGUAGE INSTINCT\n\n\ninterconnected web of thoughts in the mind and encoding them as a\nstring of words that must be uttered, one at a time, by the mouth."
    },
    {
        "document_id": "0",
        "parent_id": 139,
        "parent_text": "102 THE LANGUAGE INSTINCT\n\n\ninterconnected web of thoughts in the mind and encoding them as a\nstring of words that must be uttered, one at a time, by the mouth.\n\nOne way to see how invisible phrase structure determines meaning\nis to recall one of the reasons mentioned in Chapter 3 that language\nand thought have to be different: a particular stretch of language can\ncorrespond to two distinct thoughts. I showed you examples like\n_Child's Stool Is Great for Use in Garden,_ where the single word\n_stool_ has two meanings, corresponding to two entries in the mental\ndictionary. But sometimes a whole sentence has two meanings, even\nif each individual word has only one meaning. In the movie _Animal_\n_Crackers,_ Groucho Marx says, \"I once shot an elephant in my pajamas.\nHow he got into my pajamas I'll never know.\" Here are some similar\nambiguities that accidentally appeared in newspapers:\n\n\nYoko Ono will talk about her husband John Lennon who\nwas killed in an interview with Barbara Walters.\nTwo cars were reported stolen by the Groveton police yesterday.\nThe license fee for altered dogs with a certificate will be $3\n\nand for pets owned by senior citizens who have not been\naltered the fee will be $1.50.\nTonight's program discusses stress, exercise, nutrition, and\n\nsex with Celtic forward Scott Wedman, Dr. Ruth Westheimer, and Dick Cavett.\nWe will sell gasoline to anyone in a glass container.\nFor sale: Mixing bowl set designed to please a cook with\n\nround bottom for efficient beating.\n\n\nThe two meanings in each sentence come from the different ways in\nwhich the words can be joined up in a tree. For example, in _discuss_\n_sex with Dick Cavett,_ the writer put the words together according to\nthe tree at the left (\"PP\" means prepositional phrase): sex is what is\nto be discussed, and it is to be discussed with Dick Cavett.\n\n\nHow Language Works 103"
    },
    {
        "document_id": "0",
        "parent_id": 140,
        "parent_text": "round bottom for efficient beating.\n\n\nThe two meanings in each sentence come from the different ways in\nwhich the words can be joined up in a tree. For example, in _discuss_\n_sex with Dick Cavett,_ the writer put the words together according to\nthe tree at the left (\"PP\" means prepositional phrase): sex is what is\nto be discussed, and it is to be discussed with Dick Cavett.\n\n\nHow Language Works 103\n\n\nThe alternative meaning comes from our analyzing the words according to the tree at the right: the words _sex with Dick Cavett_ form\na single branch of the tree, and sex with Dick Cavett is what is to be\ndiscussed.\n\n\nPhrase structure, clearly, is the kind of stuff language is made of.\nBut what I have shown you is just a toy. In the rest of the chapter I\nwill try to explain the modern Chomskyan theory of how language\nworks. Chomsky's writings are \"classics\" in Mark Twain's sense:\nsomething that everybody wants to have read and nobody wants to\nread. When I come across one of the countless popular books on\nmind, language, and human nature that refer to \"Chomsky's deep\nstructure of meaning common to all human languages\" (wrong in two\nways, we shall see), I know that Chomsky's books of the last twentyfive years are sitting on a high shelf in the author's study, their spines\nuncracked, their folios uncut. Many people want to have a go at\nspeculating about the mind but have the same impatience about\nmastering the details of how language works that Eliza Doolittle\nshowed to Henry Higgins in _Pygmalion_ when she complained, \"I\ndon't want to talk grammar. I want to talk like a lady in a flower\nshop.\"\n\nFor nonspecialists the reaction is even more extreme. In Shakespeare's _The Second Part of King Henry VI,_ the rebel Dick the Butcher\nspeaks the well-known line \"The first thing we do, let's kill all the\nlawyers.\" Less well known is the second thing Dick suggests they do:\nbehead Lord Say. Why? Here is the indictment presented by the\nmob's leader, Jack Cade:\n\n\n104 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 141,
        "parent_text": "For nonspecialists the reaction is even more extreme. In Shakespeare's _The Second Part of King Henry VI,_ the rebel Dick the Butcher\nspeaks the well-known line \"The first thing we do, let's kill all the\nlawyers.\" Less well known is the second thing Dick suggests they do:\nbehead Lord Say. Why? Here is the indictment presented by the\nmob's leader, Jack Cade:\n\n\n104 THE LANGUAGE INSTINCT\n\n\nThou hast most traitorously corrupted the youth of the realm in\nerecting a grammar school. . . . It will be proved to thy face that\nthou hast men about thee that usually talk of a noun and a verb,\nand such abominable words as no Christian ear can endure to hear.\n\n\nAnd who can blame the grammarphobe, when a typical passage from\none of Chomsky's technical works reads as follows?\n\n\nTo summarize, we have been led to the following conclusions, on\nthe assumption that the trace of a zero-level category must be\nproperly governed. 1. VP is α-marked by 1.2. Only lexical categories\nare L-markers, so that VP is not L-marked by I. 3. α-government\nis restricted to sisterhood without the qualification (35). 4. Only the\nterminus of an X0-chain can α-mark or Case-mark. 5. Head-to-head\nmovement forms an A-chain. 6. SPEC-head agreement and chains\ninvolve the same indexing. 7. Chain coindexing holds of the links\nof an extended chain. 8. There is no accidental coindexing of I. 9.\nI-V coindexing is a form of head-head agreement; if it is restricted\nto aspectual verbs, then base-generated structures of the form (174)\ncount as adjunction structures. 10. Possibly, a verb does not prop­\nerly govern its α-marked complement."
    },
    {
        "document_id": "0",
        "parent_id": 142,
        "parent_text": "All this is unfortunate. People, especially those who hold forth on\nthe nature of mind, should be just plain curious about the code that\nthe human species uses to speak and understand. In return, the\nscholars who study language for a living should see that such curiosity\ncan be satisfied. Chomsky's theory need not be treated by either\ngroup as a set of cabalistic incantations that only the initiated can\nmutter. It is a set of discoveries about the design of language that can\nbe appreciated intuitively if one first understands the problems to\nwhich the theory provides solutions. In fact, grasping grammatical\ntheory provides an intellectual pleasure that is rare in the social sci­\nences. When I entered high school in the late 1960s and electives\nwere chosen for their \"relevance,\" Latin underwent a steep decline\nin popularity (thanks to students like me, I confess). Our Latin teacher\nMrs. Rillie, whose merry birthday parties for Rome failed to slow the\ndecline, tried to persuade us that Latin grammar honed the mind\nwith its demands for precision, logic, and consistency. (Nowadays,\nsuch arguments are more likely to come from the computer program\n\nHow Language Works 105\n\n\nming teachers.) Mrs. Rillie had a point, but Latin declensional paradigms are not the best way to convey the inherent beauty of grammar.\nThe insights behind Universal Grammar are much more interesting,\nnot only because they are more general and elegant but because they\nare about living minds rather than dead tongues.\n\n\nLet's start with nouns and verbs. Your grammar teacher may have\nhad you memorize some formula that equated parts of speech with\nkinds of meanings, like\n\n\nA NOUN'S the name of any thing;\nAs _school_ or _garden, hoop_ or _swing._\n\nVERBS tell of something being done;\nTo _read, count, sing, laugh, jump,_ or _run._"
    },
    {
        "document_id": "0",
        "parent_id": 143,
        "parent_text": "Let's start with nouns and verbs. Your grammar teacher may have\nhad you memorize some formula that equated parts of speech with\nkinds of meanings, like\n\n\nA NOUN'S the name of any thing;\nAs _school_ or _garden, hoop_ or _swing._\n\nVERBS tell of something being done;\nTo _read, count, sing, laugh, jump,_ or _run._\n\n\nBut as in most matters about language, she did not get it quite right.\nIt is true that most names for persons, places, and things are nouns,\nbut it is not true that most nouns are names for persons, places, or\nthings. There are nouns with all kinds of meanings:\n\n\nthe _destruction_ of the city [an action]\nthe _way_ to San Jose [a path]\n_whiteness_ moves downward [a quality]\nthree _miles_ along the path [a measurement in space]\nIt takes three _hours_ to solve the problem, [a measurement\nin time]\nTell me the _answer,_ [\"what the answer is,\" a question]\nShe is a _fool,_ [a category or kind]\na _meeting_ [an event]\nthe _square root_ of minus two [an abstract concept]\nHe finally kicked _the bucket,_ [no meaning at all]\n\n\nLikewise, though words for things being done, such as _count_ and\n_jump,_ are usually verbs, verbs can be other things, like mental states\n_(know, like),_ possession _(own, have),_ and abstract relations among\nideas _(falsify, prove)._\n\nConversely, a single concept, like \"being interested,\" can be expressed by different parts of speech:\n\n\n106 THE LANGUAGE INSTINCT\n\n\nher _interest_ in fungi [noun]\nFungi are starting to _interest_ her more and more, [verb]\nShe seems _interested_ in fungi. Fungi seem _interesting_ to her.\n\n[adjective]\n_Interestingly,_ the fungi grew an inch in an hour, [adverb]"
    },
    {
        "document_id": "0",
        "parent_id": 144,
        "parent_text": "Conversely, a single concept, like \"being interested,\" can be expressed by different parts of speech:\n\n\n106 THE LANGUAGE INSTINCT\n\n\nher _interest_ in fungi [noun]\nFungi are starting to _interest_ her more and more, [verb]\nShe seems _interested_ in fungi. Fungi seem _interesting_ to her.\n\n[adjective]\n_Interestingly,_ the fungi grew an inch in an hour, [adverb]\n\n\nA part of speech, then, is not a kind of meaning; it is a kind of\ntoken that obeys certain formal rules, like a chess piece or a poker\nchip. A noun, for example, is simply a word that does nouny things;\nit is the kind of word that comes after an article, can have an _'s_ stuck\nonto it, and so on. There is a connection between concepts and partof-speech categories, but it is a subtle and abstract one. When we\nconstrue an aspect of the world as something that can be identified\nand counted or measured and that can play a role in events, language\noften allows us to express that aspect as a noun, whether or not it is\na physical object. For example, when we say _I have three reasons for_\n_leaving,_ we are counting reasons as if they were objects (though of\ncourse we do not literally think that a reason can sit on a table or be\nkicked across a room). Similarly, when we construe some aspect of\nthe world as an event or state involving several participants that affect\none other, language often allows us to express that aspect as a verb.\nFor example, when we say _The situation justified drastic measures,_ we\nare talking about justification as if it were something the situation\ndid, though again we know that justification is not something we can\nwatch happening at a particular time and place. Nouns are _often_ used\nfor names of things, and verbs for something being done, but because\nthe human mind can construe reality in a variety of ways, nouns and\nverbs are not limited to those uses."
    },
    {
        "document_id": "0",
        "parent_id": 145,
        "parent_text": "Now what about the phrases that group words into branches? One\nof the most intriguing discoveries of modern linguistics is that there\nappears to be a common anatomy in all phrases in all the world's\nlanguages.\n\nTake the English noun phrase. A noun phrase (NP) is named after\none special word, a noun, that must be inside it. The noun phrase\nowes most of its properties to that one noun. For example, the NP\n_the cat in the hat_ refers to a kind of cat, not a kind of hat; the meaning\nof the word _cat_ is the core of the meaning of the whole phrase.\n\n\nHow Language Works 107\n\n\nSimilarly, the phrase _fox in socks_ refers to a fox, not socks, and the\nentire phrase is singular in number (that is, we say that the fox in\nsocks _is_ or _was_ here, not _are_ or _were_ here), because the word _fox_ is\nsingular in number. This special noun is called the \"head\" of the\nphrase, and the information filed with that word in memory \"percolates up\" to the topmost node, where it is interpreted as characterizing\nthe phrase as a whole. The same goes for verb phrases: _flying to Rio_\n_before the police catch him_ is an example of flying, not an example of\ncatching, so the verb _flying_ is called its head. Here we have the first\nprinciple of building the meaning of a phrase out of the meaning of\nthe words inside the phrase. What the entire phrase is \"about\" is\nwhat its head word is about."
    },
    {
        "document_id": "0",
        "parent_id": 146,
        "parent_text": "The second principle allows phrases to refer not just to single things\nor actions in the world but to sets of players that interact with each\nother in a particular way, each with a specific role. For example, the\nsentence _Sergey gave the documents to the spy_ is not just about any\nold act of giving. It choreographs three entities: Sergey (the giver),\ndocuments (the gift), and a spy (the recipient). These role-players are\nusually called \"arguments,\" which has nothing to do with bickering;\nit's the term used in logic and mathematics for a participant in a\nrelationship. A noun phrase, too, can assign roles to one or more\nplayers, as in _picture of John, governor of California,_ and _sex with Dick_\n_Cavett,_ each defining one role. The head and its role-players—other\nthan the subject role, which is special—are joined together in a\nsubphrase, smaller than an NP or a VP, that has the kind of nonmnemonic label that has made generative linguistics so uninviting,\n\n\"N-bar\" and \"V-bar,\" named after the way they are written, N\nand V:\n\n\nThe third ingredient of a phrase is one or more modifiers (usually\ncalled \"adjuncts\"). A modifier is different from a role-player. Take\nthe phrase _the man from Illinois._ Being a man from Illinois is not like\n\n\n108 THE LANGUAGE INSTINCT\n\n\nbeing a governor of California. To be a governor, you have to be a\ngovernor of something; the Californianess plays a role in what it\nmeans for someone to be governor of California. In contrast, _from_\n_Illinois_ is just a bit of information that we add on to help identify\nwhich man we are talking about; being from one state or another is\nnot an inherent part of what it means to be a man. This distinction\nin meaning between role-players and modifiers (\"arguments\" and\n\"adjuncts-,' in lingo) dictates the geometry of the phrase structure tree. The role-player stays next to the head noun inside the Nbar, but the modifier goes upstairs, though still inside the NP house:"
    },
    {
        "document_id": "0",
        "parent_id": 147,
        "parent_text": "This restriction on the geometry of phrase structure trees is not just\nplaying with notation; it is a hypothesis about how the rules of language are set up in our brains, governing the way we talk. It dictates\nthat if a phrase contains both a role-player _and_ a modifier, the roleplayer has to be closer to the head than the modifier is—there's no\nway the modifier could get between the head noun and the roleplayer without crossing branches in the tree (that is, sticking extraneous words in among the bits of the N-bar), which is illegal. Consider\nRonald Reagan. He used to be the governor of California, but he was\nborn in Tampico, Illinois. When he was in office, he could have been\nreferred to as _the governor of California from Illinois_ (role-player, then\nmodifier). It would have sounded odd to refer to him as _the governor_\n_from Illinois of California_ (modifier, then role-player). More pointedly, in 1964 Robert F. Kennedy's senatorial ambitions ran up against\nthe inconvenient fact that both Massachusetts seats were already\noccupied (one by his younger brother Edward). So he simply took\nup residence in New York and ran for the U.S. Senate from there,\nsoon becoming _the senator from New York from Massachusetts._ Not\n_the senator from Massachusetts from New York_ —though that does\n\n\nHow Language Works 109\n\n\ncome close to the joke that Bay Staters used to tell at the time, that\nthey lived in the only state entitled to _three_ senators."
    },
    {
        "document_id": "0",
        "parent_id": 148,
        "parent_text": "How Language Works 109\n\n\ncome close to the joke that Bay Staters used to tell at the time, that\nthey lived in the only state entitled to _three_ senators.\n\nInterestingly, what is true of N-bars and noun phrases is true of Vbars and verb phrases. Say that Sergey gave those documents to the\nspy in a hotel. The phrase _to the spy_ is one of the role-players of the\nverb _give_ —there is no such thing as giving without a getter. Therefore\n_to the spy_ lives with the head verb inside the V-bar. But _in a hotel_ is\na modifier, a comment, an afterthought, and is kept outside the Vbar, in the VP. Thus the phrases are inherently ordered: we can say\n_gave the documents to the spy in a hotel,_ but not _gave in a hotel the_\n_documents to the spy._ When a head is accompanied by just one phrase,\nhowever, that phrase can be either a role-player (inside the V-bar) or\na modifier (outside the V-bar but inside the VP), and the actual order\nof the words is the same. Consider the following newspaper report:\n\n\nOne witness told the commissioners that she had seen sexual\nintercourse taking place between two parked cars in front\nof her house.\n\n\nThe aggrieved woman had a modifier interpretation in mind for\n_between two parked cars,_ but twisted readers give it a role-player\ninterpretation.\n\nThe fourth and final component of a phrase is a special position\nreserved for subjects (which linguists call \"SPEC,\" pronounced\n\"speck,\" short for \"specifier\"; don't ask). The subject is a special\nrole-player, usually the causal agent if there is one. For example, in\nthe verb phrase _the guitarists destroy the hotel room,_ the phrase _the_\n_guitarists_ is the subject; it is the causal agent of the event consisting\nof the hotel room being destroyed. Actually, noun phrases can have\nsubjects too, as in the parallel NP _the guitarists' destruction of the_\n_hotel room._ Here, then, is the full anatomy of a VP and of an NP:\n\n\n110 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 149,
        "parent_text": "110 THE LANGUAGE INSTINCT\n\n\nNow the story begins to get interesting. You must have noticed\nthat noun phrases and verb phrases have a lot in common: (1) a head,\nwhich gives the phrase its name and determines what it is about, (2)\nsome role-players, which are grouped with the head inside a\nsubphrase (the N-bar or V-bar), (3) modifiers, which appear outside\nthe N-or V-bar, and (4) a subject. The orderings inside a noun phrase\nand inside a verb phrase are the same: the noun comes before its roleplayers _(the destruction of the hotel room,_ not _the of the hotel room_\n_destruction),_ and the verb comes before _its_ role-players _(to destroy the_\n_hotel room,_ not _to the hotel room destroy)._ The modifiers go to the\nright in both cases, the subject to the left. It seems as if there is a\nstandard design to the two phrases.\n\nIn fact, the design pops up all over the place. Take, for example,\nthe prepositional phrase (PP) _in the hotel._ It has a head, the preposition _in,_ which means something like \"interior region,\" and then a\nrole, the thing whose interior region is being picked out, in this case\na hotel. And the same goes for the adjective phrase (AP): in _afraid of_\n_the wolf,_ the head adjective, _afraid,_ occurs before its role-player, the\nsource of the fear."
    },
    {
        "document_id": "0",
        "parent_id": 150,
        "parent_text": "In fact, the design pops up all over the place. Take, for example,\nthe prepositional phrase (PP) _in the hotel._ It has a head, the preposition _in,_ which means something like \"interior region,\" and then a\nrole, the thing whose interior region is being picked out, in this case\na hotel. And the same goes for the adjective phrase (AP): in _afraid of_\n_the wolf,_ the head adjective, _afraid,_ occurs before its role-player, the\nsource of the fear.\n\nWith this common design, there is no need to write out a long list\nof rules to capture what is inside a speaker's head. There may be just\none pair of super-rules for the entire language, where the distinctions\namong nouns, verbs, prepositions, and adjectives are collapsed and\nall four are specified with a variable like \"X.\" Since a phrase just\ninherits the properties of its head _(a tall man_ is a kind of _man),_ it's\nredundant to call a phrase headed by a noun a \"noun phrase\"—we\ncould just call it an \"X phrase,\" since the nounhood of the head noun,\nlike the manhood of the head noun and all the other information in\nthe head noun, percolates up to characterize the whole phrase. Here\nis what the super-rules look like (as before, focus on the summary of\nthe rule, not the rule itself):\n\n\nXP —> (SPEC) YP*\n\"A phrase consists of an optional subject, followed by an\nX-bar, followed by any number of modifiers.\"\n\n—> X ZP*\n\"An X-bar consists of a head word, followed by any number\nof role-players.\"\n\n\n**How Language W o r k s** 111\n\n\nJust plug in noun, verb, adjective, or preposition for X, Y, and Z,\nand you have the actual phrase structure rules that spell the phrases.\nThis streamlined version of phrase structure is called \"the X-bar\ntheory.\""
    },
    {
        "document_id": "0",
        "parent_id": 151,
        "parent_text": "XP —> (SPEC) YP*\n\"A phrase consists of an optional subject, followed by an\nX-bar, followed by any number of modifiers.\"\n\n—> X ZP*\n\"An X-bar consists of a head word, followed by any number\nof role-players.\"\n\n\n**How Language W o r k s** 111\n\n\nJust plug in noun, verb, adjective, or preposition for X, Y, and Z,\nand you have the actual phrase structure rules that spell the phrases.\nThis streamlined version of phrase structure is called \"the X-bar\ntheory.\"\n\nThis general blueprint for phrases extends even farther, to other\nlanguages. In English, the head of a phrase comes before its roleplayers. In many languages, it is the other way around—but it is the\nother way around across the board, across all the kinds of phrases in\nthe language. For example, in Japanese, the verb comes _after_ its\nobject, not before: they say _Kenji sushi ate,_ not _Kenji ate sushi._ The\npreposition comes after its noun phrase: _Kenji to,_ not _to Kenji_ (so\nthey are actually called \"postpositions\"). The adjective comes after\nits complement: _Kenji than taller,_ not _taller than Kenji._ Even the\nwords marking questions are flipped: they say, roughly, _Kenji eat did?,_\nnot _Did Kenji eat?_ Japanese and English are looking-glass versions of\neach other. And such consistency has been found in scores of languages: if a language has the verb before the object, as in English, it\nwill also have prepositions; if it has the verb after the object, as in\nJapanese, it will have postpositions.\n\nThis is a remarkable discovery. It means that the super-rules suffice\nnot only for all phrases in English but for all phrases in all languages,\nwith one modification: removing the left-to-right order from each\nsuper-rule. The trees becomes mobiles. One of the rules would say:\n\n\n—> {ZP*, X}\n\"An X-bar is composed of a head X and any number of\nrole-players, in either order.\""
    },
    {
        "document_id": "0",
        "parent_id": 152,
        "parent_text": "This is a remarkable discovery. It means that the super-rules suffice\nnot only for all phrases in English but for all phrases in all languages,\nwith one modification: removing the left-to-right order from each\nsuper-rule. The trees becomes mobiles. One of the rules would say:\n\n\n—> {ZP*, X}\n\"An X-bar is composed of a head X and any number of\nrole-players, in either order.\"\n\n\nTo get English, one appends a single bit of information saying that\nthe order within an X-bar is \"head-first.\" To get Japanese, that bit\nof information would say that the order is \"head-last.\" Similarly, the\nother super-rule (the one for phrases) can be distilled so that left-toright order boils away, and an ordered phrase in a particular language\ncan be reconstituted by adding back either \"X-bar-first\" or \"X-bar last.\" The piece of information that makes one language different\nfrom another is called a parameter.\n\nIn fact, the super-rule is beginning to look less like an exact blueprint for a particular phrase and more like a general guideline or\n\n\nTHE LANGUAGE INSTINCT\n\n\nprinciple for what phrases must look like. The principle is usable only\nafter you combine it with a language's particular setting for the order\nparameter. This general conception of grammar, first proposed by\nChomsky, is called the \"principles and parameters\" theory."
    },
    {
        "document_id": "0",
        "parent_id": 153,
        "parent_text": "In fact, the super-rule is beginning to look less like an exact blueprint for a particular phrase and more like a general guideline or\n\n\nTHE LANGUAGE INSTINCT\n\n\nprinciple for what phrases must look like. The principle is usable only\nafter you combine it with a language's particular setting for the order\nparameter. This general conception of grammar, first proposed by\nChomsky, is called the \"principles and parameters\" theory.\n\nChomsky suggests that the unordered super-rules (principles) are\nuniversal and innate, and that when children learn a particular language, they do not have to learn a long list of rules, because they were\nborn knowing the super-rules. All they have to learn is whether their\nparticular language has the parameter value head-first, as in English,\nor head-last, as in Japanese. They can do that merely by noticing\nwhether a verb comes before or after its object in any sentence in\ntheir parents' speech. If the verb comes before the object, as in _Eat_\n_your spinach!,_ the child concludes that the language is head-first; if it\ncomes after, as in _Your spinach eat!,_ the child concludes that the\nlanguage is head-last. Huge chunks of grammar are then available to\nthe child, all at once, as if the child were merely flipping a switch to\none of two possible positions. If this theory of language learning is\ntrue, it would help solve the mystery of how children's grammar\nexplodes into adultlike complexity in so short a time. They are not\nacquiring dozens or hundreds of rules; they are just setting a few\nmental switches.\n\n\nThe principles and parameters of phrase structure specify only\nwhat kinds of ingredients may go into a phrase in what order. They\ndo not spell out any particular phrase. Left to themselves, they\nwould run amok and produce all kinds of mischief. Take a look at\nthe following sentences, which all conform to the principles or\nsuper-rules. The ones I have marked with an asterisk do not sound\nright.\n\n\nMelvin dined.\n*Melvin dined the pizza.\n\nMelvin devoured the pizza.\n*Melvin devoured."
    },
    {
        "document_id": "0",
        "parent_id": 154,
        "parent_text": "The principles and parameters of phrase structure specify only\nwhat kinds of ingredients may go into a phrase in what order. They\ndo not spell out any particular phrase. Left to themselves, they\nwould run amok and produce all kinds of mischief. Take a look at\nthe following sentences, which all conform to the principles or\nsuper-rules. The ones I have marked with an asterisk do not sound\nright.\n\n\nMelvin dined.\n*Melvin dined the pizza.\n\nMelvin devoured the pizza.\n*Melvin devoured.\n\nMelvin put the car in the garage.\n*Melvin put.\n\n\nHow Language Works 113\n\n\n*Melvin put the car.\n*Melvin put in the garage.\n\nSheila alleged that Bill is a liar.\n*Sheila alleged the claim.\n\n   - Sheila alleged.\n\n\nIt must be the verb's fault. Some verbs, like _dine,_ refuse to appear\nin the company of a direct object noun phrase. Others, like _devour,_\nwon't appear without one. This is true even though _dine_ and _devour_\nare very close in meaning, both being ways of eating. You may dimly\nrecall from grammar lessons that verbs like _dine_ are called \"intransitive\" and verbs like _devour_ are called \"transitive.\" But verbs come in\nmany flavors, not just these two. The verb _put_ is not content unless\nit has both an object NP _(the car)_ and a prepositional phrase _(in the_\n_garage)._ The verb _allege_ requires an embedded sentence _(that Bill is_\n_a liar)_ and nothing else.\n\nWithin a phrase, then, the verb is a little despot, dictating which\nof the slots made available by the super-rules are to be filled. These\ndemands are stored in the verb's entry in the mental dictionary, more\nor less as follows:\n\n\n_dine:_\nverb\nmeans \"to eat a meal in a refined setting\"\neater = subject\n\n_devour:_\nverb\nmeans \"to eat something ravenously\"\neater = subject\nthing eaten = object\n\n_put:_\nverb\nmeans \"to cause something to go to some place\"\nputter = subject\nthing put = object\nplace = prepositional object\n\n\n114 THE LANGUAGE INSTINCT\n\n\n_allege:_\nverb\nmeans \"to declare without proof\ndeclarer = subject\ndeclaration = complement sentence"
    },
    {
        "document_id": "0",
        "parent_id": 155,
        "parent_text": "_dine:_\nverb\nmeans \"to eat a meal in a refined setting\"\neater = subject\n\n_devour:_\nverb\nmeans \"to eat something ravenously\"\neater = subject\nthing eaten = object\n\n_put:_\nverb\nmeans \"to cause something to go to some place\"\nputter = subject\nthing put = object\nplace = prepositional object\n\n\n114 THE LANGUAGE INSTINCT\n\n\n_allege:_\nverb\nmeans \"to declare without proof\ndeclarer = subject\ndeclaration = complement sentence\n\n\nEach of these entries lists a definition (in mentalese) of some kind of\nevent, followed by the players that have roles in the event. The entry\nindicates how each role-player may be plugged into the sentence—\nas a subject, an object, a prepositional object, an embedded sentence,\nand so on. For a sentence to feel grammatical, the verb's demands\nmust be satisfied. _Melvin devoured_ is bad because _devours_ desire for\na \"thing eaten\" role is left unfulfilled. _Melvin dined the pizza_ is bad\nbecause _dine_ didn't order _pizza_ or any other object.\n\nBecause verbs have the power to dictate how a sentence conveys\nwho did what to whom, one cannot sort out the roles in a sentence\nwithout looking up the verb. That is why your grammar teacher got\nit wrong when she told you that the subject of the sentence is the\n\"doer of the action.\" The subject of the sentence is often the doer,\nbut only when the verb says so; the verb can also assign it other roles:\n\n\nThe big bad wolf _frightened_ the three little pigs. [The subject\n\nis doing the frightening.]\nThe three little pigs _feared_ the big bad wolf. [The subject\n\nis being frightened.]\n\nMy true love _gave_ me a partridge in a pear tree. [The subject\n\nis doing the giving.]\nI _received_ a partridge in a pear tree from my true love. [The\n\nsubject is being given to.]\n\nDr. Nussbaum _performed_ plastic surgery. [The subject is\noperating on someone.]\nCheryl _underwent_ plastic surgery. [The subject is being operated on.]"
    },
    {
        "document_id": "0",
        "parent_id": 156,
        "parent_text": "is doing the frightening.]\nThe three little pigs _feared_ the big bad wolf. [The subject\n\nis being frightened.]\n\nMy true love _gave_ me a partridge in a pear tree. [The subject\n\nis doing the giving.]\nI _received_ a partridge in a pear tree from my true love. [The\n\nsubject is being given to.]\n\nDr. Nussbaum _performed_ plastic surgery. [The subject is\noperating on someone.]\nCheryl _underwent_ plastic surgery. [The subject is being operated on.]\n\n\nIn fact, many verbs have two distinct entries, each casting a different set of roles. This can give rise to a common kind of ambiguity, as\nin the old joke: \"Call me a taxi.\" \"OK, you're a taxi.\" In one of the\nHarlem Globetrotters' routines, the referee tells Meadowlark Lemon\n\n\nHow Language Works 115\n\n\nto shoot the ball. Lemon points his finger at the ball and shouts,\n\"Bang!\" The comedian Dick Gregory tells of walking up to a lunch\ncounter in Mississippi during the days of racial segregation. The\nwaitress said to him, \"We don't serve colored people.\" \"That's fine,\"\nhe replied, \"I don't eat colored people. I'd like a piece of chicken.\"\n\n\nSo how do we actually distinguish _Man bites dog_ from _Dog bites_\n_man?_ The dictionary entry for _bite_ says \"The biter is the subject; the\nbitten thing is the object.\" But how do we _find_ subjects and objects\nin the tree? Grammar puts little tags on the noun phrases that can\nbe matched up with the roles laid out in a verb's dictionary entry.\nThese tags are called _cases._ In many languages, cases appear as prefixes\nor suffixes on the nouns. For example, in Latin, the nouns for man\nand dog, _homo_ and _canis,_ change their endings depending on who is\nbiting whom:\n\n\nCanis hominem mordet. [not news]\nHomo canem mordet. [news]"
    },
    {
        "document_id": "0",
        "parent_id": 157,
        "parent_text": "Canis hominem mordet. [not news]\nHomo canem mordet. [news]\n\n\nJulius Caesar knew who bit whom because the noun corresponding\nto the bitee appeared with _-em_ at the end. Indeed, this allowed Caesar\nto find the biter and bitee even when the order of the two was flipped,\nwhich Latin allows: _Hominem canis mordet_ means the same thing as\n_Canis hominem mordet,_ and _Canem homo mordet_ means the same\nthing as _Homo canem mordet._ Thanks to case markers, verbs' dictionary entries can be relieved of the duty of keeping track of where their\nrole-players actually appear in the sentence. A verb need only indicate\nthat, say, the doer is a subject; whether the subject is in first or third\nor fourth position in the sentence is up to the rest of the grammar, and\nthe interpretation is the same. Indeed, in what are called \"scrambling\"\nlanguages, case markers are exploited even further: the article, adjective, and noun inside a phrase are each tagged with a particular case\nmarker, and the speaker can scramble the words of the phrase all\nover the sentence (say, put the adjective at the end for emphasis),\nknowing that the listener can mentally join them back up. This process, called agreement or concord, is a second engineering solution\n(aside from phrase structure itself) to the problem of encoding a\n\n\n116 THE LANGUAGE INSTINCT\n\n\ntangle of interconnected thoughts into strings of words that appear\none after the other."
    },
    {
        "document_id": "0",
        "parent_id": 158,
        "parent_text": "116 THE LANGUAGE INSTINCT\n\n\ntangle of interconnected thoughts into strings of words that appear\none after the other.\n\nCenturies ago, English, like Latin, had suffixes that marked case\novertly. But the suffixes have all eroded, and overt case survives only\nin the personal pronouns—I, _he, she, we, they_ are used for the subject\nrole; _my, his, her, our, their_ are used for the possessor role; _me, him,_\n_her, us, them_ are used for all other roles. (The _who/whom_ distinction\ncould be added to this list, but it is on the way out; in the United\nStates, _whom_ is used consistently only by careful writers and pretentious speakers.) Interestingly, since we all know to say _He saw us_ but\nnever _Him saw we,_ the syntax of case must still be alive and well in\nEnglish. Though nouns appear physically unchanged no matter what\nrole they play, they are tagged with silent cases. Alice realized this\nafter spotting a mouse swimming nearby in her pool of tears:\n\n\n\"Would it be of any use, now,\" thought Alice, \"to speak to this\nmouse? Everything is so out-of-the-way down here, that I should\nthink very likely it can talk: at any rate, there's no harm in trying.\"\nSo she began. \"O Mouse, do you know the way out of this pool? I\nam very tired of swimming about here, O Mouse!\" (Alice thought\nthis must be the right way of speaking to a mouse: she had never\ndone such a thing before, but she remembered having seen, in her\nbrother's Latin Grammar, \"A Mouse—of a mouse—to a mouse—\na mouse—O mouse!\")\n\n\nEnglish speakers tag a noun phrase with a case by seeing what the\nnoun is adjacent to, generally a verb or preposition (but for Alice's\nmouse, the archaic \"vocative\" case marker O). They use these case\ntags to match up each noun phrase with its verb-decreed role."
    },
    {
        "document_id": "0",
        "parent_id": 159,
        "parent_text": "English speakers tag a noun phrase with a case by seeing what the\nnoun is adjacent to, generally a verb or preposition (but for Alice's\nmouse, the archaic \"vocative\" case marker O). They use these case\ntags to match up each noun phrase with its verb-decreed role.\n\nThe requirement that noun phrases must get case tags explains why\ncertain sentences are impossible even though the super-rules admit\nthem. For example, a direct object role-player has to come right after\nthe verb, before any other role-player: one says _Tell Mary that John_\n_is coming,_ not _Tell that John is coming Mary._ The reason is that the\nNP _Mary_ cannot just float around tagless but must be case-marked,\nby sitting adjacent to the verb. Curiously, while verbs and prepositions\ncan mark case on their adjacent NP's, nouns and adjectives cannot:\n_governor California_ and _afraid the wolf,_ though interpretable, are\nungrammatical. English demands that the meaningless preposition _of_\n\n\nHow Language Works 117\n\n\nprecede the noun, as in _governor of California_ and _afraid of the wolf,_\nfor no reason other than to give it a case tag. The sentences we utter\nare kept under tight rein by verbs and prepositions—phrases cannot\njust show up anywhere they feel like in the VP but must have a job\ndescription and be wearing an identity badge at all times. Thus we\ncannot say things like _Last night I slept bad dreams a hangover snoring_\n_no pajamas sheets were wrinkled,_ even though a listener could guess\nwhat that would mean. This marks a major difference between human\nlanguages and, for example, pidgins and the signing of chimpanzees,\nwhere any word can pretty much go anywhere.\n\n\nNow, what about the most important phrase of all, the sentence?\nIf a noun phrase is a phrase built around a noun, and a verb phrase\nis a phrase built around a verb, what is a sentence built around?"
    },
    {
        "document_id": "0",
        "parent_id": 160,
        "parent_text": "Now, what about the most important phrase of all, the sentence?\nIf a noun phrase is a phrase built around a noun, and a verb phrase\nis a phrase built around a verb, what is a sentence built around?\n\nThe critic Mary McCarthy once said of her rival Lillian Hellman,\n\"Every word she writes is a lie, including 'and' and 'the.' \" The insult\nrelies on the fact that a sentence is the smallest thing that can be\neither true or false; a single word cannot be either (so McCarthy is\nalleging that Hellman's lying extends deeper than one would have\nthought possible). A sentence, then, must express some kind of meaning that does not clearly reside in its nouns and verbs but that embraces the entire combination and turns it into a proposition that can\nbe true or false. Take, for example, the optimistic sentence _The Red_\n_Sox will win the World Series._ The word _will_ does not apply to the\nRed Sox alone, nor to the World Series alone, nor to winning alone; it\napplies to an entire concept, the-Red-Sox-winning-the-World-Series.\nThat concept is timeless and therefore truthless. It can refer equally\nwell to some past glory, a hypothetical future one, even to the mere\nlogical possibility, bereft of any hope that it will ever happen. But the\nword _will_ pins the concept down to temporal coordinates, namely\nthe stretch of time subsequent to the moment the sentence is uttered.\nIf I declare \"The Red Sox will win the World Series,\" I can be right\nor wrong (probably wrong, alas).\n\nThe word _will_ is an example of an auxiliary, a word that expresses\nlayers of meaning having to do with the truth of a proposition as the\nspeaker conceives it. These layers also include negation (as in _won't_\nand _doesn't),_ necessity ( _must_ ) _,_ and possibility _(might_ and _can)._ Auxiliaries typically occur at the periphery of sentence trees, mirroring the\n\n\n118 **THE L A N G U A G E INSTINCT**"
    },
    {
        "document_id": "0",
        "parent_id": 161,
        "parent_text": "The word _will_ is an example of an auxiliary, a word that expresses\nlayers of meaning having to do with the truth of a proposition as the\nspeaker conceives it. These layers also include negation (as in _won't_\nand _doesn't),_ necessity ( _must_ ) _,_ and possibility _(might_ and _can)._ Auxiliaries typically occur at the periphery of sentence trees, mirroring the\n\n\n118 **THE L A N G U A G E INSTINCT**\n\n\nfact that they assert something about the rest of the sentence taken\nas a whole. The auxiliary is the head of the sentence in exactly the\nsame way that a noun is the head of the noun phrase. Since the\nauxiliary is also called INFL (for \"inflection\"), we can call the sentence\nan IP (an INFL phrase or auxiliary phrase). Its subject position is\nreserved for the subject of the entire sentence, reflecting the fact that\na sentence is an assertion that some predicate (the VP) is true of its\nsubject. Here, more or less, is what a sentence looks like in the current\nversion of Chomsky's theory:\n\n\nIP\n\n\n**NP** **I**\n\n\n**win the World Series**"
    },
    {
        "document_id": "0",
        "parent_id": 162,
        "parent_text": "IP\n\n\n**NP** **I**\n\n\n**win the World Series**\n\n\nAn auxiliary is an example of a \"function word,\" a different kind\nof word from nouns, verbs, and adjectives, the \"content\" words.\nFunction words include articles _(the, a, some),_ pronouns _(he, she),_\nthe possessive marker _'s,_ meaningless prepositions like _of,_ words that\nintroduce complements like _that_ and _to,_ and conjunctions like _and_\nand _or._ Function words are bits of crystallized grammar; they delineate larger phrases into which NP's and VP's and AP's fit, thereby\nproviding a scaffolding for the sentence. Accordingly, the mind treats\nfunction words differently from content words. People add new content words to the language all the time (like the noun _fax,_ and the\nverb _to snarf,_ meaning to retrieve a computer file), but the function\nwords form a closed club that resists new members. That is why all\nthe attempts to introduce gender-neutral pronouns like _hesh_ and _thon_\nhave failed. Recall, too, that patients with damage to the language\nareas of the brain have more trouble with function words like _or_ and\n_be_ than with content words like _oar_ and _bee._ When words are expen\n\nHow Language Works 119\n\n\nsive, as in telegrams and headlines, writers tend to leave the function\nwords out, hoping that the reader can reconstruct them from the\norder of the content words. But because function words are the most\nreliable clues to the phrase structure of the sentence, telegraphic\nlanguage is always a gamble. A reporter once sent Cary Grant the\ntelegram, \"How old Cary Grant?\" He replied, \"Old Cary Grant\nfine.\" Here are some headlines from a collection called _Squad Helps_\n_Dog Bite Victim,_ put together by the staff of the _Columbia Journalism_\n_Review._\n\n\nNew Housing for Elderly Not Yet Dead\nNew Missouri U. Chancellor Expects Little Sex"
    },
    {
        "document_id": "0",
        "parent_id": 163,
        "parent_text": "New Housing for Elderly Not Yet Dead\nNew Missouri U. Chancellor Expects Little Sex\n\n12 on Their Way to Cruise Among Dead in Plane Crash\nN.J. Judge to Rule on Nude Beach\nChou Remains Cremated\nChinese Apeman Dated\nHershey Bars Protest\nReagan Wins on Budget, But More Lies Ahead.\nDeer Kill 130,000\nComplaints About NBA Referees Growing Ugly\n\n\nFunction words also capture much of what makes one language\ngrammatically different from another. Though all languages have\nfunction words, the properties of the words differ in ways that can\nhave large effects on the structure of the sentences in the language.\nWe have already seen one example: overt case and agreement markers\nin Latin allow noun phrases to be scrambled; silent ones in English\nforce them to remain in place. Function words capture the grammatical look and feel of a language, as in these passages that use a language's function words but none of its content words:\n\n\nDER JAMMERWOCH\n\nEs brillig war. Die schlichte Toven\nWirrten und wimmelten in Waben.\n\n\nLE JASEROQUE\n\nIl brilgue: les toves lubricilleux\nSe gyrent en vrillant dans la guave.\n\n\n120 THE LANGUAGE INSTINCT\n\n\nThe effect can also be seen in passages that take the function words\nfrom one language but the content words from another, like the\nfollowing pseudo-German notice that used to be posted in many\nuniversity computing centers in the English-speaking world:\n\n\nACHTUNG! ALLES LOOKENSPEEPERS!\n\nDas computermachine ist nicht fuer gefingerpoken und mittengrabben. Ist easy schnappen der springenwerk, blowenfusen und poppencorken mit spitzensparken. Ist nicht fuer gewerken bei das\ndumpkopfen. Das rubbernecken sightseeren keepen das cottenpickenen hans in das pockets muss; relaxen und watchen das blinkenlichten.\n\n\nTurnabout being fair play, computer operators in Germany have\nposted a translation into pseudo-English:\n\n\nATTENTION"
    },
    {
        "document_id": "0",
        "parent_id": 164,
        "parent_text": "ACHTUNG! ALLES LOOKENSPEEPERS!\n\nDas computermachine ist nicht fuer gefingerpoken und mittengrabben. Ist easy schnappen der springenwerk, blowenfusen und poppencorken mit spitzensparken. Ist nicht fuer gewerken bei das\ndumpkopfen. Das rubbernecken sightseeren keepen das cottenpickenen hans in das pockets muss; relaxen und watchen das blinkenlichten.\n\n\nTurnabout being fair play, computer operators in Germany have\nposted a translation into pseudo-English:\n\n\nATTENTION\n\nThis room is fulfilled mit special electronische equippment. Fingergrabbing and pressing the cnoeppkes from the computers is\nallowed for die experts only! So all the \"lefthanders\" stay away and\ndo not disturben the brainstorming von here working intelligencies.\nOtherwise you will be out thrown and kicked andeswhere! Also:\nplease keep still and only watchen astaunished the blinkenlights.\n\n\nAnyone who goes to cocktail parties knows that one of Chomsky's\nmain contributions to intellectual life is the concept of \"deep structure,\" together with the \"transformations\" that map it onto \"surface\nstructure.\" When Chomsky introduced the terms in the behaviorist\nclimate of the early 1960s, the reaction was sensational. Deep structure came to refer to everything that was hidden, profound, universal,\nor meaningful, and before long there was talk of the deep structure\nof visual perception, stories, myths, poems, paintings, musical compositions, and so on. Anticlimactically, I must now divulge that \"deep\nstructure\" is a prosaic technical gadget in grammatical theory. It is\nnot the meaning of a sentence, nor is it what is universal across all\nhuman languages. Though universal grammar and abstract phrase\nstructures seem to be permanent features of grammatical theory, many\n\n\nHow Language Works 121\n\n\nlinguists—including, in his most recent writings, Chomsky himself—\nthink one can do without deep structure per se. To discourage all the\nhype incited by the word \"deep,\" linguists now usually refer to it as\n\"d-structure.\" The concept is actually quite simple."
    },
    {
        "document_id": "0",
        "parent_id": 165,
        "parent_text": "How Language Works 121\n\n\nlinguists—including, in his most recent writings, Chomsky himself—\nthink one can do without deep structure per se. To discourage all the\nhype incited by the word \"deep,\" linguists now usually refer to it as\n\"d-structure.\" The concept is actually quite simple.\n\nRecall that for a sentence to be well formed, the verb must get\nwhat it wants: all the roles listed in the verb's dictionary entry must\nappear in their designated positions. But in many sentences, the verb\ndoes not seem to be getting what it wants. Remember that _put_ requires\na subject, an object, and a prepositional phrase; _He put the car_ and\n_He put in the garage_ sound incomplete. How, then, do we account\nfor the following perfectly good sentences?\n\n\nThe car was put in the garage.\nWhat did he put in the garage?\nWhere did he put the car?\n\n\nIn the first sentence, _put_ seems to be doing fine without an object,\nwhich is out of character. Indeed, now it rejects one: _The car was put_\n_the Toyota in the garage_ is awful. In the second sentence, _put_ also\nappears in public objectless. In the third, its obligatory prepositional\nphrase is missing. Does this mean we need to add new dictionary\nentries for _put,_ allowing it to appear in some places without its object\nor its prepositional phrase? Obviously not, or _He put the car_ and _He_\n_put in the garage_ would slip back in.\n\nIn some sense, of course, the required phrases really are there—\nthey're just not where we expect them. In the first sentence, a passive\nconstruction, the NP _the car,_ playing the role of \"thing put\" which\nordinarily would be the object, shows up in the subject position\ninstead. In the second sentence, a _wh_ -question (that is, a question\nformed with _who, what, where, when,_ or _why),_ the \"thing put\" role\nis expressed by the word _what_ and shows up at the beginning. In the\nthird sentence, the \"place\" role also shows up at the beginning instead\nof after the object, where it ordinarily belongs."
    },
    {
        "document_id": "0",
        "parent_id": 166,
        "parent_text": "A simple way to account for the entire pattern is to say that every\nsentence has two phrase structures. The phrase structure we have\nbeen talking about so far, the one defined by the super-rules, is the\ndeep structure. Deep structure is the interface between the mental\ndictionary and phrase structure. In the deep structure, all the roleplayers for _put_ appear in their expected places. Then a transforma\n\n122 THE LANGUAGE INSTINCT\n\n\ntional operation can \"move\" a phrase to a previously unfilled slot\nelsewhere in the tree. That is where we find the phrase in the actual\nsentence. This new tree is the surface structure (now called \"s-structure,\" because as a mere \"surface\" representation it never used to get\nproper respect). Here are the deep structure and surface structure of\na passive sentence:\n\n\nIP IP\n\n\nIn the deep structure on the left, _the car_ is where the verb wanted it; in\nthe surface structure on the right, it is where we actually hear it. In the\nsurface structure, the position from which the phrase was moved con\ntains an inaudible symbol that was left behind by the movement\ntransformation, called a \"trace.\" The trace serves as a reminder of\nthe role that the moved phrase is playing. It tells us that to find out\nwhat _the car_ is doing in the putting event, we should look up the\n\"object\" slot in the entry for the verb _put;_ that slot says \"thing put.\"\nThanks to the trace, the surface structure contains the information\nneeded to recover the meaning of the sentence; the original deep\nstructure, which was used only to plug in the right sets of words from\nthe lexicon, plays no role."
    },
    {
        "document_id": "0",
        "parent_id": 167,
        "parent_text": "Why do languages bother with separate deep structures and surface\nstructures? Because it takes more than just keeping the verb happy—\nwhat deep structure does—to have a usable sentence. A given concept\noften has to play one kind of role, defined by the verb in the verb\nphrase, and simultaneously a separate role, independent of the verb,\ndefined by some other layer of the tree. Consider the difference\nbetween _heavers build dams_ and its passive, _Dams are built by beavers._\n\n\nHow Language Works 123\n\n\nDown in the verb phrase—the level of who did what to whom—the\nnouns are playing the same roles in both sentences. Beavers do the\nbuilding, dams get built. But up at the sentence (IP) level—the level\nof subject-predicate relations, of what is being asserted to be true of\nwhat—they are playing different roles. The active sentence is saying\nsomething about beavers in general, and happens to be true; the\npassive sentence is saying something about dams in general, and\nhappens to be false (since some dams, like the Grand Coulee Dam,\nare not built by beavers). The surface structure, which puts _dams_ in\nthe sentence's subject position but links it to a trace of its original\nverb phrase position, allows the cake to be both eaten and had."
    },
    {
        "document_id": "0",
        "parent_id": 168,
        "parent_text": "The ability to move phrases around while still retaining their roles\nalso gives the speaker of a rigid-word-order language like English a\nbit of wiggle room. For example, phrases that are ordinarily buried\ndeep in the tree can be moved to early in the sentence, where they\ncan hook up with material fresh in the listener's mind. For example,\nif a play-by-play announcer has been describing Nevin Markwart's\nprogression down the ice, he could say _Markwart spears Gretzky!!!_\nBut if it was Wayne Gretzky the announcer had been describing, he\nwould say _Gretzky is speared by Markwart!!!!_ Moreover, because a\npassive participle has the option of leaving the doer role, ordinarily\nthe subject, unfilled in deep structure, it is useful when one wants to\navoid mentioning that role altogether, as in Ronald Reagan's evasive\nconcession _Mistakes were made._\n\nHooking up players with different roles in different scenarios is\nsomething that grammar excels at. In a _wh_ -question like\n\n\nWhat did he put _[trace]_ in the garage?\n\n\nthe noun phrase _what_ gets to live a double life. Down in the whodid-what-to-whom realm of the verb phrase, the position of the trace\nindicates that the entity has the role of the thing being put; up in the\nwhat-is-being-asserted-of-what realm of the sentence, the word _what_\nindicates that the point of the sentence is to ask the listener to provide\nthe identity of something. If a logician were to express the meaning\nbehind the sentence, it would be something like \"For which x, John\nput _x_ in the garage.\" When these movement operations are combined\nwith other components of syntax, as in _She was told by Bob to be_\n_examined by a doctor_ or _Who did he say that Barry tried to convince_\n\n\n124 THE LANGUAGE INSTINCT\n\n\n_to leave?_ or _Tex is fun for anyone to tease,_ the components interact\nto determine the meaning of the sentence in chains of deduction as\nintricate and precise as the workings of a fine Swiss watch."
    },
    {
        "document_id": "0",
        "parent_id": 169,
        "parent_text": "124 THE LANGUAGE INSTINCT\n\n\n_to leave?_ or _Tex is fun for anyone to tease,_ the components interact\nto determine the meaning of the sentence in chains of deduction as\nintricate and precise as the workings of a fine Swiss watch.\n\n\nNow that I have dissected syntax in front of you, I hope your\nreaction is more favorable than Eliza Doolittle's or Jack Cade's. At\nthe very least I hope you are impressed at how syntax is a Darwinian\n\"organ of extreme perfection and complication.\" Syntax is complex,\nbut the complexity is there for a reason. For our thoughts are surely\neven more complex, and we are limited by a mouth that can pronounce a single word at a time. Science has begun to crack the\nbeautifully designed code that our brains use to convey complex\nthoughts as words and their orderings."
    },
    {
        "document_id": "0",
        "parent_id": 170,
        "parent_text": "The workings of syntax are important for another reason. Grammar\noffers a clear refutation of the empiricist doctrine that there is nothing\nin the mind that was not first in the senses. Traces, cases, X-bars, and\nthe other paraphernalia of syntax are colorless, odorless, and tasteless,\nbut they, or something like them, must be a part of our unconscious\nmental life. This should not be surprising to a thoughtful computer\nscientist. There is no way one can write a halfway intelligent program\nwithout defining variables and data structures that do not directly\ncorrespond to anything in the input or output. For example, a graphics program that had to store an image of a triangle inside a circle\nwould not store the actual keystrokes that the user typed to draw the\nshapes, because the same shapes could have been drawn in a different\norder or with a different device like a mouse or a light pen. Nor\nwould it store the list of dots that have to be lit up to display the\nshapes on a video screen, because the user might later want to move\nthe circle around and leave the triangle in place, or make the circle\nbigger or smaller, and one long list of dots would not allow the\nprogram to know which dots belong to the circle and which to the\ntriangle. Instead, the shapes would be stored in some more abstract\nformat (like the coordinates of a few defining points for each shape),\na format that mirrors neither the inputs nor the outputs to the program but that can be translated to and from them when the need\narises.\n\nGrammar, a form of mental software, must have evolved under\nsimilar design specifications. Though psychologists under the influ\n\nHow Language Works 125"
    },
    {
        "document_id": "0",
        "parent_id": 171,
        "parent_text": "Grammar, a form of mental software, must have evolved under\nsimilar design specifications. Though psychologists under the influ\n\nHow Language Works 125\n\n\nence of empiricism often suggest that grammar mirrors commands to\nthe speech muscles, melodies in speech sounds, or mental scripts for\nthe ways that people and things tend to interact, I think all these\nsuggestions miss the mark. Grammar is a protocol that has to interconnect the ear, the mouth, and the mind, three very different\nkinds of machine. It cannot be tailored to any of them but must have\nan abstract logic of its own.\n\nThe idea that the human mind is designed to use abstract variables\nand data structures used to be, and in some circles still is, a shocking\nand revolutionary claim, because the structures have no direct counterpart in the child's experience. Some of the organization of grammar\nwould have to be there from the start, part of the language-learning\nmechanism that allows children to make sense out of the noises they\nhear from their parents. The details of syntax have figured prominently in the history of psychology, because they are a case where\ncomplexity in the mind is not caused by learning; learning is caused\nby complexity in the mind. And that was real news."
    },
    {
        "document_id": "0",
        "parent_id": 172,
        "parent_text": "# 5"
    },
    {
        "document_id": "0",
        "parent_id": 173,
        "parent_text": "#### Words, Words, Words\n\nThe word _glamour_ comes from the word _grammar,_ and since\nthe Chomskyan revolution the etymology has been fitting. Who could\nnot be dazzled by the creative power of the mental grammar, by its\nability to convey an infinite number of thoughts with a finite set of\nrules? There has been a book on mind and matter called _Grammatical_\n_Man,_ and a Nobel Prize lecture comparing the machinery of life to a\ngenerative grammar. Chomsky has been interviewed in _Rolling Stone_\nand alluded to on _Saturday Night Live._ In Woody Allen's story \"The\nWhore of Mensa,\" the patron asks, \"Suppose I wanted Noam Chomsky explained to me by two girls?\" \"It'd cost you,\" she replies.\n\nUnlike the mental grammar, the mental dictionary has had no\ncachet. It seems like nothing more than a humdrum list of words,\neach transcribed into the head by dull-witted rote memorization. In\nthe preface to his _Dictionary,_ Samuel Johnson wrote:\n\n\nIt is the fate of those who dwell at the lower employments of life,\nto be rather driven by the fear of evil, than attracted by the prospect\nof good; to be exposed to censure, without hope of praise; to be\ndisgraced by miscarriage, or punished for neglect, where success\nwould have been without applause, and diligence without reward.\nAmong these unhappy mortals is the writer of dictionaries.\n\n\nJohnson's own dictionary defines _lexicographer_ as \"a harmless drudge,\nthat busies himself in tracing the original, and detailing the signification of words.\"\n\n\n126\n\n\nWords, Words, Words 127\n\n\nIn this chapter we will see that the stereotype is unfair. The world\nof words is just as wondrous as the world of syntax, or even more so.\nFor not only are people as infinitely creative with words as they\nare with phrases and sentences, but memorizing individual words\ndemands its own special virtuosity."
    },
    {
        "document_id": "0",
        "parent_id": 174,
        "parent_text": "Johnson's own dictionary defines _lexicographer_ as \"a harmless drudge,\nthat busies himself in tracing the original, and detailing the signification of words.\"\n\n\n126\n\n\nWords, Words, Words 127\n\n\nIn this chapter we will see that the stereotype is unfair. The world\nof words is just as wondrous as the world of syntax, or even more so.\nFor not only are people as infinitely creative with words as they\nare with phrases and sentences, but memorizing individual words\ndemands its own special virtuosity.\n\nRecall the wug-test, passed by any preschooler: \"Here is a wug.\nNow there are two of them. There are two .\" Before being so\nchallenged, the child has neither heard anyone say, nor been rewarded\nfor saying, the word _wugs._ Therefore words are not simply retrieved\nfrom a mental archive. People must have a mental rule for generating\nnew words from old ones, something like \"To form the plural of a\nnoun, add the suffix _-s.\"_ The engineering trick behind human language—its being a discrete combinatorial system—is used in at least\ntwo different places: sentences and phrases are built out of words by\nthe rules of syntax, and the words themselves are built out of smaller\nbits by another set of rules, the rules of \"morphology.\"\n\nThe creative powers of English morphology are pathetic compared\nto what we find in other languages. The English noun comes in exactly\ntwo forms _(duck_ and _ducks),_ the verb in four _(quack, quacks, quacked,_\n_quacking)._ In modern Italian and Spanish every verb has about fifty\nforms; in classical Greek, three hundred and fifty; in Turkish, two\nmillion! Many of the languages I have brought up, such as Eskimo,\nApache, Hopi, Kivunjo, and American Sign Language, are known for\nthis prodigious ability. How do they do it? Here is an example from\nKivunjo, the Bantu language that was said to make English look like\ncheckers compared to chess. The verb \"Näïkìmlyìïà,\" meaning \"He\nis eating it for her,\" is composed of eight parts:\n\n\n   - N-: A marker indicating that the word is the \"focus\" of"
    },
    {
        "document_id": "0",
        "parent_id": 175,
        "parent_text": "- N-: A marker indicating that the word is the \"focus\" of\n\nthat point in the conversation.\n\n   - -ä-: A subject agreement marker. It identifies the eater as\n\nfalling into Class 1 of the sixteen gender classes, \"human\nsingular.\" (Remember that to a linguist \"gender\" means\nkind, not sex.) Other genders embrace nouns that pertain\nto several humans, thin or extended objects, objects that\ncome in pairs or clusters, the pairs or clusters themselves,\ninstruments, animals, body parts, diminutives (small or\ncute versions of things), abstract qualities, precise locations, and general locales.\n\n\n128 THE LANGUAGE INSTINCT\n\n\n   - -ï-: Present tense. Other tenses in Bantu can refer to today,\n\nearlier today, yesterday, no earlier than yesterday, yesterday or earlier, in the remote past, habitually, ongoing,\nconsecutively, hypothetically, in the future, at an indeterminate time, not yet, and sometimes.\n\n   - -kì-: An object agreement marker, in this case indicating\n\nthat the thing eaten falls into gender Class 7.\n\n   - -m-: A benefactive marker, indicating for whose benefit\n\nthe action is taking place, in this case a member of gender\nClass 1.\n\n   - -lyì-: The verb, \"to eat.\"\n\n   - -ï-: An \"applicative\" marker, indicating that the verb's cast\n\nof players has been augmented by one additional role, in\nthis case the benefactive. (As an analogy, imagine that in\nEnglish we had to add a suffix to the verb _bake_ when it\nis used in _1 baked her a cake_ as opposed to the usual _I_\n_baked a cake.)_\n\n   - -à : A final vowel, which can indicate indicative versus\n\nsubjunctive mood.\n\n\nIf you multiply out the number of possible combinations of the seven\nprefixes and suffixes, the product is about half a million, and that is\nthe number of possible forms per verb in the language. In effect,\nKivunjo and languages like it are building an entire sentence inside a\nsingle complex word, the verb."
    },
    {
        "document_id": "0",
        "parent_id": 176,
        "parent_text": "- -à : A final vowel, which can indicate indicative versus\n\nsubjunctive mood.\n\n\nIf you multiply out the number of possible combinations of the seven\nprefixes and suffixes, the product is about half a million, and that is\nthe number of possible forms per verb in the language. In effect,\nKivunjo and languages like it are building an entire sentence inside a\nsingle complex word, the verb.\n\nBut I have been a bit unfair to English. English is genuinely crude\nin its \"inflectional\" morphology, where one modifies a word to fit the\nsentence, like marking a noun for the plural with _-s_ or a verb for past\ntense with _-ed._ But English holds its own in \"derivational\" morphology, where one creates a new word out of an old one. For example,\nthe suffix _-able,_ as in _learnable, teachable,_ and _huggable,_ converts a\nverb meaning \"to do X\" into an adjective meaning \"capable of having\nX done to it.\" Most people are surprised to learn how many derivational suffixes there are in English. Here are the more common ones:\n\n\n\n-able\n-age\n-al\n\n\n\n-ate\n-ed\n\n-en\n\n\n\n-ify -ize\n\n\n\n-ion\n-ish\n\n\n\n\n**-** ly\n-ment\n\n\nWords, Words, Words 129\n\n\n-an -er -ism -ness\n-ant -ful -ist -ory\n-ance -hood -ity -ous\n\n-ary -ic -ive -y"
    },
    {
        "document_id": "0",
        "parent_id": 177,
        "parent_text": "-able\n-age\n-al\n\n\n\n-ate\n-ed\n\n-en\n\n\n\n-ify -ize\n\n\n\n-ion\n-ish\n\n\n\n\n**-** ly\n-ment\n\n\nWords, Words, Words 129\n\n\n-an -er -ism -ness\n-ant -ful -ist -ory\n-ance -hood -ity -ous\n\n-ary -ic -ive -y\n\n\nIn addition, English is free and easy with \"compounding,\" which\nglues two words together to form a new one, like _toothbrush_ and\n_mouse-eater._ Thanks to these processes, the number of possible\nwords, even in morphologically impoverished English, is immense.\nThe computational linguist Richard Sproat compiled all the distinct\nwords used in the forty-four million words of text from Associated\nPress news stories beginning in mid-February 1988. Up through December 30, the list contained three hundred thousand distinct word\nforms, about as many as in a good unabridged dictionary. You might\nguess that this would exhaust the English words that would ever\nappear in such stories. But when Sproat looked at what came over\nthe wire on December 31, he found no fewer than thirty-five new\nforms, including _instrumenting, counterprograms, armhole, part-Vul-_\n_can, fuzzier, groveled, boulderlike, mega-lizard, traumatological,_ and\n_ex-critters._\n\nEven more impressive, the output of one morphological rule can\nbe the input to another, or to itself: one can talk about the _unmicro-_\n_waveability_ of some French fries or a _toothbrush-holder fastener box_\nin which to keep one's toothbrush-holder fasteners. This makes the\nnumber of possible words in a language bigger than immense; like\nthe number of sentences, it is infinite. Putting aside fanciful coinages\nconcocted for immortality in _Guinness,_ a candidate for the longest\nword to date in English might be _floccinaucinihilipilification,_ defined\nin the _Oxford English Dictionary_ as \"the categorizing of something as\nworthless or trivial.\" But that is a record meant to be broken:"
    },
    {
        "document_id": "0",
        "parent_id": 178,
        "parent_text": "_floccinaucinihilipilificational:_ pertaining to the categorizing\nof something as worthless or trivial\n_floccinaucinihilipilificationalize:_ to cause something to pertain\nto the categorizing of something as worthless or trivial\n_floccinaucinihilipilificationalization:_ the act of causing something to pertain to the categorizing of something as worthless or trivial\n\n\n130 THE LANGUAGE INSTINCT\n\n\n_floccinaucinihilipilificationalizationai._ pertaining to the act\nof causing something to pertain to the categorizing of\nsomething as worthless or trivial\n_floccinaucinihilipilificationalizationalize:_ to cause something\nto pertain to the act of causing something to pertain . . .\n\n\nOr, if you suffer from sesquipedaliaphobia, you can think of your\n_great-grandmother,_ your _great-great-grandmother,_ your _great-great-_\n_great-grandmother,_ and so on, limited only in practice by the number\nof generations since Eve."
    },
    {
        "document_id": "0",
        "parent_id": 179,
        "parent_text": "Or, if you suffer from sesquipedaliaphobia, you can think of your\n_great-grandmother,_ your _great-great-grandmother,_ your _great-great-_\n_great-grandmother,_ and so on, limited only in practice by the number\nof generations since Eve.\n\nWhat's more, words, like sentences, are too delicately layered to\nbe generated by a chaining device (a system that selects an item from\none list, then moves on to some other list, then to another). When\nRonald Reagan proposed the Strategic Defense Initiative, popularly\nknown as Star Wars, he imagined a future in which an incoming\nSoviet missile would be shot down by an _anti-missile missile._ But\ncritics pointed out that the Soviet Union could counterattack with an\n_anti-anti-missile-missile missile._ No problem, said his MIT-educated\nengineers; we'll just build an _anti-anti-anti-missile-missile-missile mis-_\n_sile._ These high-tech weapons need a high-tech grammar—something\nthat can keep track of all the _anti's_ at the beginning of the word so\nthat it can complete the word with an equal number of _missile's,_\nplus one, at the end. A word structure grammar (a phrase structure\ngrammar for words) that can embed a word in between an _anti-_ and\nits _missile_ can achieve these objectives; a chaining device cannot,\nbecause it has forgotten the pieces that it laid down at the beginning\nof the long word by the time it gets to the end.\n\n\nLike syntax, morphology is a cleverly designed system, and many\nof the seeming oddities of words are predictable products of its\ninternal logic. Words have a delicate anatomy consisting of pieces,\ncalled morphemes, that fit together in certain ways. The word structure system is an extension of the X-bar phase structure system, in\nwhich big nounish things are built out of smaller nounish things,\nsmaller nounish things are built out of still smaller nounish things,\nand so on. The biggest phrase involving nouns is the noun phrase; a\nnoun phrase contains an N-bar; an N-bar contains a noun—the\n\n\nWords, Words, Words 131"
    },
    {
        "document_id": "0",
        "parent_id": 180,
        "parent_text": "Words, Words, Words 131\n\n\nword. Jumping from syntax to morphology, we simply continue the\ndissection, analyzing the word into smaller and smaller nounish\npieces.\n\nHere is a picture of the structure of the word _dogs:_\n\n\nThe top of this mini-tree is \"N\" for \"noun\"; this allows the clocking\nmaneuver in which the whole word can be plugged into the noun slot\ninside any noun phrase. Down inside the word, we have two parts:\nthe bare word form _dog,_ usually called the stem, and the plural\ninflection _-s._ The rule responsible for inflected words (the rule of\nwug-test fame) is simply\n\n\nN —> Nstem Ninflection\n\"A noun can consist of a noun stem followed by a noun\ninflection.\"\n\n\nThe rule nicely interfaces with the mental dictionary: _dog_ would be\nlisted as a noun stem meaning \"dog,\" and _-s_ would be listed as a\nnoun inflection meaning \"plural of.\"\n\nThis rule is the simplest, most stripped-down example of anything\nwe would want to call a rule of grammar. In my laboratory we use it\nas an easily studied instance of mental grammar, allowing us to document in great detail the psychology of linguistic rules from infancy to\nold age in both normal and neurologically impaired people, in much\nthe same way that biologists focus on the fruit fly _Drosophila_ to\nstudy the machinery of genes. Though simple, the rule that glues an\ninflection to a stem is a surprisingly powerful computational operation. That is because it recognizes an abstract mental symbol, like\n\"noun stem,\" instead of being associated with a particular list of\nwords or a particular list of sounds or a particular list of meanings.\nWe can use the rule to inflect any item in the mental dictionary that\nlists \"noun stem\" in its entry, without caring what the word means;\n\n\n132 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 181,
        "parent_text": "132 THE LANGUAGE INSTINCT\n\n\nwe can convert not only _dog_ to _dogs_ but also _hour_ to _hours_ and\n_justification_ to _justifications._ Likewise, the rule allows us to form\nplurals without caring what the word sounds like; we pluralize unusual-sounding words as in _the Gorbachevs, the Bachs,_ and _the Mao_\n_Zedongs._ For the same reason, the rule is perfectly happy applying to\nbrand-new nouns, like _faxes, dweebs, wugs,_ and _zots._\n\nWe apply the rule so effortlessly that perhaps the only way I can\ndrum up some admiration for what it accomplishes is to compare\nhumans with a certain kind of computer program that many computer scientists tout as the wave of the future. These programs,\ncalled \"artificial neural networks,\" do not apply a rule like the one I\nhave just shown you. An artificial neural network works by analogy,\nconverting _wug_ to _wugged_ because it is vaguely similar to\n_hug-hugged, walk-walked,_ and thousands of other verbs the network has been trained to recognize. But when the network is faced\nwith a new verb that is unlike anything it has previously been\ntrained on, it often mangles it, because the network does not have\nan abstract, all-embracing category \"verb stem\" to fall back on and\nadd an affix to. Here are some comparisons between what people\ntypically do and what artificial neural networks typically do when\ngiven a wag-test:\n\n\nTYPICAL PAST-TENSE FORM\n\nTYPICAL PAST-TENSE FORM GIVEN BY NEURAL\n\nVERB GIVEN BY PEOPLE NETWORKS\n\nmail mailed membled\nconflict conflicted conflafted\nwink winked wok\nquiver quivered quess\nsatisfy satisfied sedderded\nsmairf smairfed sprurice\ntrilb trilbed treelilt\nsmeej smeejed leefloag\nfrilg frilged freezled\n\n\nStems can be built out of parts, too, in a second, deeper level of\nword assembly. In compounds like _Yugoslavia report, sushi-lover,_\n_broccoli-green,_ and _toothbrush,_\n\n\nWords, Words, Words 133\n\n\n**Nstem**\n\n\n**Nstem** **Nstem**\n\n\nYugoslavia **report**\n\n\ntwo stems are joined together to form a new stem, by the rule\n\n\nNstem —> Nstem Nstem"
    },
    {
        "document_id": "0",
        "parent_id": 182,
        "parent_text": "Stems can be built out of parts, too, in a second, deeper level of\nword assembly. In compounds like _Yugoslavia report, sushi-lover,_\n_broccoli-green,_ and _toothbrush,_\n\n\nWords, Words, Words 133\n\n\n**Nstem**\n\n\n**Nstem** **Nstem**\n\n\nYugoslavia **report**\n\n\ntwo stems are joined together to form a new stem, by the rule\n\n\nNstem —> Nstem Nstem\n\n\"A noun stem can consist of a noun stem followed by\nanother noun stem.\"\n\n\nIn English, a compound is often spelled with a hyphen or by running\nits two words together, but it can also be spelled with a space between\nthe two components as if they were still separate words. This confused\nyour grammar teacher into telling you that in _Yugoslavia report,_ \"Yugoslavia\" is an adjective. To see that this can't be right, just try\ncomparing it with a real adjective like _interesting._ You can say _This_\n_report seems interesting_ but not _This report seems Yugoslavia!_ There\nis a simple way to tell whether something is a compound word or a\nphrase: compounds generally have stress on the first word, phrases\non the second. A _dark room_ (phrase) is any room that is dark, but a\n_dark room_ (compound word) is where photographers work, and a\ndarkroom can be lit when the photographer is done. A _black board_\n(phrase) is necessarily a board that is black, but some _blackboards_\n(compound word) are green or even white. Without pronunciation\nor punctuation as a guide, some word strings can be read either as a\nphrase or as a compound, like the following headlines:\n\n\nSquad Helps Dog Bite Victim\nMan Eating Piranha Mistakenly Sold as Pet Fish\nJuvenile Court to Try Shooting Defendant\n\n\nNew stems can also be formed out of old ones by adding affixes\n(prefixes and suffixes), like the _-al, -ize,_ and _-ation_ I used recursively\nto get longer and longer words ad infinitum (as in _sensationalizational-_\n_ization)._ For example, _-able_ combines with any verb to create an\n\n\n134 T H E L A N G U A G E I N S T I N C T"
    },
    {
        "document_id": "0",
        "parent_id": 183,
        "parent_text": "Squad Helps Dog Bite Victim\nMan Eating Piranha Mistakenly Sold as Pet Fish\nJuvenile Court to Try Shooting Defendant\n\n\nNew stems can also be formed out of old ones by adding affixes\n(prefixes and suffixes), like the _-al, -ize,_ and _-ation_ I used recursively\nto get longer and longer words ad infinitum (as in _sensationalizational-_\n_ization)._ For example, _-able_ combines with any verb to create an\n\n\n134 T H E L A N G U A G E I N S T I N C T\n\n\nadjective, as in _crunch-crunchable._ The suffix _-er_ converts any verb\nto a noun, as in _crunch-cruncher,_ and the suffix _-ness_ converts any\nadjective into a noun, as in _crunchy-crunchiness._\n\n\nAstem\n\n\nVstcm Astemaffix\n\n\ncrunch -able\nThe rule forming them is\n\n\nAstern Stem Astemaffix\n\"An adjective stem can consist of a stem joined to a suffix.\"\n\n\nand a suffix like _-able_ would have a mental dictionary entry like the\nfollowing:\n\n\n_-able:_\n\nadjective stem affix\nmeans \"capable of being X'd\"\nattach me to a verb stem\n\n\nLike inflections, stem affixes are promiscuous, mating with any stem\nthat has the right category label, and so we have _crunchable, scrunch-_\n_able, shmooshable, wuggable,_ and so on. Their meanings are predictable: capable of being crunched, capable of being scrunched, capable\nof being shmooshed, even capable of being \"wugged,\" whatever _wug_\nmeans. (Though I can think of an exception: in the sentence _I asked_\n_him what he thought of my review of his book, and his response_\n_was unprintable,_ the word _unprintable_ means something much more\nspecific than \"incapable of being printed.\")\n\nThe scheme for computing the meaning of a stem out of the meaning of its parts is similar to the one used in syntax: one special element\nis the \"head,\" and it determines what the conglomeration refers to.\nJust as the phrase _the cat in the hat_ is a kind of cat, showing that _cat_\nis its head, a _Yugoslavia report_ is a kind of report, and _shmooshability_\nis a kind of ability, so _report_ and _-ability_ must be the heads of those\n\n\nWords, Words, Words 135"
    },
    {
        "document_id": "0",
        "parent_id": 184,
        "parent_text": "The scheme for computing the meaning of a stem out of the meaning of its parts is similar to the one used in syntax: one special element\nis the \"head,\" and it determines what the conglomeration refers to.\nJust as the phrase _the cat in the hat_ is a kind of cat, showing that _cat_\nis its head, a _Yugoslavia report_ is a kind of report, and _shmooshability_\nis a kind of ability, so _report_ and _-ability_ must be the heads of those\n\n\nWords, Words, Words 135\n\n\nwords. The head of an English word is simply its rightmost morpheme.\n\n\nContinuing the dissection, we can tease stems into even smaller\nparts. The smallest part of a word, the part that cannot be cut up\ninto any smaller parts, is called its root. Roots can combine with\nspecial suffixes to form stems. For example, the root _Darwin_ can be\nfound inside the stem _Darwinian._ The stem _Darwinian_ in turn can be\nfed into the suffixing rule to yield the new stem _Darwinianism._ From\nthere, the inflectional rule could even give us the word _Darwinianisms,_\nembodying all three levels of word structure:\n\n\nInterestingly, the pieces fit together in only certain ways. Thus _Dar-_\n_winism,_ a stem formed by the stem suffix _-ism,_ cannot be a host for\n_-ian,_ because _-ian_ attaches only to roots; hence _Darwinismian_ (which\nwould mean \"pertaining to Darwinism\") sounds ridiculous. Similarly,\n_Darwinsian_ (\"pertaining to the two famous Darwins, Charles and\nErasmus\"), _Darwinsianism,_ and _Darwinsism_ are quite impossible, because whole inflected words cannot have any root or stem suffixes\njoined to them.\n\nDown at the bottommost level of roots and root affixes, we have\nentered a strange world. Take _electricity._ It seems to contain two\nparts, _electric_ and _-ity:_\n\n\n136 THE LANGUAGE INSTINCT\n\n\n**Nstem**\n\n\n**Nroot** **Nrootsuffix**\n\n\n**electric** **-ity**\n\n\nBut are these words really assembled by a rule, gluing a dictionary\nentry for _-ity_ onto the root _electric,_ like this?\n\n\nNstem —> Nroot Nrootsuffix\n\"A noun stem can be composed of a noun root and a\nsuffix.\"\n\n_-ity:_"
    },
    {
        "document_id": "0",
        "parent_id": 185,
        "parent_text": "Down at the bottommost level of roots and root affixes, we have\nentered a strange world. Take _electricity._ It seems to contain two\nparts, _electric_ and _-ity:_\n\n\n136 THE LANGUAGE INSTINCT\n\n\n**Nstem**\n\n\n**Nroot** **Nrootsuffix**\n\n\n**electric** **-ity**\n\n\nBut are these words really assembled by a rule, gluing a dictionary\nentry for _-ity_ onto the root _electric,_ like this?\n\n\nNstem —> Nroot Nrootsuffix\n\"A noun stem can be composed of a noun root and a\nsuffix.\"\n\n_-ity:_\n\nnoun root suffix\nmeans \"the state of being X\"\nattach me to a noun root\n\n\nNot this time. First, you can't get _electricity_ simply by gluing together the word _electric_ and the suffix _-ity_ —that would sound like\n\"electrick itty.\" The root that _-ity_ is attached to has changed its\npronunciation to \"electríss.\" That residue, left behind when the suffix\nhas been removed, is a root that cannot be pronounced in isolation.\n\nSecond, root-affix combinations have unpredictable meanings; the\nneat scheme for interpreting the meaning of the whole from the\nmeaning of the parts breaks down. _Complexity_ is the state of being\ncomplex, but _electricity_ is not the state of being electric (you would\nnever say that the electricity of this new can opener makes it convenient); it is the force powering something electric. Similarly, _instru-_\n_mental_ has nothing to do with instruments, _intoxicate_ is not about\ntoxic substances, one does not recite at a _recital,_ and a five-speed\n_transmission_ is not an act of transmitting.\n\nThird, the supposed rule and affix do not apply to words freely,\nunlike the other rules and affixes we have looked at. For example,\nsomething can be _academic_ or _acrobatic_ or _aerodynamic_ or _alcoholic,_\nbut _academicity,_ _acrobaticity,_ _aerodynamicity,_ and _alcoholicity_ sound\nhorrible (to pick just the first four words ending in _-ic_ in my electronic\ndictionary).\n\nSo at the third and most microscopic level of word structure, roots\n\n\nWords, Words, Words 137"
    },
    {
        "document_id": "0",
        "parent_id": 186,
        "parent_text": "Third, the supposed rule and affix do not apply to words freely,\nunlike the other rules and affixes we have looked at. For example,\nsomething can be _academic_ or _acrobatic_ or _aerodynamic_ or _alcoholic,_\nbut _academicity,_ _acrobaticity,_ _aerodynamicity,_ and _alcoholicity_ sound\nhorrible (to pick just the first four words ending in _-ic_ in my electronic\ndictionary).\n\nSo at the third and most microscopic level of word structure, roots\n\n\nWords, Words, Words 137\n\n\nand their affixes, we do not find bona fide rules that build words\naccording to predictable formulas, _wug-style._ The stems seem to be\nstored in the mental dictionary with their own idiosyncratic meanings\nattached. Many of these complex stems originally were formed after\nthe Renaissance, when scholars imported many words and suffixes\ninto English from Latin and French, using some of the rules appropriate to those languages of learning. We have inherited the words,\nbut not the rules. The reason to think that modern English speakers\nmentally analyze these words as trees at all, rather than as homogeneous strings of sound, is that we all sense that there is a natural\nbreak point between the _electric_ and the _-ity._ We also recognize that\nthere is an affinity between the word _electric_ and the word _electricity,_\nand we recognize that any other word containing _-ity_ must be a noun."
    },
    {
        "document_id": "0",
        "parent_id": 187,
        "parent_text": "Our ability to appreciate a pattern inside a word, while knowing\nthat the pattern is not the product of some potent rule, is the inspiration for a whole genre of wordplay. Self-conscious writers and speakers often extend Latinate root suffixes to new forms by analogy, such\nas _religiosity, criticality, systematicity,_ _randomicity, insipidify, calumni-_\n_ate,_ _conciliate,_ _stereotypy,_ _disaffiliate,_ _gallonage,_ and _Shavian._ The\nwords have an air of heaviosity and seriosity about them, making the\nstyle an easy target for parody. A 1982 editorial cartoon by Jeff\nMacNelly put the following resignation speech into the mouth of\nAlexander Haig, the malaprop-prone Secretary of State:\n\n\nI decisioned the necessifaction of the resignatory action/option due\nto the dangerosity of the trendflowing of foreign policy away from\nour originatious careful coursing towards consistensivity, purposity,\nsteadfastnitude, and above all, clarity.\n\n\nAnother cartoon, by Tom Toles, showed a bearded academician explaining the reason verbal Scholastic Aptitude Test scores were at an\nall-time low:\n\n\nIncomplete implementation of strategized programmatics designated to maximize acquisition of awareness and utilization of communications skills pursuant to standardized review and assessment\nof languaginal development.\n\n\nIn the culture of computer programmers and managers, this analogymaking is used for playful precision, not pomposity. _The New_\n\n\n138 THE LANGUAGE INSTINCT\n\n\n_Hacker's Dictionary,_ a compilation of hackish jargon, is a near-exhaustive catalogue of the not-quite-freely-extendible root affixes in English:"
    },
    {
        "document_id": "0",
        "parent_id": 188,
        "parent_text": "In the culture of computer programmers and managers, this analogymaking is used for playful precision, not pomposity. _The New_\n\n\n138 THE LANGUAGE INSTINCT\n\n\n_Hacker's Dictionary,_ a compilation of hackish jargon, is a near-exhaustive catalogue of the not-quite-freely-extendible root affixes in English:\n\n\n_ambimoustrous_ adj. Capable of operating a mouse with\neither hand.\n_barfulous_ adj. Something that would make anyone barf.\n_bogosity_ n. The degree to which something is bogus.\n_bogotify_ v. To render something bogus.\n_bozotic_ adj. Having the quality of Bozo the Clown.\n_cuspy_ adj. Functionally elegant.\n_depeditate_ v. To cut the feet off of (e.g., while printing the\nbottom of a page).\n_dimwittery_ n. Example of a dim-witted statement.\n_geekdom_ n. State of being a techno-nerd.\n_marketroid_ n. Member of a company's marketing department.\n_mumblage_ n. The topic of one's mumbling.\n_pessimal_ adj. Opposite of \"optimal.\"\n\n_wedgitude_ n. The state of being wedged (stuck; incapable\n\nof proceeding without help).\n_wizardly_ adj. Pertaining to expert programmers.\n\n\nDown at the level of word roots, we also find messy patterns in\nirregular plurals like _mouse-mice_ and _man-men_ and in irregular pasttense forms like _drink-drank_ and _seek-sought._ Irregular forms tend\nto come in families, like _drink-drank, sink-sank, shrink-shrank,_\n_stink-stank,_ _sing-sang,_ _ring-rang,_ _spring-sprang,_ _swim-swam,_ and\n_sit-sat,_ or _blow-blew,_ _know-knew,_ _grow-grew,_ _throw-threw,_\n_fly-flew,_ and _slay-slew._ This is because thousands of years ago ProtoIndo-European, the language ancestral to English and most other\nEuropean languages, had rules that replaced one vowel with another\nto form the past tense, just as we now have a rule that adds _-ed._ The\nirregular or \"strong\" verbs in modern English are mere fossils of\nthese rules; the rules themselves are dead and gone. Most verbs that\nwould seem eligible to belong to the irregular families are arbitrarily\nexcluded, as we see in the following doggerel:"
    },
    {
        "document_id": "0",
        "parent_id": 189,
        "parent_text": "Words, Words, Words 139\n\n\nSally Salter, she was a young teacher who taught,\nAnd her friend, Charley Church, was a preacher who praught;\nThough his enemies called him a screecher, who scraught.\n\nHis heart, when he saw her, kept sinking, and sunk;\nAnd his eye, meeting hers, began winking, and wunk;\nWhile she in her turn, fell to thinking, and thunk.\n\nIn secret he wanted to speak, and he spoke,\nTo seek with his lips what his heart long had soke,\nSo he managed to let the truth leak, and it loke.\n\nThe kiss he was dying to steal, then he stole;\nAt the feet where he wanted to kneel, then he knole;\nAnd he said, \"I feel better than ever I fole.\"\n\n\nPeople must simply be memorizing each past-tense form separately.\nBut as this poem shows, they can be sensitive to the patterns among\nthem and can even extend the patterns to new words for humorous\neffect, as in Haigspeak and hackspeak. Many of us have been tempted\nby the cuteness of _sneeze-snoze, squeeze-squoze, take-took-tooken,_\nand _shit-shat,_ which are based on analogies with _freeze-froze,_\n_break-broke-broken,_ and _sit-sat._ In _Crazy English_ Richard Lederer\nwrote an essay called \"Foxen in the Henhice,\" featuring irregular\nplurals gone mad: _booth-beeth,_ _harmonica-harmonicae,_\n_mother-methren,_ _drum-dra,_ _Kleenex-Kleenices,_ and _bathtub-bath-_\n_tubim._ Hackers speak of _faxen, VAXen, boxen, meece,_ and _Macin-_\n_teesh._ _Newsweek_ magazine once referred to the white-caped,\nrhinestone-studded Las Vegas entertainers as _Elvii._ In the _Peanuts_\ncomic strip, Linus's teacher Miss Othmar once had the class glue\neggshells into model _igli._ Maggie Sullivan wrote an article in the\n_New York Times_ calling for \"strengthening\" the English language by\nconjugating more verbs as if they were strong:\n\n\n_Subdue, subdid, subdone:_ Nothing could have subdone him\n\nthe way her violet eyes subdid him.\n_Seesaw, sawsaw, seensaw:_ While the children sawsaw, the\n\nold man thought of long ago when he had seensaw.\n_Pay, pew, pain:_ He had pain for not choosing a wife more\n\ncarefully."
    },
    {
        "document_id": "0",
        "parent_id": 190,
        "parent_text": "_Subdue, subdid, subdone:_ Nothing could have subdone him\n\nthe way her violet eyes subdid him.\n_Seesaw, sawsaw, seensaw:_ While the children sawsaw, the\n\nold man thought of long ago when he had seensaw.\n_Pay, pew, pain:_ He had pain for not choosing a wife more\n\ncarefully.\n\n\n140 THE LANGUAGE INSTINCT\n\n\n_Ensnare, ensnore, ensnorn:_ In the 60's and 70's, Sominex\nads ensnore many who had never been ensnorn by ads\nbefore.\n_Commemoreat, commemorate, commemoreaten:_ At the banquet to commemoreat Herbert Hoover, spirits were high,\nand by the end of the evening many other Republicans\nhad been commemoreaten.\n\n\nIn Boston there is an old joke about a woman who landed at Logan\nAirport and asked the taxi driver, \"Can you take me someplace where\nI can get scrod?\" He replied, \"Gee, that's the first time I've heard it\nin the pluperfect subjunctive.\"\n\nOccasionally a playful or cool-sounding form will catch on and\nspread through the language community, as _catch-caught_ did several\nhundred years ago on the analogy of _teach-taught_ and as _sneak-snuck_\nis doing today on the analogy of _stick-stuck._ (I am told that _has tooken_\nis the preferred form among today's mall rats.) This process can be\nseen clearly when we compare dialects, which retain the products of\ntheir own earlier fads. The curmudgeonly columnist H. L. Mencken\nwas also a respectable amateur linguist, and he documented many\npast-tense forms found in American regional dialects, like _heat-_\n_het_ (similar to _bleed-bled),_ _drag-drug_ _(dig-dug),_ and _help-holp_\n_(tell-told)._ Dizzy Dean, the St. Louis Cardinals pitcher and CBS\nannouncer, was notorious for saying \"He slood into second base,\"\ncommon in his native Arkansas. For four decades English teachers\nacross the nation engaged in a letter-writing campaign to CBS demanding that he be removed, much to his delight. One of his replies,\nduring the Great Depression, was \"A lot of folks that ain't sayin'\n'ain't' ain't eatin'.\" Once he baited them with the following play-byplay:"
    },
    {
        "document_id": "0",
        "parent_id": 191,
        "parent_text": "The pitcher wound up and flang the ball at the batter. The batter\nswang and missed. The pitcher flang the ball again and this time\nthe batter connected. He hit a high fly right to the center fielder\nThe center fielder was all set to catch the ball, but at the last minute\nhis eyes were blound by the sun and he dropped it!\n\n\nBut successful adoptions of such creative extensions are rare; irregulars remain mostly as isolated oddballs.\n\n\nWords, Words, Words 141\n\n\nIrregularity in grammar seems like the epitome of human eccentricity and quirkiness. Irregular forms are explicitly abolished in \"rationally designed\" languages like Esperanto, Orwell's Newspeak, and\nPlanetary League Auxiliary Speech in Robert Heinlein's science fiction novel _Time for the Stars._ Perhaps in defiance of such regimentation, a woman in search of a nonconformist soulmate recently wrote\nthis personal ad in the _New York Review of Books:_\n\n\nAre you an irregular verb who believes\nnouns have more power than adjectives? Unpretentious, professional\nDWF, 5 yr. European resident, sometime violinist, slim, attractive, with married children... . Seeking sensitive,\nsanguine, youthful man, mid 50's-60's,\nhealth-conscious, intellectually adventurous, who values truth, loyalty, and\nopenness.\n\n\nA general statement of irregularity and the human condition comes\nfrom the novelist Marguerite Yourcenar: \"Grammar, with its mixture\nof logical rule and arbitrary usage, proposes to a young mind a foretaste of what will be offered to him later on by law and ethics, those\nsciences of human conduct, and by all the systems wherein man has\ncodified his instinctive experience.\""
    },
    {
        "document_id": "0",
        "parent_id": 192,
        "parent_text": "A general statement of irregularity and the human condition comes\nfrom the novelist Marguerite Yourcenar: \"Grammar, with its mixture\nof logical rule and arbitrary usage, proposes to a young mind a foretaste of what will be offered to him later on by law and ethics, those\nsciences of human conduct, and by all the systems wherein man has\ncodified his instinctive experience.\"\n\nFor all its symbolism about the freewheeling human spirit, though,\nirregularity is tightly encapsulated in the word-building system; the\nsystem as a whole is quite cuspy. Irregular forms are roots, which are\nfound inside stems, which are found inside words, some of which can\nbe formed by regular inflection. This layering not only predicts many\nof the possible and impossible words of English (for example, why\n_Darwinianism_ sounds better than _Darwinismian);_ it provides a neat\nexplanation for many trivia questions about seemingly illogical usage,\nsuch as: Why in baseball is a batter said to have _flied out_ —why has\nno mere mortal ever _flown out_ to center field? Why is the hockey\nteam in Toronto called the _Maple Leafs_ and not the _Maple Leaves?_\nWhy do many people say _Walkmans,_ rather than _Walkmen,_ as the\n\n\n142 THE LANGUAGE INSTINCT\n\n\nplural of _Walkman?_ Why would it sound odd for someone to say that\nall of his daughter's friends are _low-lives?_"
    },
    {
        "document_id": "0",
        "parent_id": 193,
        "parent_text": "142 THE LANGUAGE INSTINCT\n\n\nplural of _Walkman?_ Why would it sound odd for someone to say that\nall of his daughter's friends are _low-lives?_\n\nConsult any style manual or how-to book on grammar, and it will\ngive one of two explanations as to why the irregular is tossed aside—\nboth wrong. One is that the books are closed on irregular words in\nEnglish; any new form added to the language must be regular. Not\ntrue: if I coin new words like _to re-sing_ or _to out-sing,_ their pasts are\n_re-sang_ and _out-sang,_ not _re-singed_ and _out-singed._ Similarly, I recently\nread that there are peasants who run around with small tanks in\nChina's oil fields, scavenging oil from unguarded wells; the article\ncalls them _oil-mice,_ not _oil-mouses._ The second explanation is that\nwhen a word acquires a new, nonliteral sense, like baseball's _fly out,_\nthat sense requires a regular form. The oil-mice clearly falsify that\nexplanation, as do the many other metaphors based on irregular\nnouns, which steadfastly keep their irregularity: _sawteeth_ (not _saw-_\n_tooths), Freud's intellectual children_ (not _childs), snowmen_ (not _snow-_\n_mans),_ and so on. Likewise, when the verb _to blow_ developed slang\nmeanings like _to blow him away_ (assassinate) and _to blow it off_ (dismiss\ncasually), the past-tense forms remained irregular: _blew him away_ and\n_blew off the exam,_ not _blowed him away_ and _blowed off the exam._"
    },
    {
        "document_id": "0",
        "parent_id": 194,
        "parent_text": "The real rationale for _flied out_ and _Walkmans_ comes from the\nalgorithm for interpreting the meanings of complex words from the\nmeanings of the simple words they are built out of. Recall that when\na big word is built out of smaller words, the big word gets all its\nproperties from one special word sitting inside it at the extreme right:\nthe head. The head of the verb _to overshoot_ is the verb _to shoot,_ so\n_overshooting_ is a kind of _shooting,_ and it is a verb, because _shoot_ is a\nverb. Similarly, a _workman_ is a singular noun, because _man,_ its head,\nis a singular noun, and it refers to a kind of man, not a kind of work.\nHere is what the word structures look like:\n\n\nV N\n\n\nP V N N\n\n\nover shoot work man\n\n\nCrucially, the percolation conduit from the head to the top node\napplies to _all_ the information stored with the head word: not just its\n\n\nWords, Words, Words 143\n\n\nnounhood or verbhood, and not just its meaning, but any irregular\nform that is stored with it, too. For example, part of the mental\ndictionary entry for _shoot_ would say \"I have my own irregular pasttense form, _shot.\"_ This bit of information percolates up and applies\nto the complex word, just like any other piece of information. The\npast tense of _overshoot_ is thus _overshot_ (not _overshooted)._ Likewise,\nthe word _man_ bears the tag \"My plural is _men.\"_ Since _man_ is the\nhead of _workman,_ the tag percolates up to the N symbol standing for\n_workman,_ and so the plural of _workman_ is _workmen._ This is also why\nwe get _out-sang, oil-mice, sawteeth,_ and _blew him away._"
    },
    {
        "document_id": "0",
        "parent_id": 195,
        "parent_text": "Now we can answer the trivia questions. The source of quirkiness\nin words like _fly out_ and _Walkmans_ is their _headlessness._ A headless\nword is an exceptional item that, for one reason or another, differs\nin some property from its rightmost element, the one it would be\nbased on if it were like ordinary words. A simple example of a headless\nword is a _low-life_ —not a kind of life at all but a kind of person,\nnamely one who leads a low life. In the word _low-life,_ then, the normal\npercolation pipeline must be blocked. Now, a pipeline inside a word\ncannot be blocked for just one kind of information; if it is blocked\nfor one thing, nothing passes through. If _low-life_ does not get its\nmeaning from _life,_ it cannot get its plural from _life_ either. The irregular\nform associated with _life,_ namely _lives,_ is trapped in the dictionary,\nwith no way to bubble up to the whole word _low-life._ The all-purpose\nregular rule, \"Add the _-s_ suffix,\" steps in by default, and we get _low-_\n_lifes._ By similar unconscious reasoning, speakers arrive at _saber-tooths_\n(a kind of tiger, not a kind of tooth), _tenderfoots_ (novice cub scouts,\nwho are not a kind of foot but a kind of youngster that has tender\n_ieet),flatfoots_ (also not a kind of foot but a slang term for policemen),\nand _still lifes_ (not a kind of life but a kind of painting).\n\nSince the Sony Walkman was introduced, no one has been sure\nwhether two of them should be _Walkmen_ or _Walkmans._ (The nonsexist alternative _Walkperson_ would leave us on the hook, because we\nwould be faced with a choice between _Walkpersons_ and _Walkpeople.)_\nThe temptation to say _Walkmans_ comes from the word's being headless: a Walkman is not a kind of man, so it must not be getting its\nmeaning from the word _man_ inside it, and by the logic of headlessness\nit shouldn't receive a plural form from _man,_ either. But it is hard to\nbe comfortable with any kind of plural, because the relation between\n_Walkman_ and _man_ feels utterly obscure. It feels obscure because the"
    },
    {
        "document_id": "0",
        "parent_id": 196,
        "parent_text": "144 THE LANGUAGE INSTINCT\n\n\nword was not put together by any recognizable scheme. It is an\nexample of the pseudo-English that is popular in Japan in signs and\nproduct names. (For example, one popular soft drink is called Sweat,\nand T-shirts have enigmatic inscriptions like CIRCUIT BEAVER, NURSE\n\nMENTALITY, and BONERACTIVE WEAR.) The Sony Corporation has an\nofficial answer to the question of how to refer to more than one\nWalkman. Fearing that their trademark, if converted to a noun, may\nbecome as generic as _aspirin_ or _kleenex,_ they sidestep the grammatical\nissues by insisting upon _Walkman Personal Stereos._\n\nWhat about flying out? To the baseball cognoscenti, it is not directly based on the familiar verb _to fly_ (\"to proceed through the air\")\nbut on the noun _a fly_ (\"a ball hit on a conspicuously parabolic\ntrajectory\"). To _fly out_ means \"to make an out by hitting a fly that\ngets caught.\" The noun _a fly,_ of course, itself came from the verb _to_\n_fly._ The word-within-a-word-within-a-word structure can be seen in\nthis bamboo-like tree:\n\n\nSince the whole word, represented by its topmost label, is a verb, but\nthe element it is made out of one level down is a noun, _to fly out,_ like\n_low-life,_ must be headless—if the noun _fly_ were its head, _fly out_ would\nhave to be a noun, too, which it is not. Lacking a head and its\nassociated data pipeline, the irregular forms of the original verb _to_\n_fly,_ namely _flew_ and _flown,_ are trapped at the bottommost level and\ncannot bubble up to attach to the whole word. The regular _-ed_ rule\nrushes in in its usual role as the last resort, and thus we say that Wade\nBoggs _flied out._ What kills the irregularity of _to fly out,_ then, is not\nits specialized meaning, but its being a verb based on a word that is\nnot a verb. By the same logic, we say _They ringed the city with artillery_\n(\"formed a ring around it\"), not _They rang the city with artillery,_ and\n_He grandstanded to the crowd_ (\"played to the grandstand\"), not _He_\n_grandstood to the crowd._"
    },
    {
        "document_id": "0",
        "parent_id": 197,
        "parent_text": "Words, Words, Words 145\n\n\nThis principle works every time. Remember Sally Ride, the astronaut? She received a lot of publicity because she was America's first\nwoman in space. But recently Mae Jemison did her one better. Not\nonly is Jemison America's first _black_ woman in space, but she appeared in _People_ magazine in 1993 in their list of the fifty most\nbeautiful people in the world. Publicity-wise, she has out-Sally-Rided\nSally Ride (not _has out-Sally-Ridden Sally Ride)._ For many years New\nYork State's most infamous prison was Sing Sing. But since the riot\nat the Attica Correctional Facility in 1971, Attica has become even\nmore infamous: it has out-Sing-Singed Sing Sing (not _has out-Sing-_\n_Sung Sing Sing)._\n\nAs for the Maple Leafs, the noun being pluralized is not _leaf,_ the\nunit of foliage, but a noun based on the _name_ Maple Leaf, Canada's\nnational symbol. A name is not the same thing as a noun. (For\nexample, whereas a noun may be preceded by an article like _the,_ a\nname may not be: you cannot refer to someone as _the Donald,_ unless\nyou are Ivana Trump, whose first language is Czech.) Therefore, the\nnoun _a Maple Leaf_ (referring to, say, the goalie) must be headless,\nbecause it is a noun based on a word that is not a noun. And a noun\nthat does not get its nounhood from one of its components cannot\nget an irregular plural from that component either; hence it defaults\nto the regular form _Maple Leafs._ This explanation also answers a\nquestion that kept bothering David Letterman throughout one of his\nrecent _Late Night_ shows: why is the new major league baseball team\nin Miami called the Florida Marlins rather than the Florida Marlin,\ngiven that those fish are referred to in the plural as _marlin?_ Indeed,\nthe explanation applies to all nouns based on names:"
    },
    {
        "document_id": "0",
        "parent_id": 198,
        "parent_text": "I'm sick of dealing with all the _Mickey Mouses_ in this administration, [not _Mickey Mice]_\nHollywood has been relying on movies based on comic\nbook heroes and their sequels, like the three _Supermans_\nand the two _Batmans._ [not _Supermen_ and _Batmen]_\nWhy has the second half of the twentieth century produced\nno _Thomas Manns?_ [not _Thomas Menn]_\nWe're having Julia Child and her husband over for dinner\ntonight. You know, _the Childs_ are great cooks. [not _the_\n_Children]_\n\n\n146 THE LANGUAGE INSTINCT\n\n\nIrregular forms, then, live at the bottom of word structure trees,\nwhere roots and stems from the mental dictionary are inserted. The\ndevelopmental psycholinguist Peter Gordon has capitalized on this\neffect in an ingenious experiment that shows how children's minds\nseem to be designed with the logic of word structure built in.\n\nGordon focused on a seeming oddity first noticed by the linguist\nPaul Kiparsky: compounds can be formed out of irregular plurals but\nnot out of regular plurals. For example, a house infested with mice\ncan be described as _mice-infested,_ but it sounds awkward to describe\na house infested with rats as _rats-infested._ We say that it is _rat-infested,_\neven though by definition one rat does not make an infestation.\nSimilarly, there has been much talk about _men-bashing_ but no talk\nabout _gays-bashing_ (only _gay-bashing),_ and there are _teethmarks,_ but\nno _clawsmarks._ Once there was a song about a _purple-people-eater,_\nbut it would be ungrammatical to sing about a _purple-babies-eater._\nSince the licit irregular plurals and the illicit regular plurals have\nsimilar meanings, it must be the grammar of irregularity that makes\nthe difference."
    },
    {
        "document_id": "0",
        "parent_id": 199,
        "parent_text": "The theory of word structure explains the effect easily. Irregular\nplurals, because they are quirky, have to be stored in the mental\ndictionary as roots or stems; they cannot be generated by a rule.\nBecause of this storage, they can be fed into the compounding rule\nthat joins an existing stem to another existing stem to yield a new\nstem. But regular plurals are not stems stored in the mental dictionary;\nthey are complex words that are assembled on the fly by inflectional\nrules whenever they are needed. They are put together too late in the\nroot-to-stem-to-word assembly process to be available to the compounding rule, whose inputs can only come out of the dictionary.\n\nGordon found that three- to five-year-old children obey this restriction fastidiously. Showing the children a puppet, he first asked them,\n\"Here is a monster who likes to eat mud. What do you call him?\"\nHe then gave them the answer, _a mud-eater,_ to get them started.\nChildren like to play along, and the more gruesome the meal, the\nmore eagerly they fill in the blank, often to the dismay of their\nonlooking parents. The crucial parts came next. A \"monster who\nlikes to eat mice,\" the children said, was a _mice-eater._ But a \"monster\nwho likes to eat rats\" was never called a _rats-eater,_ only a _rat-eater._\n\n\nWords, Words, Words 147\n\n\n(Even the children who made the error _mouses_ in their spontaneous\nspeech never called the puppet a _mouses-eater.)_ The children, in other\nwords, respected the subtle restrictions on combining plurals and\ncompounds inherent in the word structure rules. This suggests that\nthe rules take the same form in the unconscious mind of the child as\nthey do in the unconscious mind of the adult."
    },
    {
        "document_id": "0",
        "parent_id": 200,
        "parent_text": "Words, Words, Words 147\n\n\n(Even the children who made the error _mouses_ in their spontaneous\nspeech never called the puppet a _mouses-eater.)_ The children, in other\nwords, respected the subtle restrictions on combining plurals and\ncompounds inherent in the word structure rules. This suggests that\nthe rules take the same form in the unconscious mind of the child as\nthey do in the unconscious mind of the adult.\n\nBut the most interesting discovery came when Gordon examined\nhow children might have acquired this constraint. Perhaps, he reasoned, they learned it from their parents by listening for whether the\nplurals that occur inside the parents' compounds are irregular, regular, or both, and then duplicate whatever kinds of compounds they\nhear. This would be impossible, he discovered. Motherese just doesn't\nhave any compounds containing plurals. Most compounds are like\n_toothbrush,_ with singular nouns inside them; compounds like _mice-_\n_infested,_ though grammatically possible, are seldom used. The children produced _mice-eater_ but never _rats-eater,_ even though they had\nno evidence from adult speech that this is how languages work. We\nhave another demonstration of knowledge despite \"poverty of the\ninput,\" and it suggests that another basic aspect of grammar may be\ninnate. Just as Crain and Nakayama's Jabba experiment showed that\nin syntax children automatically distinguish between word strings and\nphrase structures, Gordon's mice-eater experiment shows that in\nmorphology children automatically distinguish between roots stored\nin the mental dictionary and inflected words created by a rule."
    },
    {
        "document_id": "0",
        "parent_id": 201,
        "parent_text": "A word, in a word, is complicated. But then what in the world _is_\na word? We have just seen that \"words\" can be built out of parts by\nmorphological rules. But then what makes them different from\nphrases or sentences? Shouldn't we reserve the word \"word\" for a\nthing that has to be rote-memorized, the arbitrary Saussurean sign\nthat exemplifies the first of the two principles of how language works\n(the other being the discrete combinatorial system)? The puzzlement\ncomes from the fact that the everyday word \"word\" is not scientifically\nprecise. It can refer to two things.\n\nThe concept of a word that I have used so far in this chapter is a\nlinguistic object that, even if built out of parts by the rules of morphology, behaves as the indivisible, smallest unit with respect to the rules\nof syntax—a \"syntactic atom,\" in _atom's_ original sense of something\n\n\n148 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 202,
        "parent_text": "The concept of a word that I have used so far in this chapter is a\nlinguistic object that, even if built out of parts by the rules of morphology, behaves as the indivisible, smallest unit with respect to the rules\nof syntax—a \"syntactic atom,\" in _atom's_ original sense of something\n\n\n148 THE LANGUAGE INSTINCT\n\n\nthat cannot be split. The rules of syntax can look inside a sentence\nor phrase and cut and paste the smaller phrases inside it. For example,\nthe rule for producing questions can look inside the sentence _This_\n_monster eats mice_ and move the phrase corresponding to _mice_ to the\nfront, yielding _\"What did this monster eat?_ But the rules of syntax halt\nat the boundary between a phrase and a word; even if the word is\nbuilt out of parts, the rules cannot look \"inside\" the word and fiddle\nwith those parts. For example, the question rule cannot look inside\nthe word _mice-eater_ in the sentence _This monster is a mice-eater_ and\nmove the morpheme corresponding to _mice_ to the front; the resulting\nquestion is virtually unintelligible: _What is this monster an -eater?_\n(Answer: mice.) Similarly, the rules of syntax can stick an adverb\ninside a phrase, as in _This monster eats mice quickly._ But they cannot\nstick an adverb inside a word, as in _This monster is a mice-quickly-_\n_eater._ For these reasons, we say that words, even if they are generated\nout of parts by one set of rules, are not the same thing as phrases,\nwhich are generated out of parts by a different set of rules. Thus one\nprecise sense of our everyday term \"word\" refers to the units of\nlanguage that are the products of morphological rules, and which are\nunsplittable by syntactic rules."
    },
    {
        "document_id": "0",
        "parent_id": 203,
        "parent_text": "The second, very different sense of \"word\" refers to a rote-memorized chunk: a string of linguistic stuff that is arbitrarily associated\nwith a particular meaning, one item from the long list we call the\nmental dictionary. The grammarians Anna Maria Di Sciullo and Edwin Williams coined the term \"listeme,\" the unit of a memorized list,\nto refer to this sense of \"word\" (their term is a play on \"morpheme,\"\nthe unit of morphology, and \"phoneme,\" the unit of sound). Note\nthat a listeme need not coincide with the first precise sense of \"word,\"\na syntactic atom. A listeme can be a tree branch of any size, as long\nas it cannot be produced mechanically by rules and therefore has to\nbe memorized. Take idioms. There is no way to predict the meaning\nof _kick the bucket, buy the farm, spill the beans, bite the bullet, screw_\n_the pooch, give up the ghost, hit the fan,_ or _go bananas_ from the\nmeanings of their components using the usual rules of heads and roleplayers. _Kicking the bucket_ is not a kind of kicking, and buckets have\nnothing to do with it. The meanings of these phrase-sized units have\nto be memorized as listemes, just as if they were simple word-sized\nunits, and so they are really \"words\" in this second sense. Di Sciullo\nand Williams, speaking as grammatical chauvinists, describe the men\n\nWords, Words, Words 149\n\n\ntal dictionary (lexicon) as follows: \"If conceived of as the set of\nlistemes, the lexicon is incredibly boring by its very nature. . . . The\nlexicon is like a prison—it contains only the lawless, and the only\nthing that its inmates have in common is their lawlessness.\"\n\nIn the rest of this chapter I turn to the second sense of \"word,\"\nthe listeme. It will be a kind of prison reform: I want to show that\nthe lexicon, though a repository of lawless listemes, is deserving of\nrespect and appreciation. What seems to a grammarian like an act of\nbrute force incarceration—a child hears a parent use a word and\nthenceforth retains that word in memory—is actually an inspiring\nfeat."
    },
    {
        "document_id": "0",
        "parent_id": 204,
        "parent_text": "In the rest of this chapter I turn to the second sense of \"word,\"\nthe listeme. It will be a kind of prison reform: I want to show that\nthe lexicon, though a repository of lawless listemes, is deserving of\nrespect and appreciation. What seems to a grammarian like an act of\nbrute force incarceration—a child hears a parent use a word and\nthenceforth retains that word in memory—is actually an inspiring\nfeat.\n\n\nOne extraordinary feature of the lexicon is the sheer capacity for\nmemorization that goes into building it. How many words do you\nthink an average person knows? If you are like most writers who have\noffered an opinion based on the number of words they hear or read,\nyou might guess a few hundred for the uneducated, a few thousand\nfor the literate, and as many as 15,000 for gifted wordsmiths like\nShakespeare (that is how many distinct words are found in his collected plays and sonnets)."
    },
    {
        "document_id": "0",
        "parent_id": 205,
        "parent_text": "One extraordinary feature of the lexicon is the sheer capacity for\nmemorization that goes into building it. How many words do you\nthink an average person knows? If you are like most writers who have\noffered an opinion based on the number of words they hear or read,\nyou might guess a few hundred for the uneducated, a few thousand\nfor the literate, and as many as 15,000 for gifted wordsmiths like\nShakespeare (that is how many distinct words are found in his collected plays and sonnets).\n\nThe real answer is very different. People can recognize vastly more\nwords than they have occasion to use in some fixed period of time or\nspace. To estimate the size of a person's vocabulary—in the sense of\nmemorized listemes, not morphological products, of course, because\nthe latter are infinite—psychologists use the following method. Start\nwith the largest unabridged dictionary available; the smaller the dictionary, the more words a person might know but not get credit for.\nFunk & Wagnall's _New Standard Unabridged Dictionary,_ to take an\nexample, has 450,000 entries, a healthy number, but too many to test\nexhaustively. (At thirty seconds a word, eight hours a day, it would\ntake more than a year to test a single person.) Instead, draw a sample—say, the third entry from the top of the first column on every\neighth left-hand page. Entries often have many meanings, such as\n_\"hard:_ (1) firm; (2) difficult; (3) harsh; (4) toilsome . . .\" and so on,\nbut counting them would require making arbitrary decisions about\nhow to lump or split the meanings. Thus it is practical only to estimate\nhow many words a person has learned at least one meaning for, not\nhow many meanings a person has learned altogether. The testee is\n\n\n150 THE LANGUAGE INSTINCT\n\n\npresented with each word in the sample, and asked to choose the\nclosest synonym from a set of alternatives. After a correction for\nguessing, the proportion correct is multiplied by the size of the dictionary, and that is an estimate of the person's vocabulary size."
    },
    {
        "document_id": "0",
        "parent_id": 206,
        "parent_text": "150 THE LANGUAGE INSTINCT\n\n\npresented with each word in the sample, and asked to choose the\nclosest synonym from a set of alternatives. After a correction for\nguessing, the proportion correct is multiplied by the size of the dictionary, and that is an estimate of the person's vocabulary size.\n\nActually, another correction must be applied first. Dictionaries are\nconsumer products, not scientific instruments, and for advertising\npurposes their editors often inflate the number of entries. (\"Authoritative. Comprehensive. Over 1.7 million words of text and 160,000\ndefinitions. Includes a 16-page full-color atlas.\") They do it by including compounds and affixed forms whose meanings are predictable\nfrom the meanings of their roots and the rules of morphology, and\nthus are not true listemes. For example, my desk dictionary includes,\ntogether with _sail,_ the derivatives _sailplane, sailer, sailless, sailing-boat,_\nand _sailcloth,_ whose meanings I could deduce even if I had never\nheard them before."
    },
    {
        "document_id": "0",
        "parent_id": 207,
        "parent_text": "The most sophisticated estimate comes from the psychologists William Nagy and Richard Anderson. They began with a list of 227,553\ndifferent words. Of these, 45,453 were simple roots and stems. Of\nthe remaining 182,100 derivatives and compounds, they estimated\nthat all but 42,080 could be understood in context by someone who\nknew their components. Thus there were a total of 44,453 + 42,080\n= 88,533 listeme words. By sampling from this list and testing the\nsample, Nagy and Anderson estimated that an average American\nhigh school graduate knows 45,000 words—three times as many as\nShakespeare managed to use! Actually, this is an underestimate, because proper names, numbers, foreign words, acronyms, and many\ncommon undecomposable compounds were excluded. There is no\nneed to follow the rules of Scrabble in estimating vocabulary size;\nthese forms are all listemes, and a person should be given credit for\nthem. If they had been included, the average high school graduate\nwould probably be credited with something like 60,000 words (a\ntetrabard?), and superior students, because they read more, would\nprobably merit a figure twice as high, an octobard.\n\nIs 60,000 words a lot or a little? It helps to think of how quickly\nthey must have been learned. Word learning generally begins around\nthe age of twelve months. Therefore, high school graduates, who have\nbeen at it for about seventeen years, must have been learning an\naverage of ten new words a day continuously since their first birthdays,\nor about a new word every ninety waking minutes. Using similar\n\n\nWords, Words, Words 151"
    },
    {
        "document_id": "0",
        "parent_id": 208,
        "parent_text": "Is 60,000 words a lot or a little? It helps to think of how quickly\nthey must have been learned. Word learning generally begins around\nthe age of twelve months. Therefore, high school graduates, who have\nbeen at it for about seventeen years, must have been learning an\naverage of ten new words a day continuously since their first birthdays,\nor about a new word every ninety waking minutes. Using similar\n\n\nWords, Words, Words 151\n\n\ntechniques, we can estimate that an average six-year-old commands\nabout 13,000 words (notwithstanding those dull, dull _Dick and Jane_\nreading primers, which were based on ridiculously lowball estimates).\nA bit of arithmetic shows that preliterate children, who are limited\nto ambient speech, must be lexical vacuum cleaners, inhaling a new\nword every two waking hours, day in, day out. Remember that we\nare talking about listemes, each involving an arbitrary pairing. Think\nabout having to memorize a new batting average or treaty date or\nphone number every ninety minutes of your waking life since you\ntook your first steps. The brain seems to be reserving an especially\ncapacious storage space and an especially rapid transcribing mechanism for the mental dictionary. Indeed, naturalistic studies by the\npsychologist Susan Carey have shown that if you casually slip a new\ncolor word like _olive_ into a conversation with a three-year-old, the\nchild will probably remember something about it five weeks later."
    },
    {
        "document_id": "0",
        "parent_id": 209,
        "parent_text": "Now think of what goes into each act of memorization. A word is\nthe quintessential symbol. Its power comes from the fact that every\nmember of a linguistic community uses it interchangeably in speaking\nand understanding. If you use a word, then as long as it is not too\nobscure I can take it for granted that if I later utter it to a third party,\nhe will understand my use of it the same way I understood yours. I\ndo not have to try the word back on you to see how you react, or test\nit out on every third party and see how they react, or wait for you to\nuse it with third parties. This sounds more obvious than it is. After\nall, if I observe that a bear snarls before it attacks, I cannot expect to\nscare a mosquito by snarling at it; if I bang a pot and the bear flees,\nI cannot expect the bear to bang a pot to scare hunters. Even within\nour species, learning a word from another person is not just a case of\nimitating that person's behavior. Actions are tied to particular kinds\nof actors and targets of the action in ways that words are not. If a girl\nlearns to flirt by watching her older sister, she does not flirt with the\nsister or with their parents but only with the kind of person that she\nobserves to be directly affected by the sister's behavior. Words, in\ncontrast, are a universal currency within a community. In order to\nlearn to use a word upon merely hearing it used by others, babies\nmust tacitly assume that a word is not merely a person's characteristic\nbehavior in affecting the behavior of others, but a shared bidirectional\n\n\n152 THE LANGUAGE INSTINCT\n\n\nsymbol, available to convert meaning to sound by any person when\nthe person speaks, and sound to meaning by any person when the\nperson listens, according to the same code.\n\nSince a word is a pure symbol, the relation between its sound and\nits meaning is utterly arbitrary. As Shakespeare (using a mere tenth\nof a percent of his written lexicon and a far tinier fraction of his\nmental one) put it,"
    },
    {
        "document_id": "0",
        "parent_id": 210,
        "parent_text": "152 THE LANGUAGE INSTINCT\n\n\nsymbol, available to convert meaning to sound by any person when\nthe person speaks, and sound to meaning by any person when the\nperson listens, according to the same code.\n\nSince a word is a pure symbol, the relation between its sound and\nits meaning is utterly arbitrary. As Shakespeare (using a mere tenth\nof a percent of his written lexicon and a far tinier fraction of his\nmental one) put it,\n\n\nWhat's in a name? that which we call a rose\nBy any other name would smell as sweet.\n\n\nBecause of that arbitrariness, there is no hope that mnemonic tricks\nmight lighten the memorization burden, at least for words that are\nnot built out of other words. Babies should not, and apparently do\nnot, expect _cattle_ to mean something similar to _battle,_ or _singing_ to\nbe like _stinging,_ or _coats_ to resemble _goats._ Onomatopoeia, where it\nis found, is of no help, because it is almost as conventional as any\nother word sound. In English, pigs go \"oink\"; in Japanese, they go\n\"boo-boo.\" Even in sign languages the mimetic abilities of the hands\nare put aside and their configurations are treated as arbitrary symbols.\nResidues of resemblance between a sign and its referent can occasionally be discerned, but like onomatopoeia they are so much in the eye\nof ear of the beholder that they are of little use in learning. In\nAmerican Sign Language the sign for \"tree\" is a motion of a hand as\nif it was a branch waving in the wind; in Chinese Sign Language\n\"tree\" is indicated by the motion of sketching a tree trunk."
    },
    {
        "document_id": "0",
        "parent_id": 211,
        "parent_text": "The psychologist Laura Ann Petitto has a startling demonstration\nthat the arbitrariness of the relation between a symbol and its meaning\nis deeply entrenched in the child's mind. Shortly before they turn\ntwo, English-speaking children learn the pronouns _you_ and _me._ Often\nthey reverse them, using _you_ to refer to themselves. The error is\nforgivable. _You_ and _me_ are \"deictic\" pronouns, whose referent shifts\nwith the speaker: _you_ refers to you when I use it but to me when you\nuse it. So children may need some time to get that down. After all,\nJessica hears her mother refer to her, Jessica, using _you;_ why should\nshe not think that _you_ means \"Jessica\"?\n\nNow, in ASL the sign for \"me\" is a point to one's chest; the sign\nfor \"you\" is a point to one's partner. What could be more transparent? One would expect that using \"you\" and \"me\" in ASL would be\n\n\nWords, Words, Words 153\n\n\nas foolproof as knowing how to point, which all babies, deaf and\nhearing, do before their first birthday. But for the deaf children\nPetitto studied, pointing is not pointing. The children used the sign of\npointing to their conversational partners to mean \"me\" at exactly the\nage at which hearing children use the spoken sound _you_ to mean\n\"me.\" The children were treating the gesture as a pure linguistic\nsymbol; the fact that it pointed somewhere did not register as being\nrelevant. This attitude is appropriate in learning sign languages; in\nASL, the pointing hand-shape is like a meaningless consonant or\nvowel, found as a component of many other signs, like \"candy\" and\n\"ugly.\""
    },
    {
        "document_id": "0",
        "parent_id": 212,
        "parent_text": "There is one more reason we should stand in awe of the simple act\nof learning a word. The logician W. V. O. Quine asks us to imagine\na linguist studying a newly discovered tribe. A rabbit scurries by,\nand a native shouts, \"Gavagai!\" What does _gavagai_ mean? Logically\nspeaking, it needn't be \"rabbit.\" It could refer to that particular\nrabbit (Flopsy, for example). It could mean any furry thing, any\nmammal, or any member of that species of rabbit (say, _Oryctolagus_\n_cuniculus),_ or any member of that variety of that species (say, chinchilla rabbit). It could mean scurrying rabbit, scurrying thing, rabbit\nplus the ground it scurries upon, or scurrying in general. It could\nmean footprint-maker, or habitat for rabbit-fleas. It could mean the\ntop half of a rabbit, or rabbit-meat-on-the-hoof, or possessor of at\nleast one rabbit's foot. It could mean anything that is either a rabbit\nor a Buick. It could mean collection of undetached rabbit parts,\nor \"Lo! Rabbithood again!,\" or \"It rabbiteth,\" analogous to \"It\nraineth.\"\n\nThe problem is the same when the child is the linguist and the\nparents are the natives. Somehow a baby must intuit the correct\nmeaning of a word and avoid the mind-boggling number of logically\nimpeccable alternatives. It is an example of a more general problem\nthat Quine calls \"the scandal of induction,\" which applies to scientists\nand children alike: how can they be so successful at observing a finite\nset of events and making some correct generalization about all future\nevents of that sort, rejecting an infinite number of false generalizations\nthat are also consistent with the original observations?\n\nWe all get away with induction because we are not open-minded\n\n\n154 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 213,
        "parent_text": "We all get away with induction because we are not open-minded\n\n\n154 THE LANGUAGE INSTINCT\n\n\nlogicians but happily blinkered humans, innately constrained to make\nonly certain kinds of guesses—the probably correct kinds—about\nhow the world and its occupants work. Let's say the word-learning\nbaby has a brain that carves the world into discrete, bounded, cohesive objects and into the actions they undergo, and that the baby\nforms mental categories that lump together objects that are of the\nsame kind. Let's also say that babies are designed to expect a language\nto contain words for kinds of objects and words for kinds of actions—\nnouns and verbs, more or less. Then the undetached rabbit parts,\nrabbit-trod ground, intermittent rabbiting, and other accurate descriptions of the scene will, fortunately, not occur to them as possible\nmeanings of _gavagai._\n\nBut could there really be a preordained harmony between the\nchild's mind and the parent's? Many thinkers, from the woolliest\nmystics to the sharpest logicians, united only in their assault on common sense, have claimed that the distinction between an object and\nan action is not in the world or even in our minds, initially, but is\nimposed on us by our language's distinction between nouns and\nverbs. And if it is the word that delineates the thing and the act, it\ncannot be the concepts of thing and act that allow for the learning of\nthe word."
    },
    {
        "document_id": "0",
        "parent_id": 214,
        "parent_text": "I think common sense wins this one. In an important sense, there\nreally are things and kinds of things and actions out there in the\nworld, and our mind is designed to find them and to label them with\nwords. That important sense is Darwin's. It's a jungle out there, and\nthe organism designed to make successful predictions about what is\ngoing to happen next will leave behind more babies designed just like\nit. Slicing space-time into objects and actions is an eminently sensible\nway to make predictions given the way the world is put together.\nConceiving of an extent of solid matter as a thing—that is, giving a\nsingle mentalese name to all of its parts—invites the prediction that\nthose parts will continue to occupy some region of space and will\nmove as a unit. And for many portions of the world, that prediction\nis correct. Look away, and the rabbit still exists; lift the rabbit by the\nscruff of the neck, and the rabbit's foot and the rabbit ears come\nalong for the ride.\n\nWhat about kinds of things, or categories? Isn't it true that no two\nindividuals are exactly alike? Yes, but they are not arbitrary collections of properties, either. Things that have long furry ears and tails\n\n\nWords, Words, Words 155\n\n\nlike pom-poms also tend to eat carrots, scurry into burrows, and\nbreed like, well, rabbits. Lumping objects into categories—giving\nthem a category label in mentalese—allows one, when viewing an\nentity, to infer some of the properties one cannot directly observe,\nusing the properties one _can_ observe. If Flopsy has long furry ears,\nhe is a \"rabbit\"; if he is a rabbit, he might scurry into a burrow and\nquickly make more rabbits."
    },
    {
        "document_id": "0",
        "parent_id": 215,
        "parent_text": "Words, Words, Words 155\n\n\nlike pom-poms also tend to eat carrots, scurry into burrows, and\nbreed like, well, rabbits. Lumping objects into categories—giving\nthem a category label in mentalese—allows one, when viewing an\nentity, to infer some of the properties one cannot directly observe,\nusing the properties one _can_ observe. If Flopsy has long furry ears,\nhe is a \"rabbit\"; if he is a rabbit, he might scurry into a burrow and\nquickly make more rabbits.\n\nMoreover, it pays to give objects several labels in mentalese, designating different-sized categories like \"cottontail rabbit,\" \"rabbit,\"\n\"mammal,\" \"animal,\" and \"living thing.\" There is a tradeoff involved\nin choosing one category over another. It takes less effort to determine\nthat Peter Cottontail is an animal than that he is a cottontail (for\nexample, an animallike motion will suffice for us to recognize that he\nis an animal, leaving it open whether or not he is a cottontail). But\nwe can predict more new things about Peter if we know he is a\ncottontail than if we merely know he is an animal. If he is a cottontail,\nhe likes carrots and inhabits open country or woodland clearings; if\nhe is merely an animal, he could eat anything and live anywhere, for\nall one knows. The middle-sized or \"basic-level\" category \"rabbit\"\nrepresents a compromise between how easy it is to label something\nand how much good the label does you."
    },
    {
        "document_id": "0",
        "parent_id": 216,
        "parent_text": "Finally, why separate the rabbit from the scurry? Presumably because there are predictable consequences of rabbithood that cut\nacross whether it is scurrying, eating, or sleeping: make a loud sound,\nand in all cases it will be down a hole lickety-split. The consequences\nof making a loud noise in the presence of lionhood, whether eating\nor sleeping, are predictably different, and that is a difference that\nmakes a difference. Likewise, scurrying has certain consequences\nregardless of who is doing it; whether it be rabbit or lion, a scurrier\ndoes not remain in the same place for long. With sleeping, a silent\napproach will generally work to keep a sleeper—rabbit or lion—\nmotionless. Therefore a powerful prognosticator should have separate\nsets of mental labels for kinds of objects and kinds of actions. That\nway, it does not have to learn separately what happens when a rabbit\nscurries, what happens when a lion scurries, what happens when a\nrabbit sleeps, what happens when a lion sleeps, what happens when\na gazelle scurries, what happens when a gazelle sleeps, and on and\non; knowing about rabbits and lions and gazelles in general, and\nscurrying and sleeping in general, will suffice. With _m_ objects and _n_\n\n\n156 THE LANGUAGE INSTINCT\n\n\nactions, a knower needn't go through _m_ x _n_ learning experiences;\nit can get away with _m + n_ of them."
    },
    {
        "document_id": "0",
        "parent_id": 217,
        "parent_text": "156 THE LANGUAGE INSTINCT\n\n\nactions, a knower needn't go through _m_ x _n_ learning experiences;\nit can get away with _m + n_ of them.\n\nSo even a wordless thinker does well to chop continuously flowing\nexperience into things, kinds of things, and actions (not to mention\nplaces, paths, events, states, kinds of stuff, properties, and other types\nof concepts). Indeed, experimental studies of baby cognition have\nshown that infants have the concept of an object before they learn\nany words for objects, just as we would expect. Well before their first\nbirthday, when first words appear, babies seem to keep track of the\nbits of stuff that we would call objects: they show surprise if the parts\nof an object suddenly go their own ways, of if the object magically\nappears or disappears, passes through another solid object, or hovers\nin the air without visible means of support."
    },
    {
        "document_id": "0",
        "parent_id": 218,
        "parent_text": "Attaching words to these concepts, of course, allows one to share\none's hard-won discoveries and insights about the world with the less\nexperienced or the less observant. Figuring out which word to attach\nto which concept is the _gavagai_ problem, and if infants start out with\nconcepts corresponding to the kinds of meanings that languages use,\nthe problem is partly solved. Laboratory studies confirm that young\nchildren assume that certain kinds of concepts get certain types of\nwords, and other kinds of concepts cannot be the meaning of a word\nat all. The developmental psychologists Ellen Markman and Jeanne\nHutchinson gave two- and three-year-old children a set of pictures,\nand for each picture asked them to \"find another one that is the same\nas this.\" Children are intrigued by objects that interact, and when\nfaced with these instructions they tend to select pictures that make\ngroups of role-players like a blue jay and a nest or a dog and a bone.\nBut when Markman and Hutchinson told them to \"find another _dax_\nthat is the same as this _dax\"_ the children's criterion shifted. A word\nmust label a _kind_ of thing, they seemed to be reasoning, so they put\ntogether a bird with another type of bird, a dog with another type of\ndog. For a child, a _dax_ simply cannot mean \"a dog or its bone,\"\ninteresting though the combination may be.\n\nOf course, more than one word can be applied to a thing: Peter\nCottontail is not only a _rabbit_ but an _animal_ and a _cottontail._ Children\nhave a bias to interpret nouns as middle-level kinds of objects like\n\"rabbit,\" but they also must overcome that bias, to learn other types\nof words like _animal._ Children seem to manage this by being in sync\nwith a striking feature of language. Though most common words have\n\n\nWords, Words, Words 157"
    },
    {
        "document_id": "0",
        "parent_id": 219,
        "parent_text": "Of course, more than one word can be applied to a thing: Peter\nCottontail is not only a _rabbit_ but an _animal_ and a _cottontail._ Children\nhave a bias to interpret nouns as middle-level kinds of objects like\n\"rabbit,\" but they also must overcome that bias, to learn other types\nof words like _animal._ Children seem to manage this by being in sync\nwith a striking feature of language. Though most common words have\n\n\nWords, Words, Words 157\n\n\nmany meanings, few meanings have more than one word. That is,\nhomonyms are plentiful, synonyms rare. (Virtually all supposed synonyms have some difference in meaning, however small. For example,\n_skinny_ and _slim_ differ in their connotation of desirability; _policeman_\nand _cop_ differ in formality.) No one really knows why languages are\nso stingy with words and profligate with meanings, but children seem\nto expect it (or perhaps it is this expectation that causes it!), and that\nhelps them further with the _gavagai_ problem. If a child already knows\na word for a kind of thing, then when another word is used for it, he\nor she does not take the easy but wrong way and treat it as a synonym.\nInstead, the child tries out some other possible concept. For example,\nMarkman found that if you show a child a pair of pewter tongs and\ncall it _biff,_ the child interprets _biff_ as meaning tongs in general,\nshowing the usual bias for middle-level objects, so when asked for\n\"more biffs,\" the child picks out a pair of plastic tongs. But if you\nshow the child a pewter cup and call it _biff,_ the child does not\ninterpret _biff_ as meaning \"cup,\" because most children already know\na word that means \"cup,\" namely, _cup._ Loathing synonyms, the children guess that _biff_ must mean something else, and the stuff the cup\nis made of is the next most readily available concept. When asked for\nmore _biffs,_ the child chooses a pewter spoon or pewter tongs."
    },
    {
        "document_id": "0",
        "parent_id": 220,
        "parent_text": "Many other ingenious studies have shown how children home in\non the correct meanings for different kinds of words. Once children\nknow some syntax, they can use it to sort out different kinds of\nmeaning. For example, the psychologist Roger Brown showed children a picture of hands kneading a mass of little squares in a bowl.\nIf he asked them, \"Can you see any sibbing?,\" the children pointed\nto the hands. If instead he asked them, \"Can you see a sib?,\" they\npoint to the bowl. And if he asked, \"Can you see any sib?,\" they\npoint to the stuff inside the bowl. Other experiments have uncovered\ngreat sophistication in children's understanding of how classes of\nwords fit into sentence structures and how they relate to concepts\nand kinds.\n\nSo what's in a name? The answer, we have seen, is, a great deal. In\nthe sense of a morphological product, a name is an intricate structure,\nelegantly assembled by layers of rules and lawful even at its quirkiest.\nAnd in the sense of a listeme, a name is a pure symbol, part of a cast\nof thousands, rapidly acquired because of a harmony between the\nmind of the child, the mind of the adult, and the texture of reality."
    },
    {
        "document_id": "0",
        "parent_id": 221,
        "parent_text": "### 6"
    },
    {
        "document_id": "0",
        "parent_id": 222,
        "parent_text": "#### The Sounds of Silence\n\n**W h e n** I was a student I worked in a laboratory at McGill\n\nUniversity that studied auditory perception. Using a computer, I\nwould synthesize trains of overlapping tones and determine whether\nthey sounded like one rich sound or two pure ones. One Monday\nmorning I had an odd experience: the tones suddenly turned into a\nchorus of screaming munchkins. Like this: (beep boop-boop)\n(beep boop-boop) (beep boop-boop) HUMPTY-DUMPTYHUMPTY-DUMPTY-HUMPTY-DUMPTY (beep boop-boop) (beep\nboop-boop) HUMPTY-DUMPTY-HUMPTY-DUMPTY-HUMPTYHUMPTY-DUMPTY-DUMPTY (beep boop-boop) (beep boopboop) (beep boop-boop) HUMPTY-DUMPTY (beep boop-boop)\nHUMPTY-HUMPTY-HUMPTY-DUMPTY (beep boop-boop). I\nchecked the oscilloscope: two streams of tones, as programmed. The\neffect had to be perceptual. With a bit of effort I could go back and\nforth, hearing the sound as either beeps or munchkins. When a fellow\nstudent entered, I recounted my discovery, mentioning that I couldn't\nwait to tell Professor Bregman, who directed the laboratory. She\noffered some advice: don't tell anyone, except perhaps Professor\nPoser (who directed the psychopathology program).\n\nYears later I discovered what I had discovered. The psychologists\nRobert Remez, David Pisoni, and their colleagues, braver men than\nI am, published an article in _Science_ on \"sine-wave speech.\" They\nsynthesized three simultaneous wavering tones. Physically, the sound\nwas nothing at all like speech, but the tones followed the same contours as the bands of energy in the sentence \"Where were you a\n\n\n**158**\n\n\nThe Sounds of Silence 159"
    },
    {
        "document_id": "0",
        "parent_id": 223,
        "parent_text": "Years later I discovered what I had discovered. The psychologists\nRobert Remez, David Pisoni, and their colleagues, braver men than\nI am, published an article in _Science_ on \"sine-wave speech.\" They\nsynthesized three simultaneous wavering tones. Physically, the sound\nwas nothing at all like speech, but the tones followed the same contours as the bands of energy in the sentence \"Where were you a\n\n\n**158**\n\n\nThe Sounds of Silence 159\n\n\nyear ago?\" Volunteers described what they heard as \"science fiction\nsounds\" or \"computer bleeps.\" A second group of volunteers was\ntold that the sounds had been generated by a bad speech synthesizer.\nThey were able to make out many of the words, and a quarter of\nthem could write down the sentence perfectly. The brain can hear\nspeech content in sounds that have only the remotest resemblance to\nspeech. Indeed, sine-wave speech is how mynah birds fool us. They\nhave a valve on each bronchial tube and can control them independently, producing two wavering tones which we hear as speech."
    },
    {
        "document_id": "0",
        "parent_id": 224,
        "parent_text": "Our brains can flip between hearing something as a bleep and\nhearing it as a word because phonetic perception is like a sixth sense.\nWhen we listen to speech the actual sounds go in one ear and out\nthe other; what we perceive is _language._ Our experience of words\nand syllables, of the \"b\"-ness of _b_ and the \"ee\"-ness of _ee,_ is as\nseparable from our experience of pitch and loudness as lyrics are\nfrom a score. Sometimes, as in sine-wave speech, the senses of hearing\nand phonetics compete over which gets to interpret a sound, and\nour perception jumps back and forth. Sometimes the two senses\nsimultaneously interpret a single sound. If one takes a tape recording\nof _da,_ electronically removes the initial chirplike portion that distinguishes the _da_ from _ga_ and _ka,_ and plays the chirp to one ear and the\nresidue to the other, what people hear is a chirp in one ear and _da_ in\nthe other—a single clip of sound is perceived simultaneously as _d-_\nness and a chirp. And sometimes phonetic perception can transcend\nthe auditory channel. If you watch an English-subtitled movie in a\nlanguage you know poorly, after a few minutes you may feel as if you\nare actually understanding the speech. In the laboratory, researchers\ncan dub a speech sound like _ga_ onto a close-up video of a mouth\narticulating _va, ba, tha,_ or _da._ Viewers literally _hear_ a consonant like\nthe one they see the mouth making—an astonishing illusion with the\npleasing name \"McGurk effect,\" after one of its discoverers.\n\nActually, one does not need electronic wizardry to create a speech\nillusion. All speech is an illusion. We hear speech as a string of\nseparate words, but unlike the tree falling in the forest with no one\nto hear it, a word boundary with no one to hear it has no sound. In\nthe speech sound wave, one word runs into the next seamlessly; there\nare no little silences between spoken words the way there are white\nspaces between written words. We simply hallucinate word boundaries when we reach the edge of a stretch of sound that matches some"
    },
    {
        "document_id": "0",
        "parent_id": 225,
        "parent_text": "160 THE LANGUAGE INSTINCT\n\n\nentry in our mental dictionary. This becomes apparent when we listen\nto speech in a foreign language: it is impossible to tell where one\nword ends and the next begins. The seamlessness of speech is also\napparent in \"oronyms,\" strings of sound that can be carved into\nwords in two different ways:\n\n\nThe good can decay many ways.\nThe good candy came anyways.\n\nThe stuffy nose can lead to problems.\nThe stuff he knows can lead to problems.\n\nSome others I've seen.\nSome mothers I've seen.\n\n\nOronyms are often used in songs and nursery rhymes:\n\n\nI scream,\nYou scream,\nWe all scream\nFor ice cream.\n\nMairzey doats and dozey doats\nAnd little lamsey divey,\nA kiddley-divey do,\nWouldn't you?\n\nFuzzy Wuzzy was a bear,\nFuzzy Wuzzy had no hair.\nFuzzy Wuzzy wasn't fuzzy,\nWas he?\n\nIn fir tar is,\nIn oak none is.\nIn mud eel is,\nIn clay none is.\nGoats eat ivy.\nMares eat oats.\n\n\nAnd some are discovered inadvertently by teachers reading their\nstudents' term papers and homework assignments:\n\n\nThe Sounds of Silence 161\n\n\nJose can you see by the donzerly light? [Oh say can you see\n\nby the dawn's early light?]\nIt's a doggy-dog world. [dog-eat-dog]\nEugene O'Neill won a Pullet Surprise. [Pulitzer Prize]\nMy mother comes from Pencil Vanea. [Pennsylvania]\nHe was a notor republic. [notary public]\nThey played the Bohemian Rap City. [Bohemian Rhapsody]\n\n\nEven the sequence of sounds we think we hear within a word are\nan illusion. If you were to cut up a tape of someone saying _cat,_ you\nwould not get pieces that sounded like _k, a,_ and _t_ (the units called\n\"phonemes\" that correspond roughly to the letters of the alphabet).\nAnd if you spliced the pieces together in the reverse order, they would\nbe unintelligible, not _tack._ As we shall see, information about each\ncomponent of a word is smeared over the entire word."
    },
    {
        "document_id": "0",
        "parent_id": 226,
        "parent_text": "Even the sequence of sounds we think we hear within a word are\nan illusion. If you were to cut up a tape of someone saying _cat,_ you\nwould not get pieces that sounded like _k, a,_ and _t_ (the units called\n\"phonemes\" that correspond roughly to the letters of the alphabet).\nAnd if you spliced the pieces together in the reverse order, they would\nbe unintelligible, not _tack._ As we shall see, information about each\ncomponent of a word is smeared over the entire word.\n\nSpeech perception is another one of the biological miracles making\nup the language instinct. There are obvious advantages to using the\nmouth and ear as a channel of communication, and we do not find\nany hearing community opting for sign language, though it is just as\nexpressive. Speech does not require good lighting, face-to-face contact, or monopolizing the hands and eyes, and it can be shouted over\nlong distances or whispered to conceal the message. But to take\nadvantage of the medium of sound, speech has to overcome the\nproblem that the ear is a narrow informational bottleneck. When\nengineers first tried to develop reading machines for the blind in the\n1940s, they devised a set of noises that corresponded to the letters of\nthe alphabet. Even with heroic training, people could not recognize\nthe sounds at a rate faster than good Morse code operators, about\nthree units a second. Real speech, somehow, is perceived an order of\nmagnitude faster: ten to fifteen phonemes per second for casual\nspeech, twenty to thirty per second for the man in the late-night VegO-Matic ads, and as many as forty to fifty per second for artificially\nsped-up speech. Given how the human auditory system works, this\nis almost unbelievable. When a sound like a click is repeated at a rate\nof twenty times a second or faster, we no longer hear it as a sequence\nof separate sounds but as a low buzz. If we can hear forty-five phonemes per second, the phonemes cannot possibly be consecutive bits\nof sound; each moment of sound must have several phonemes packed"
    },
    {
        "document_id": "0",
        "parent_id": 227,
        "parent_text": "162 THE LANGUAGE INSTINCT\n\n\ninto it that our brains somehow unpack. As a result, speech is by far\nthe fastest way of getting information into the head through the ear."
    },
    {
        "document_id": "0",
        "parent_id": 228,
        "parent_text": "No human-made system can match a human in decoding speech.\nIt is not for lack of need or trying. A speech recognizer would be a\nboon to quadriplegics and other disabled people, to professionals\nwho have to get information into a computer while their eyes or hands\nare busy, to people who never learned to type, to users of telephone\nservices, and to the growing number of typists who are victims of\nrepetitive-motion syndromes. So it is not surprising that engineers\nhave been working for more than forty years to get computers to\nrecognize the spoken word. The engineers have been frustrated by a\ntradeoff. If a system has to be able to listen to many different people,\nit can recognize only a tiny number of words. For example, telephone\ncompanies are beginning to install directory assistance systems that\ncan recognize anyone saying the word _yes,_ or, in the more advanced\nsystems, the ten English digits (which, fortunately for the engineers,\nhave very different sounds). But if a system has to recognize a large\nnumber of words, it has to be trained to the voice of a single speaker.\nNo system today can duplicate a person's ability to recognize both\nmany words and many speakers. Perhaps the state of the art is a\nsystem called DragonDictate, which runs on a personal computer and\ncan recognize 30,000 words. But it has severe limitations. It has to be\ntrained extensively on the voice of the user. You . . . have . . . to . . .\ntalk . . . to . . . i t . . . like . . . this, with quarter-second pauses between\nthe words (so it operates at about one-fifth the rate of ordinary\nspeech). If you have to use a word that is not in its dictionary, like a\nname, you have to spell it out using the \"Alpha, Bravo, Charlie\"\nalphabet. And the program still garbles words about fifteen percent\nof the time, more than once per sentence. It is an impressive product\nbut no match for even a mediocre stenographer."
    },
    {
        "document_id": "0",
        "parent_id": 229,
        "parent_text": "The physical and neural machinery of speech is a solution to two\nproblems in the design of the human communication system. A person might know 60,000 words, but a person's mouth cannot make\n60,000 different noises (at least, not ones that the ear can easily\ndiscriminate). So language has exploited the principle of the discrete\ncombinatorial system again. Sentences and phrases are built out of\nwords, words are built out of morphemes, and morphemes, in turn,\nare built out of phonemes. Unlike words and morphemes, though,\nphonemes do not contribute bits of meaning to the whole. The mean\n\nThe Sounds of Silence 163\n\n\ning of _dog_ is not predictable from the meaning of _d,_ the meaning of\no, the meaning of _g,_ and their order. Phonemes are a different kind\nof linguistic object. They connect outward to speech, not inward to\nmentalese: a phoneme corresponds to an act of making a sound. A\ndivision into independent discrete combinatorial systems, one combining meaningless sounds into meaningful morphemes, the others\ncombining meaningful morphemes into meaningful words, phrases,\nand sentences, is a fundamental design feature of human language,\nwhich the linguist Charles Hockett has called \"duality of patterning.\""
    },
    {
        "document_id": "0",
        "parent_id": 230,
        "parent_text": "But the phonological module of the language instinct has to do\nmore than spell out the morphemes. The rules of language are discrete\ncombinatorial systems: phonemes snap cleanly into morphemes, morphemes into words, words into phrases. They do not blend or melt\nor coalesce: _Dog bites man_ differs from _Man bites dog,_ and believing\nin God is different from believing in Dog. But to get these structures\nout of one head and into another, they must be converted to audible\nsignals. The audible signals people can produce are not a series of\ncrisp beeps like on a touch-tone phone. Speech is a river of breath,\nbent into hisses and hums by the soft flesh of the mouth and throat.\nThe problems Mother Nature faced are digital-to-analog conversion\nwhen the talker encodes strings of discrete symbols into a continuous\nstream of sound, and analog-to-digital conversion when the listener\ndecodes continuous speech back into discrete symbols.\n\nThe sounds of language, then, are put together in several steps. A\nfinite inventory of phonemes is sampled and permuted to define\nwords, and the resulting strings of phonemes are then massaged to\nmake them easier to pronounce and understand before they are actually articulated. I will trace out these steps for you and show you how\nthey shape some of our everyday encounters with speech: poetry and\nsong, slips of the ear, accents, speech recognition machines, and crazy\nEnglish spelling.\n\n\nOne easy way to understand speech sounds is to track a glob of air\nthrough the vocal tract into the world, starting in the lungs.\n\nWhen we talk, we depart from our usual rhythmic breathing and\ntake in quick breaths of air, then release them steadily, using the\nmuscles of the ribs to counteract the elastic recoil force of the lungs.\n(If we did not, our speech would sound like the pathetic whine of a\n\n\n164 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 231,
        "parent_text": "One easy way to understand speech sounds is to track a glob of air\nthrough the vocal tract into the world, starting in the lungs.\n\nWhen we talk, we depart from our usual rhythmic breathing and\ntake in quick breaths of air, then release them steadily, using the\nmuscles of the ribs to counteract the elastic recoil force of the lungs.\n(If we did not, our speech would sound like the pathetic whine of a\n\n\n164 THE LANGUAGE INSTINCT\n\n\nreleased balloon.) Syntax overrides carbon dioxide: we suppress the\ndelicately tuned feedback loop that controls our breathing rate to\nregulate oxygen intake, and instead we time our exhalations to the\nlength of the phrase or sentence we intend to utter. This can lead to\nmild hyperventilation or hypoxia, which is why public speaking is so\nexhausting and why it is difficult to carry on a conversation with a\njogging partner.\n\nThe air leaves the lungs through the trachea (windpipe), which\nopens into the larynx (the voice-box, visible on the outside as the\nAdam's apple). The larynx is a valve consisting of an opening (the\nglottis) covered by two flaps of retractable muscular tissue called the\nvocal folds (they are also called \"vocal cords\" because of an early\nanatomist's error; they are not cords at all). The vocal folds can close\noff the glottis tightly, sealing the lungs. This is useful when we want\nto stiffen our upper body, which is a floppy bag of air. Get up from\nyour chair without using your arms; you will feel your larynx tighten.\nThe larynx is also closed off in physiological functions like coughing\nand defecation. The grunt of the weightlifter or tennis player is a\nreminder that we use the same organ to seal the lungs and to produce\nsound."
    },
    {
        "document_id": "0",
        "parent_id": 232,
        "parent_text": "The vocal folds can also be partly stretched over the glottis to\nproduce a buzz as the air rushes past. This happens because the highpressure air pushes the vocal folds open, at which point they spring\nback and get sucked together, closing the glottis until air pressure\nbuilds up and pushes them open again, starting a new cycle. Breath\nis thus broken into a series of puffs of air, which we perceive as a\nbuzz, called \"voicing.\" You can hear and feel the buzz by making\nthe sounds _ssssssss,_ which lacks voicing, and _zzzzzzzz,_ which has it.\n\nThe frequency of the vocal folds' opening and closing determines\nthe pitch of the voice. By changing the tension and position of the\nvocal folds, we can control the frequency and hence the pitch. This\nis most obvious in humming or singing, but we also change pitch\ncontinuously over the course of a sentence, a process called intonation. Normal intonation is what makes natural speech sound different\nfrom the speech of robots in old science fiction movies and of the\nConeheads on _Saturday Night Live._ Intonation is also controlled in\nsarcasm, emphasis, and an emotional tone of voice such as anger or\ncheeriness. In \"tone languages\" like Chinese, rising or falling tones\ndistinguish certain vowels from others.\n\n\nThe Sounds of Silence 165\n\n\nThough voicing creates a sound wave with a dominant frequency\nof vibration, it is not like a tuning fork or a test of the Emergency\nBroadcasting System, a pure tone with that frequency alone. Voicing\nis a rich, buzzy sound with many \"harmonics.\" A male voice is a wave\nwith vibrations not only at 100 cycles per second but also at 200 cps,\n300 cps, 400 cps, 500 cps, 600 cps, 700 cps, and so on, all the way\nup to 4000 cps and beyond. A female voice has vibrations at 200 cps,\n400 cps, 600 cps, and so on. The richness of the sound source is\ncrucial—it is the raw material that the rest of the vocal tract sculpts\ninto vowels and consonants."
    },
    {
        "document_id": "0",
        "parent_id": 233,
        "parent_text": "If for some reason we cannot produce a hum from the larynx, any\nrich source of sound will do. When we whisper, we spread the vocal\nfolds, causing the air stream to break apart chaotically at the edges\nof the folds and creating a turbulence or noise that sounds like hissing\nor radio static. A hissing noise is not a neatly repeating wave consisting\nof a sequence of harmonics, as we find in the periodic sound of a\nspeaking voice, but a jagged, spiky wave consisting of a hodgepodge\nof constantly changing frequencies. This mixture, though, is all that\nthe rest of the vocal tract needs for intelligible whispering. Some\nlaryngectomy patients are taught \"esophageal speech,\" or controlled\nburping, which provides the necessary noise. Others place a vibrator\nagainst their necks. In the 1970s the guitarist Peter Frampton funneled the amplified sound of his electric guitar through a tube into\nhis mouth, allowing him to articulate his twangings. The effect was\ngood for a couple of hit records before he sank into rock-and-roll\noblivion.\n\nThe richly vibrating air then runs through a gantlet of chambers\nbefore leaving the head: the throat or \"pharynx\" behind the tongue,\nthe mouth region between the tongue and palate, the opening between the lips, and an alternative route to the external world through\nthe nose. Each chamber has a particular length and shape, which\naffects the sound passing through by the phenomenon called \"resonance.\" Sounds of different frequencies have different wavelengths\n(the distance between the crests of the sound wave); higher pitches\nhave shorter wavelengths. A sound wave moving down the length of\na tube bounces back when it reaches the opening at the other end.\nIf the length of the tube is a certain fraction of the wavelength of the\nsound, each reflected wave will reinforce the next incoming one; if it\nis of a different length, they will interfere with one another. (This is\n\n\n166 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 234,
        "parent_text": "166 THE LANGUAGE INSTINCT\n\n\nsimilar to how you get the best effect pushing a child on a swing if\nyou synchronize each push with the top of the arc.) Thus a tube of a\nparticular length amplifies some sound frequencies and filters out\nothers. You can hear the effect when you fill a bottle. The noise of\nthe sloshing water gets filtered by the chamber of air between the\nsurface and the opening: the more water, the smaller the chamber,\nthe higher the resonant frequency of the chamber, and the tinnier the\ngurgle.\n\nWhat we hear as different vowels are the different combinations\nof amplification and filtering of the sound coming up from the larynx.\nThese combinations are produced by moving five speech organs\naround in the mouth to change the shapes and lengths of the resonant\ncavities that the sound passes through. For example, _ee_ is defined by\ntwo resonances, one from 200 to 350 cps produced mainly by the\nthroat cavity, and the other from 2100 to 3000 cps produced mainly\nby the mouth cavity. The range of frequencies that a chamber filters\nis independent of the particular mixture of frequencies that enters it,\nso we can hear an _ee_ as an _ee_ whether it is spoken, whispered, sung\nhigh, sung low, burped, or twanged."
    },
    {
        "document_id": "0",
        "parent_id": 235,
        "parent_text": "The tongue is the most important of the speech organs, making\nlanguage truly the \"gift of tongues.\" Actually, the tongue is three\norgans in one: the hump or body, the tip, and the root (the muscles\nthat anchor it to the jaw). Pronounce the vowels in _bet_ and _butt_\nrepeatedly, _e-uh, e-uh, e-ub._ You should feel the body of your tongue\nmoving forwards and backwards (if you put a finger between your\nteeth, you can feel it with the finger). When your tongue is in the\nfront of your mouth, it lengthens the air chamber behind it in your\nthroat and shortens the one in front of it in your mouth, altering one\nof the resonances: for the _bet_ vowel, the mouth amplifies sounds near\n600 and 1800 cps; for the _butt_ vowel, it amplifies sounds near 600\nand 1200. Now pronounce the vowels in _beet_ and _bat_ alternately. The\nbody of your tongue will jump up and down, at right angles to the\n_bet-butt_ motion; you can even feel your jaw move to help it. This,\ntoo, alters the shapes of the throat and mouth chambers, and hence\ntheir resonances. The brain interprets the different patterns of amplification and filtering as different vowels.\n\nThe link between the postures of the tongue and the vowels it\nsculpts gives rise to a quaint curiosity of English and many other\n\n\nThe Sounds of Silence 167\n\n\nlanguages called phonetic symbolism. When the tongue is high and\nat the front of the mouth, it makes a small resonant cavity there that\namplifies some higher frequencies, and the resulting vowels like _ee_\nand _i_ (as in _bit)_ remind people of little things. When the tongue is\nlow and to the back, it makes a large resonant cavity that amplifies\nsome lower frequencies, and the resulting vowels like _a_ in _father_ and"
    },
    {
        "document_id": "0",
        "parent_id": 236,
        "parent_text": "The Sounds of Silence 167\n\n\nlanguages called phonetic symbolism. When the tongue is high and\nat the front of the mouth, it makes a small resonant cavity there that\namplifies some higher frequencies, and the resulting vowels like _ee_\nand _i_ (as in _bit)_ remind people of little things. When the tongue is\nlow and to the back, it makes a large resonant cavity that amplifies\nsome lower frequencies, and the resulting vowels like _a_ in _father_ and\n\n- in _core_ and in _cot_ remind people of large things. Thus mice are\nt _ee_ ny and squeak, but elephants are hum _o_ ngous and ro _a_ r. Audio\nspeakers have small tw _ee_ ters for the high sounds and large w _oo_ fers\nfor the low ones. English speakers correctly guess that in Chinese\n_ch'ing_ means light and _ch'ung_ means heavy. (In controlled studies\nwith large numbers of foreign words, the hit rate is statistically above\nchance, though just barely.) When I questioned our local computer\nwizard about what she meant when she said she was going to _frob_ my\nworkstation, she gave me this tutorial on hackerese. When you get a\nbrand-new graphic equalizer for your stereo and aimlessly slide the\nknobs up and down to hear the effects, that is _frobbing._ When you\nmove the knobs by medium-sized amounts to get the sound to your\ngeneral liking, that is _twiddling._ When you make the final small adjustments to get it perfect, that is _tweaking._ The _ob, id,_ and _eak_ sounds\nperfectly follow the large-to-small continuum of phonetic symbolism."
    },
    {
        "document_id": "0",
        "parent_id": 237,
        "parent_text": "And at the risk of sounding like Andy Rooney on _Sixty Minutes,_\nhave you ever wondered why we say _fiddle-faddle_ and not _faddle-_\n_fiddle?_ Why is it _ping-pong_ and _pitter-patter_ rather than _pong-ping_ and\n_patter-pitter?_ Why _dribs and drabs,_ rather than vice versa? Why can't\na kitchen be _span and spic?_ Whence _riff-raff, mish-mash, flim-flam,_\n_chit-chat, tit for tat, knick-knack, zig-zag, sing-song, ding-dong, King_\n_Kong, criss-cross, shilly-shally, see-saw,_ _hee-haw, flip-flop,_ _hippity-hop,_\n_tick-tock,_ _tic-tac-toe,_ _eeny-meeny-miney-moe,_ _bric-a-brac,_ _clickety-clack,_\n_hickory-dickory-dock,_ _kit and kaboodle,_ and _bibbity-bobbity-boo?_ The\nanswer is that the vowels for which the tongue is high and in the front\nalways come before the vowels for which the tongue is low and in the\nback. No one knows why they are aligned in this order, but it seems\nto be a kind of syllogism from two other oddities. The first is that\nwords that connote me-here-now tend to have higher and fronter\nvowels than verbs that connote distance from \"me\": _me_ versus _you,_\n_here_ versus _there, this_ versus _that._ The second is that words that\nconnote me-here-now tend to come before words that connote literal\n\n\n168 THE LANGUAGE INSTINCT\n\n\nor metaphorical distance from \"me\" (or a prototypical generic\nspeaker): _here and there_ (not _there and here), this and that, now and_\n_then, father and son, man and machine, friend or foe, the Harvard-_\n_Yale game_ (among Harvard students), _the Yale-Harvard game_ (among\nYalies), _Serbo-Croatian_ (among Serbs), _Croat-Serbian_ (among Croats).\nThe syllogism seems to be: \"me\" = high front vowel; me first;\ntherefore, high front vowel first. It is as if the mind just cannot bring\nitself to flip a coin in ordering words; if meaning does not determine\nthe order, sound is brought to bear, and the rationale is based on\nhow the tongue produces the vowels."
    },
    {
        "document_id": "0",
        "parent_id": 238,
        "parent_text": "Let's look at the other speech organs. Pay attention to your lips\nwhen you alternate between the vowels in _boot_ and _book._ For _boot,_\nyou round the lips and protrude them. This adds an air chamber,\nwith its own resonances, to the front of the vocal tract, amplifying\nand filtering other sets of frequencies and thus defining other vowel\ncontrasts. Because of the acoustic effects of the lips, when we talk to\na happy person over the phone, we can literally hear the smile.\n\nRemember your grade-school teacher telling you that the vowel\nsounds in _bat, bet, bit, bottle,_ and _butt_ were \"short,\" and the vowel\nsounds in _bait, beet, bite, boat,_ and _boot_ were \"long\"? And you didn't\nknow what she was talking about? Well, forget it; her information is\nfive hundreds years out of date. Older stages of English differentiated\nwords by whether their vowels were pronounced quickly or were\ndrawn out, a bit like the modern distinction between _bad_ meaning\n\"bad\" and _baaaad_ meaning \"good.\" But in the fifteenth century\nEnglish pronunciation underwent a convulsion called the Great\nVowel Shift. The vowels that had simply been pronounced longer\nnow became \"tense\": by advancing the tongue root (the muscles\nattaching the tongue to the jaw), the tongue becomes tense and\nhumped rather than lax and flat, and the hump narrows the air\nchamber in the mouth above it, changing the resonances. Also, some\ntense vowels in modern English, like in _bite_ and _brow,_ are \"diphthongs,\" two vowels pronounced in quick succession as if they were\none: ba-eet, bra-oh.\n\nYou can hear the effects of the fifth speech organ by drawing out\nthe vowel in _Sam_ and _sat,_ postponing the final consonant indefinitely.\nIn most dialects of English, the vowels will be different: the vowel in\n_Sam_ will have a twangy, nasal sound. That is because the soft palate\n\n\nThe Sounds of Silence 169"
    },
    {
        "document_id": "0",
        "parent_id": 239,
        "parent_text": "You can hear the effects of the fifth speech organ by drawing out\nthe vowel in _Sam_ and _sat,_ postponing the final consonant indefinitely.\nIn most dialects of English, the vowels will be different: the vowel in\n_Sam_ will have a twangy, nasal sound. That is because the soft palate\n\n\nThe Sounds of Silence 169\n\n\nor velum (the fleshy flap at the back of the hard palate) is opened,\nallowing air to flow out through the nose as well as through the\nmouth. The nose is another resonant chamber, and when vibrating\nair flows through it, yet another set of frequencies gets amplified and\nfiltered. English does not differentiate words by whether their vowels\nare nasal or not, but many languages, like French, Polish, and Portuguese, do. English speakers who open their soft palate even when\npronouncing _sat_ are said to have a \"nasal\" voice. When you have a\ncold and your nose is blocked, opening the soft palate makes no\ndifference, and your voice is the opposite of nasal."
    },
    {
        "document_id": "0",
        "parent_id": 240,
        "parent_text": "So far we have just discussed the vowels—sounds where the air\nhas clear passage from the larynx to the world. When some barrier\nis put in the way, one gets a consonant. Pronounce _ssssss._ The tip of\nyour tongue—the sixth speech organ—is brought up almost against\nthe gum ridge, leaving a small opening. When you force a stream of\nair through the opening, the air breaks apart turbulently, creating\nnoise. Depending on the size of the opening and the length of the\nresonant cavities in front of it, the noise will have some of its frequencies louder than others, and the peak and range of frequencies define\nthe sound we hear as _s._ This noise-making comes from the friction of\nmoving air, so this kind of sound is called a fricative. When rushing\nair is squeezed between the tongue and palate, we get _sh;_ between\nthe tongue and teeth, _th;_ and between the lower lip and teeth, _f_ . The\nbody of the tongue, or the vocal folds of the larynx, can also be\npositioned to create turbulence, defining the various \"ch\" sounds in\nlanguages like German, Hebrew, and Arabic _(Bach, Chanukah,_ and\nso on).\n\nNow pronounce a _t._ The tip of the tongue gets in the way of the\nairstream, but this time it does not merely impede the flow; it stops\nit entirely. When the pressure builds up, you release the tip of the\ntongue, allowing the air to pop out (flutists use this motion to demarcate musical notes). Other \"stop\" consonants can be formed by the\nlips ( _p_ ), by the body of the tongue pressed against the palate _(k),_ and\nby the larynx (in the \"glottal\" consonants in _uh-oh)._ What a listener\nhears when you produce a stop consonant is the following. First,\nnothing, as the air is dammed up behind the stoppage: stop conso\n\n170 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 241,
        "parent_text": "170 THE LANGUAGE INSTINCT\n\n\nnants are the sounds of silence. Then, a brief burst of noise as the air\nis released; its frequency depends on the size of the opening and the\nresonant cavities in front of it. Finally, a smoothly changing resonance,\nas voicing fades in while the tongue is gliding into the position of\nwhatever vowel comes next. As we shall see, this hop-skip-and-jump\nmakes life miserable for speech engineers.\n\nFinally, pronounce _m._ Your lips are sealed, just like for _p._ But this\ntime the air does not back up silently; you can say _mmmmm_ until you\nare out of breath. That is because you have also opened your soft\npalate, allowing all of the air to escape through your nose. The voicing\nsound is now amplified at the resonant frequencies of the nose and\nof the part of the mouth behind the blockage. Releasing the lips\ncauses a sliding resonance similar in shape to what we heard for the\nrelease in _p,_ except without the silence, noise burst, and fade-in. The\nsound _n_ works similarly to _m,_ except that the blockage is created by\nthe tip of the tongue, the same organ used for _d_ and _s._ So does the\n_ng_ in _sing,_ except that the body of the tongue does the job.\n\nWhy do we say _razzle-dazzle_ instead of _dazzle-razzle?_ Why _super-_\n_duper,_ _helter-skelter,_ _harum-scarum,_ _hocus-pocus,_ _willy-nilly,_ _hully-_\n_gully,_ _roly-poly, holy moly, herky-jerky,_ _walkie-talkie,_ _namby-pamby,_\n_mumbo-jumbo, loosey-goosey, wing-ding, wham-bam, hobnob, razza-_\n_matazz,_ and _rub-a-dub-dub?_ I thought you'd never ask. Consonants\ndiffer in \"obstruency\"—the degree to which they impede the flow of\nair, ranging from merely making it resonate, to forcing it noisily past\nan obstruction, to stopping it up altogether. The word beginning with\nthe less obstruent consonant always comes before the word beginning\nwith the more obstruent consonant. Why ask why?"
    },
    {
        "document_id": "0",
        "parent_id": 242,
        "parent_text": "Now that you have completed a guided tour up the vocal tract,\nyou can understand how the vast majority of sounds in the world's\nlanguages are created and heard. The trick is that a speech sound is\nnot a single gesture by a single organ. Every speech sound is a _combi-_\n_nation_ of gestures, each exerting its own pattern of sculpting of the\nsound wave, all executed more or less simultaneously—that is one of\nthe reasons speech can be so rapid. As you may have noticed, a sound\ncan be nasal or not, and produced by the tongue body, the tongue\ntip, or the lips, in all six possible combinations:\n\n\nThe Sounds of Silence 171\n\n\nNasal Not Nasal\n(Soft Palate Open) (Soft Palate\nClosed)\n\nLips _m_ _p_\nTongue tip _n_ _t_\nTongue body _ng_ _k_\n\n\nSimilarly, voicing combines in all possible ways with the choice of\nspeech organ:\n\n\nVoicing No Voicing\n(Larynx Hums) (Larynx Doesn't Hum)\n\nLips _b_ _p_\nTongue tip _d_ _t_\nTongue body _g_ _k_\n\n\nSpeech sounds thus nicely fill the rows and columns and layers of a\nmultidimensional matrix. First, one of the six speech organs is chosen\nas the major articulator: the larynx, soft palate, tongue body, tongue\ntip, tongue root, or lips. Second, a manner of moving that articulator\nis selected: fricative, stop, or vowel. Third, configurations of the other\nspeech organs can be specified: for the soft palate, nasal or not; for\nthe larynx, voiced or not; for the tongue root, tense or lax; for the lips,\nrounded or unrounded. Each manner or configuration is a symbol for\na set of commands to the speech muscles, and such symbols are called\nfeatures. To articulate a phoneme, the commands must be executed\nwith precise timing, the most complicated gymnastics we are called\nupon to perform."
    },
    {
        "document_id": "0",
        "parent_id": 243,
        "parent_text": "English multiplies out enough of these combinations to define 40\nphonemes, a bit above the average for the world's languages. Other\nlanguages range from 11 (Polynesian) to 141 (Khoisan or \"Bushman\"). The total inventory of phonemes across the world numbers\nin the thousands, but they are all defined as combinations of the six\nspeech organs and their shapes and motions. Other mouth sounds\nare not used in any language: scraping teeth, clucking the tongue\nagainst the floor of the mouth, making raspberries, and squawking\nlike Donald Duck, for instance. Even the unusual Khoisan and Bantu\n\n\n172 THE LANGUAGE INSTINCT\n\n\nclicks (similar to the sound of _tsk-tsk_ and made famous by the Xhosa\npop singer Miriam Makeba) are not miscellaneous phonemes added\nto those languages. Clicking is a manner-of-articulation feature, like\nstop or fricative, and it combines with all the other features to define\na new layer of rows and columns in the language's table of phonemes.\nThere are clicks produced by the lips, tongue tip, and tongue body,\nany of which can be nasalized or not, voiced or not, and so on, as\nmany as 48 click sounds in all!\n\n\nAn inventory of phonemes is one of the things that gives a language\nits characteristic sound pattern. For example, Japanese is famous for\nnot distinguishing _r_ from _l_ . When I arrived in Japan on November 4,\n1992, the linguist Masaaki Yamanashi greeted me with a twinkle and\nsaid, \"In Japan, we have been very interested in Clinton's erection.\""
    },
    {
        "document_id": "0",
        "parent_id": 244,
        "parent_text": "An inventory of phonemes is one of the things that gives a language\nits characteristic sound pattern. For example, Japanese is famous for\nnot distinguishing _r_ from _l_ . When I arrived in Japan on November 4,\n1992, the linguist Masaaki Yamanashi greeted me with a twinkle and\nsaid, \"In Japan, we have been very interested in Clinton's erection.\"\n\nWe can often recognize a language's sound pattern even in a speech\nstream that contains no real words, as with the Swedish chef on _The_\n_Muppets_ or John Belushi's samurai dry cleaner. The linguist Sarah G.\nThomason has found that people who claim to be channeling back\nto past lives or speaking in tongues are really producing gibberish\nthat conforms to a sound pattern vaguely reminiscent of the claimed\nlanguage. For example, one hypnotized channeler, who claimed to\nbe a nineteenth-century Bulgarian talking to her mother about soldiers laying waste to the countryside, produced generic pseudo-Slavic\ngobbledygook like this:\n\n\nOvishta reshta rovishta. Vishna beretishti? Ushna barishta dashto.\nNa darishnoshto. Korapshnoshashit darishtoy. Aobashni bedetpa.\n\n\nAnd of course, when the words in one language are pronounced with\nthe sound pattern of another, we call it a foreign accent, as in the\nfollowing excerpt from a fractured fairy tale by Bob Belviso:\n\n\nGIACCHE ENNE BINNESTAUCCHE\n\nUans appona taim uase disse boi. Neimmese Giacche. Naise boi.\nLive uite ise mamma. Mainde da cao.\n\nUane dei, di spaghetti ise olle ronne aute. Dei goine feinte fromme\n\n\nThe Sounds of Silence 173\n\n\n\nno fudde. Mamma soi orais, \"Oreie Giacche, teicche da cao enne\ntraide erra forre bocchese spaghetti enne somme uaine.\"\n\nBai enne bai commese omme Giacche. I garra no fudde, i garra\nno uaine. Meichese misteicche, enne traidese da cao forre bonce\nbinnese.\n\nGiacchasse!\n\n\n\nWhat defines the sound pattern of a language? It must be more\nthan just an inventory of phonemes. Consider the following words:\n\n\nptak thale hlad\nplaft sram mgla\nvlas flutch dnom\nrtut toasp nyip"
    },
    {
        "document_id": "0",
        "parent_id": 245,
        "parent_text": "The Sounds of Silence 173\n\n\n\nno fudde. Mamma soi orais, \"Oreie Giacche, teicche da cao enne\ntraide erra forre bocchese spaghetti enne somme uaine.\"\n\nBai enne bai commese omme Giacche. I garra no fudde, i garra\nno uaine. Meichese misteicche, enne traidese da cao forre bonce\nbinnese.\n\nGiacchasse!\n\n\n\nWhat defines the sound pattern of a language? It must be more\nthan just an inventory of phonemes. Consider the following words:\n\n\nptak thale hlad\nplaft sram mgla\nvlas flutch dnom\nrtut toasp nyip\n\n\nAll of the phonemes are found in English, but any native speaker\nrecognizes that _thale, plaft,_ and _flutch_ are not English words but could\nbe, whereas the remaining ones are not English words and could not\nbe. Speakers must have tacit knowledge about how phonemes are\nstrung together in their language.\n\nPhonemes are not assembled into words as one-dimensional leftto-right strings. Like words and phrases, they are grouped into units,\nwhich are then grouped into bigger units, and so on, defining a tree.\nThe group of consonants (C) at the beginning of a syllable is called\nan onset; the vowel (V) and any consonants coming after it are called\nthe rime:\n\n\nThe rules generating syllables define legal and illegal kinds of words\nin a language. In English an onset can consist of a cluster of consonants, like _flit, thrive,_ and _spring,_ as long as they follow certain restric\n\n174 THE LANGUAGE INSTINCT\n\n\ntions. (For example, _vlit_ and _sring_ are impossible.) A rime can consist\nof a vowel followed by a consonant or certain clusters of consonants,\nas in _toast, lift,_ and _sixths._ In Japanese, in contrast, an onset can have\nonly a single consonant and a rime must be a bare vowel; hence\n_strawberry ice cream_ is translated as _sutoroberi aisukurimo, girlfriend_\nas _garufurendo._ Italian allows some clusters of consonants in an onset\nbut no consonants at the end of a rime. Belviso used this constraint\nto simulate the sound pattern of Italian in the Giacche story; _and_\nbecomes _enne, from_ becomes _fromme, beans_ becomes _binnese._"
    },
    {
        "document_id": "0",
        "parent_id": 246,
        "parent_text": "Onsets and rimes not only define the possible sounds of a language;\nthey are the pieces of word-sound that are most salient to people,\nand thus are the units that get manipulated in poetry and word games.\nWords that rhyme share a rime; words that alliterate share an onset\n(or just an initial consonant). Pig Latin, eggy-peggy, aygo-paygo, and\nother secret languages of children tend to splice words at onset-rime\nboundaries, as does the Yinglish construction in _fancy-shmancy_ and\n_Oedipus-Shmoedipus._ In the 1964 hit song \"The Name Game\"\n(\"Noam Noam Bo-Boam, Bonana Fana Fo-Foam, Fee Fi Mo Moam,\nNoam\"), Shirley Ellis could have saved several lines in the stanza\nexplaining the rules if she had simply referred to onsets and rimes.\n\nSyllables, in turn, are collected into rhythmic groups called feet:\n\n\nSyllables and feet are classified as strong (s) and weak (w) by other\nrules, and the pattern of weak and strong branches determines how\nmuch stress each syllable will be given when it is pronounced. Feet,\nlike onsets and rhymes, are salient chunks of word that we tend to\n\n\nThe Sounds of Silence 175\n\n\nmanipulate in poetry and wordplay. Meter is defined by the kind of\nfeet that go into a line. A succession of feet with a strong-weak pattern\nis a trochaic meter, as in _Mary had a little lamb;_ a succession with a\nweak-strong pattern is iambic, as in _The rain in Spain falls mainly in_\n_the plain._ An argot popular among young ruffians contains forms like\n_fan-fuckin-tastic, abso-bloody-lutely, Phila-fuckin-delphia,_ and _Kalama-_\n_fuckin-zoo._ Ordinarily, expletives appear in front of an emphatically\nstressed word; Dorothy Parker once replied to a question about why\nshe had not been at the symphony lately by saying \"I've been too\nfucking busy and vice versa.\" But in this lingo they are placed inside\na single word, always in front of a stressed foot. The rule is followed\nreligiously: _Philadel-fuckin-phia_ would get you laughed out of the pool\nhall."
    },
    {
        "document_id": "0",
        "parent_id": 247,
        "parent_text": "The assemblies of phonemes in the morphemes and words stored\nin memory undergo a series of adjustments before they are actually\narticulated as sounds, and these adjustments give further definition\nto the sound pattern of a language. Say the words _pat_ and _pad._ Now\nadd the inflection _-ing_ and pronounce them again: _patting, padding._\nIn many dialects of English they are now pronounced identically; the\noriginal difference between the _t_ and the _d_ has been obliterated. What\nobliterated them is a phonological rule called flapping: if a stop\nconsonant produced with the tip of the tongue appears between two\nvowels, the consonant is pronounced by flicking the tongue against\nthe gum ridge, rather than keeping it there long enough for air pressure to build up. Rules like flapping apply not only when two morphemes are joined, like _pat_ and _-ing;_ they also apply to one-piece\nwords. For many English speakers _ladder_ and _latter,_ though they\n\"feel\" like they are made out of different sounds and indeed are\nrepresented differently in the mental dictionary, are pronounced the\nsame (except in artificially exaggerated speech). Thus when cows\ncome up in conversation, often some wag will speak of an udder\nmystery, an udder success, and so on.\n\nInterestingly, phonological rules apply in an ordered sequence, as\nif words were manufactured on an assembly line. Pronounce _write_\nand _ride._ In most dialects of English, the vowels differ in some way.\nAt the very least, the _i_ in _ride_ is longer than the _i_ in _write._ In some\ndialects, like the Canadian English of newscaster Peter Jennings,\n\n\n176 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 248,
        "parent_text": "Interestingly, phonological rules apply in an ordered sequence, as\nif words were manufactured on an assembly line. Pronounce _write_\nand _ride._ In most dialects of English, the vowels differ in some way.\nAt the very least, the _i_ in _ride_ is longer than the _i_ in _write._ In some\ndialects, like the Canadian English of newscaster Peter Jennings,\n\n\n176 THE LANGUAGE INSTINCT\n\n\nhockey star Wayne Gretzky, and yours truly (an accent satirized a\nfew years back, eh, in the television characters Bob and Doug McKenzie), the vowels are completely different: _ride_ contains a diphthong\ngliding from the vowel in _hot_ to the vowel _ee; write_ contains a diphthong gliding from the higher vowel in _hut_ to _ee._ But regardless of\nexactly how the vowel is altered, it is altered in a consistent pattern:\nthere are no words with long/low _i_ followed by _t,_ nor with short/high\n_i_ followed by _d._ Using the same logic that allowed Lois Lane in her\nrare lucid moments to deduce that Clark Kent and Superman were\nthe same, namely that they are never in the same place at the same\ntime, we can infer that there is a single _i_ in the mental dictionary,\nwhich is altered by a rule before being pronounced, depending on\nwhether it appears in the company of _t_ or _d._ We can even guess that\nthe initial form stored in memory is like the one in _ride,_ and that _write_\nis the product of the rule, rather than vice versa. The evidence is that\nwhen there is no _t_ or _d_ after the _i,_ as in _rye,_ and thus no rule disguising\nthe underlying form, it is the vowel in _ride_ that we hear."
    },
    {
        "document_id": "0",
        "parent_id": 249,
        "parent_text": "Now pronounce _writing_ and _riding._ The _t_ and _d_ have been made\nidentical by the flapping rule. But the two _**i's**_ are still different. How\ncan that be? It is only the difference between _t_ and _d_ that causes a\ndifference between the two _**i's,**_ and that difference has been erased\nby the flapping rule. This shows that the rule that alters _i_ must have\napplied _before_ the flapping rule, while _t_ and _d_ were still distinct. In\nother words, the two rules apply in a fixed order, vowel-change before\nflapping. Presumably the ordering comes about because the flapping\nrule is in some sense there to make articulation easier and thus is\nfarther downstream in the chain of processing from brain to tongue.\n\nNotice another important feature of the vowel-altering rule. The\nvowel _i_ is altered in front of many different consonants, not just _t._\nCompare:\n\n\nprize price\nfive fife\njibe hype\n\ngeiger biker\n\n\nDoes this mean there are five different rules that alter _i_ —one for _z_\nversus _s,_ one for _v_ versus _f_, and so on? Surely not. The changetriggering consonants _t_, _s, f, p,_ and _k_ all differ in the same way from\n\n\nThe Sounds of Silence 177\n\n\ntheir counterparts _d, z, v, b,_ and _g:_ they are unvoiced, whereas the\ncounterparts are voiced. We need only one rule, then: change _i_ whenever it appears before an _unvoiced_ consonant. The proof that this is\nthe real rule in people's heads (and not just a way to save ink by\nreplacing five rules with one) is that if an English speaker succeeds\nin pronouncing the German _ch_ in _the Third Reich,_ that speaker will\npronounce the _ei_ as in _write,_ not as in _ride._ The consonant _ch_ is not\nin the English inventory, so English speakers could not have learned\nany rule specifically applying to it. But it is an unvoiced consonant,\nand if the rule applies to any unvoiced consonant, an English speaker\nknows exactly what to do."
    },
    {
        "document_id": "0",
        "parent_id": 250,
        "parent_text": "This selectivity works not only in English but in all languages.\nPhonological rules are rarely triggered by a single phoneme; they are\ntriggered by an entire class of phonemes that share one or more\nfeatures (like voicing, stop versus fricative manner, or which organ is\ndoing the articulating). This suggests that rules do not \"see\" the\nphonemes in a string but instead look right through them to the\nfeatures they are made from.\n\nAnd it is features, not phonemes, that are manipulated by the rules.\nPronounce the following past-tense forms:\n\n\n\nwalked\nslapped\npassed\n\n\n\njogged\nsobbed\nfizzed\n\n\n\nIn _walked, slapped,_ and _passed,_ the _-ed_ is pronounced as a _t;_ in _jogged,_\n_sobbed,_ and _fizzed,_ it is pronounced as a _d._ By now you can probably\nfigure out what is behind the difference: the _t_ pronunciation comes\nafter voiceless consonants like _k, p,_ and _s;_ the _d_ comes after voiced\nones like _g, b,_ and _z._ There must be a rule that adjusts the pronunciation of the suffix _-ed_ by peering back into the final phoneme of the\nstem and checking to see if it has the voicing feature. We can confirm\nthe hunch by asking people to pronounce _Mozart out-Bached Bach._\nThe verb _to out-Bach_ contains the sound _ch,_ which does not exist in\nEnglish. Nonetheless everyone pronounces the _-ed_ as a _t_, because the\n_ch_ is unvoiced, and the rule puts a _t_ next to any unvoiced consonant.\nWe can even determine whether people store the _-ed_ suffix as a t in\nmemory and use the rule to convert it to a _d_ for some words, or the\nother way around. Words like _play_ and _row_ have no consonant at the\n\n\n178 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 251,
        "parent_text": "178 THE LANGUAGE INSTINCT\n\n\nend, and everyone pronounces their past tenses like _plade_ and _rode,_\nnot _plate_ and _rote._ With no stem consonant triggering a rule, we\nmust be hearing the suffix in its pure, unaltered form in the mental\ndictionary, that is, _d._ It is a nice demonstration of one of the main\ndiscoveries of modern linguistics: a morpheme may be stored in the\nmental dictionary in a different form from the one that is ultimately\npronounced.\n\nReaders with a taste for theoretical elegance may want to bear with\nme for one more paragraph. Note that there is an uncanny pattern in\nwhat the _d-to-t_ rule is doing. First, _d_ itself is voiced, and it ends up\nnext to voiced consonants, whereas _t_ is unvoiced, and it ends up next\nto unvoiced consonants. Second, except for voicing, t and _d_ are the\nsame; they use the same speech organ, the tongue tip, and that organ\nmoves in the same way, namely sealing up the mouth at the gum ridge\nand then releasing. So the rule is not just tossing phonemes around\narbitrarily, like changing a _p_ to an _l_ following a high vowel or any\nother substitution one might pick at random. It is doing delicate\nsurgery on the _-ed_ suffix, adjusting it to be the same in voicing as its\nneighbor, but leaving the rest of its features alone. That is, in converting _slap + ed_ to _slapt,_ the rule is \"spreading\" the voicing instruction, packaged with the _p_ at the end of _slap,_ onto the _-ed_ suffix, like\nthis:\n\n\nThe voicelessness of the _t_ in _slapped_ matches the voicelessness of the\n_p_ in _slapped_ because they are the _same_ voicelessness; they are mentally\nrepresented as a single feature linked to two segments. This happens\nvery often in the world's languages. Features like voicing, vowel quality, and tones can spread sideways or sprout connections to several\n\n\nThe Sounds of Silence 179\n\n\nphonemes in a word, as if each feature lived on its own horizontal\n\"tier,\" rather than being tethered to one and only one phoneme."
    },
    {
        "document_id": "0",
        "parent_id": 252,
        "parent_text": "The Sounds of Silence 179\n\n\nphonemes in a word, as if each feature lived on its own horizontal\n\"tier,\" rather than being tethered to one and only one phoneme.\n\nSo phonological rules \"see\" features, not phonemes, and they adjust features, not phonemes. Recall, too, that languages tend to arrive\nat an inventory of phonemes by multiplying out the various combinations of some set of features. These facts show that features, not\nphonemes, are the atoms of linguistic sound stored and manipulated\nin the brain. A phoneme is merely a bundle of features. Thus even in\ndealing with its smallest units, the features, language works by using\na combinatorial system.\n\n\nEvery language has phonological rules, but what are they for? You\nmay have noticed that they often make articulation easier. Flapping\na _t_ or a _d_ between two vowels is faster than keeping the tongue in place\nlong enough for air pressure to build up. Spreading voicelessness from\nthe end of a word to its suffix spares the talker from having to turn\nthe larynx off while pronouncing the end of the stem and then turn\nit back on again for the suffix. At first glance, phonological rules seem\nto be a mere summary of articulatory laziness. And from here it is a\nsmall step to notice phonological adjustments in some dialect other\nthan one's own and conclude that they typify the slovenliness of the\nspeakers. Neither side of the Atlantic is safe. George Bernard Shaw\nwrote:\n\n\nThe English have no respect for their language and will not teach\ntheir children to speak it. They cannot spell it because they have\nnothing to spell it with but an old foreign alphabet of which only\nthe consonants—and not all of them—have any agreed speech\nvalue. Consequently it is impossible for an Englishman to open his\nmouth without making some other Englishman despise him.\n\n\nIn his article \"Howta Reckanize American Slurvian,\" Richard Lederer\nwrites:"
    },
    {
        "document_id": "0",
        "parent_id": 253,
        "parent_text": "The English have no respect for their language and will not teach\ntheir children to speak it. They cannot spell it because they have\nnothing to spell it with but an old foreign alphabet of which only\nthe consonants—and not all of them—have any agreed speech\nvalue. Consequently it is impossible for an Englishman to open his\nmouth without making some other Englishman despise him.\n\n\nIn his article \"Howta Reckanize American Slurvian,\" Richard Lederer\nwrites:\n\n\nLanguage lovers have long bewailed the sad state of pronunciation\nand articulation in the United States. Both in sorrow and in anger,\nspeakers afflicted with sensitive ears wince at such mumblings as\n\n\n180 THE LANGUAGE INSTINCT\n\n\n_guvmint_ for _government_ and _assessories_ for _accessories._ Indeed, everywhere we turn we are assaulted by a slew of slurrings.\n\n\nBut if their ears were even more sensitive, these sorrowful speakers\nmight notice that in fact there is no dialect in which sloppiness\nprevails. Phonological rules give with one hand and take away with\nthe other. The same bumpkins who are derided for dropping _g's_ in\n_Nothin' doin'_ are likely to enunciate the vowels in _pó-lice_ and _acci-_\n_dént_ that pointy-headed intellectuals reduce to a neutral \"uh\" sound.\nWhen the Brooklyn Dodgers pitcher Waite Hoyt was hit by a ball, a\nfan in the bleachers shouted, \"Hurt's hoit!\" Bostonians who pahk\ntheir cah in Hahvahd Yahd name their daughters Sheiler and Linder.\nIn 1992 an ordinance was proposed that would have banned the\nhiring of any immigrant teacher who \"speaks with an accent\" in—I\nam not making this up—Westfield, Massachusetts. An incredulous\nwoman wrote to the _Boston Globe_ recalling how her native New\nEngland teacher defined \"homonym\" using the example _orphan_ and\n_often._ Another amused reader remembered incurring the teacher's\nwrath when he spelled \"cuh-rée-uh\" _k-o-r-e-a_ and \"cuh-rée-ur\" _c-a-r-_\n_e-e-r,_ rather than vice versa. The proposal was quickly withdrawn."
    },
    {
        "document_id": "0",
        "parent_id": 254,
        "parent_text": "There is a good reason why so-called laziness in pronunciation is\nin fact tightly regulated by phonological rules, and why, as a consequence, no dialect allows its speakers to cut corners at will. Every act\nof sloppiness on the part of a speaker demands a compensating\nmeasure of mental effort on the part of the conversational partner. A\nsociety of lazy talkers would be a society of hard-working listeners.\nIf speakers were to have their way, all rules of phonology would\nspread and reduce and delete. But if listeners were to have their way,\nphonology would do the opposite: it would enhance the acoustic\ndifferences between confusable phonemes by forcing speakers to exaggerate or embroider them. And indeed, many rules of phonology\ndo that. (For example, there is a rule that forces English speakers to\nround their lips while saying _sh_ but not while saying _s._ The benefit of\nforcing everyone to make this extra gesture is that the long resonant\nchamber formed by the pursed lips enhances the lower-frequency\nnoise that distinguishes _sh_ from _s,_ allowing for easier identification of\nthe _sh_ by the listener.) Although every speaker soon becomes a listener, human hypocrisy would make it unwise to depend on the\nspeaker's foresight and consideration. Instead, a single, partly arbi\n\nThe Sounds of Silence 181\n\n\ntrary set of phonological rules, some reducing, some enhancing, is\nadopted by every member of a linguistic community when he or she\nacquires the local dialect as a child."
    },
    {
        "document_id": "0",
        "parent_id": 255,
        "parent_text": "The Sounds of Silence 181\n\n\ntrary set of phonological rules, some reducing, some enhancing, is\nadopted by every member of a linguistic community when he or she\nacquires the local dialect as a child.\n\nPhonological rules help listeners even when they do not exaggerate\nsome acoustic difference. By making speech patterns predictable, they\nadd redundancy to a language; English text has been estimated as\nbeing between two and four times as long as it has to be for its\ninformation content. For example, this book takes up about 900,000\ncharacters on my computer disk, but my file compression program\ncan exploit the redundancy in the letter sequences and squeeze it into\nabout 400,000 characters; computer files that do not contain English\ntext cannot be squished nearly that much. The logician Quine explains\nwhy many systems have redundancy built in:\n\n\nIt is the judicious excess over minimum requisite support. It is why\na good bridge does not crumble when subjected to stress beyond\nwhat reasonably could have been foreseen. It is fallback and failsafe.\nIt is why we address our mail to city and state in so many words,\ndespite the zip code. One indistinct digit in the zip code would\nspoil everything. . . . A kingdom, legend tells us, was lost for want\nof a horseshoe nail. Redundancy is our safeguard against such instability.\n\n\nThanks to the redundancy of language, yxx cxn xndxrstxnd whxt x\nxm wrxtxng xvxn xf x rxplxcx xll thx vxwxls wxth xn \" x \" (t gts lttl\nhrdr f y dn't vn kn whr th vwls r). In the comprehension of speech,\nthe redundancy conferred by phonological rules can compensate for\nsome of the ambiguity in the sound wave. For example, a listener can\nknow that \"thisrip\" must be _this rip_ and not _the srip_ because the\nEnglish consonant cluster _sr_ is illegal."
    },
    {
        "document_id": "0",
        "parent_id": 256,
        "parent_text": "Thanks to the redundancy of language, yxx cxn xndxrstxnd whxt x\nxm wrxtxng xvxn xf x rxplxcx xll thx vxwxls wxth xn \" x \" (t gts lttl\nhrdr f y dn't vn kn whr th vwls r). In the comprehension of speech,\nthe redundancy conferred by phonological rules can compensate for\nsome of the ambiguity in the sound wave. For example, a listener can\nknow that \"thisrip\" must be _this rip_ and not _the srip_ because the\nEnglish consonant cluster _sr_ is illegal.\n\n\nSo why is it that a nation that can put a man on the moon cannot\nbuild a computer that can take dictation? According to what I have\nexplained so far, each phoneme should have a telltale acoustic signature: a set of resonances for vowels, a noise band for fricatives, a\nsilence-burst-transition sequence for stops. The sequences of phonemes are massaged in predictable ways by ordered phonological\n\n\n182 THE LANGUAGE INSTINCT\n\n\nrules, whose effects could presumably be undone by applying them\nin reverse.\n\nThe reason that speech recognition is so hard is that there's many\na slip 'twixt brain and lip. No two people's voices are alike, either in\nthe shape of the vocal tract that sculpts the sounds, or in the person's\nprecise habits of articulation. Phonemes also sound very different\ndepending on how much they are stressed and how quickly they are\nspoken; in rapid speech, many are swallowed outright."
    },
    {
        "document_id": "0",
        "parent_id": 257,
        "parent_text": "But the main reason an electric stenographer is not just around the\ncorner has to do with a general phenomenon in muscle control called\ncoarticulation. Put a saucer in front of you and a coffee cup a foot or\nso away from it on one side. Now quickly touch the saucer and pick\nup the cup. You probably touched the saucer at the edge nearest the\ncup, not dead center. Your fingers probably assumed the handlegrasping posture while your hand was making its way to the cup, well\nbefore it arrived. This graceful smoothing and overlapping of gestures\nis ubiquitous in motor control. It reduces the forces necessary to\nmove body parts around and lessens the wear and tear on the joints.\nThe tongue and throat are no different. When we want to articulate\na phoneme, our tongue cannot assume the target posture instantaneously; it is a heavy slab of meat that takes time to heft into place. So\nwhile we are moving it, our brains are anticipating the next posture\nin planning the trajectory, just like the cup-and-saucer maneuver.\nAmong the range of positions in the mouth that can define a phoneme,\nwe place the tongue in the one that offers the shortest path to the\ntarget for the next phoneme. If the current phoneme does not specify\nwhere a speech organ should be, we anticipate where the next phoneme wants it to be and put it there in advance. Most of us are\ncompletely unaware of these adjustments until they are called to our\nattention. Say _Cape Cod._ Until now you probably never noticed that\nyour tongue body is in different positions for the two _k_ sounds. In\n_horseshoe,_ the first s becomes a _sh;_ in _NPR,_ the n becomes an _m;_ in\n_month_ and _width,_ the _n_ and _d_ are articulated at the teeth, not the\nusual gum ridge.\n\nBecause sound waves are minutely sensitive to the shapes of the\ncavities they pass through, this coarticulation wreaks havoc with\nthe speech sound. Each phoneme's sound signature is colored by the\nphonemes that come before and after, sometimes to the point of\n\n\nThe Sounds of Silence 183"
    },
    {
        "document_id": "0",
        "parent_id": 258,
        "parent_text": "Because sound waves are minutely sensitive to the shapes of the\ncavities they pass through, this coarticulation wreaks havoc with\nthe speech sound. Each phoneme's sound signature is colored by the\nphonemes that come before and after, sometimes to the point of\n\n\nThe Sounds of Silence 183\n\n\nhaving nothing in common with its sound signature in the company\nof a different set of phonemes. That is why you cannot cut up a tape\nof the sound _cat_ and hope to find a beginning piece that contains the\n_k_ alone. As you make earlier and earlier cuts', the piece may go from\nsounding like _ka_ to sounding like a chirp or whistle. This shingling\nof phonemes in the speech stream could, in principle, be a boon to\nan optimally designed speech recognizer. Consonant and vowels are\nbeing signaled simultaneously, greatly increasing the rate of phonemes\nper second, as I noted at the beginning of this chapter, and there are\nmany redundant sound cues to a given phoneme. But this advantage\ncan be enjoyed only by a high-tech speech recognizer, one that has\nsome kind of knowledge of how vocal tracts blend sounds.\n\nThe human brain, of course, is a high-tech speech recognizer, but\nno one knows how it succeeds. For this reason psychologists who\nstudy speech perception and engineers who build speech recognition\nmachines keep a close eye on each other's work. Speech recognition\nmay be so hard that there are only a few ways it could be solved in\nprinciple. If so, the way the brain does it may offer hints as to the\nbest way to build a machine to do it, and how a successful machine\ndoes it may suggest hypotheses about how the brain does it."
    },
    {
        "document_id": "0",
        "parent_id": 259,
        "parent_text": "Early in the history of speech research, it became clear that human\nlisteners might somehow take advantage of their expectations of the\nkinds of things a speaker is likely to say. This could narrow down the\nalternatives left open by the acoustic analysis of the speech signal.\nWe have already noted that the rules of phonology provide one sort\nof redundancy that can be exploited, but people might go even farther. The psychologist George Miller played tapes of sentences in\nbackground noise and asked people to repeat back exactly what they\nheard. Some of the sentences followed the rules of English syntax\nand made sense:\n\n\nFurry wildcats fight furious battles.\nRespectable jewelers give accurate appraisals.\nLighted cigarettes create smoky fumes.\nGallant gentlemen save distressed damsels.\nSoapy detergents dissolve greasy stains.\n\n\n184 THE LANGUAGE INSTINCT\n\n\nOthers were created by scrambling the words within phrases to create\ncolorless-green-ideas sentences, grammatical but nonsensical:\n\n\nFurry jewelers create distressed stains.\nRespectable cigarettes save greasy battles.\nLighted gentlemen dissolve furious appraisals.\nGallant detergents fight accurate fumes.\nSoapy wildcats give smoky damsels.\n\n\nA third kind was created by scrambling the phrase structure but\nkeeping related words together, as in\n\n\nFurry fight furious wildcat battles.\nJewelers respectable appraisals accurate give.\n\n\nFinally, some sentences were utter word salad, like\n\n\nFurry create distressed jewelers stains.\nCigarettes respectable battles greasy save.\n\n\nPeople did best with the grammatical sensible sentences, worse with\nthe grammatical nonsense and the ungrammatical sense, and worst\nof all with the ungrammatical nonsense. A few years later the psychologist Richard Warren taped sentences like _The state governors met_\n_with their respective legislatures convening in the capital city,_ excised\nthe first _s_ from _legislatures,_ and spliced in a cough. Listeners could\nnot tell that any sound was missing."
    },
    {
        "document_id": "0",
        "parent_id": 260,
        "parent_text": "People did best with the grammatical sensible sentences, worse with\nthe grammatical nonsense and the ungrammatical sense, and worst\nof all with the ungrammatical nonsense. A few years later the psychologist Richard Warren taped sentences like _The state governors met_\n_with their respective legislatures convening in the capital city,_ excised\nthe first _s_ from _legislatures,_ and spliced in a cough. Listeners could\nnot tell that any sound was missing.\n\nIf one thinks of the sound wave as sitting at the bottom of a\nhierarchy from sounds to phonemes to words to phrases to the meanings of sentences to general knowledge, these demonstrations seem\nto imply that human speech perception works from the top down\nrather than just from the bottom up. Maybe we are constantly guessing what a speaker will say next, using every scrap of conscious\nand unconscious knowledge at our disposal, from how coarticulation\ndistorts sounds, to the rules of English phonology, to the rules of\nEnglish syntax, to stereotypes about who tends to do what to whom\nin the world, to hunches about what our conversational partner has\nin mind at that very moment. If the expectations are accurate enough,\nthe acoustic analysis can be fairly crude; what the sound wave lacks,\n\n\nThe Sounds of Silence 185"
    },
    {
        "document_id": "0",
        "parent_id": 261,
        "parent_text": "The Sounds of Silence 185\n\n\nthe context can fill in. For example, if you are listening to a discussion\nabout the destruction of ecological habitats, you might be on the\nlookout for words pertaining to threatened animals and plants, and\nthen when you hear speech sounds whose phonemes you cannot pick\nout like \"eesees,\" you would perceive it correctly as _species_ —unless\nyou are Emily Litella, the hearing-impaired editorialist on _Saturday_\n_Night Live_ who argued passionately against the campaign to protect\nendangered feces. (Indeed, the humor in the Gilda Radner character,\nwho also fulminated against saving Soviet jewelry, stopping violins in\nthe streets, and preserving natural racehorses, comes not from her\nimpairment at the bottom of the speech-processing system but from\nher ditziness at the top, the level that should have prevented her from\narriving at her interpretations.)"
    },
    {
        "document_id": "0",
        "parent_id": 262,
        "parent_text": "The top-down theory of speech perception exerts a powerful emotional tug on some people. It confirms the relativist philosophy that\nwe hear what we expect to hear, that our knowledge determines our\nperception, and ultimately that we are not in direct contact with any\nobjective reality. In a sense, perception that is strongly driven from\nthe top down would be a barely controlled hallucination, and that is\nthe problem. A perceiver forced to rely on its expectations is at a\nsevere disadvantage in a world that is unpredictable even under the\nbest of circumstances. There is reason to believe that human speech\nperception is, in fact, driven quite strongly by acoustics. If you have\nan indulgent friend, you can try the following experiment. Pick ten\nwords at random out of a dictionary, phone up the friend, and say the\nwords clearly. Chances are the friend will reproduce them perfectly,\nrelying only on the information in the sound wave and knowledge of\nEnglish vocabulary and phonology. The friend could not have been\nusing any higher-level expectations about phrase structure, context,\nor story line because a list of words blurted out of the blue has none.\nThough we may call upon high-level conceptual knowledge in noisy\nor degraded circumstances (and even here it is not clear whether the\nknowledge alters perception or just allows us to guess intelligently\nafter the fact), our brains seem designed to squeeze every last drop\nof phonetic information out of the sound wave itself. Our sixth sense\nmay perceive speech as language, not as sound, but it _is_ a sense,\nsomething that connects us to the world, and not just a form of\nsuggestibility.\n\nAnother demonstration that speech perception is not the same\n\n\n186 THE LANGUAGE INSTINCT\n\n\nthing as fleshing out expectations comes from an illusion that the\ncolumnist Jon Carroll has called the mondegreen, after his mis-hearing of the folk ballad \"The Bonnie Earl O'Moray\":"
    },
    {
        "document_id": "0",
        "parent_id": 263,
        "parent_text": "Another demonstration that speech perception is not the same\n\n\n186 THE LANGUAGE INSTINCT\n\n\nthing as fleshing out expectations comes from an illusion that the\ncolumnist Jon Carroll has called the mondegreen, after his mis-hearing of the folk ballad \"The Bonnie Earl O'Moray\":\n\n\nOh, ye hielands and ye lowlands,\nOh, where hae ye been?\nThey have slain the Earl of Moray,\nAnd laid him on the green.\n\n\nHe had always thought that the lines were \"They have slain the Earl\nof Moray, And Lady Mondegreen.\" Mondegreens are fairly common\n(they are an extreme version of the Pullet Surprises and Pencil Vaneas\nmentioned earlier); here are some examples:\n\n\nA girl with colitis goes by. [A girl with kaleidoscope eyes.\nFrom the Beatles song \"Lucy in the Sky with Diamonds.\"]\nOur father wishart in heaven; Harold be they name . . .\n\nLead us not into Penn Station. [Our father which art in\nHeaven; hallowed be thy name . . . Lead us not into\ntemptation. From the Lord's Prayer.]\nHe is trampling out the vintage where the grapes are\n\nwrapped and stored. [. . . grapes of wrath are stored.\nFrom \"The Battle Hymn of the Republic.\"]\nGladly the cross-eyed bear. [Gladly the cross I'd bear.]\nI'll never be your pizza burnin'. [. . . your beast of burden.\n\nFrom the Rolling Stones song.]\nIt's a happy enchilada, and you think you're gonna drown.\n\n[It's a half an inch of water . . . From the John Prine song\n\"That's the Way the World Goes 'Round.\"]\n\n\nThe interesting thing about mondegreens is that the mis-hearings\nare generally _less_ plausible than the intended lyrics. In no way do they\nbear out any sane listener's general expectations of what a speaker is\nlikely to say or mean. (In one case a student stubbornly mis-heard\nthe Shocking Blue hit song \"I'm your Venus\" as \"I'm Your Penis\"\nand wondered how it was allowed on the radio.) The mondegreens\ndo conform to English phonology, English syntax (sometimes), and\nEnglish vocabulary (though not always, as in the word _mondegreen_\nitself). Apparently, listeners lock in to some set of words that fit the"
    },
    {
        "document_id": "0",
        "parent_id": 264,
        "parent_text": "The Sounds of Silence 187\n\n\nsound and that hang together more or less as English words and\nphrases, but plausibility and general expectations are not running\nthe show.\n\nThe history of artificial speech recognizers offers a similar moral.\nIn the 1970s a team of artificial intelligence researchers at CarnegieMellon University headed by Raj Reddy designed a computer program\ncalled HEARSAY that interpreted spoken commands to move chess\npieces. Influenced by the top-down theory of speech perception, they\ndesigned the program as a \"community\" of \"expert\" subprograms\ncooperating to give the most likely interpretation of the signal. There\nwere subprograms that specialized in acoustic analysis, in phonology,\nin the dictionary, in syntax, in rules for the legal moves of chess, even\nin chess strategy as applied to the game in progress. According to\none story, a general from the defense agency that was funding the\nresearch came up for a demonstration. As the scientists sweated he\nwas seated in front of a chessboard and a microphone hooked up to\nthe computer. The general cleared his throat. The program printed\n\"Pawn to King 4.\""
    },
    {
        "document_id": "0",
        "parent_id": 265,
        "parent_text": "The recent program DragonDictate, mentioned earlier in the chapter, places the burden more on good acoustic, phonological, and\nlexical analyses, and that seems to be responsible for its greater success. The program has a dictionary of words and their sequences of\nphonemes. To help anticipate the effects of phonological rules and\ncoarticulation, the program is told what every English phoneme\nsounds like in the context of every possible preceding phoneme and\nevery possible following phoneme. For each word, these phonemesin-context are arranged into a little chain, with a probability attached\nto each transition from one sound unit to the next. This chain serves\nas a crude model of the speaker, and when a real speaker uses the\nsystem, the probabilities in the chain are adjusted to capture that\nperson's manner of speaking. The entire word, too, has a probability\nattached to it, which depends on its frequency in the language and\non the speaker's habits. In some versions of the program, the probability value for a word is adjusted depending on which word precedes\nit; this is the only top-down information that the program uses. All\nthis knowledge allows the program to calculate which word is most\nlikely to have come out of the mouth of the speaker given the input\nsound. Even then, DragonDictate relies more on expectancies than\nan able-eared human does. In the demonstration I saw, the program\n\n\n188 THE LANGUAGE INSTINCT\n\n\nhad to be coaxed into recognizing _word_ and _worm,_ even when they\nwere pronounced as clear as a bell, because it kept playing the odds\nand guessing higher-frequency _were_ instead.\n\n\nNow that you know how individual speech units are produced,\nhow they are represented in the mental dictionary, and how they are\nrearranged and smeared before they emerge from the mouth, you\nhave reached the prize at the bottom of this chapter: why English\nspelling is not as deranged as it first appears."
    },
    {
        "document_id": "0",
        "parent_id": 266,
        "parent_text": "had to be coaxed into recognizing _word_ and _worm,_ even when they\nwere pronounced as clear as a bell, because it kept playing the odds\nand guessing higher-frequency _were_ instead.\n\n\nNow that you know how individual speech units are produced,\nhow they are represented in the mental dictionary, and how they are\nrearranged and smeared before they emerge from the mouth, you\nhave reached the prize at the bottom of this chapter: why English\nspelling is not as deranged as it first appears.\n\nThe complaint about English spelling, of course, is that it pretends\nto capture the sounds of words but does not. There is a long tradition\nof doggerel making this point, of which this stanza is a typical example:\n\n\nBeware of heard, a dreadful word\nThat looks like beard and sounds like bird,\nAnd dead: it's said like bed, not bead—\nFor goodness' sake don't call it \"deed\"!\nWatch out for meat and great and threat\n(They rhyme with suite and straight and debt).\n\n\nGeorge Bernard Shaw led a vigorous campaign to reform the English alphabet, a system so illogical, he said, that it could spell _fish_ as\n\"ghoti\"— _gh_ as in _tough, o_ as in _women, ti_ as in _nation._ (\"Mnomnoupte\" for _minute_ and \"mnopspteiche\" for _mistake_ are other examples.) In his will Shaw bequeathed a cash prize to be awarded to the\ndesigner of a replacement alphabet for English, in which each sound\nin the spoken language would be recognizable by a single symbol. He\nwrote:\n\n\nTo realize the annual difference in favour of a forty-two letter\nphonetic alphabet . . . you must multiply the number of minutes in\nthe year, the number of people in the world who are continuously\nwriting English words, casting types, manufacturing printing and\nwriting machines, by which time the total figure will have become\nso astronomical that you will realize that the cost of spelling even\none sound with two letters has cost us centuries of unnecessary\nlabour. A new British 42 letter alphabet would pay for itself a\nmillion times over not only in hours but in moments. When this is"
    },
    {
        "document_id": "0",
        "parent_id": 267,
        "parent_text": "The Sounds of Silence 189\n\n\ngrasped, all the useless twaddle about enough and cough and laugh\nand simplified spelling will be dropped, and the economists and\nstatisticians will be set to work to gather in the orthographic Golconda.\n\n\nMy defense of English spelling will be halfhearted. For although\nlanguage is an instinct, written language is not. Writing was invented\na small number of times in history, and alphabetic writing, where one\ncharacter corresponds to one sound, seems to have been invented\nonly once. Most societies have lacked written language, and those\nthat have it inherited it or borrowed it from one of the inventors.\nChildren must be taught to read and write in laborious lessons, and\nknowledge of spelling involves no daring leaps from the training\nexamples like the leaps we saw in Simon, Mayela, and the Jabba and\n_mice-eater_ experiments in Chapters 3 and 5. And people do not\nuniformly succeed. Illiteracy, the result of insufficient teaching, is the\nrule in much of the world, and dyslexia, a presumed congenital\ndifficulty in learning to read even with sufficient teaching, is a severe\nproblem even in industrial societies, found in five to ten percent of\nthe population.\n\nBut though writing is an artificial contraption connecting vision\nand language, it must tap into the language system at well-demarcated points, and that gives it a modicum of logic. In all known\nwriting systems, the symbols designate only three kinds of linguistic\nstructure: the morpheme, the syllable, and the phoneme. Mesopotamian cuneiform, Egyptian hieroglyphs, Chinese logograms, and\nJapanese kanji encode morphemes. Cherokee, Ancient Cypriot,\nand Japanese kana are syllable-based. All modern phonemic alphabets appear to be descended from a system invented by the Canaanites around 1700 B.C. No writing system has symbols for actual\nsound units that can be identified on an oscilloscope or spectrogram, such as a phoneme as it is pronounced in a particular context\nor a syllable chopped in half."
    },
    {
        "document_id": "0",
        "parent_id": 268,
        "parent_text": "Why has no writing system ever met Shaw's ideal of one symbol\nper sound? As Shaw himself said elsewhere, \"There are two tragedies\nin life. One is not to get your heart's desire. The other is to get it.\"\nJust think back to the workings of phonology and coarticulation. A\ntrue Shavian alphabet would mandate different vowels in _write_ and\n_ride,_ different consonants in _write_ and _writing,_ and different spellings\n\n\n190 THE LANGUAGE INSTINCT\n\n\nfor the past-tense suffix in _slapped, sobbed,_ and _sorted. Cape Cod_\nwould lose its visual alliteration. A _horse_ would be spelled differently\nfrom its _horseshoe,_ and National Public Radio would have the enigmatic abbreviation _MPR._ We would need brand-new letters for the\n_n_ in _month_ and the _d_ in _width._ I would spell _often_ differently from\n_orphan,_ but my neighbors here in the Hub would not, and their\nspelling of _career_ would be my spelling of _Korea_ and vice versa.\n\nObviously, alphabets do not and should not correspond to sounds;\nat best they correspond to the phonemes specified in the mental\ndictionary. The actual sounds are different in different contexts, so\ntrue phonetic spelling would only obscure their underlying identity.\nThe surface sounds are predictable by phonological rules, though, so\nthere is no need to clutter up the page with symbols for the actual\nsounds; the reader needs only the abstract blueprint for a word and\ncan flesh out the sound if needed. Indeed, for about eighty-four\npercent of English words, spelling is completely predictable from\nregular rules. Moreover, since dialects separated by time and space\noften differ most in the phonological rules that convert mental dictionary entries into pronunciations, a spelling corresponding to the\nunderlying entries, not the sounds, can be widely shared. The words\nwith truly weird spellings (like _of, people, women, have, said, do, done,_\nand _give)_ generally are the commonest ones in the language, so there\nis ample opportunity for everyone to memorize them."
    },
    {
        "document_id": "0",
        "parent_id": 269,
        "parent_text": "Even the less predictable aspects of spelling bespeak hidden linguistic regularities. Consider the following pairs of words where the same\nletters get different pronunciations:\n\n\n\nelectric-electricity\nphotograph-photography\ngrade-gradual\nhistory-historical\nrevise-revision\nadore-adoration\nbomb-bombard\nnation-national\ncritical-criticize\nmode-modular\nresident-residential\n\n\n\ndeclare-declaration\nmuscle-muscular\ncondemn-condemnation\ncourage-courageous\nromantic-romanticize\nindustry-industrial\nfact-factual\ninspire-inspiration\nsign-signature\nmalign-malignant\n\n\nThe Sounds of Silence 191\n\n\nOnce again the similar spellings, despite differences in pronunciation,\nare there for a reason: they are identifying two words as being based\non the same root morpheme. This shows that English spelling is\nnot completely phonemic; sometimes letters encode phonemes, but\nsometimes a sequence of letters is specific to a morpheme. And a\nmorphemic writing system is more useful than you might think. The\ngoal of reading, after all, is to understand the text, not to pronounce\nit. A morphemic spelling can help a reader distinguishing homophones, like _meet_ and _mete._ It can also tip off a reader that one word\ncontains another (and not just a phonologically identical impostor).\nFor example, spelling tells us that _overcome_ contains _come,_ so we\nknow that its past tense must be _overcame,_ whereas _succumb_ just\ncontains the sound \"kum,\" not the morpheme _come,_ so its past tense\nis not _succame_ but _succumbed._ Similarly, when something _recedes,_ one\nhas a _recession,_ but when someone _re-seeds_ a lawn, we have a _re-_\n_seeding._"
    },
    {
        "document_id": "0",
        "parent_id": 270,
        "parent_text": "In some ways, a morphemic writing system has served the Chinese\nwell, despite the inherent disadvantage that readers are at a loss when\nthey face a new or rare word. Mutually unintelligible dialects can\nshare texts (even if their speakers pronounce the words very differently), and many documents that are thousands of years old are\nreadable by modern speakers. Mark Twain alluded to such inertia in\nour own Roman writing system when he wrote, \"They spell it Vinci\nand pronounce it Vinchy; foreigners always spell better than they\npronounce.\"\n\nOf course English spelling could be better than it is. But it is\nalready much better than people think it is. That is because writing\nsystems do not aim to represent the actual sounds of talking, which\nwe do not hear, but the abstract units of language underlying them,\nwhich we do hear."
    },
    {
        "document_id": "0",
        "parent_id": 271,
        "parent_text": "##### 7"
    },
    {
        "document_id": "0",
        "parent_id": 272,
        "parent_text": "#### Talking Heads\n\n**For** centuries, people have been terrified that their programmed creations might outsmart them, overpower them, or put\nthem out of work. The fear has long been played out in fiction, from\nthe medieval Jewish legend of the Golem, a clay automaton animated\nby an inscription of the name of God placed in its mouth, to HAL,\nthe mutinous computer of _2001: A Space Odyssey._ But when the\nbranch of engineering called \"artificial intelligence\" (AI) was born in\nthe 1950s, it looked as though fiction was about to turn into frightening fact. It is easy to accept a computer calculating pi to a million\ndecimal places or keeping track of a company's payroll, but suddenly\ncomputers were also proving theorems in logic and playing respectable chess. In the years following there came computers that could\nbeat anyone but a grand master, and programs that outperformed\nmost experts at recommending treatments for bacterial infections and\ninvesting pension funds. With computers solving such brainy tasks,\nit seemed only a matter \"of time before a C3PO or a Terminator\nwould be available from the mail-order catalogues; only the easy tasks\nremained to be programmed. According to legend, in the 1970s\nMarvin Minsky, one of the founders of AI, assigned \"vision\" to a\ngraduate student as a summer project.\n\nBut household robots are still confined to science fiction. The main\nlesson of thirty-five years of AI research is that the hard problems are\neasy and the easy problems are hard. The mental abilities of a fouryear-old that we take for granted—recognizing a face, lifting a pencil,\nwalking across a room, answering a question—in fact solve some of\n\n\n192\n\n\n**Talking Heads** 193"
    },
    {
        "document_id": "0",
        "parent_id": 273,
        "parent_text": "But household robots are still confined to science fiction. The main\nlesson of thirty-five years of AI research is that the hard problems are\neasy and the easy problems are hard. The mental abilities of a fouryear-old that we take for granted—recognizing a face, lifting a pencil,\nwalking across a room, answering a question—in fact solve some of\n\n\n192\n\n\n**Talking Heads** 193\n\n\nthe hardest engineering problems ever conceived. Do not be fooled\nby the assembly-line robots in the automobile commercials; all they\ndo is weld and spray-paint, tasks that do not require these clumsy\nMr. Magoos to see or hold or place anything. And if you want to\nstump an artificial intelligence system, ask it questions like, Which is\nbigger, Chicago or a breadbox? Do zebras wear underwear? Is the\nfloor likely to rise up and bite you? If Susan goes to the store, does\nher head go with her? Most fears of automation are misplaced. As\nthe new generation of intelligent devices appears, it will be the stock\nanalysts and petrochemical engineers and parole board members who\nare in danger of being replaced by machines. The gardeners, receptionists, and cooks are secure in their jobs for decades to come.\n\nUnderstanding a sentence is one of these hard easy problems. To\ninteract with computers we still have to learn their languages; they\nare not smart enough to learn ours. In fact, it is all too easy to give\ncomputers more credit at understanding than they deserve."
    },
    {
        "document_id": "0",
        "parent_id": 274,
        "parent_text": "Understanding a sentence is one of these hard easy problems. To\ninteract with computers we still have to learn their languages; they\nare not smart enough to learn ours. In fact, it is all too easy to give\ncomputers more credit at understanding than they deserve.\n\nRecently an annual competition was set up for the computer program that can best fool users into thinking that they are conversing\nwith another human. The competition for the Loebner Prize was\nintended to implement a suggestion made by Alan Turing in a famous\n1950 paper. He suggested that the philosophical question \"Can machines think?\" could best be answered in an imitation game, where a\njudge converses with a person over one terminal and with a computer\nprogrammed to imitate a person on another. If the judge cannot guess\nwhich is which, Turing suggested, there is no basis for denying that the\ncomputer can think. Philosophical questions aside, it was apparent\nto the committee charged with overseeing the competition that no\nprogram could come close to winning the $100,000 prize, so they\ndevised a $1,500 version that would be fairer to the state of the art.\nEach of the judges had to stick to a single topic of conversation\nselected by the programmer or by the human foil, whichever it was,\nand the judge was not allowed to engage in any \"trickery or guile\"\nsuch as repeating a question ten times or asking whether zebras wear\nunderwear; the conversation had to be \"natural.\" After interacting\nwith several programs and human foils for about seven minutes\napiece, the judges ranked all the humans as more humanlike than any\nof the computers. About half the judges did, however, misidentify\nthe winning program as human.\n\nThe accomplishment is less impressive than it sounds. The rules\n\n\n194 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 275,
        "parent_text": "The accomplishment is less impressive than it sounds. The rules\n\n\n194 THE LANGUAGE INSTINCT\n\n\nhandcuffed the judges: \"unnatural trickery or guile\" is another way\nof referring to any attempt to determine whether one is conversing\nwith a human or a machine, which is the whole point of the test!\nAlso, the winning programmer shrewdly exploited the opportunity\nto designate the topic of conversation for his program. He chose\n\"whimsical conversation,\" which is a dubious example of a \"topic,\"\nand which, by definition, can be full of non sequiturs:\n\n\nJudge: It has been a long day! Now I think I'm ready for some fun.\n\nThe weather isn't very pleasant today. Do you have any jokes\nthat could lift the clouds?\nComputer: Everybody talks about the weather but nobody seems\n\nto do much about it. Why do you need to tell me now you think\nyou're ready for some fun? Groannnnnn . . .\nJudge: You're trying to make this difficult for me aren't you? I just\n\nexplained that I was ready for fun!\nComputer: Would you prefer it if it was not true that I are trying\n\nto make this difficult for you aren't you? I just explained that I\nwas ready for fun! I am, therefore I compute . . . What makes\nyou think I am trying to make this difficult for you aren't I?\nJudge: I can't say I understand the question . . . but the whimsy of\n\na poet is one thing and the whimsy of most of us is another.\nComputer: How do you know you can't say you understand the\n\nquestion .. . but the whimsy of a poet is one thing and the\nwhimsy of most of us is another."
    },
    {
        "document_id": "0",
        "parent_id": 276,
        "parent_text": "to make this difficult for you aren't you? I just explained that I\nwas ready for fun! I am, therefore I compute . . . What makes\nyou think I am trying to make this difficult for you aren't I?\nJudge: I can't say I understand the question . . . but the whimsy of\n\na poet is one thing and the whimsy of most of us is another.\nComputer: How do you know you can't say you understand the\n\nquestion .. . but the whimsy of a poet is one thing and the\nwhimsy of most of us is another.\n\n\nIn fact the programmer had simply updated a technique invented\nin 1965 by the computer scientist Joseph Weizenbaum. Weizenbaum\nwrote a rather stupid program called E L I Z A, named after the Shaw\nheroine, which looked for a few key words in an input line, retrieved\na canned response from a list, and inserted fragments of the input\nline into its response (with some minor substitutions, like \"you are\"\nfor \"I am\"). It could thus crudely simulate a conversation. One\nversion, called Doctor, mimicked a Rogerian psychotherapist, taking\nadvantage of Carl Rogers' philosophy that a therapist should recast\npatients' statements back to them for their contemplation. A version\nof the program was later sold as a computer game in Radio Shack\nstores, and another comes packaged with my word processing program, GNU Emacs. (The documentation says, \"If using Emacs be\n\n**Talking Heads** 195\n\n\ncomes terribly frustrating and none of the techniques described above\nsolve the problem, Emacs can still help you. Type 'M-x doctor\nRET.' \") Here is a typical dialogue:\n\n\nUser: I have been rather depressed lately.\nComputer: Are you depressed often?\nUser: Yes, almost all the time.\nComputer: Why do you say yes almost all the time?\nUser: Right now I feel like I could cry.\nComputer: Is it because right now you feel like you could cry that\nyou came to me?\n\n\nTo Weizenbaum's horror, one day he found his secretary transfixed\nat the terminal, pouring her heart out to the program."
    },
    {
        "document_id": "0",
        "parent_id": 277,
        "parent_text": "User: I have been rather depressed lately.\nComputer: Are you depressed often?\nUser: Yes, almost all the time.\nComputer: Why do you say yes almost all the time?\nUser: Right now I feel like I could cry.\nComputer: Is it because right now you feel like you could cry that\nyou came to me?\n\n\nTo Weizenbaum's horror, one day he found his secretary transfixed\nat the terminal, pouring her heart out to the program.\n\nMost computer scientists are annoyed by the Loebner Prize competition. They consider it a pointless publicity stunt, because it is an\nexercise in how to fool an amateur, not how to get computers to use\nlanguage. (Artificial intelligence researchers and other professionals\nwho are knowledgeable about language were not allowed to act as\njudges, and none bothered to compete; the submissions were from\nhobbyists.) It is about as productive as promoting biology by offering\na prize to the designer of the most convincing silk flower, or running\na space program by simulating a moon landing on a Hollywood\nback lot. There has been intensive research on computer languageunderstanding systems, but no serious engineer has the hubris to\npredict that the systems will duplicate the human ability anytime\nsoon.\n\nIn fact, from a scientist's perspective, people have no right to be\nas good at sentence understanding as they are. Not only can they\nsolve a viciously complex task, but they solve it _**fast.**_ Comprehension\nordinarily takes place in \"real time.\" Listeners keep up with talkers;\nthey do not wait for the end of a batch of speech and interpret it after\na proportional delay, like a critic reviewing a book. And the lag\nbetween speaker's mouth and listener's mind is remarkably short:\nabout a syllable or two, around half a second. Some people can\nunderstand _and_ repeat sentences, shadowing a speaker as he speaks,\nwith a lag of a quarter of a second!\n\nUnderstanding understanding has practical applications other than\nbuilding machines we can converse with. Human sentence comprehen\n\n196 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 278,
        "parent_text": "Understanding understanding has practical applications other than\nbuilding machines we can converse with. Human sentence comprehen\n\n196 THE LANGUAGE INSTINCT\n\n\nsion is fast and powerful, but it is not perfect. It works when the\nincoming conversation or text is structured in certain ways. When it is\nnot, the process can bog down, backtrack, and misunderstand. As we\nexplore language understanding in this chapter, we will discover which\nkinds of sentences mesh with the mind of the understander. One practical benefit is a set of guidelines for clear prose, a scientific style manual,\nsuch as Joseph Williams's 1990 _Style: Toward Clarity and Grace,_ which\nis informed by many of the findings we will examine.\n\nAnother practical application involves the law. Judges are frequently faced with guessing how a typical person is likely to understand some ambiguous passage, such as a customer scanning a\ncontract, a jury listening to instructions, or a member of the public\nreading a potentially libelous characterization. Many of people's habits of interpretation have been worked out in the laboratory, and the\nlinguist and lawyer Lawrence Solan has explained the connections\nbetween language and law in his interesting 1993 book _The Language_\n_of Judges,_ to which we will return.\n\n\nHow do we understand a sentence? The first step is to \"parse\" it. This\ndoes not refer to the exercises you grudgingly did in elementary school,\nwhich Dave Barry's \"Ask Mr. Language Person\" remembers as follows:\n\n\nQ. Please explain how to diagram a sentence."
    },
    {
        "document_id": "0",
        "parent_id": 279,
        "parent_text": "How do we understand a sentence? The first step is to \"parse\" it. This\ndoes not refer to the exercises you grudgingly did in elementary school,\nwhich Dave Barry's \"Ask Mr. Language Person\" remembers as follows:\n\n\nQ. Please explain how to diagram a sentence.\n\nA. First spread the sentence out on a clean, flat surface, such as an\nironing board. Then, using a sharp pencil or X-Acto knife, locate\nthe \"predicate,\" which indicates where the action has taken place\nand is usually located directly behind the gills. For example, in the\nsentence: \"LaMont never would of bit a forest ranger,\" the action\nprobably took place in a forest. Thus your diagram would be shaped\nlike a little tree with branches sticking out of it to indicate the\nlocations of the various particles of speech, such as your gerunds,\nproverbs, adjutants, etc.\n\n\nBut it does involve a similar process of finding subject, verbs, objects,\nand so on, that takes place unconsciously. Unless you are Woody Allen\nspeed-reading _War and Peace,_ you have to group words into phrases,\ndetermine which phrase is the subject of which verb, and so on. For\nexample, to understand the sentence _The cat in the hat came back,_ you\n\n\nTalking Heads 197\n\n\nhave to group the words _the cat in the hat_ into one phrase, to see that\nit is the cat that came back, not just the hat. To distinguish _Dog bites man_\nfrom _Man bites dog,_ you have to find the subject and the object. And to\ndistinguish _Man bites dog_ from _Man is bitten by dog_ or _Man suffers dog_\n_bite,_ you have to look up the verbs' entries in the mental dictionary to\ndetermine what the subject, _man,_ is doing or having done to him."
    },
    {
        "document_id": "0",
        "parent_id": 280,
        "parent_text": "Talking Heads 197\n\n\nhave to group the words _the cat in the hat_ into one phrase, to see that\nit is the cat that came back, not just the hat. To distinguish _Dog bites man_\nfrom _Man bites dog,_ you have to find the subject and the object. And to\ndistinguish _Man bites dog_ from _Man is bitten by dog_ or _Man suffers dog_\n_bite,_ you have to look up the verbs' entries in the mental dictionary to\ndetermine what the subject, _man,_ is doing or having done to him.\n\nGrammar itself is a mere code or protocol, a static database specifying what kinds of sounds correspond to what kinds of meanings in\na particular language. It is not a recipe or program for speaking\nand understanding. Speaking and understanding share a grammatical\ndatabase (the language we speak is the same as the language we\nunderstand), but they also need procedures that specify what the\nmind should _do,_ step by step, when the words start pouring in or\nwhen one is about to speak. The mental program that analyzes sentence structure during language comprehension is called the parser.\n\nThe best way to appreciate how understanding works is to trace\nthe parsing of a simple sentence, generated by a toy grammar like the\none of Chapter 4, which I repeat here:\n\n\nS —> NP VP\n\"A sentence can consist of a noun phrase and a verb\nphrase.\"\n\nNP —> (det) N (PP)\n\"A noun phrase can consist of an optional determiner, a\nnoun, and an optional prepositional phrase.\"\n\nVP —> V NP (PP)\n\"A verb phrase can consist of a verb, a noun phrase, and\n\nan optional prepositional phrase.\"\nPP —> P NP\n\"A prepositional phrase can consist of a preposition and a\nnoun phrase.\"\n\nN —> boy, girl, dog, cat, ice cream, candy, hot dogs\n\"The nouns in the mental dictionary include _boy, girl, . . .\"_\n\nV —> eats, likes, bites\n\n\"The verbs in the mental dictionary include _eats, likes, bites.\"_\n\nP —> with, in, near\n\"The prepositions include _with, in, near.\"_\n\n\n198 **THE** **L A N G U A G E INSTINCT**\n\n\ndet —> a, the, one\n\"The determiners include _a, the, one.\"_"
    },
    {
        "document_id": "0",
        "parent_id": 281,
        "parent_text": "an optional prepositional phrase.\"\nPP —> P NP\n\"A prepositional phrase can consist of a preposition and a\nnoun phrase.\"\n\nN —> boy, girl, dog, cat, ice cream, candy, hot dogs\n\"The nouns in the mental dictionary include _boy, girl, . . .\"_\n\nV —> eats, likes, bites\n\n\"The verbs in the mental dictionary include _eats, likes, bites.\"_\n\nP —> with, in, near\n\"The prepositions include _with, in, near.\"_\n\n\n198 **THE** **L A N G U A G E INSTINCT**\n\n\ndet —> a, the, one\n\"The determiners include _a, the, one.\"_\n\n\nTake the sentence _The dog likes ice cream._ The first word arriving\nat the mental parser is _the._ The parser looks it up in the mental\ndictionary, which is equivalent to finding it on the right-hand side of\na rule and discovering its category on the left-hand side. It is a\ndeterminer (det). This allows the parser to grow the first twig of the\ntree for the sentence. (Admittedly, a tree that grows upside down\nfrom its leaves to its root is botanically improbable.)\n\n\nDeterminers, like all words, have to be part of some larger phrase.\nThe parser can figure out which phrase is by checking to see which\nrule has \"det\" on its right-hand side. That rule is the one defining a\nnoun phrase, NP. More tree can be grown:\n\n\nThis dangling structure must be held in a kind of memory. The parser\nkeeps in mind that the word at hand, _the,_ is part of a noun phrase,\nwhich soon must be completed by finding words that fill its other\nslots—in this case, at least a noun.\n\nIn the meantime, the tree continues to grow, for NP's cannot float\naround unattached. Having checked the right-hand sides of the rules\nfor an NP symbol, the parser has several options. The freshly built\n\n\nTalking Heads 199\n\n\nNP could be part of a sentence, part of a verb phrase, or part of a\nprepositional phrase. The choice can be resolved from the root down:\nall words and phrases must eventually be plugged into a sentence (S),\nand a sentence must begin with an NP, so the sentence rule is the\nlogical one to use to grow more of the tree:"
    },
    {
        "document_id": "0",
        "parent_id": 282,
        "parent_text": "Talking Heads 199\n\n\nNP could be part of a sentence, part of a verb phrase, or part of a\nprepositional phrase. The choice can be resolved from the root down:\nall words and phrases must eventually be plugged into a sentence (S),\nand a sentence must begin with an NP, so the sentence rule is the\nlogical one to use to grow more of the tree:\n\n\nNote that the parser is now keeping _two_ incomplete branches in\nmemory: the noun phrase, which needs an N to complete it, and the\nsentence, which needs a VP.\n\nThe dangling N twig is equivalent to a prediction that the next word\nshould be a noun. When the next word, _dog,_ comes in, a check against\nthe rules confirms the prediction: _dog_ is part of the N rule. This allows\n_dog_ to be integrated into the tree, completing the noun phrase:\n\n\nThe parser no longer has to remember that there is an NP to be\ncompleted; all it has to keep in mind is the incomplete S.\n\nAt this point some of the meaning of the sentence can be inferred.\nRemember that the noun inside a noun phrase is a head (what the\nphrase is about) and that other phrases inside the noun phrase can\nmodify the head. By looking up the definitions of _dog_ and _the_ in their\n\n\n200 **THE** **L A N G U A G E** **INSTINCT**\n\n\ndictionary entries, the parser can note that the phrase is referring to\na previously mentioned dog.\n\nThe next word is _likes,_ which is found to be a verb, V. A verb has\nnowhere to come from but a verb phrase, VP, which, fortunately, has\nalready been predicted, so they can just be joined up. The verb phrase\ncontains more than a V; it also has a noun phrase (its object). The\nparser therefore predicts that an NP is what should come next:\n\n\nWhat does come next is _ice cream,_ a noun, which can be part of an\nNP—just as the dangling NP branch predicts. The last pieces of the\npuzzle snap nicely together:"
    },
    {
        "document_id": "0",
        "parent_id": 283,
        "parent_text": "The next word is _likes,_ which is found to be a verb, V. A verb has\nnowhere to come from but a verb phrase, VP, which, fortunately, has\nalready been predicted, so they can just be joined up. The verb phrase\ncontains more than a V; it also has a noun phrase (its object). The\nparser therefore predicts that an NP is what should come next:\n\n\nWhat does come next is _ice cream,_ a noun, which can be part of an\nNP—just as the dangling NP branch predicts. The last pieces of the\npuzzle snap nicely together:\n\n\nThe word _ice cream_ has completed the noun phrase, so it need not\nbe kept in memory any longer; the NP has completed the verb phrase,\nso it can be forgotten, too; and the VP has completed the sentence.\nWhen memory has been emptied of all its incomplete dangling\nbranches, we experience the mental \"click\" that signals that we have\njust heard a complete grammatical sentence.\n\n\nTalking Heads 201\n\n\nAs the parser has been joining up branches, it has been building\nup the meaning of the sentence, using the definitions in the mental\ndictionary and the principles for combining them. The verb is the\nhead of its VP, so the VP is about liking. The NP inside the VP, _ice_\n\n_cream,_ is the verb's object. The dictionary entry for _likes_ says that its\nobject is the liked entity; therefore the VP is about being fond of ice\ncream. The NP to the left of a tensed verb is the subject; the entry\nfor _likes_ says that its subject is the one doing the liking. Combining\nthe semantics of the subject with the semantics of the VP, the parser\nhas determined that the sentence asserts that an aforementioned canine is fond of frozen confections."
    },
    {
        "document_id": "0",
        "parent_id": 284,
        "parent_text": "_cream,_ is the verb's object. The dictionary entry for _likes_ says that its\nobject is the liked entity; therefore the VP is about being fond of ice\ncream. The NP to the left of a tensed verb is the subject; the entry\nfor _likes_ says that its subject is the one doing the liking. Combining\nthe semantics of the subject with the semantics of the VP, the parser\nhas determined that the sentence asserts that an aforementioned canine is fond of frozen confections.\n\n\nWhy is it so hard to program a computer to do this? And why do\npeople, too, suddenly find it hard to do this when reading bureaucratese and other bad writing? As we stepped our way through the\nsentence pretending we were the parser, we faced two computational\nburdens. One was memory: we had to keep track of the dangling\nphrases that needed particular kinds of words to complete them. The\nother was decision-making: when a word or phrase was found on the\nright-hand side of two different rules, we had to decide which to use\nto build the next branch of the tree. In accord with the first law of\nartificial intelligence, that the hard problems are easy and the easy\nproblems are hard, it turns out that the memory part is easy for\ncomputers and hard for people, and the decision-making part is easy\nfor people (at least when the sentence has been well constructed) and\nhard for computers."
    },
    {
        "document_id": "0",
        "parent_id": 285,
        "parent_text": "A sentence parser requires many kinds of memory, but the most\nobvious is the one for incomplete phrases, the remembrance of things\nparsed. Computers must set aside a set of memory locations, usually\ncalled a \"stack,\" for this task; this is what allows a parser to use\nphrase structure grammar at all, as opposed to being a word-chain\ndevice. People, too, must dedicate some of their short-term memory\nto dangling phrases. But short-term memory is the primary bottleneck\nin human information processing. Only a few items—the usual estimate is seven, plus or minus two—can be held in mind at once, and\nthe items are immediately subject to fading or being overwritten. In\nthe following sentences you can feel the effects of keeping a dangling\nphrase open in memory too long:\n\n\n202 THE LANGUAGE INSTINCT\n\n\nHe gave the girl that he met in New York while visiting his\nparents for ten days around Christmas and New Year's\nthe candy.\nHe sent the poisoned candy that he had received in the mail\nfrom one of his business rivals connected with the Mafia\nto the police.\nShe saw the matter that had caused her so much anxiety in\nformer years when she was employed as an efficiency\nexpert by the company through.\nThat many teachers are being laid off in a shortsighted\nattempt to balance this year's budget at the same time\nthat the governor's cronies and bureaucratic hacks are\nlining their pockets is appalling.\n\n\nThese memory-stretching sentences are called \"top-heavy\" in style\nmanuals. In languages that use case markers to signal meaning, a\nheavy phrase can simply be slid to the end of the sentences, so the\nlistener can digest the beginning without having to hold the heavy\nphrase in mind. English is tyrannical about order, but even English\nprovides its speakers with some alternative constructions in which\nthe order of phrases is inverted. A considerate writer can use them\nto save the heaviest for last and lighten the burden on the listener.\nNote how much easier these sentences are to understand:"
    },
    {
        "document_id": "0",
        "parent_id": 286,
        "parent_text": "He gave the candy to the girl that he met in New York\nwhile visiting his parents for ten days around Christmas\nand New Year's.\nHe sent to the police the poisoned candy that he had received in the mail from one of his business rivals connected with the Mafia.\nShe saw the matter through that had caused her so much\nanxiety in former years when she was employed as an\nefficiency expert by the company.\nIt is appalling that teachers are being laid off in a shortsighted attempt to balance this year's budget at the same\ntime that the governor's cronies and bureaucratic hacks\nare lining their pockets.\n\n\nTalking Heads 203\n\n\nMany linguists believe that the reason that languages allow phrase\nmovement, or choices among more-or-less synonymous constructions,\nis to ease the load on the listener's memory.\n\nAs long as the words in a sentence can be immediately grouped\ninto complete phrases, the sentence can be quite complex but still\nunderstandable:\n\n\nRemarkable is the rapidity of the motion of the wing of the\nhummingbird.\nThis is the cow with the crumpled horn that tossed the dog\nthat worried the cat that killed the rat that ate the malt\nthat lay in the house that Jack built.\nThen came the Holy One, blessed be He, and destroyed\nthe angel of death that slew the butcher that killed the\nox that drank the water that quenched the fire that\nburned the stick that beat the dog that bit the cat my\nfather bought for two zuzim.\n\n\nThese sentences are called \"right-branching,\" because of the geometry of their phrase structure trees. Note that as one goes from left to\nright, only one branch has to be left dangling at a time:\n\n\n204 THE LANGUAGE INSTINCT\n\n\nSentences can also branch to the left. Left-branching trees are most\ncommon in head-last languages like Japanese but are found in a few\nconstructions in English, too. As before, the parser never has to keep\nmore than one dangling branch in mind at a time:\n\n\n**The hummingbird's wing's motion's rapidity is remarkable**"
    },
    {
        "document_id": "0",
        "parent_id": 287,
        "parent_text": "204 THE LANGUAGE INSTINCT\n\n\nSentences can also branch to the left. Left-branching trees are most\ncommon in head-last languages like Japanese but are found in a few\nconstructions in English, too. As before, the parser never has to keep\nmore than one dangling branch in mind at a time:\n\n\n**The hummingbird's wing's motion's rapidity is remarkable**\n\n\nThere is a third kind of tree geometry, but it goes down far less\neasily. Take the sentence\n\n\nThe rapidity that the motion has is remarkable.\n\n\nThe clause _that the motion has_ has been embedded in the noun\nphrase containing _The rapidity._ The result is a bit stilted but easy to\nunderstand. One can also say\n\n\nThe motion that the wing has is remarkable.\n\n\nBut the result of embedding the _motion that the wing has_ phrase\ninside the _rapidity that the motion has_ phrase is surprisingly hard to\nunderstand:\n\n\nThe rapidity that the motion that the wing has has is remarkable.\n\n\nEmbedding a third phrase, like _the wing that the hummingbird has,_\ncreating a triply embedded onion sentence, results in complete unintelligibility:\n\n\nTalking Heads 205\n\n\n**The rapidity that the motion that the wing that the hummingbird has has has is remarkable**\n\n\nWhen the human parser encounters the three successive _has's,_ it\nthrashes ineffectively, not knowing what to do with them. But the\nproblem is not that the phrases have to be held in memory too\nlong; even short sentences are uninterpretable if they have multiple\nembeddings:\n\n\nThe dog the stick the fire burned beat bit the cat.\nThe malt that the rat that the cat killed ate lay in the house.\nIf if if it rains it pours I get depressed I should get help.\nThat that that he left is apparent is clear is obvious."
    },
    {
        "document_id": "0",
        "parent_id": 288,
        "parent_text": "The dog the stick the fire burned beat bit the cat.\nThe malt that the rat that the cat killed ate lay in the house.\nIf if if it rains it pours I get depressed I should get help.\nThat that that he left is apparent is clear is obvious.\n\n\nWhy does human sentence understanding undergo such complete collapse when interpreting sentences that are like onions or\nRussian dolls? This is one of the most challenging puzzles about\nthe design of the mental parser and the mental grammar. At first\none might wonder whether the sentences are even grammatical.\nPerhaps we got the rules wrong, and the real rules do not even\nprovide a way for these words to fit together. Could the maligned\nword-chain device of Chapter 4, which has no memory for dangling\nphrases, be the right model of humans after all? No way; the\nsentences check out perfectly. A noun phrase can contain a modifying clause; if you can say _the rat,_ you can say _the rat that S,_ where\nS is a sentence missing an object that modifies _the rat._ And a\nsentence like _the cat killed X_ can contain a noun phrase, such as\nits subject, _the cat._ So when you say _The rat that the cat killed,_ you\n\n\n206 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 289,
        "parent_text": "206 THE LANGUAGE INSTINCT\n\n\nhave modified a noun phrase with something that in turn contains a\nnoun phrase. With just these two abilities, onion sentences become\npossible: just modify the noun phrase inside a clause with a modifying clause of its own. The only way to prevent onion sentences\nwould be to claim that the mental grammar defines two different\nkinds of noun phrase, a kind that can be modified and a kind that\ncan go inside a modifier. But that can't be right: both kinds of\nnoun phrase would have to be allowed to contain the same twenty\nthousand nouns, both would have to allow articles and adjectives\nand possessors in identical positions, and so on. Entities should\nnot be multiplied unnecessarily, and that is what such tinkering\nwould do. Positing different kinds of phrases in the mental grammar just to explain why onion sentences are unintelligible would\nmake the grammar exponentially more complicated and would give\nthe child an exponentially larger number of rules to record when\nlearning the language. The problem must lie elsewhere.\n\nOnion sentences show that a grammar and a parser are different\nthings. A person can implicitly \"know\" constructions that he or she\ncan never understand, in the same way that Alice knew addition\ndespite the Red Queen's judgment:\n\n\n\"Can you do addition?\" the White Queen asked. \"What's one\nand one and one and one and one and one and one and one and\none and one?\"\n\n\"I don't know,\" said Alice. \"I lost count.\"\n\"She can't do Addition,\" the Red Queen interrupted.\n\n\nWhy does the human parser seem to lose count? Is there not\nenough room in short-term memory to hold more than one or two\ndangling phrases at a time? The problem must be more subtle.\nSome three-layer onion sentences are a little hard because of the\nmemory load but are not nearly as opaque as the _has has has_\nsentence:\n\n\nThe cheese that some rats I saw were trying to eat turned\nout to be rancid.\nThe policies that the students I know object to most strenuously are those pertaining to smoking.\n\n\nTalking Heads 207"
    },
    {
        "document_id": "0",
        "parent_id": 290,
        "parent_text": "The cheese that some rats I saw were trying to eat turned\nout to be rancid.\nThe policies that the students I know object to most strenuously are those pertaining to smoking.\n\n\nTalking Heads 207\n\n\nThe guy who is sitting between the table that I like and the\n\nempty chair just winked.\nThe woman who the janitor we just hired hit on is very\n\npretty.\n\n\nWhat boggles the human parser is not the amount of memory needed\nbut the _kind_ of memory: keeping a particular kind of phrase in\nmemory, intending to get back to it, at the same time as it is analyzing\nanother example of _that very same kind of phrase._ Examples of these\n\"recursive\" structures include a relative clause in the middle of the\nsame kind of relative clause, or an _if. . . then_ sentence inside another\n_if. . . then_ sentence. It is as if the human sentence parser keeps track\nof where it is in a sentence not by writing down a list of currently\nincomplete phrases in the order in which they must be completed,\nbut by writing a number in a slot next to each phrase type on a master\nchecklist. When a type of phrase has to be remembered more than\nonce—so that both it _(the cat that_ . . .) and the identical type of phrase\nit is inside of _(the rat that_ . . .) can be completed in order—there is\nnot enough room on the checklist for both numbers to fit, and the\nphrases cannot be completed properly."
    },
    {
        "document_id": "0",
        "parent_id": 291,
        "parent_text": "Unlike memory, which people are bad at and computers are good\nat, decision-making is something that people are good at and computers are bad at. I contrived the toy grammar and the baby sentence\nwe have just walked through so that every word had a single dictionary\nentry (that is, was at the right-hand side of only one rule). But all you\nhave to do is open up a dictionary, and you will see that many nouns\nhave a secondary entry as a verb, and vice versa. For example, _dog_ is\nlisted a second time—as a verb, for sentences like _Scandals dogged_\n_the administration all year._ Similarly, in real life _hot dog_ is not only a\nnoun but a verb, meaning \"to show off.\" And each of the verbs in\nthe toy grammar should also be listed as nouns, because English\nspeakers can talk of cheap _eats,_ his _likes_ and dislikes, and taking a\nfew _bites._ Even the determiner _one,_ as in _one dog,_ can have a second\nlife as a noun, as in _Nixon's the one._\n\nThese local ambiguities present a parser with a bewildering number\nof forks at every step along the road. When it comes across, say, the\nword _one_ at the beginning of a sentence, it cannot simply build\n\n\n208 **T H E L A N G U A G E I N S T I N C T**\n\n\nbut must also keep in mind\n\n\nSimilarly, it has to jot down two rival branches when it comes across\n_dog,_ one in case it is a noun, the other in case it is a verb. To handle\n_one dog,_ it would need to check four possibilities: determiner-noun,\ndeterminer-verb, noun-noun, and noun-verb. Of course determinerverb can be eliminated because no rule of grammar allows it, but it\nstill must be checked."
    },
    {
        "document_id": "0",
        "parent_id": 292,
        "parent_text": "208 **T H E L A N G U A G E I N S T I N C T**\n\n\nbut must also keep in mind\n\n\nSimilarly, it has to jot down two rival branches when it comes across\n_dog,_ one in case it is a noun, the other in case it is a verb. To handle\n_one dog,_ it would need to check four possibilities: determiner-noun,\ndeterminer-verb, noun-noun, and noun-verb. Of course determinerverb can be eliminated because no rule of grammar allows it, but it\nstill must be checked.\n\nIt gets even worse when the words are grouped into phrases, because phrases can fit inside larger phrases in many different ways.\nEven in our toy grammar, a prepositional phrase (PP) can go inside\neither a noun phrase or a verb phrase—as in the ambiguous _discuss_\n_sex with Dick Cavett,_ where the writer intended the PP _with Dick_\n_Cavett_ to go inside the verb phrase (discuss it with him) but readers\ncan interpret it as going inside the noun phrase (sex with him). These\nambiguities are the rule, not the exception; there can be dozens or\nhundreds of possibilities to check at every point in a sentence. For\nexample, after processing _The plastic pencil marks_ . . ., the parser has\nto keep several options open: it can be a four-word noun phrase, as\nin _The plastic pencil marks were ugly,_ or a three-word noun phrase\nplus a verb, as in _The plastic pencil marks easily._ In fact, even the first\ntwo words, _The plastic_ . . ., are temporarily ambiguous: compare _The_\n_plastic rose fell_ with _The plastic rose and fell._\n\nIf it were just a matter of keeping track of all the possibilities at\neach point, a computer would have little trouble. It might churn away\nfor minutes on a simple sentence, or use up so much short-term\nmemory that the printout would spill halfway across the room, but\neventually most of the possibilities at each decision point would be\ncontradicted by later information in the sentence. If so, a single tree\nand its associated meaning should pop out at the end of the sentence,\n\n\nTalking Heads 209"
    },
    {
        "document_id": "0",
        "parent_id": 293,
        "parent_text": "If it were just a matter of keeping track of all the possibilities at\neach point, a computer would have little trouble. It might churn away\nfor minutes on a simple sentence, or use up so much short-term\nmemory that the printout would spill halfway across the room, but\neventually most of the possibilities at each decision point would be\ncontradicted by later information in the sentence. If so, a single tree\nand its associated meaning should pop out at the end of the sentence,\n\n\nTalking Heads 209\n\n\nas in the toy example. When the local ambiguities fail to cancel each\nother out and two consistent trees are found for the same sentence,\nwe should have a sentence that people find ambiguous, like\n\n\nIngres enjoyed painting his models nude.\nMy son has grown another foot.\nVisiting relatives can be boring.\nVegetarians don't know how good meat tastes.\nI saw the man with the binoculars.\n\n\nBut here is the problem. Computer parsers are too meticulous for\ntheir own good. They find ambiguities that are quite legitimate, as far\nas English grammar is concerned, but that would never occur to a\nsane person. One of the first computer parsers, developed at Harvard\nin the 1960s, provides a famous example. The sentence _Time flies like_\n_an arrow_ is surely unambiguous if there ever was an unambiguous\nsentence (ignoring the difference between literal and metaphorical\nmeanings, which have nothing to do with syntax). But to the surprise\nof the programmers, the sharp-eyed computer found it to have five\ndifferent trees!\n\n\nTime proceeds as quickly as an arrow proceeds, (the intended reading)\nMeasure the speed of flies in the same way that you measure\nthe speed of an arrow.\nMeasure the speed of flies in the same way that an arrow\nmeasures the speed of flies.\nMeasure the speed of flies that resemble an arrow.\nFlies of a particular kind, time-flies, are fond of an arrow."
    },
    {
        "document_id": "0",
        "parent_id": 294,
        "parent_text": "Time proceeds as quickly as an arrow proceeds, (the intended reading)\nMeasure the speed of flies in the same way that you measure\nthe speed of an arrow.\nMeasure the speed of flies in the same way that an arrow\nmeasures the speed of flies.\nMeasure the speed of flies that resemble an arrow.\nFlies of a particular kind, time-flies, are fond of an arrow.\n\n\nAmong computer scientists the discovery has been summed up in the\naphorism \"Time flies like an arrow; fruit flies like a banana.\" Or\nconsider the song line _Mary had a little lamb._ Unambiguous? Imagine\nthat the second line was: _With mint sauce._ Or: _And the doctors were_\n_surprised._ Or: _The tramp!_ There is even structure in seemingly nonsensical lists of words. For example, this fiendish string devised by my\nstudent Annie Senghas is a grammatical sentence:\n\n\n210 THE LANGUAGE INSTINCT\n\n\nBuffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\n\n\nAmerican bison are called _buffalo._ A kind of bison that conies from\nBuffalo, New York, could be called a _Buffalo buffalo._ Recall that there\nis a verb _to buffalo_ that means \"to overwhelm, to intimidate.\" Imagine\nthat New York State bison intimidate one another: _(The) Buffalo_\n_buffalo_ _(that)_ _Buffalo_ _buffalo_ _(often)_ _buffalo_ _(in_ _turn)_ _buffalo_ _(other)_\n_Buffalo buffalo._ The psycholinguist and philosopher Jerry Fodor has\nobserved that a Yale University football cheer\n\n\nBulldogs Bulldogs Bulldogs Fight Fight Fight!\n\n\nis a grammatical sentence, albeit a triply center-embedded one."
    },
    {
        "document_id": "0",
        "parent_id": 295,
        "parent_text": "Bulldogs Bulldogs Bulldogs Fight Fight Fight!\n\n\nis a grammatical sentence, albeit a triply center-embedded one.\n\nHow do people home in on the sensible analysis of a sentence,\nwithout tarrying over all the grammatically legitimate but bizarre\nalternatives? There are two possibilities. One is that our brains are\nlike computer parsers, computing dozens of doomed tree fragments\nin the background, and the unlikely ones are somehow filtered out\nbefore they reach consciousness. The other is that the human parser\nsomehow gambles at each step about the alternative most likely to be\ntrue and then plows ahead with that single interpretation as far as\npossible. Computer scientists call these alternatives \"breadth-first\nsearch\" and \"depth-first search.\"\n\nAt the level of individual words, it looks as if the brain does a\nbreadth-first search, entertaining, however briefly, several entries for\nan ambiguous word, even unlikely ones. In an ingenious experiment,\nthe psycholinguist David Swinney had people listen over headphones\nto passages like the following:\n\n\nRumor had it that, for years, the government building had\nbeen plagued with problems. The man was not surprised\nwhen he found several spiders, roaches, and other bugs\nin the corner of his room.\n\n\nDid you notice that the last sentence contains an ambiguous word,\n_bug,_ which can mean either \"insect\" or \"surveillance device\"? Probably not; the second meaning is more obscure and makes no sense in\n\n\nTalking Heads 211"
    },
    {
        "document_id": "0",
        "parent_id": 296,
        "parent_text": "Rumor had it that, for years, the government building had\nbeen plagued with problems. The man was not surprised\nwhen he found several spiders, roaches, and other bugs\nin the corner of his room.\n\n\nDid you notice that the last sentence contains an ambiguous word,\n_bug,_ which can mean either \"insect\" or \"surveillance device\"? Probably not; the second meaning is more obscure and makes no sense in\n\n\nTalking Heads 211\n\n\ncontext. But psycholinguists are interested in mental processes that\nlast only milliseconds and need a more subtle technique than just\nasking people. As soon as the word _bug_ had been read from the tape,\na computer flashed a word on a screen, and the person had to press\na button as soon as he or she had recognized it. (Another button was\navailable for nonwords like _blick.)_ It is well known that when a person\nhears one word, any word related to it is easier to recognize, as if the\nmental dictionary is organized like a thesaurus, so that when one\nword is found, others similar in meaning are more readily available.\nAs expected, people pressed the button faster when recognizing _ant,_\nwhich is related to _bug,_ than when recognizing _sew,_ which is unrelated. Surprisingly, people were just as primed to recognize the word\n_spy,_ which is, of course, related to _bug,_ but only to the meaning that\nmakes no sense in the context. It suggests that the brain knee-jerkingly\nactivates both entries for _bug,_ even though one of them could sensibly\nbe ruled out beforehand. The irrelevant meaning is not around long:\nif the test word appeared on the screen three syllables after _bugs_\ninstead of right after it, then only _ant_ was recognized quickly; _spy_ was\nno longer any faster than _sew._ Presumably that is why people deny\nthat they even entertain the inappropriate meaning."
    },
    {
        "document_id": "0",
        "parent_id": 297,
        "parent_text": "The psychologists Mark Seidenberg and Michael Tanenhaus\nshowed the same effect for words that were ambiguous as to part-ofspeech category, like _tires,_ which we encountered in the ambiguous\nheadline _Stud Tires Out._ Regardless of whether the word appeared\nin a noun position, like _The tires_ . . ., or in a verb position, like _He_\n_tires . . .,_ the word primed both _wheels,_ which is related to the noun\nmeaning, and _fatigue,_ which is related to the verb meaning. Mental\ndictionary lookup, then, is quick and thorough but not very bright;\nit retrieves nonsensical entries that must be weeded out later.\n\nAt the level of the phrases and sentences that span many words,\nthough, people clearly are not computing every possible tree for a\nsentence. We know this for two reasons. One is that many sensible\nambiguities are simply never recognized. How else can we explain\nthe ambiguous newspaper passages that escaped the notice of editors,\nno doubt to their horror later on? I cannot resist quoting some more:\n\n\nThe judge sentenced the killer to die in the electric chair\nfor the second time.\n\n\n212 THE LANGUAGE INSTINCT\n\n\nDr. Tackett Gives Talk on Moon\nNo one was injured in the blast, which was attributed to\n\nthe buildup of gas by one town official.\nThe summary of information contains totals of the number\n\nof students broken down by sex, marital status, and age.\n\n\nI once read a book jacket flap that said that the author lived with\nher husband, an architect and an amateur musician in Cheshire,\nConnecticut. For a moment I thought it was a menage a quatre.\n\nNot only do people fail to find some of the trees that are consistent\nwith a sentence; sometimes they stubbornly fail to find the _only_ tree\nthat is consistent with a sentence. Take these sentences:\n\n\nThe horse raced past the barn fell.\nThe man who hunts ducks out on weekends.\nThe cotton clothing is usually made of grows in Mississippi.\nThe prime number few.\nFat people eat accumulates.\nThe tycoon sold the offshore oil tracts for a lot of money\nwanted to kill JR."
    },
    {
        "document_id": "0",
        "parent_id": 298,
        "parent_text": "Not only do people fail to find some of the trees that are consistent\nwith a sentence; sometimes they stubbornly fail to find the _only_ tree\nthat is consistent with a sentence. Take these sentences:\n\n\nThe horse raced past the barn fell.\nThe man who hunts ducks out on weekends.\nThe cotton clothing is usually made of grows in Mississippi.\nThe prime number few.\nFat people eat accumulates.\nThe tycoon sold the offshore oil tracts for a lot of money\nwanted to kill JR.\n\n\nMost people proceed contendedly through the sentence up to a certain point, then hit a wall and frantically look back to earlier words\nto try to figure out where they went wrong. Often the attempt fails\nand people assume that the sentences have an extra word tacked onto\nthe end or consist of two pieces of sentence stitched together. In fact,\neach one is a grammatical sentence:\n\n\nThe horse that was walked past the fence proceeded steadily, but the horse raced past the barn fell.\nThe man who fishes goes into work seven days a week, but\nthe man who hunts ducks out on weekends.\nThe cotton that sheets are usually made of grows in Egypt,\nbut the cotton clothing is usually made of grows in Mississippi.\nThe mediocre are numerous, but the prime number few.\nCarbohydrates that people eat are quickly broken down,\nbut fat people eat accumulates.\n\n\nTalking Heads **2 1 3**\n\n\nJR Ewing had swindled one tycoon too many into buying\nuseless properties. The tycoon sold the offshore oil tracts\nfor a lot of money wanted to kill JR."
    },
    {
        "document_id": "0",
        "parent_id": 299,
        "parent_text": "Talking Heads **2 1 3**\n\n\nJR Ewing had swindled one tycoon too many into buying\nuseless properties. The tycoon sold the offshore oil tracts\nfor a lot of money wanted to kill JR.\n\n\nThese are called garden path sentences, because their first words\nlead the listener \"up the garden path\" to an incorrect analysis. Garden\npath sentences show that people, unlike computers, do not build all\npossible trees as they go along; if they did, the correct tree would be\namong them. Rather, people mainly use a depth-first strategy, picking\nan analysis that seems to be working and pursuing it as long as\npossible; if they come across words that cannot be fitted into the tree,\nthey backtrack and start over with a different tree. (Sometimes people\ncan hold a second tree in mind, especially people with good memories,\nbut the vast majority of possible trees are never entertained.) The\ndepth-first strategy gambles that a tree that has fit the words so far\nwill continue to fit new ones, and thereby saves memory space by\nkeeping only that tree in mind, at the cost of having to start over if\nit bet on the wrong horse raced past the barn.\n\nGarden path sentences, by the way, are one of the hallmarks of\nbad writing. Sentences are not laid out with clear markers at every\nfork, allowing the reader to stride confidently through to the end.\nInstead the reader repeatedly runs up against dead ends and has to\nwend his way back. Here are some examples I have collected from\nnewspapers and magazines:\n\n\nDelays Dog Deaf-Mute Murder Trial\nBritish Banks Soldier On\nI thought that the Vietnam war would end for at least an\nappreciable chunk of time this kind of reflex anticommunist hysteria.\nThe musicians are master mimics of the formulas they dress\nup with irony.\nThe movie is Tom Wolfe's dreary vision of a past that never\nwas set against a comic view of the modern hype-bound\nworld.\nThat Johnny Most didn't need to apologize to Chick Kearn,\nBill King, or anyone else when it came to describing the\naction [Johnny Most when he was in his prime]."
    },
    {
        "document_id": "0",
        "parent_id": 300,
        "parent_text": "214 THE LANGUAGE INSTINCT\n\n\nFamily Leave Law a Landmark Not Only for Newborn's\nParents\nCondom Improving Sensation to be Sold\n\n\nIn contrast, a great writer like Shaw can send a reader in a straight\nline from the first word of a sentence to the full stop, even if it is 110\nwords away.\n\n\nA depth-first parser must use some criterion to pick one tree (or a\nsmall number) and run with it—ideally the tree most likely to be\ncorrect. One possibility is that the entirety of human intelligence is\nbrought to bear on the problem, analyzing the sentence from the top\ndown. According to this view, people would not bother to build any\npart of a tree if they could guess in advance that the meaning for that\nbranch would not make sense in context. There has been a lot of debate\namong psycholinguists about whether this would be a sensible way for\nthe human sentence parser to work. To the extent that a listener's\nintelligence can actually predict a speaker's intentions accurately, a topdown design would steer the parser toward correct sentence analyses.\nBut the entirety of human intelligence is a lot of intelligence, and using\nit all at once may be too slow to allow for real-time parsing as the\nhurricane of words whizzes by. Jerry Fodor, quoting Hamlet, suggests\nthat if knowledge and context had to guide sentence parsing, \"the native\nhue of resolution would be sicklied o'er with the pale cast of thought.\"\nHe has suggested that the human parser is an encapsulated module that\ncan look up information only in the mental grammar and the mental\ndictionary, not in the mental encyclopedia."
    },
    {
        "document_id": "0",
        "parent_id": 301,
        "parent_text": "Ultimately the matter must be settled in the laboratory. The human\nparser does seem to use at least a bit of knowledge about what tends\nto happen in the world. In an experiment by the psychologists John\nTrueswell, Michael Tanenhaus, and Susan Garnsey, people bit on a\nbar to keep their heads perfectly still and read sentences on a computer screen while their eye movements were recorded. The sentences\nhad potential garden paths in them. For example, read the sentence\n\n\nThe defendant examined by the lawyer turned out to be\nunreliable.\n\n\nTalking Heads 2 1 5\n\n\nYou may have been momentarily sidetracked at the word _by,_ because\nup to that point the sentence could have been about the defendant's\nexamining something rather than his being examined. Indeed, the\nsubjects' eyes lingered on the word _by_ and were likely to backtrack to\nreinterpret the beginning of the sentence (compared to unambiguous\ncontrol sentences). But now read the following sentence:\n\n\nThe evidence examined by the lawyer turned out to be\nunreliable.\n\n\nIf garden paths can be avoided by common-sense knowledge, this\nsentence should be much easier. Evidence, unlike defendants, can't\nexamine anything, so the incorrect tree, in which the evidence would\nbe examining something, is potentially avoidable. People do avoid it:\nthe subjects' eyes hopped through the sentence with little pausing or\nbacktracking. Of course, the knowledge being applied is quite crude\n(defendants examine things; evidence doesn't), and the tree that it\ncalls for was fairly easy to find, compared with the dozens that a\ncomputer can find. So no one knows _how much_ of a person's general\nsmarts can be applied to understanding sentences in real time; it is\nan active area of laboratory research."
    },
    {
        "document_id": "0",
        "parent_id": 302,
        "parent_text": "Words themselves also provide some guidance. Recall that each\nverb makes demands of what else can go in the verb phrase (for\nexample, you can't just _devour_ but have to _devour something;_ you\ncan't _dine something,_ you can only _dine)._ The most common entry\nfor a verb seems to pressure the mental parser to find the role-players\nit wants. Trueswell and Tanenhaus watched their volunteers' eyeballs\nas they read\n\n\nThe student forgot the solution was in the back of the book.\n\n\nAt the point of reaching _was,_ the eyes lingered and then hopped back,\nbecause the people misinterpreted the sentence as being about a\nstudent forgetting the solution, period. Presumably, inside people's\nheads the word _forget_ was saying to the parser \"Find me an object,\nnow!\" Another sentence was\n\n\n216 THE LANGUAGE INSTINCT\n\n\nThe student hoped the solution was in the back of the book.\n\n\nWith this one there was little problem, because the word _hope_ was\nsaying, instead, \"Find me a sentence!\" and a sentence was there to\nbe found."
    },
    {
        "document_id": "0",
        "parent_id": 303,
        "parent_text": "216 THE LANGUAGE INSTINCT\n\n\nThe student hoped the solution was in the back of the book.\n\n\nWith this one there was little problem, because the word _hope_ was\nsaying, instead, \"Find me a sentence!\" and a sentence was there to\nbe found.\n\nWords can also help by suggesting to the parser exactly which\nother words they tend to appear with inside a given kind of phrase.\nThough word-by-word transition probabilities are not enough to understand a sentence (Chapter 4), they could be helpful; a parser\narmed with good statistics, when deciding between two possible trees\nallowed by a grammar, can opt for the tree that was most likely to\nhave been spoken. The human parser seems to be somewhat sensitive\nto word pair probabilities: many garden paths seem especially seductive because they contain common pairs like _cotton clothing, fat people,_\nand _prime number._ Whether or not the brain benefits from language\nstatistics, computers certainly do. In laboratories at AT&T and IBM,\ncomputers have been tabulating millions of words of text from sources\nlike the _Wall Street journal_ and Associated Press stories. Engineers\nare hoping that if they equip their parsers with the frequencies with\nwhich each word is used, and the frequencies with which sets of\nwords hang around together, the parsers will resolve ambiguities\nsensibly.\n\nFinally, people find their way through a sentence by favoring trees\nwith certain shapes, a kind of mental topiary. One guideline is momentum: people like to pack new words into the current dangling\nphrase, instead of closing off the phrase and hopping up to add the\nwords to a dangling phrase one branch up. This \"late closure\" strategy\nmight explain why we travel the garden path in the sentence\n\n\nFlip said that Squeaky will do the work yesterday."
    },
    {
        "document_id": "0",
        "parent_id": 304,
        "parent_text": "Finally, people find their way through a sentence by favoring trees\nwith certain shapes, a kind of mental topiary. One guideline is momentum: people like to pack new words into the current dangling\nphrase, instead of closing off the phrase and hopping up to add the\nwords to a dangling phrase one branch up. This \"late closure\" strategy\nmight explain why we travel the garden path in the sentence\n\n\nFlip said that Squeaky will do the work yesterday.\n\n\nThe sentence is grammatical and sensible, but it takes a second look\n(or maybe even a third) to realize it. We are led astray because\nwhen we encounter the adverb _yesterday,_ we try to pack it inside the\ncurrently open VP _do the work,_ rather than closing off that VP and\nhanging the adverb upstairs, where it would go in the same phrase as\n_Flip said._ (Note, by the way, that our knowledge of what is plausible,\nlike the fact that the meaning of _will_ is incompatible with the meaning\nof _yesterday,_ did not keep us from taking the garden path. This\n\n\nTalking Heads 217\n\n\nsuggests that the power of general knowledge to guide sentence understanding is limited.) Here is an another example, though this time\nthe psycholinguist responsible for it, Annie Senghas, did not contrive\nit as an example; one day she just blurted out, \"The woman sitting\nnext to Steven Pinker's pants are like mine.\" (Annie was pointing out\nthat the woman sitting next to me had pants like hers.)\n\nA second guideline is thrift: people to try to attach a phrase to a\ntree using as few branches as possible. This explains why we take the\ngarden path in the sentence\n\n\nSherlock Holmes didn't suspect the very beautiful young\ncountess was a fraud.\n\n\nIt takes only one branch to attach the _countess_ inside the VP, where\nSherlock would suspect her, but two branches to attach her to an S\nthat is itself attached to the VP, where he would suspect her of being\na fraud:\n\n\nThe mental parser seems to go for the minimal attachment, though\nlater in the sentence it proves to be incorrect."
    },
    {
        "document_id": "0",
        "parent_id": 305,
        "parent_text": "Sherlock Holmes didn't suspect the very beautiful young\ncountess was a fraud.\n\n\nIt takes only one branch to attach the _countess_ inside the VP, where\nSherlock would suspect her, but two branches to attach her to an S\nthat is itself attached to the VP, where he would suspect her of being\na fraud:\n\n\nThe mental parser seems to go for the minimal attachment, though\nlater in the sentence it proves to be incorrect.\n\n\nSince most sentences are ambiguous, and since laws and contracts\nmust be couched in sentences, the principles of parsing can make a\nbig difference in people's lives. Lawrence Solan discusses many examples in his recent book. Examine these passages, the first from an\ninsurance contract, the second from a statute, the third from instructions to a jury:\n\n\nSuch insurance as is provided by this policy applies to the use of a\nnon-owned vehicle by the named insured and any person responsi\n\n218 THE LANGUAGE INSTINCT\n\n\nble for use by the named insured provided such use is with the\npermission of the owner.\n\nEvery person who sells any controlled substance which is specified\nin subdivision (d) shall be punished. . . . (d) Any material, compound, mixture, or preparation which contains any quantity of the\nfollowing substances having a potential for abuse associated with\na stimulant effect on the central nervous system: Amphetamine;\nMethamphetamine . . .\n\nThe jurors must not be swayed by mere sentiment, conjecture,\nsympathy, passion, prejudice, public opinion or public feeling."
    },
    {
        "document_id": "0",
        "parent_id": 306,
        "parent_text": "Every person who sells any controlled substance which is specified\nin subdivision (d) shall be punished. . . . (d) Any material, compound, mixture, or preparation which contains any quantity of the\nfollowing substances having a potential for abuse associated with\na stimulant effect on the central nervous system: Amphetamine;\nMethamphetamine . . .\n\nThe jurors must not be swayed by mere sentiment, conjecture,\nsympathy, passion, prejudice, public opinion or public feeling.\n\n\nIn the first case, a woman was distraught over being abandoned in\na restaurant by her date, and drove off in what she thought was the\ndate's Cadillac, which she then totaled. It turned out to be someone\nelse's Cadillac, and she had to recover the money from her insurance\ncompany. Was she covered? A California appellate court said yes.\nThe policy was ambiguous, they noted, because the requirement _with_\n_the permission of the owner,_ which she obviously did not meet, could\nbe construed as applying narrowly to _any person responsible for use_\n_by the named insured,_ rather than to _the named insured_ (that is, her)\n_and any person_ _responsible for use by_ _the named insured._\n\nIn the second case, a drug dealer was trying to swindle a customer—unfortunately for him, an undercover narcotics agent—by\nselling him a bag of inert powder that had only a minuscule trace of\nmethamphetamine. The _substance_ had \"a potential for abuse,\" but\nthe _quantity of the substance_ did not. Did he break the law? The\nappellate court said he did."
    },
    {
        "document_id": "0",
        "parent_id": 307,
        "parent_text": "In the second case, a drug dealer was trying to swindle a customer—unfortunately for him, an undercover narcotics agent—by\nselling him a bag of inert powder that had only a minuscule trace of\nmethamphetamine. The _substance_ had \"a potential for abuse,\" but\nthe _quantity of the substance_ did not. Did he break the law? The\nappellate court said he did.\n\nIn the third case, the defendant had been convicted of raping\nand murdering a fifteen-year-old-girl, and a jury imposed the death\npenalty. United States constitutional law forbids any instruction that\nwould deny a defendant the right to have the jury consider any\n\"sympathy factor\" raised by the evidence, which in his case consisted\nof psychological problems and a harsh family background. Did the\ninstructions unconstitutionally deprive the accused of _sympathy,_ or\ndid it deprive him only of the more trivial _mere sympathy?_ The\nUnited States Supreme Court ruled 5-4 that he was denied only _mere_\n_sympathy;_ that denial is constitutional.\n\nSolan points out that the courts often resolve these cases by relying\non \"canons of construction\" enshrined in the legal literature, which\n\n\nTalking Heads 219\n\n\ncorrespond to the principles of parsing I discussed in the preceding\nsection. For example, the Last Antecedent Rule, which the courts\nused to resolve the first two cases, is simply the \"minimal attachment\"\nstrategy that we just saw in the Sherlock sentence. The principles of\nmental parsing, then, literally have life-or-death consequences. But\npsycholinguists who are now worrying that their next experiment may\nsend someone to the gas chamber can rest easy. Solan notes that\njudges are not very good linguists; for better or worse, they try to\nfind a way around the most natural interpretation of a sentence if it\nwould stand in the way of the outcome they feel is just."
    },
    {
        "document_id": "0",
        "parent_id": 308,
        "parent_text": "I have been talking about trees, but a sentence is not just a tree.\nSince the early 1960s, when Chomsky proposed transformations that\nconvert deep structures to surface structures, psychologists have used\nlaboratory techniques to try to detect some kind of fingerprint of the\ntransformation. After a few false alarms the search was abandoned,\nand for several decades the psychology textbooks dismissed transformations as having no \"psychological reality.\" But laboratory techniques have become more sophisticated, and the detection of\nsomething like a transformational operation in people's minds and\nbrains is one of the most interesting recent findings in the psychology\nof language.\n\nTake the sentence\n\n\nThe policeman saw the boy that the crowd at the party\naccused _(trace)_ of the crime.\n\n\nWho was accused of a crime? The boy, of course, even though the\nwords _the boy_ do not occur after _accused._ According to Chomsky,\nthat is because a phrase referring to the boy really does occur after\n\n_accused_ in deep structure; it has been moved backwards to the position of _that_ by a transformation, leaving behind a silent \"trace.\" A\nperson trying to understand the sentence must undo the effect of the\ntransformation and mentally put a copy of the phrase back in the\nposition of the trace. To do so, the understander must first notice,\nwhile at the beginning of the sentence, that there is a moved phrase,\n_the boy,_ that needs a home. The understander must hold the phrase\nin short-term memory until he or she discovers a gap: a position\n\n\n220 THE LANGUAGE INSTINCT\n\n\nwhere a phrase should be but isn't. In this sentence there is a gap\nafter _accused,_ because _accused_ demands an object, but there isn't one.\nThe person can assume that the gap contains a trace and can then\nretrieve the phrase _the boy_ from short-term memory and link it to the\ntrace. Only then can the person figure out what role _the boy_ played\nin the event—in this case, being accused."
    },
    {
        "document_id": "0",
        "parent_id": 309,
        "parent_text": "220 THE LANGUAGE INSTINCT\n\n\nwhere a phrase should be but isn't. In this sentence there is a gap\nafter _accused,_ because _accused_ demands an object, but there isn't one.\nThe person can assume that the gap contains a trace and can then\nretrieve the phrase _the boy_ from short-term memory and link it to the\ntrace. Only then can the person figure out what role _the boy_ played\nin the event—in this case, being accused.\n\nRemarkably, every one of these mental processes can be measured.\nDuring the span of words between the moved phrase and the trace—\nthe region I have underlined—people must hold the phrase in memory. The strain should be visible in poorer performance of any mental\ntask carried out concurrently. And in fact, while people are reading\nthat span, they detect extraneous signals (like a blip flashed on the\nscreen) more slowly, and have more trouble keeping a list of extra\nwords in memory. Even their EEG's (electroencephalograms, or records of the brain's electrical activity) show the effects of the strain.\n\nThen, at the point at which the trace is discovered and the memory\nstore can be emptied, the dumped phrase makes an appearance on\nthe mental stage that can be detected in several ways. If an experimenter flashes a word from the moved phrase (for example, _boy)_ at\nthat point, people recognize it more quickly. They also recognize\nwords related to the moved phrase—say, _girl_ —more quickly. The\neffect is strong enough to be visible in brain waves: if interpreting\nthe trace results in an implausible interpretation, as in\n\n\nWhich food did the children read _(trace)_ in class?\n\n\nthe EEG's show a boggle reaction at the point of the trace.\n\nConnecting phrases with traces is a hairy computational operation.\nThe parser, while holding the phrase in mind, must constantly be\nchecking for the trace, an invisible and inaudible little nothing. There\nis no way of predicting how far down in the sentence the trace will\nappear, and sometimes it can be quite far down:"
    },
    {
        "document_id": "0",
        "parent_id": 310,
        "parent_text": "Which food did the children read _(trace)_ in class?\n\n\nthe EEG's show a boggle reaction at the point of the trace.\n\nConnecting phrases with traces is a hairy computational operation.\nThe parser, while holding the phrase in mind, must constantly be\nchecking for the trace, an invisible and inaudible little nothing. There\nis no way of predicting how far down in the sentence the trace will\nappear, and sometimes it can be quite far down:\n\n\nThe girl wondered who John believed that Mary claimed\nthat the baby saw _(trace)._\n\n\nAnd until it is found, the semantic role of the phrase is a wild card,\nespecially now that the _who/whom_ distinction is going the way of the\nphonograph record.\n\n\nTalking Heads 221\n\n\nI wonder who ( _trace)_ introduced John to Marsha. _[who =_\n\nthe introducer]\nI wonder who Bruce introduced _(trace)_ to Marsha. _[who =_\n\nthe one being introduced]\nI wonder who Bruce introduced John to _(trace). [who =_\n\nthe target of the introduction]\n\n\nThis problem is so tough that good writers, and even the grammar of\nthe language itself, take steps to make it easier. One principle for good\nstyle is to minimize the amount of intervening sentence in which a moved\nphrase must be held in memory (the underlined regions). This is a task\nthat the English passive construction is good for (notwithstanding the\nrecommendations of computerized \"style-checkers\" to avoid it across\nthe board). In the following pair of sentences, the passive version is\neasier, because the memory-taxing region before the trace is shorter:\n\n\nReverse the clamp that the stainless steel hex-head bolt\nextending upward from the seatpost yoke holds _(trace)_ in\nplace.\nReverse the clamp that _(trace)_ is held in place by the stainless\nsteel hex-head bolt extending upward from the seatpost\nyoke.\n\n\nAnd universally, grammars restrict the amount of tree that a phrase\ncan move across. For example, one can say\n\n\nThat's the guy that you heard the rumor about _(trace)._\n\n\nBut the following sentence is quite odd:"
    },
    {
        "document_id": "0",
        "parent_id": 311,
        "parent_text": "Reverse the clamp that the stainless steel hex-head bolt\nextending upward from the seatpost yoke holds _(trace)_ in\nplace.\nReverse the clamp that _(trace)_ is held in place by the stainless\nsteel hex-head bolt extending upward from the seatpost\nyoke.\n\n\nAnd universally, grammars restrict the amount of tree that a phrase\ncan move across. For example, one can say\n\n\nThat's the guy that you heard the rumor about _(trace)._\n\n\nBut the following sentence is quite odd:\n\n\nThat's the guy that you heard the rumor that Mary likes\n\n_(trace)._\n\n\nLanguages have \"bounding\" restrictions that turn some phrases, like\nthe complex noun phrase _the rumor that Mary likes him,_ into \"islands\"\nfrom which no words can escape. This is a boon to listeners, because\nthe parser, knowing that the speaker could not have moved something\nout of such a phrase, can get away with not monitoring it for a trace.\nBut the boon to listeners exerts a cost on speakers; for these sentences\n\n\n222 THE LANGUAGE INSTINCT\n\n\nthey have to resort to a clumsy extra pronoun, as in _That's the guy_\n_that you heard the rumor that Mary likes him._\n\n\nParsing, for all its importance, is only the first step in understanding\na sentence. Imagine parsing the following real-life dialogue:"
    },
    {
        "document_id": "0",
        "parent_id": 312,
        "parent_text": "222 THE LANGUAGE INSTINCT\n\n\nthey have to resort to a clumsy extra pronoun, as in _That's the guy_\n_that you heard the rumor that Mary likes him._\n\n\nParsing, for all its importance, is only the first step in understanding\na sentence. Imagine parsing the following real-life dialogue:\n\n\nP: The grand jury thing has its, uh, uh, uh—view of this they might,\nuh. Suppose we have a grand jury proceeding. Would that,\nwould that, what would that do to the Ervin thing? Would it go\nright ahead anyway?\nD: Probably.\nP: But then on that score, though, we have—let me just, uh, run\nby that, that—You do that on a grand jury, we could then have\na much better cause in terms of saying, \"Look, this is a grand\njury, in which, uh, the prosecutor—\" How about a special prosecutor? We could use Petersen, or use another one. You see he\nis probably suspect. Would you call in another prosecutor?\nD: I'd like to have Petersen on our side, advising us [laughs] frankly.\nP: Frankly. Well, Petersen is honest. Is anybody about to be question him, are they?\nD: No, no, but he'll get a barrage when, uh, these Watergate hearings start.\nP: Yes, but he can go up and say that he's, he's been told to go\nfurther in the Grand Jury and go in to this and that and the\nother thing. Call everybody in the White House. I want them to\ncome, I want the, uh, uh, to go to the Grand Jury.\nD: This may result—This may happen even without our calling for\nit when, uh, when these, uh—\nP: Vescoe?\nD: No. Well, that's one possibility. But also when these people go\nback before the Grand Jury here, they are going to pull all\nthese criminal defendants back in before the Grand Jury and\nimmunize them.\nP: And immunize them: Why? Who? Are you going to—On what?\nD: Uh, the U.S. Attorney's Office will.\nP: To do what?\nD: To talk about anything further they want to talk about.\nP: Yeah. What do they gain out of it?\nD: Nothing.\n\n\nTalking Heads 223\n\n\nP: To hell with them.\nD: They, they're going to stonewall it, uh, as it now stands. Except"
    },
    {
        "document_id": "0",
        "parent_id": 313,
        "parent_text": "Talking Heads 223\n\n\nP: To hell with them.\nD: They, they're going to stonewall it, uh, as it now stands. Except\n\nfor Hunt. That's why, that's the leverage in his threat.\nH: This is Hunt's opportunity.\nP: That's why, that's why,\nH: God, if he can lay this—\nP: That's why your, for your immediate thing you've got no choice\nwith Hunt but the hundred and twenty or whatever it is, right?\nD: That's right.\nP: Would you agree that that's a buy time thing, you better damn\nwell get that done, but fast?\nD: I think he ought to be given some signal, anyway, to, to—\nP: [expletive deleted], get it, in a, in a way that, uh—Who's going to\ntalk to him? Colson? He's the one who's supposed to know him.\nD: Well, Colson doesn't have any money though. That's the thing.\nThat's been our, one of the real problems. They have, uh, been\nunable to raise any money. A million dollars in cash, or, or the\nlike, has been just a very difficult problem as we've discussed\nbefore. Apparently, Mitchell talked to Pappas, and I called him\nlast—John asked me to call him last night after our discussion\nand after you'd met with John to see where that was. And I, I\nsaid, \"Have you talked to, to Pappas?\" He was at home, and\nMartha picked up the phone so it was all in code. \"Did you talk\nto the Greek?\" And he said, uh, \"Yes, I have.\" And I said, \"Is\nthe Greek bearing gifts?\" He said, \"Well, I want to call you\ntomorrow on that.\"\n\nP: Well, look, uh, what is it that you need on that, uh, when, uh,\nuh? Now look [unintelligible] I am, uh, unfamiliar with the\nmoney situation."
    },
    {
        "document_id": "0",
        "parent_id": 314,
        "parent_text": "P: Well, look, uh, what is it that you need on that, uh, when, uh,\nuh? Now look [unintelligible] I am, uh, unfamiliar with the\nmoney situation.\n\n\nThis dialogue took place on March 17, 1973, among President\nRichard Nixon (P), his counsel John W. Dean 3rd (D), and his chief\nof staff H. R. Haldeman (H). Howard Hunt, working for Nixon's\nre-election campaign in June 1972, had directed a break-in at the\nDemocratic Party headquarters in the Watergate building, in which\nhis men bugged the telephones of the party chairman and other\nworkers. Several investigations were under way to determine if the\noperation had been ordered from the White House, by Haldeman or\nAttorney General John Mitchell. The men are discussing whether to\npay $120,000 in \"hush money\" to Hunt before he testified before a\n\n\n2 2 4 THE LANGUAGE INSTINCT\n\n\ngrand jury. We have this verbatim dialogue because in 1970 Nixon,\nclaiming to be acting on behalf of future historians, bugged his own\noffice and began secretly taping all his conversations. In February\n1974 the Judiciary Committee of the House of Representatives subpoenaed the tapes to help them determine whether Nixon should be\nimpeached. This excerpt is from their transcription. Largely on the\nbasis of this passage, the committee recommended impeachment.\nNixon resigned in August 1974.\n\nThe Watergate tapes are the most famous and extensive transcripts\nof real-life speech ever published. When they were released, Americans were shocked, though not all for the same reason. Some people—a very small number—were surprised that Nixon had taken\npart in a conspiracy to obstruct justice. A few were surprised that the\nleader of the free world cussed like a stevedore. But one thing that\nsurprised everyone was what ordinary conversation looks like when\nit is written down verbatim. Conversation out of context is virtually\nopaque."
    },
    {
        "document_id": "0",
        "parent_id": 315,
        "parent_text": "Part of the problem comes from the circumstances of transcription:\nthe intonation and timing that delineate phrases is lost, and a transcription from anything but the highest-fidelity tape is unreliable.\nIndeed, in the White House's independent transcription of this lowquality recording, many puzzling passages are rendered more sensibly.\nFor example, _I want the, uh, uh, to go_ is transcribed as _I want them,_\n_uh, uh, to go._\n\nBut even when transcribed perfectly, conversation is hard to interpret. People often speak in fragments, interrupting themselves in\nmidsentence to reformulate the thought or change the subject. It's\noften unclear who or what is being talked about, because conversers\nuse pronouns _(him, them, this, that, we, they, it, one),_ generic words\n_(do,_ _happen,_ _the thing,_ _the situation,_ _that score,_ _these people,_ _whatever),_\nand ellipses _(The U.S. Attorney's Office will_ and _That's why)._ Intentions are expressed indirectly. In this episode, whether a man would\nend the year as president of the United States or as a convicted\ncriminal literally hinged on the meaning of _get it_ and on whether\n_What is it that you need?_ was meant as a request for information or\nas an implicit offer to provide something.\n\nNot everyone was shocked by the unintelligibility of transcribed\nspeech. Journalists know all about it, and it is a routine practice to\n\n       \n\nTalking Heads 225\n\n\nedit quotations and interviews heavily before they are published. For\nmany years the temperamental Boston Red Sox pitcher Roger Clemens complained bitterly that the press misquoted him. The _Boston_\n_Herald,_ in what they must have known was a cruel trick, responded\nby running a daily feature in which his post-game comments were\nreproduced word for word."
    },
    {
        "document_id": "0",
        "parent_id": 316,
        "parent_text": "Talking Heads 225\n\n\nedit quotations and interviews heavily before they are published. For\nmany years the temperamental Boston Red Sox pitcher Roger Clemens complained bitterly that the press misquoted him. The _Boston_\n_Herald,_ in what they must have known was a cruel trick, responded\nby running a daily feature in which his post-game comments were\nreproduced word for word.\n\nJournalists' editing of conversations became a legal issue in 1983,\nwhen the writer Janet Malcolm published an unflattering _New Yorker_\nseries about the psychoanalyst Jeffrey Masson. Masson had written a\nbook accusing Freud of dishonesty and cowardice in retracting his\nobservation that neurosis is caused by sexual abuse in childhood, and\nwas fired as the curator of the Freud archives in London. According\nto Malcolm, Masson described himself in her interviews as \"an intellectual gigolo\" and \"after Freud, the greatest analyst who's ever\nlived,\" and as planning to turn Anna Freud's house after her death\ninto \"a place of sex, women, and fun.\" Masson sued Malcolm and\nthe _New Yorker_ for ten million dollars, claiming that he had never\nsaid these things and that other quotations had been altered to make\nhim look ridiculous. Though Malcolm could not document the quotations from her tapes and handwritten notes, she denied having manufactured them, and her lawyers argued that even if she had, they were\na \"rational interpretation\" of what Masson had said. Doctored quotes,\nthey argued, are standard journalistic practice and are not examples\nof printing something with knowledge that it is false or with reckless\ndisregard for whether it is false, part of the definition of libel."
    },
    {
        "document_id": "0",
        "parent_id": 317,
        "parent_text": "Several courts threw out the case on First Amendment grounds,\nbut in June 1991 the Supreme Court unanimously reinstated it. In a\nclosely watched opinion, the majority defined a middle ground for\njournalists' treatment of quotations. (Requiring them to publish\nquotes verbatim was not even considered.) Justice Kennedy, writing\nfor the majority, said that the \"deliberate alteration of the words\nuttered by a plaintiff does not equate with knowledge of falsity,\" and\nthat \"If an author alters a speaker's words, but effects no material\nchange in meaning, the speaker suffers no injury to reputation. We\nreject any special test of falsity for quotations, including one which\nwould draw the line at correction of grammar or syntax.\" If the\nSupreme Court had asked me, I would have sided with Justices White\nand Scalia in calling for some such line to be drawn. Like many\n\n\n226 THE LANGUAGE INSTINCT\n\n\nlinguists, I doubt that it is possible to alter a speaker's words—\nincluding most grammar and syntax—without materially changing\nthe meaning.\n\nThese incidents show that real speech is very far from _The dog likes_\n_ice cream_ and that there is much more to understanding a sentence\nthan parsing it. Comprehension uses the semantic information recovered from a tree as just one premise in a complex chain of inference\nto the speaker's intentions. Why is this so? Why is it that even honest\nspeakers rarely articulate the truth, the whole truth, and nothing but\nthe truth?\n\nThe first reason is air time. Conversation would bog down if one\nhad to refer to the United States Senate Select Committee on the\nWatergate Break-In and Related Sabotage Efforts by uttering that full\ndescription every time. Once alluded to, _the Ervin thing,_ or just _it,_\nwill suffice. For the same reason it is wasteful to spell out the following\nchain of logic:"
    },
    {
        "document_id": "0",
        "parent_id": 318,
        "parent_text": "The first reason is air time. Conversation would bog down if one\nhad to refer to the United States Senate Select Committee on the\nWatergate Break-In and Related Sabotage Efforts by uttering that full\ndescription every time. Once alluded to, _the Ervin thing,_ or just _it,_\nwill suffice. For the same reason it is wasteful to spell out the following\nchain of logic:\n\n\nHunt knows who gave him the orders to organize the Watergate break-in.\nThe person who gave him the orders might be part of our\nadministration.\nIf the person is in our administration and his identity becomes public, the entire administration will suffer.\nHunt has an incentive to reveal the identity of the person\nwho gave him the orders because it might reduce his\nprison sentence.\nSome people will take risks if they are given enough money.\nTherefore Hunt may conceal the identity of his superior if\nhe is given enough money.\nThere is reason to believe that approximately $120,000\nwould be a large enough incentive for Hunt to conceal\nthe identity of the person who gave him the order.\nHunt could accept that money now, but it is in his interest\nto continue to blackmail us in the future.\nNonetheless it might be sufficient for us to keep him quiet\nin the short run because the press and the public might\nlose interest in the Watergate scandal in the months to\ncome, and if he reveals the identity later, the consequences for our administration would not be as negative.\n\n\nTalking Heads 227\n\n\nTherefore the self-interested course of action for us is to\npay Hunt the amount of money that would be a large\nenough incentive for him to keep silent until such time\nas public interest in Watergate wanes.\n\n\nIt is more efficient to say, \"For your immediate thing you've got no\nchoice with Hunt but the hundred and twenty or whatever it is.\""
    },
    {
        "document_id": "0",
        "parent_id": 319,
        "parent_text": "Talking Heads 227\n\n\nTherefore the self-interested course of action for us is to\npay Hunt the amount of money that would be a large\nenough incentive for him to keep silent until such time\nas public interest in Watergate wanes.\n\n\nIt is more efficient to say, \"For your immediate thing you've got no\nchoice with Hunt but the hundred and twenty or whatever it is.\"\n\nThe efficiency, though, depends on the participants' sharing a lot\nof background knowledge about the events and about the psychology\nof human behavior. They must use this knowledge to cross-reference\nthe names, pronouns, and descriptions with a single cast of characters,\nand to **fill** in the logical steps that connect each sentence with the\nnext. If background assumptions are not shared—for example, if\none's conversational partner is from a very different culture, or is\nschizophrenic, or is a machine—then the best parsing in the world\nwill fail to deliver the full meaning of a sentence. Some computer\nscientists have tried to equip programs with little \"scripts\" of stereotyped settings like restaurants and birthday parties to help their programs **fill** in the missing parts of texts while understanding them.\nAnother team is trying to teach a computer the basics of human\ncommon sense, which they estimate to comprise about ten million\nfacts. To see how formidable the task is, consider how much knowledge about human behavior must be interpolated to understand what\n_he_ means in a simple dialogue like this:\n\n\nWoman: I'm leaving you.\nMan: Who is he?"
    },
    {
        "document_id": "0",
        "parent_id": 320,
        "parent_text": "Woman: I'm leaving you.\nMan: Who is he?\n\n\nUnderstanding, then, requires integrating the fragments gleaned\nfrom a sentence into a vast mental database. For that to work, speakers\ncannot just toss one fact after another into a listener's head. Knowledge is not like a list of facts in a trivia column but is organized into\na complex network. When a series of facts comes in succession, as in\na dialogue or text, the language must be structured so that the listener\ncan place each fact into an existing framework. Thus information\nabout the old, the given, the understood, the topic, should go early\nin the sentence, usually as the subject, and information about the\nnew, the focus, the comment, should go at the end. Putting the topic\nearly in the sentence is another function of the maligned passive\n\n\n228 THE LANGUAGE INSTINCT\n\n\nconstruction. In his book on style, Williams notes that the usual\nadvice \"Avoid passives\" should be flouted when the topic being\ndiscussed has the role connected with the deep-structure object of\nthe verb. For example, read the following two-sentence discussion:\n\n\nSome astonishing questions about the nature of the universe\nhave been raised by scientists studying the nature of black\nholes in space. The collapse of a dead star into a point\nperhaps no larger than a marble creates a black hole.\n\n\nThe second sentence feels like a non sequitur. It is much better to\nput it in the passive voice:\n\n\nSome astonishing questions about the nature of the universe\nhave been raised by scientists studying the nature of black\nholes in space. A black hole is created by the collapse of\na dead star into a point perhaps no larger than a marble.\n\n\nThe second sentence now fits in smoothly, because its subject, _a black_\n\n_hole,_ is the topic, and its predicate adds new information to that topic.\nIn an extended conversation or essay, a good writer or speaker will\nmake the focus of one sentence the topic of the next one, linking\npropositions into an orderly train."
    },
    {
        "document_id": "0",
        "parent_id": 321,
        "parent_text": "The second sentence now fits in smoothly, because its subject, _a black_\n\n_hole,_ is the topic, and its predicate adds new information to that topic.\nIn an extended conversation or essay, a good writer or speaker will\nmake the focus of one sentence the topic of the next one, linking\npropositions into an orderly train.\n\nThe study of how sentences are woven into a discourse and interpreted in context (sometimes called \"pragmatics\") has made an interesting discovery, first pointed out by the philosopher Paul Grice and\nrecently refined by the anthropologist Dan Sperber and the linguist\nDeirdre Wilson. The act of communicating relies on a mutual expectation of cooperation between speaker and listener. The speaker, having\nmade a claim on the precious ear of the listener, implicitly guarantees\nthat the information to be conveyed is relevant: that it is not already\nknown, and that it is sufficiently connected to what the listener is\nthinking that he or she can make inferences to new conclusions with\nlittle extra mental effort. Thus listeners tacitly expect speakers to be\ninformative, truthful, relevant, clear, unambiguous, brief, and orderly.\nThese expectations help to winnow out the inappropriate readings of\nan ambiguous sentence, to piece together fractured utterances, to\nexcuse slips of the tongue, to guess the referents of pronouns and\ndescriptions, and to fill in the missing steps of an argument. (When\n\n\nTalking Heads 229\n\n\na receiver of a message is not cooperative but adversarial, all of this\nmissing information must be stated explicitly, which is why we have\nthe tortuous language of legal contracts with their \"party of the first\npart\" and \"all rights under said copyright and all renewals thereof\nsubject to the terms of this Agreement.\")"
    },
    {
        "document_id": "0",
        "parent_id": 322,
        "parent_text": "Talking Heads 229\n\n\na receiver of a message is not cooperative but adversarial, all of this\nmissing information must be stated explicitly, which is why we have\nthe tortuous language of legal contracts with their \"party of the first\npart\" and \"all rights under said copyright and all renewals thereof\nsubject to the terms of this Agreement.\")\n\nThe interesting discovery is that the maxims of relevant conversation are often observed in the breach. Speakers deliberately flout them\nin the literal content of their speech so that listeners can interpolate\nassumptions that would restore the conversation to relevance. Those\nassumptions then serve as the real message. A familiar example is the\nfollowing kind of letter of recommendation:\n\n\nDear Professor Pinker:\n\nI am very pleased to be able to recommend Irving Smith to you.\nMr. Smith is a model student. He dresses well and is extremely\npunctual. I have known Mr. Smith for three years now, and in every\nway I have found him to be most cooperative. His wife is charming.\n\n\nSincerely,\n\n\nJohn Jones\nProfessor\n\n\nThough the letter contains nothing but positive, factual statements,\nit guarantees that Mr. Smith will not get the position he is seeking.\nThe letter contains no information relevant to the reader's needs, and\nthereby violates the maxim that speakers be informative. The reader\nworks on the tacit assumption that the communicative act as a whole\n_is_ relevant, even if the content of the letter itself is not, so he infers\na premise that together with the letter makes the act relevant: that\nthe writer has no relevant positive information to convey. Why does\nthe writer demand this minuet, rather than just saying \"Stay away\nfrom Smith; he's dumb as a tree\"? It is because of another premise\nthat the reader can interpolate: the writer is the kind of person who\ndoes not casually injure those who put their trust in him."
    },
    {
        "document_id": "0",
        "parent_id": 323,
        "parent_text": "It is natural that people exploit the expectations necessary for\nsuccessful conversation as a way of slipping their real intentions into\ncovert layers of meaning. Human communication is not just a transfer\nof information like two fax machines connected with a wire; it is a\n\n\n230 THE LANGUAGE INSTINCT\n\n\nseries of alternating displays of behavior by sensitive, scheming, second-guessing, social animals. When we put words into people's ears\nwe are impinging on them and revealing our own intentions, honorable or not, just as surely as if we were touching them. Nowhere is\nthis more apparent than in the convoluted departures from plain\nspeaking found in every society that are called politeness. Taken\nliterally, the statement \"I was wondering if you would be able to drive\nme to the airport\" is a prolix string of incongruities. Why notify me\nof the contents of your ruminations? Why are you pondering my\ncompetence to drive you to the airport, and under which hypothetical\ncircumstances? Of course the real intent—\"Drive me to the airport\"—is easily inferred, but because it was never stated, I have an\nout. Neither of us has to live with the face-threatening consequences\nof your issuing a command that presupposes you could coerce my\ncompliance. Intentional violations of the unstated norms of conversation are also the trigger for many of the less pedestrian forms of\nnonliteral language, such as irony, humor, metaphor, sarcasm, putdowns, ripostes, rhetoric, persuasion, and poetry."
    },
    {
        "document_id": "0",
        "parent_id": 324,
        "parent_text": "Metaphor and humor are useful ways to summarize the two mental\nperformances that go into understanding a sentence. Most of our\neveryday expressions about language use a \"conduit\" metaphor that\ncaptures the parsing process. In this metaphor, ideas are objects,\nsentences are containers, and communication is sending. We \"gather\"\nour ideas to \"put\" them \"into\" words, and if our verbiage is not\n\"empty\" or \"hollow,\" we might \"convey\" or \"get\" these ideas\n\"across\" \"to\" a listener, who can \"unpack\" our words to \"extract\"\ntheir \"content.\" But as we have seen, the metaphor is misleading.\nThe complete process of understanding is better characterized by the\njoke about the two psychoanalysts who meet on the street. One says,\n\"Good morning\"; the other thinks, \"I wonder what he meant by\nthat.\""
    },
    {
        "document_id": "0",
        "parent_id": 325,
        "parent_text": "#### 8 The Tower of Babel\n\n**And** the whole earth was of one language, and of one speech.\nAnd it came to pass, as they journeyed from the east, that they\nfound a plain in the land of Shinar; and they dwelt there. And they\nsaid one to another, Go to, let us make brick, and burn them\nthoroughly. And they had brick for stone, and slime had they for\nmorter. And they said, Go to, let us build us a city and a tower,\nwhose top may reach unto heaven; and let us make us a name, lest\nwe be scattered abroad upon the face of the whole earth. And the\nLord came down to see the city and the tower, which the children\nof men builded. And the Lord said, Behold, the people is one, and\nthey have all one language; and this they begin to do: and now\nnothing will be restrained from them, which they have imagined to\ndo. Go to, let us go down, and there confound their language, that\nthey may not understand one another's speech. So the Lord scattered them abroad from thence upon the face of all the earth: and\nthey left off to build the city. Therefore is the name of it called\nBabel; because the Lord did there confound the language of all the\nearth: and from thence did the Lord scatter them abroad upon the\nface of all the earth. (Genesis 11:1-9)\n\n\nIn the year of our Lord 1957, the linguist Martin Joos reviewed the\npreceding three decades of research in linguistics and concluded that\nGod had actually gone much farther in confounding the language of\nNoah's descendants. Whereas the God of Genesis was said to be\ncontent with mere mutual unintelligibility, Joos declared that \"lan\n\n2 3 1\n\n\n232 THE LANGUAGE INSTINCT\n\n\nguages could differ from each other without limit and in unpredictable ways.\" That same year, the Chomskyan revolution began with\nthe publication of _Syntactic Structures,_ and the next three decades\ntook us back to the literal biblical account. According to Chomsky,\na visiting Martian scientist would surely conclude that aside from\ntheir mutually unintelligible vocabularies, Earthlings speak a single\nlanguage."
    },
    {
        "document_id": "0",
        "parent_id": 326,
        "parent_text": "2 3 1\n\n\n232 THE LANGUAGE INSTINCT\n\n\nguages could differ from each other without limit and in unpredictable ways.\" That same year, the Chomskyan revolution began with\nthe publication of _Syntactic Structures,_ and the next three decades\ntook us back to the literal biblical account. According to Chomsky,\na visiting Martian scientist would surely conclude that aside from\ntheir mutually unintelligible vocabularies, Earthlings speak a single\nlanguage.\n\nEven by the standards of theological debates, these interpretations\nare strikingly different. Where did they come from? The 4,000 to\n6,000 languages of the planet do look impressively different from\nEnglish and from one another. Here are the most conspicuous ways\nin which languages can differ from what we are used to in English:\n\n\n1. English is an \"isolating\" language, which builds sentences by\nrearranging immutable word-sized units, like _Dog bites man_\nand _Man bites dog._ Other languages express who did what to\nwhom by modifying nouns with case affixes, or by modifying\nthe verb with affixes that agree with its role-players in number,\ngender, and person. One example is Latin, an \"inflecting\"\nlanguage in which each affix contains several pieces of information; another is Kivunjo, an \"agglutinating\" language in which\neach affix conveys one piece of information and many affixes are\nstrung together, as in the eight-part verb in Chapter 5.\n\n2. English is a \"fixed-word-order\" language where each phrase\nhas a fixed position. \"Free-word-order\" languages allow\nphrase order to vary. In an extreme case like the Australian\naboriginal language Warlpiri, words from different phrases\ncan be scrambled together: _This man speared a kangaroo_ can\nbe expressed as _Man_ _this_ _kangaroo_ _speared,_ _Man_ _kangaroo_\n\n_speared this,_ and any of the other four orders, all completely\nsynonymous."
    },
    {
        "document_id": "0",
        "parent_id": 327,
        "parent_text": "2. English is a \"fixed-word-order\" language where each phrase\nhas a fixed position. \"Free-word-order\" languages allow\nphrase order to vary. In an extreme case like the Australian\naboriginal language Warlpiri, words from different phrases\ncan be scrambled together: _This man speared a kangaroo_ can\nbe expressed as _Man_ _this_ _kangaroo_ _speared,_ _Man_ _kangaroo_\n\n_speared this,_ and any of the other four orders, all completely\nsynonymous.\n\n3. English is an \"accusative\" language, where the subject of an\nintransitive verb, like _she_ in _She ran,_ is treated identically to\nthe subject of a transitive verb, like _she_ in _She kissed Larry,_\nand different from the object of the transitive verb, like _her_ in\n_Larry kissed her._ \"Ergative\" languages like Basque and many\nAustralian languages have a different scheme for collapsing\nthese three roles. The subject of an intransitive verb and the\n_object_ of a transitive verb are identical, and the subject of the\n\n\nThe Tower of Babel 233"
    },
    {
        "document_id": "0",
        "parent_id": 328,
        "parent_text": "The Tower of Babel 233\n\n\ntransitive is the one that behaves differently. It is as if we were\nto say _Ran her_ to mean \"She ran.\"\n4. English is a \"subject-prominent\" language in which all sentences must have a subject (even if there is nothing for the subject\nto refer to, as in _It is raining_ or _There is a unicorn in the garden)._\nIn \"topic-prominent\" languages like Japanese, sentences have\na special position that is filled by the current topic of the\nconversation, as in _This place, planting wheat is good_ or _Califor-_\n_nia,_ _climate is good._\n5. English is an \"SVO\" language, with the order subject-verbobject _(Dog bites man)._ Japanese is subject-object-verb (SOV:\n_Dog man bites);_ Modern Irish (Gaelic) is verb-subject-object\n(VSO: _Bites dog man)._\n6. In English, a noun can name a thing in any construction: _a_\n_banana; two bananas; any banana; all the bananas._ In \"classifier\" languages, nouns fall into gender classes like human,\nanimal, inanimate, one-dimensional, two-dimensional, cluster,\ntool, food, and so on. In many constructions, the name for\nthe class, not the noun itself, must be used—for example,\nthree hammers would be referred to as _three tools, to wit_\n_hammer._\n\n\nAnd, of course, a glance at a grammar for any particular language\nwill reveal dozens or hundreds of idiosyncrasies.\n\nOn the other hand, one can also hear striking universals through\nthe babble. In 1963 the linguist Joseph Greenberg examined a sample\nof 30 far-flung languages from five continents, including Serbian,\nItalian, Basque, Finnish, Swahili, Nubian, Masaai, Berber, Turkish,\nHebrew, Hindi, Japanese, Burmese, Malay, Maori, Mayan, and Quechua (a descendant of the language of the Incas). Greenberg was\nnot working in the Chomskyan school; he just wanted to see if any\ninteresting properties of grammar could be found in all these languages. In his first investigation, which focused on the order of words\nand morphemes, he found no fewer than forty-five universals."
    },
    {
        "document_id": "0",
        "parent_id": 329,
        "parent_text": "Since then, many other surveys have been conducted, involving\nscores of languages from every part of the world, and literally hundreds of universal patterns have been documented. Some hold absolutely. For example, no language forms questions by reversing the\norder of words within a sentence, like _Built ]ack that house the this_\n\n\n234 THE LANGUAGE INSTINCT\n\n\n_is?_ Some are statistical: subjects normally precede objects in almost\nall languages, and verbs and their objects tend to be adjacent. Thus\nmost languages have SVO or SOV order; fewer have VSO; VOS\nand OVS are rare (less than 1%); and OSV may be nonexistent\n(there are a few candidates, but not all linguists agree that they are\nOSV). The largest number of universals involve implications: if a\nlanguage has X, it will also have Y. We came across a typical\nexample of an implicational universal in Chapter 4: if the basic\norder of a language is SOV, it will usually have question words at\nthe end of the sentence, and postpositions; if it is SVO, it will\nhave question words at the beginning, and prepositions. Universal\nimplications are found in all aspects of language, from phonology\n(for instance, if a language has nasal vowels, it will have non-nasal\nvowels) to word meanings (if a language has a word for \"purple,\"\nit will have a word for \"red\"; if a language has a word for \"leg,\"\nit will have a word for \"arm.\")\n\nIf lists of universals show that languages do not vary freely, do they\nimply that languages are restricted by the structure of the brain? Not\ndirectly. First one must rule out two alternative explanations."
    },
    {
        "document_id": "0",
        "parent_id": 330,
        "parent_text": "If lists of universals show that languages do not vary freely, do they\nimply that languages are restricted by the structure of the brain? Not\ndirectly. First one must rule out two alternative explanations.\n\nOne possibility is that language originated only once, and all existing languages are the descendants of that proto-language and retain\nsome of its features. These features would be similar across the languages for the same reason that alphabetical order is similar across\nthe Hebrew, Greek, Roman, and Cyrillic alphabets. There is nothing\nspecial about alphabetical order; it was just the order that the Canaanites invented, and all Western alphabets came from theirs. No linguist\naccepts this as an explanation for language universals. For one thing,\nthere can be radical breaks in language transmission across the generations, the most extreme being creolization, but universals hold of all\nlanguages including Creoles. Moreover, simple logic shows that a\nuniversal implication, like \"If a language has SVO order, then it has\nprepositions, but if it has SOV order, then it has postpositions,\"\ncannot be transmitted from parent to child the way words are. An\nimplication, by its very logic, is not a fact about English: children\ncould learn that English is SVO _and_ has prepositions, but nothing\ncould show them that _if a_ language is SVO, _then_ it must have prepositions. A universal implication is a fact about all languages, visible only\nfrom the vantage point of a comparative linguist. If a language changes\nfrom SOV to SVO over the course of history and its postpositions\n\n\nThe Tower of Babel 235\n\n\nflip to prepositions, there has to be some explanation of what keeps\nthese two developments in sync."
    },
    {
        "document_id": "0",
        "parent_id": 331,
        "parent_text": "The Tower of Babel 235\n\n\nflip to prepositions, there has to be some explanation of what keeps\nthese two developments in sync.\n\nAlso, if universals were simply what is passed down through the\ngenerations, we would expect that the major differences between\nkinds of language should correlate with the branches of the linguistic\nfamily tree, just as the difference between two cultures generally\ncorrelates with how long ago they separated. As humanity's original\nlanguage differentiated over time, some branches might become SOV\nand others SVO; within each of these branches some might have\nagglutinated words, others isolated words. But this is not so. Beyond\na time depth of about a thousand years, history and typology often\ndo not correlate well at all. Languages can change from grammatical\ntype to type relatively quickly, and can cycle among a few types over\nand over; aside from vocabulary, they do not progressively differentiate and diverge. For example, English has changed from a free-wordorder, highly inflected, topic-prominent language, as its sister German\nremains to this day, to a fixed-word-order, poorly inflected, subjectprominent language, all in less than a millennium. Many language\nfamilies contain close to the full gamut of variations seen across the\nworld in particular aspects of grammar. The absence of a strong\ncorrelation between the grammatical properties of languages and their\nplace in the family tree of languages suggests that language universals\nare not just the properties that happen to have survived from the\nhypothetical mother of all languages."
    },
    {
        "document_id": "0",
        "parent_id": 332,
        "parent_text": "The second counterexplanation that one must rule out before attributing a universal of language to a universal language instinct is that\nlanguages might reflect universals of thought or of mental information\nprocessing that are not specific to language. As we saw in Chapter 3,\nuniversals of color vocabulary probably come from universals of color\nvision. Perhaps subjects precede objects because the subject of an\naction verb denotes the causal agent (as in _Dog bites man);_ putting\nthe subject first mirrors the cause coming before the effect. Perhaps\nhead-first or head-last ordering is consistent across all the phrases in\na language because it enforces a consistent branching direction, right\nor left, in the language's phrase structure trees, avoiding difficult-tounderstand onion constructions. For example, Japanese is SOV and\nhas modifiers to the left; this gives it constructions like \"modifierS O V\" with the modifier on the outside rather than \"S-modifier O V\"\nwith the modifier embedded inside.\n\n\n236 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 333,
        "parent_text": "236 THE LANGUAGE INSTINCT\n\n\nBut these functional explanations are often tenuous, and for many\nuniversals they do not work at all. For example, Greenberg noted\nthat if a language has both derivational suffixes (which create new\nwords from old ones) and inflectional suffixes (which modify a word\nto fit its role in the sentence), then the derivational suffixes are always\ncloser to the stem than the inflectional ones. In Chapter 5 we saw\nthis principle in English in the difference between the grammatical\n_Darwinisms_ and the ungrammatical _Darwinsism._ It is hard to think\nof how this law could be a consequence of any universal principle of\nthought or memory: why would the concept of two ideologies based\non one Darwin be thinkable, but the concept of one ideology based\non two Darwins (say, Charles and Erasmus) not be thinkable (unless\none reasons in a circle and declares that the mind must find _-ism_ to\nbe more cognitively basic than the plural, because that's the order we\nsee in language)? And remember Peter Gordon's experiments showing that children say _mice-eater_ but never _rats-eater,_ despite the conceptual similarity of rats and mice and despite the absence of either\nkind of compound in parents' speech. His results corroborate the\nsuggestion that this particular universal is caused by the way that\nmorphological rules are computed in the brain, with inflection\napplying to the products of derivation but not vice versa."
    },
    {
        "document_id": "0",
        "parent_id": 334,
        "parent_text": "In any case, Greenbergisms are not the best place to look for a\nneurologically given Universal Grammar that existed before Babel. It\nis the organization of grammar as a whole, not some laundry list of\nfacts, that we should be looking at. Arguing about the possible causes\nof something like SVO order misses the forest for the trees. What is\nmost striking of all is that we can look at a randomly picked language\nand find things that can sensibly be called subjects, objects, and verbs\nto begin with. After all, if we were asked to look for the order of\nsubject, object, and verb in musical notation, or in the computer\nprogramming language F O R T R A N, or in Morse code, or in arithmetic,\nwe would protest that the very idea is nonsensical. It would be like\nassembling a representative collection of the world's cultures from\nthe six continents and trying to survey the colors of their hockey team\njerseys or the form of their harakiri rituals. We should be impressed,\nfirst and foremost, that research on universals of grammar is even\npossible!\n\nWhen linguists claim to find the same kinds of linguistic gadgets\nin language after language, it is not just because they expect languages\n\n\nThe Tower of Babel 237\n\n\nto have subjects and so they label as a \"subject\" the first kind of\nphrase they see that resembles an English subject. Rather, if a linguist\nexamining a language for the first time calls a phrase a \"subject\"\nusing one criterion based on English subjects—say, denoting the\nagent role of action verbs—the linguist soon discovers that other\ncriteria, like agreeing with the verb in person and number and occurring before the object, will be true of that phrase as well. It is\nthese _correlations_ among the properties of a linguistic thingamabob\nacross languages that make it scientifically meaningful to talk about\nsubjects and objects and nouns and verbs and auxiliaries and inflections—and not just Word Class #2,783 and Word Class #1,491—\nin languages from Abaza to Zyrian."
    },
    {
        "document_id": "0",
        "parent_id": 335,
        "parent_text": "Chomsky's claim that from a Martian's-eye-view all humans speak\na single language is based on the discovery that the same symbolmanipulating machinery, without exception, underlies the world's\nlanguages. Linguists have long known that the basic design features\nof language are found everywhere. Many were documented in 1960 by\nthe non-Chomskyan linguist C. F. Hockett in a comparison between\nhuman languages and animal communication systems (Hockett was\nnot acquainted with Martian). Languages use the mouth-to-ear channel as long as the users have intact hearing (manual and facial gestures,\nof course, are the substitute channel used by the deaf). A common\ngrammatical code, neutral between production and comprehension,\nallows speakers to produce any linguistic message they can understand, and vice versa. Words have stable meanings, linked to them\nby arbitrary convention. Speech sounds are treated discontinuously;\na sound that is acoustically halfway between _bat_ and _pat_ does not\nmean something halfway between batting and patting. Languages can\nconvey meanings that are abstract and remote in time or space from\nthe speaker. Linguistic forms are infinite in number, because they are\ncreated by a discrete combinatorial system. Languages all show a\nduality of patterning in which one rule system is used to order phonemes within morphemes, independent of meaning, and another is\nused to order morphemes within words and phrases, specifying their\nmeaning.\n\nChomskyan linguistics, in combination with Greenbergian surveys,\nallows us to go well beyond this basic spec sheet. It is safe to say that\nthe grammatical machinery we used for English in Chapters 4-6 is\nused in all the world's languages. All languages have a vocabulary\n\n\n238 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 336,
        "parent_text": "Chomskyan linguistics, in combination with Greenbergian surveys,\nallows us to go well beyond this basic spec sheet. It is safe to say that\nthe grammatical machinery we used for English in Chapters 4-6 is\nused in all the world's languages. All languages have a vocabulary\n\n\n238 THE LANGUAGE INSTINCT\n\n\nin the thousands or tens of thousands, sorted into part-of-speech\ncategories including noun and verb. Words are organized into phrases\naccording to the X-bar system (nouns are found inside N-bars, which\nare found inside noun phrases, and so on). The higher levels of phrase\nstructure include auxiliaries ( I N F L ), which signify tense, modality,\naspect, and negation. Nouns are marked for case and assigned semantic roles by the mental dictionary entry of the verb or other predicate.\nPhrases can be moved from their deep-structure positions, leaving a\ngap or \"trace,\" by a structure-dependent movement rule, thereby\nforming questions, relative clauses, passives, and other widespread\nconstructions. New word structures can be created and modified by\nderivational and inflectional rules. Inflectional rules primarily mark\nnouns for case and number, and mark verbs for tense, aspect, mood,\nvoice, negation, and agreement with subjects and objects in number,\ngender, and person. The phonological forms of words are defined by\nmetrical and syllable trees and separate tiers of features like voicing,\ntone, and manner and place of articulation, and are subsequently\nadjusted by ordered phonological rules. Though many of these arrangements are in some sense useful, their details, found in language\nafter language but not in any artificial system like F O R T R A N or musical\nnotation, give a strong impression that a Universal Grammar, not\nreducible to history or cognition, underlies the human language instinct."
    },
    {
        "document_id": "0",
        "parent_id": 337,
        "parent_text": "God did not have to do much to confound the language of Noah's\ndescendants. In addition to vocabulary—whether the word for\n\"mouse\" is _mouse_ or _souris_ —a few properties of language are simply\nnot specified in Universal Grammar and can vary as parameters. For\nexample, it is up to each language to choose whether the order of\nelements within a phrase is head-first or head-last _(eat sushi_ and _to_\n_Chicago_ versus _sushi eat_ and _Chicago to)_ and whether a subject is\nmandatory in all sentences or can be omitted when the speaker desires. Furthermore, a particular grammatical widget often does a great\ndeal of important work in one language and hums away unobtrusively\nin the corner of another. The overall impression is that Universal\nGrammar is like an archetypal body plan found across vast numbers\nof animals in a phylum. For example, among all the amphibians,\nreptiles, birds, and mammals, there is a common body architecture,\nwith a segmented backbone, four jointed limbs, a tail, a skull, and so\n\n\nThe Tower of Babel 239\n\n\non. The various parts can be grotesquely distorted or stunted across\nanimals: a bat's wing is a hand, a horse trots on its middle toes,\nwhales' forelimbs have become flippers and their hindlimbs have\nshrunken to invisible nubs, and the tiny hammer, anvil, and stirrup\nof the mammalian middle ear are jaw parts of reptiles. But from newts\nto elephants, a common topology of the body plan—the shin bone\nconnected to the thigh bone, the thigh bone connected to the hip\nbone—can be discerned. Many of the differences are caused by minor\nvariations in the relative timing and rate of growth of the parts during\nembryonic development. Differences among languages are similar.\nThere seems to be a common plan of syntactic, morphological, and\nphonological rules and principles, with a small set of varying parameters, like a checklist of options. Once set, a parameter can have farreaching changes on the superficial appearance of the language."
    },
    {
        "document_id": "0",
        "parent_id": 338,
        "parent_text": "If there is a single plan just beneath the surfaces of the world's\nlanguages, then any basic property of one language should be found in\nall the others. Let's reexamine the six supposedly un-English language\ntraits that opened the chapter. A closer look shows that all of them\ncan be found right here in English, and that the supposedly distinctive\ntraits of English can be found in the other languages.\n\n\n1. English, like the inflecting languages it supposedly differs\nfrom, has an agreement marker, the third person singular _-s_\nin _He walks._ It also has case distinctions in the pronouns, such\nas _he_ versus _him._ And like agglutinating languages, it has\nmachinery that can glue many bits together into a long word,\nlike the derivational rules and affixes that create _sensationaliza-_\n_tion_ and _Darwinianisms._ Chinese is supposed to be an even\nmore extreme example of an isolating language than English,\nbut it, too, contains rules that create multipart words such as\ncompounds and derivatives.\n\n2. English, like free-word-order languages, has free ordering in\nstrings of prepositional phrases, where each preposition marks\nthe semantic role of its noun phrase as if it were a case marker:\n_The package was sent from_ _Chicago to Boston_ _by Mary;_ _The_\n_package was sent by Mary to Boston from Chicago; The package_\n_was sent to Boston from Chicago by Mary,_ and so on. Conversely, in so-called scrambling languages at the other extreme,\n\n\n240 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 339,
        "parent_text": "2. English, like free-word-order languages, has free ordering in\nstrings of prepositional phrases, where each preposition marks\nthe semantic role of its noun phrase as if it were a case marker:\n_The package was sent from_ _Chicago to Boston_ _by Mary;_ _The_\n_package was sent by Mary to Boston from Chicago; The package_\n_was sent to Boston from Chicago by Mary,_ and so on. Conversely, in so-called scrambling languages at the other extreme,\n\n\n240 THE LANGUAGE INSTINCT\n\n\nlike Warlpiri, word order is never completely free; auxiliaries,\nfor example, must go in the second position in a sentence,\nwhich is rather like their positioning in English.\n3. English, like ergative languages, marks a similarity between\nthe objects of transitive verbs and the subjects of intransitive\nverbs. Just compare _John broke the glass (glass =_ object) with\n_The glass broke (glass_ = subject of intransitive), or _Three men_\n_arrived_ with _There arrived three men._\n4. English, like topic-prominent languages, has a topic constituent in constructions like _As for fish, I eat salmon_ and _John I_\n\n_never_ _really_ _liked._\n5. Like SOV languages, not too long ago English availed itself\nof an SOV order, which is still interpretable in archaic expressions like _Till death do us part_ and _With this ring I thee wed._\n6. Like classifier languages, English insists upon classifiers for\nmany nouns: you can't refer to a single square as _a paper_ but\nmust say _a sheet of paper._ Similarly, English speakers say _a_\n\n_piece of fruit_ (which refers to an apple, not a piece of an apple),\n\n_a blade of grass, a stick of wood,_ _fifty_ _head of cattle,_ and so on."
    },
    {
        "document_id": "0",
        "parent_id": 340,
        "parent_text": "_piece of fruit_ (which refers to an apple, not a piece of an apple),\n\n_a blade of grass, a stick of wood,_ _fifty_ _head of cattle,_ and so on.\n\n\nIf a Martian scientist concludes that humans speak a single language, that scientist might well wonder why Earthspeak has those\nthousands of mutually unintelligible dialects (assuming that the Martian has not read Genesis 11; perhaps Mars is beyond the reach of\nthe Gideon Society). If the basic plan of language is innate and fixed\nacross the species, why not the whole banana? Why the head-first\nparameter, the different-sized color vocabularies, the Boston accent?\n\nTerrestrial scientists have no conclusive answer. The theoretical\nphysicist Freeman Dyson proposed that linguistic diversity is here for\na reason: \"it was nature's way to make it possible for us to evolve\nrapidly,\" by creating isolated ethnic groups in which undiluted biological and cultural evolution can proceed swiftly. But Dyson's evolutionary reasoning is defective. Lacking foresight, lineages try to be\nthe best that they can be, _now;_ they do not initiate change for change's\nsake on the chance that one of the changes might come in handy in\nsome ice age ten thousand years in the future. Dyson is not the first\nto ascribe a purpose to linguistic diversity. A Colombian Bara Indian,\na member of an outbreeding set of tribes, when asked by a linguist\n\n\nThe Tower of Babel 2 4 1\n\n\nwhy there were so many languages, explained, \"If we were all Tukano\nspeakers, where would we get our women?\""
    },
    {
        "document_id": "0",
        "parent_id": 341,
        "parent_text": "The Tower of Babel 2 4 1\n\n\nwhy there were so many languages, explained, \"If we were all Tukano\nspeakers, where would we get our women?\"\n\nAs a native of Quebec, I can testify that differences in language\nlead to differences in ethnic identification, with widespread effects,\ngood and bad. But the suggestions of Dyson and the Bara put the\ncausal arrow backwards. Surely head-first parameters and all the rest\nrepresent massive overkill in some design to distinguish among ethnic\ngroups, assuming that that was even evolutionarily desirable. Humans\nare ingenious at sniffing out minor differences to figure out whom\nthey should despise. All it takes is that European-Americans have\nlight skin and African-Americans have dark skin, that Hindus make\na point of not eating beef and Moslems make a point of not eating\npork, or, in the Dr. Seuss story, that the Star-Bellied Sneetches have\nbellies with stars and the Plain-Bellied Sneetches have none upon\nthars. Once there is more than one language, ethnocentrism can do\nthe rest; we need to understand why there is more than one language.\n\nDarwin himself expressed the key insight:\n\n\nThe formation of different languages and of distinct species, and\nthe proofs that both have been developed through a gradual process,\nare curiously parallel. . . . We find in distinct languages striking\nhomologies due to community of descent, and analogies due to a\nsimilar process of formation. . . . Languages, like organic beings,\ncan be classed in groups under groups; and they can be classed\neither naturally, according to descent, or artificially by other characters. Dominant languages and dialects spread widely, and lead to\nthe gradual extinction of other tongues. A language, like a species,\nwhen extinct, never . . . reappears."
    },
    {
        "document_id": "0",
        "parent_id": 342,
        "parent_text": "That is, English is similar though not identical to German for the\nsame reason that foxes are similar though not identical to wolves:\nEnglish and German are modifications of a common ancestor language spoken in the past, and foxes and wolves are modifications of\na common ancestor species that lived in the past. Indeed, Darwin\nclaimed to have taken some of his ideas about biological evolution\nfrom the linguistics of his time, which we will encounter later in this\nchapter.\n\nDifferences among languages, like differences among species, are\nthe effects of three processes acting over long spans of time. One\n\n\n242 THE LANGUAGE INSTINCT\n\n\nprocess is variation—mutation, in the case of species; linguistic innovation, in the case of languages. The second is heredity, so that\ndescendants resemble their progenitors in these variations—genetic\ninheritance, in the case of species; the ability to learn, in the case of\nlanguages. The third is isolation—by geography, breeding season, or\nreproductive anatomy, in the case of species; by migration or social\nbarriers, in the case of languages. In both cases, isolated populations\naccumulate separate sets of variations and hence diverge over time.\nTo understand why there is more than one language, then, we must\nunderstand the effects of innovation, learning, and migration."
    },
    {
        "document_id": "0",
        "parent_id": 343,
        "parent_text": "Let me begin with the ability to learn, and by convincing you that\nthere is something to explain. Many social scientists believe that\nlearning is some pinnacle of evolution that humans have scaled from\nthe lowlands of instinct, so that our ability to learn can be explained\nby our exalted braininess. But biology says otherwise. Learning is\nfound in organisms as simple as bacteria, and, as James and Chomsky\npointed out, human intelligence may depend on our having _more_\ninnate instincts, not fewer. Learning is an option, like camouflage or\nhorns, that nature gives organisms as needed—when some aspect of\nthe organisms' environmental niche is so unpredictable that anticipation of its contingencies cannot be wired in. For example, birds that\nnest on small cliff ledges do not learn to recognize their offspring.\nThey do not need to, for any blob of the right size and shape in their\nnest is sure to be one. Birds that nest in large colonies, in contrast,\nare in danger of feeding some neighbor's offspring that sneaks in,\nand they have evolved a mechanism that allows them to learn the\nparticular nuances of their own babies.\n\nEven when a trait starts off as a product of learning, it does not\nhave to remain so. Evolutionary theory, supported by computer simulations, has shown that when an environment is stable, there is a\nselective pressure for learned abilities to become increasingly innate.\nThat is because if an ability is innate, it can be deployed earlier in the\nlifespan of the creature, and there is less of a chance that an unlucky\ncreature will miss out on the experiences that would have been necessary to teach it.\n\nWhy might it pay for the child to learn parts of a language rather\nthan having the whole system hard-wired? For vocabulary, the bene\n\nThe Tower of Babel 243"
    },
    {
        "document_id": "0",
        "parent_id": 344,
        "parent_text": "Why might it pay for the child to learn parts of a language rather\nthan having the whole system hard-wired? For vocabulary, the bene\n\nThe Tower of Babel 243\n\n\nfits are fairly obvious: 60,000 words might be too many to evolve,\nstore, and maintain in a genome comprising only 50,000 to 100,000\ngenes. And words for new plants, animals, tools, and especially people\nare needed throughout the lifespan. But what good is it to learn\ndifferent grammars? No one knows, but here are some plausible\nhypotheses.\n\nPerhaps some of the things about language that we have to learn\nare easily learned by simple mechanisms that antedated the evolution\nof grammar. For example, a simple kind of learning circuit might\nsuffice to record which element comes before which other one, as\nlong as the elements are first defined and identified by some other\ncognitive module. If a universal grammar module defines a head and\na role-player, their relative ordering (head-first or head-last) could\nthus be recorded easily. If so, evolution, having made the basic computational units of language innate, may have seen no need to replace\nevery bit of learned information with innate wiring. Computer simulations of evolution show that the pressure to replace learned neural\nconnections with innate ones diminishes as more and more of the\nnetwork becomes innate, because it becomes less and less likely that\nlearning will fail for the rest.\n\nA second reason for language to be partly learned is that language\ninherently involves sharing a code with other people. An innate grammar is useless if you are the only one possessing it: it is a tango of\none, the sound of one hand clapping. But the genomes of other people\nmutate and drift and recombine when they have children. Rather than\nselecting for a completely innate grammar, which would soon fall out\nof register with everyone else's, evolution may have given children an\nability to learn the variable parts of language as a way of synchronizing\ntheir grammars with that of the community."
    },
    {
        "document_id": "0",
        "parent_id": 345,
        "parent_text": "The second component of language differentiation is a source of\nvariation. Some person, somewhere, must begin to speak differently\nfrom the neighbors, and the innovation must spread and catch on\nlike a contagious disease until it becomes epidemic, at which point\nchildren perpetuate it. Change can arise from many sources. Words\nare coined, borrowed from other languages, stretched in meaning,\nand forgotten. New jargon or speech styles may sound way cool within\nsome subculture and then infiltrate the mainstream. Specific examples\n\n\n244 THE LANGUAGE INSTINCT\n\n\nof these borrowings are a subject of fascination to pop language\nfanciers and fill many books and columns. Personally, I have trouble\ngetting excited. Should we really be astounded to learn that English\nborrowed _kimono_ from Japanese, _banana_ from Spanish, _moccasin_\nfrom the American Indians, and so on?\n\nBecause of the language instinct, there is something much more\nfascinating about linguistic innovation: each link in the chain of language transmission is a human brain. That brain is equipped with a\nuniversal grammar and is always on the lookout for examples in\nambient speech of various kinds of rules. Because speech can be\nsloppy and words and sentences ambiguous, people are occasionally\napt to _reanalyze_ the speech they hear—they interpret it as having\ncome from a different dictionary entry or rule than the ones that the\nspeaker actually used."
    },
    {
        "document_id": "0",
        "parent_id": 346,
        "parent_text": "A simple example is the word _orange._ Originally it was _norange,_\nborrowed from the Spanish _naranja._ But at some point some unknown\ncreative speaker must have reanalyzed _a norange_ as _an orange._ Though\nthe speaker's and hearer's analyses specify identical sounds for that\nparticular phrase, _anorange,_ once the hearer uses the rest of grammar\ncreatively, the change becomes audible, as in _those oranges_ rather\nthan _those noranges._ (This particular change has been common in\nEnglish. Shakespeare used _nuncle_ as an affectionate name, a recutting\nof _mine Uncle_ to _my nuncle,_ and _Ned_ came from _Edward_ by a similar\nroute. Nowadays many people talk about _a whole nother thing,_ and\nI know of a child who eats _ectarines_ and an adult called _Nalice_ who\nrefers to people she doesn't care for as _nidiots.)_\n\nReanalysis, a product of the discrete combinatorial creativity of the\nlanguage instinct, partly spoils the analogy between language change\non the one hand and biological and cultural evolution on the other.\nMany linguistic innovations are not like random mutation, drift, erosion, or borrowing. They are more like legends or jokes that are\nembellished or improved or reworked with each retelling. That is\nwhy, although grammars change quickly through history, they do not\ndegenerate, for reanalysis is an inexhaustible source of new complexity. Nor must they progressively differentiate, for grammars can hop\namong the grooves made available by the universal grammar in everyone's mind. Moreover, one change in a language can cause an imbalance that can trigger a cascade of other changes elsewhere, like falling\ndominoes. Any part of language can change:\n\n\nThe Tower of Babel 245"
    },
    {
        "document_id": "0",
        "parent_id": 347,
        "parent_text": "The Tower of Babel 245\n\n\n - Many phonological rules arose when hearers in some community\nreanalyzed rapid, coarticulated speech. Imagine a dialect that lacks\nthe rule that converts _t_ to a flapped _d_ in _utter._ Its speakers generally\npronounce the _t_ as a _t_, but may not do so when speaking rapidly or\naffecting a casual \"lazy\" style. Hearers may then credit them with a\nflapping rule, and they (or their children) would then pronounce the\n_t_ as a flap even in careful speech. Taken further, even the underlying\nphonemes can be reanalyzed. This is how we got _v._ Old English didn't\nhave a _v_ ; our word _starve_ was originally _steorfan._ But any _f_ between\ntwo vowels was pronounced with voicing turned on, so _ofer_ was\npronounced \"over,\" thanks to a rule similar to the contemporary\nflapping rule. Listeners eventually analyzed the _v_ as a separate phoneme, rather than as a pronunciation of _f_, so now the word actually\nis _over,_ and _v_ and _f_ are available as separate phonemes. For example,\nwe can now differentiate words like _waver_ and _wafer,_ but King\nEthelbald could not have.\n\n  - The phonological rules governing the _pronunciation_ of words can,\nin turn, be reanalyzed into morphological rules governing the _con-_\n_struction_ of them. Germanic languages like Old English had an \"umlaut\" rule that changed a back vowel to a front vowel if the next\nsyllable contained a high front vowel sound. For example, in _foti,_ the\nplural of \"foot,\" the back _o_ was altered by the rule to a front e,\nharmonizing with the front _i._ Subsequently the _i_ at the end ceased\nbeing pronounced, and because the phonological rule no longer had\nanything to trigger it, speakers reinterpreted the _o-e_ shift as a morphological relationship signaling the plural—resulting in our\n\n_foot-feet,_ _mouse-mice,_ _goose-geese,_ _tooth-teeth,_ and _louse-lice._"
    },
    {
        "document_id": "0",
        "parent_id": 348,
        "parent_text": "_foot-feet,_ _mouse-mice,_ _goose-geese,_ _tooth-teeth,_ and _louse-lice._\n\n  - Reanalysis can also take two variants of one word, one created\nfrom the other by an inflectional rule, and recategorize them as separate words. The speakers of yesteryear might have noticed that an\ninflectional _oo-ee_ rule applies not to all items but only to a few:\n_tooth-teeth,_ but not _booth-heeth._ So _teeth_ was interpreted as a separate, irregular word linked to _tooth,_ rather than the product of a rule\napplied to _tooth._ The vowel change no longer acts like a rule—hence\nLederer's humorous story \"Foxen in the Henhice.\" Other sets of\nvaguely related words came into English by this route, like\n\n_brother-brethren,_ _half-halve,_ _teeth-teethe,_ _to_ _fall-to_ _fell,_ _to_ _rise-to_\n_raise;_ even _wrought,_ which used to be the past tense of _work._\n\n  - Other morphological rules can be formed when the words that\n\n\n246 THE LANGUAGE INSTINCT\n\n\ncommonly accompany some other word get eroded and then glued\nonto it. Tense markers may come from auxiliaries; for example, as\nI've mentioned, the English _-ed_ suffix may have evolved from _did:_\n_hammer-did —> hammered._ Case markers may come from slurred\nprepositions or from sequences of verbs (for example, in a language\nthat allows the construction _take nail hit it, take_ might erode into an\naccusative case marker like _ta-)._ Agreement markers can arise from\npronouns: in _John, he kissed her, he_ and _her_ can eventually glom\nonto the verb as agreement affixes."
    },
    {
        "document_id": "0",
        "parent_id": 349,
        "parent_text": "- Syntactic constructions can arise when a word order that is merely\npreferred becomes reanalyzed as obligatory. For example, when English had case markers, both _give him a book_ and _give a book him_\nwere possible, but the former was more common. When the case\nmarkers eroded in casual speech, many sentences would have become\nambiguous if order were still allowed to vary. The more common\norder was thus enshrined as a rule of syntax. Other constructions can\narise from multiple reanalyses. The English perfect _1 had written a_\n_book_ originally came from _I had a book written_ (meaning \"I owned a\nbook that was written\"). The reanalysis was inviting because the SOV\npattern was alive in English; the participle _written_ could be reanalyzed\nas the main verb of the sentence, and _had_ could be reanalyzed as its\nauxiliary, begetting a new analysis with a related meaning.\n\n\nThe third ingredient for language splitting is separation among\ngroups of speakers, so that successful innovations do not take over\neverywhere but accumulate separately in the different groups. Though\npeople modify their language every generation, the extent of these\nchanges is slight: vastly more sounds are preserved than mutated,\nmore constructions analyzed properly than reanalyzed. Because of\nthis overall conservatism, some patterns of vocabulary, sound, and\ngrammar survive for millennia. They serve as the fossilized tracks of\nmass migrations in the remote past, clues to how human beings spread\nout over the earth to end up where we find them today.\n\nHow far back can we trace the language of this book, modern\nAmerican English? Surprisingly far, perhaps five or even nine thousand years. Our knowledge of where our language has come from is\nconsiderably more precise than the recollection of Dave Barry's Mr.\nLanguage Person: \"The English language is a rich verbal tapestry\n\n\nThe Tower of Babel 247"
    },
    {
        "document_id": "0",
        "parent_id": 350,
        "parent_text": "How far back can we trace the language of this book, modern\nAmerican English? Surprisingly far, perhaps five or even nine thousand years. Our knowledge of where our language has come from is\nconsiderably more precise than the recollection of Dave Barry's Mr.\nLanguage Person: \"The English language is a rich verbal tapestry\n\n\nThe Tower of Babel 247\n\n\nwoven together from the tongues of the Greeks, the Latins, the\nAngles, the Klaxtons, the Celtics, and many more other ancient peoples, all of whom had severe drinking problems.\" Let's work our way\nback."
    },
    {
        "document_id": "0",
        "parent_id": 351,
        "parent_text": "America and England first came to be divided by a common language, in Wilde's memorable words, when colonists and immigrants\nisolated themselves from British speech by crossing the Atlantic\nOcean. England was already a Babel of regional and class dialects\nwhen the first colonists left. What was to become the standard American dialect was seeded by the ambitious or dissatisfied members of\nlower and middle classes from southeastern England. By the eighteenth century an American accent was noted, and pronunciation in\nthe American South was particularly influenced by the immigration\nof the Ulster Scots. Westward expansions preserved the layers of\ndialects of the eastern seaboard, though the farther west the pioneers\nwent, the more their dialects mixed, especially in California, which\nrequired leapfrogging of the vast interior desert. Because of immigration, mobility, literacy, and now the mass media, the English of the\nUnited States, even with its rich regional differences, is homogeneous\ncompared with the languages in territories of similar size in the rest\nof the world; the process has been called \"Babel in reverse.\" It is\noften said that the dialects of the Ozarks and Appalachia are a relict\nof Elizabethan English, but this is just a quaint myth, coming from\nthe misconception of language as a cultural artifact. We think of the\nfolk ballads, the hand-stitched quilts, and the whiskey aging slowly\nin oak casks and easily swallow the rumor that in this land that time\nforgot, the people still speak the traditional tongue lovingly handed\ndown through the generations. But language does not work that\nway—at all times, in all communities, language changes, though the\nvarious parts of a language may change in different ways in different\ncommunities. Thus it is true that these dialects preserve some English\nforms that are rare elsewhere, such as _afeared, yourn, hisn,_ and _et,_\n_holp,_ and _dome_ as the past of _eat, help,_ and _climb._ But so does _every_"
    },
    {
        "document_id": "0",
        "parent_id": 352,
        "parent_text": "forgot, the people still speak the traditional tongue lovingly handed\ndown through the generations. But language does not work that\nway—at all times, in all communities, language changes, though the\nvarious parts of a language may change in different ways in different\ncommunities. Thus it is true that these dialects preserve some English\nforms that are rare elsewhere, such as _afeared, yourn, hisn,_ and _et,_\n_holp,_ and _dome_ as the past of _eat, help,_ and _climb._ But so does _every_\nvariety of American English, including the standard one. Many socalled Americanisms were in fact carried over from England, where\nthey were subsequently lost. For example, the participle _gotten,_ the\npronunciation of _a_ in _path_ and _bath_ with a front-of-the-mouth \"a\"\nrather than the back-of-the-mouth \"ah,\" and the use of _mad_ to mean\n\"angry,\" _fall_ to mean \"autumn,\" and _sick_ to mean \"ill,\" strike the"
    },
    {
        "document_id": "0",
        "parent_id": 353,
        "parent_text": "248 **THE** **L A N G U A G E** **INSTINCT**\n\n\nBritish ear as ail-American, but they are actually holdovers from the\nEnglish that was spoken in the British Isles at the time of the American\ncolonization.\n\nEnglish has changed on both sides of the Atlantic, and had been\nchanging well before the voyage of the _Mayflower._ What grew into\nstandard contemporary English was simply the dialect spoken around\nLondon, the political and economic center of England, in the seventeenth century. In the centuries preceding, it had undergone a number\nof major changes, as you can see in these versions of the Lord's\nPrayer:\n\n\nC O N T E M P O R A R Y E N G L I S H : Our Father, who is in heaven, may your\nname be kept holy. May your kingdom come into being. May your\nwill be followed on earth, just as it is in heaven. Give us this day\nour food for the day. And forgive us our offenses, just as we forgive\nthose who have offended us. And do not bring us to the test. But\nfree us from evil. For the kingdom, the power, and the glory are\nyours forever. Amen.\n\nE A R L Y M O D E R N E N G L I S H ( C . 1600): Our father which are in heaven,\nhallowed be thy Name. Thy kingdom come. Thy will be done, on\nearth, as it is in heaven. Give us this day our daily bread. And\nforgive us our trespasses, as we forgive those who trespass against\nus. And lead us not into temptation, but deliver us from evil. For\nthine is the kingdom, and the power, and the glory, for ever, amen.\n\nM I D D L E E N G L I S H ( C . 1400): Oure fadir that art in heuenes halowid\nbe thi name, thi kyngdom come to, be thi wille don in erthe es in\nheuene, yeue to us this day oure bread ouir other substance, &\nforyeue to us oure dettis, as we forgeuen to oure dettouris, & lede\nus not in to temptacion: but delyuer us from yuel, amen."
    },
    {
        "document_id": "0",
        "parent_id": 354,
        "parent_text": "M I D D L E E N G L I S H ( C . 1400): Oure fadir that art in heuenes halowid\nbe thi name, thi kyngdom come to, be thi wille don in erthe es in\nheuene, yeue to us this day oure bread ouir other substance, &\nforyeue to us oure dettis, as we forgeuen to oure dettouris, & lede\nus not in to temptacion: but delyuer us from yuel, amen.\n\nO L D E N G L I S H (c. 1000): Faeder ure thu the eart on heofonum, si thin\nnama gehalgod. Tobecume thin rice. Gewurthe in willa on eorthan\nswa swa on heofonum. Urne gedaeghwamlican hlaf syle us to daeg.\nAnd forgyf us ure gyltas, swa swa we forgyfath urum gyltedum. And\nne gelaed thu us on contnungen ac alys us of yfele. Sothlice.\n\n\nThe roots of English are in northern Germany near Denmark,\nwhich was inhabited early in the first millennium by pagan tribes\ncalled the Angles, the Saxons, and the Jutes. After the armies of the\n\n\nThe Tower of Babel 249\n\n\ncollapsing Roman Empire left Britain in the fifth century, these tribes\ninvaded what was to become England (Angle-land) and displaced the\nindigenous Celts there into Scotland, Ireland, Wales, and Cornwall.\nLinguistically, the defeat was total; English has virtually no traces of\nCeltic. Vikings invaded in the ninth to eleventh centuries, but their\nlanguage, Old Norse, was similar enough to Anglo-Saxon that aside\nfrom many borrowings, the language, Old English, did not change\nmuch."
    },
    {
        "document_id": "0",
        "parent_id": 355,
        "parent_text": "In 1066 William the Conqueror invaded Britain, bringing with him\nthe Norman dialect of French, which became the language of the\nruling classes. When King John of the Anglo-Norman kingdom lost\nNormandy shortly after 1200, English reestablished itself as the exclusive language of England, though with a marked influence of French\nthat lasts to this day in the form of thousands of words and a variety of\ngrammatical quirks that go with them. This \"Latinate\" vocabulary—\nincluding such words as _donate, vibrate,_ and _desist_ —has a more\nrestricted syntax; for example, you can say _give the museum a painting_\nbut not _donate the museum a painting,_ _shake it up_ but not _vibrate it_\n_up._ The vocabulary also has its own sound pattern: Latinate words\nare largely polysyllabic with stress on the second syllable, such as\n_desist, construct,_ and _transmit,_ whereas their Anglo-Saxon synonyms\n_stop, build,_ and _send_ are single syllables. The Latinate words also\ntrigger many of the sound changes that make English morphology and\nspelling so idiosyncratic, like _electric-electricity_ and _nation-national._\nBecause Latinate words are longer, and are more formal because of\ntheir ancestry in the government, church, and schools of the Norman\nconquerors, overusing them produces the stuffy prose universally\ndeplored by style manuals, such as _The adolescents who had effectuated_\n_forcible_ _entry_ _into_ _the_ _domicile_ _were_ _apprehended_ versus _We_ _caught_\n_the kids who broke into the house._ Orwell captured the flabbiness of\nLatinate English in his translation of a passage from Ecclesiastes into\nmodern institutionalese:\n\n\nI returned and saw under the sun, that the race is not to the swift,\nnor the battle to the strong, neither yet bread to the wise, nor yet\nriches to men of understanding, nor yet favour to men of skill; but\ntime and chance happeneth to them all.\n\nObjective consideration of contemporary phenomena compels the\nconclusion that success or failure in competitive activities exhibits\n\n\n250 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 356,
        "parent_text": "I returned and saw under the sun, that the race is not to the swift,\nnor the battle to the strong, neither yet bread to the wise, nor yet\nriches to men of understanding, nor yet favour to men of skill; but\ntime and chance happeneth to them all.\n\nObjective consideration of contemporary phenomena compels the\nconclusion that success or failure in competitive activities exhibits\n\n\n250 THE LANGUAGE INSTINCT\n\n\nno tendency to be commensurate with innate capacity, but that a\nconsiderable element of the unpredictable must invariably be taken\ninto account.\n\n\nEnglish changed noticeably in the Middle English period\n(1100-1450) in which Chaucer lived. Originally all syllables were\nenunciated, including those now represented in spelling by \"silent\"\nletters. For example, _make_ would have been pronounced with two\nsyllables. But the final syllables became reduced to the generic schwa\nlike the _a_ in _allow_ and in many cases they were eliminated entirely.\nSince the final syllables contained the case markers, overt case began\nto vanish, and the word order became fixed to eliminate the resulting\nambiguity. For the same reason, prepositions and auxiliaries like _of_\nand _do_ and _will_ and _have_ were bled of their original meanings and\ngiven important grammatical duties. Thus many of the signatures of\nmodern English syntax were the result of a chain of effects beginning\nwith a simple shift in pronunciation."
    },
    {
        "document_id": "0",
        "parent_id": 357,
        "parent_text": "The period of Early Modern English, the language of Shakespeare\nand the King James Bible, lasted from 1450 to 1700. It began with\nthe Great Vowel Shift, a revolution in the pronunciation of long\nvowels whose causes remain mysterious. (Perhaps it was to compensate for the fact that long vowels sounded too similar to short vowels\nin the monosyllables that were now prevalent; or perhaps it was a\nway for the upper classes to differentiate themselves from the lower\nclasses once Norman French became obsolete.) Before the vowel\nshift, _mouse_ had been pronounced \"mooce\"; the old \"oo\" turned\ninto a diphthong. The gap left by the departed \"oo\" was filled by\nraising what used to be an \"oh\" sound; what we pronounce as _goose_\nhad, before the Great Vowel Shift, been pronounced \"goce.\" That\nvacuum, in turn, was filled by the \"o\" vowel (as in _hot,_ only drawn\nout), giving us _broken_ from what had previously been pronounced\nmore like \"brocken.\" In a similar rotation, the \"ee\" vowel turned\ninto a diphthong; _like_ had been pronounced \"leek.\" This dragged in\nthe vowel \"eh\" to replace it; our _geese_ was originally pronounced\n\"gace.\" And that gap was filled when the long version of _ah_ was\nraised, resulting in _name_ from what used to be pronounced \"nahma.\"\nThe spelling never bothered to track these shifts, which is why the\nletter _a_ is pronounced one way in _cam_ and another way in _came,_\nwhere it had formerly been just a longer version of the _a_ in _cam._ This\n\n\nThe Tower of Babel 251\n\n\nis also why vowels are rendered differently in English spelling than\nin all the other European alphabets and in \"phonetic\" spelling."
    },
    {
        "document_id": "0",
        "parent_id": 358,
        "parent_text": "The Tower of Babel 251\n\n\nis also why vowels are rendered differently in English spelling than\nin all the other European alphabets and in \"phonetic\" spelling.\n\nIncidentally, fifteenth-century Englishmen did not wake up one\nday and suddenly pronounce their vowels differently, like a switch to\nDaylight Savings Time. To the people living through it, the Great\nVowel Shift probably felt like the current trend in the Chicago area\nto pronounce _hot_ like _hat,_ or the growing popularity of that strange\nsurfer dialect in which _dude_ is pronounced something like \"diiihhhoooood.\"\n\n\nWhat happens if we try to go back farther in time? The languages\nof the Angles and the Saxons did not come out of thin air; they\nevolved from Proto-Germanic, the language of a tribe that occupied\nmuch of northern Europe in the first millennium B . C . The western\nbranch of the tribe split into groups that gave us not only AngloSaxon, but German and its offshoot Yiddish, and Dutch and its\noffshoot Afrikaans. The northern branch settled Scandinavia and\ncame to speak Swedish, Danish, Norwegian, and Icelandic. The similarities in vocabulary among these languages are visible in an instant,\nand there are many similarities in grammar as well, such as forms of\nthe past-tense ending _-ed._\n\nThe ancestors of the Germanic tribes left no clear mark in written\nhistory or the archeological record. But they did leave a special mark\non the territory they occupied. That mark was discerned in 1786 by\nSir William Jones, a British judge stationed in India, in one of the\nmost extraordinary discoveries in all scholarship. Jones had taken up\nthe study of Sanskrit, a long-dead language, and noted:"
    },
    {
        "document_id": "0",
        "parent_id": 359,
        "parent_text": "The ancestors of the Germanic tribes left no clear mark in written\nhistory or the archeological record. But they did leave a special mark\non the territory they occupied. That mark was discerned in 1786 by\nSir William Jones, a British judge stationed in India, in one of the\nmost extraordinary discoveries in all scholarship. Jones had taken up\nthe study of Sanskrit, a long-dead language, and noted:\n\n\nThe Sanskrit language, whatever may be its antiquity, is of a wonderful structure; more perfect than the Greek, more copious than the\nLatin, and more exquisitely refined than either, yet bearing to both\nof them a stronger affinity, both in the roots of verbs and in the\nforms of grammar, than could possibly have been produced by\naccident; so strong indeed that no philologer could examine them\nall three, without believing them to have sprung from some common\nsource, which, perhaps no longer exists; there is a similar reason,\nthough not quite so forcible, for supposing that both the Gothic\n\n[Germanic] and the Celtic, though blended with a very different\n\n\n2 5 2 THE LANGUAGE INSTINCT\n\n\nidiom, had the same origin as the Sanskrit; and the old Persian\nmight be added to the same family . ..\n\n\nHere are the kinds of affinities that impressed Jones:\n\n\nENGLISH: brother mead is thou bearest he bears\nGREEK: phrater methu esti phereis pherei\nLATIN: frater est fers fert\nOLD SLAVIC: bratre mid yeste berasi beretu\nOLD IRISH: brathir mith is beri\nSANSKRIT: bhrater medhu asti bharasi bharati"
    },
    {
        "document_id": "0",
        "parent_id": 360,
        "parent_text": "[Germanic] and the Celtic, though blended with a very different\n\n\n2 5 2 THE LANGUAGE INSTINCT\n\n\nidiom, had the same origin as the Sanskrit; and the old Persian\nmight be added to the same family . ..\n\n\nHere are the kinds of affinities that impressed Jones:\n\n\nENGLISH: brother mead is thou bearest he bears\nGREEK: phrater methu esti phereis pherei\nLATIN: frater est fers fert\nOLD SLAVIC: bratre mid yeste berasi beretu\nOLD IRISH: brathir mith is beri\nSANSKRIT: bhrater medhu asti bharasi bharati\n\n\nSuch similarities in vocabulary and grammar are seen in an immense\nnumber of modern languages. Among others, they embrace Germanic, Greek, Romance (French, Spanish, Italian, Portuguese, Romanian), Slavic (Russian, Czech, Polish, Bulgarian, Serbo-Croatian),\nCeltic (Gaelic, Irish, Welsh, Breton), and Indo-Iranian (Persian, Afghan, Kurdish, Sanskrit, Hindi, Bengali, and the Romany language of\nthe Gypsies). Subsequent scholars were able to add Anatolian (extinct\nlanguages spoken in Turkey, including Hittite), Armenian, Baltic\n(Lithuanian and Latvian), and Tocharian (two extinct languages spoken in China). The similarities are so pervasive that linguists have\nreconstructed a grammar and a large dictionary for a hypothetical\ncommon ancestor language, Proto-Indo-European, and a set of systematic rules by which the daughter languages changed. For example,\nJacob Grimm (one of the two Grimm brothers, famous as collectors\nof fairy tales) discovered the rule by which _p_ and _t_ in Proto-IndoEuropean became _f_ and _th_ in Germanic, as one can see in comparing\nLatin _pater_ and Sanskrit _piter_ with English _father._"
    },
    {
        "document_id": "0",
        "parent_id": 361,
        "parent_text": "The implications are mind-boggling. Some ancient tribe must have\ntaken over most of Europe, Turkey, Iran, Afghanistan, Pakistan,\nnorthern India, western Russia, and parts of China. The idea has\nexcited the imagination of a century of linguists and archeologists,\nthough even today no one really knows who the Indo-Europeans\nwere. Ingenious scholars have made guesses from the reconstructed\nvocabulary. Words for metals, wheeled vehicles, farm implements,\nand domesticated animals and plants suggest that the Indo-Europeans\nwere a late Neolithic people. The ecological distributions of the natural objects for which there are Proto-Indo-European words—elm and\n\n\nThe Tower of Babel 253\n\n\nwillow, for example, but not olive or palm—have been used to place\nthe speakers somewhere in the territory from inland northern Europe\nto southern Russia. Combined with words for patriarch, fort, horse,\nand weapons, the reconstructions led to an image of a powerful\nconquering tribe spilling out of an ancestral homeland on horseback to\noverrun most of Europe and Asia. The word 'Aryan\" became associated with the Indo-Europeans, and the Nazis claimed them as ancestors. More sanely, archeologists have linked them to artifacts of the\nKurgan culture in the southern Russian steppes from around 3500\nB.C., a band of tribes that first harnessed the horse for military purposes."
    },
    {
        "document_id": "0",
        "parent_id": 362,
        "parent_text": "Recently the archeologist Colin Renfrew has argued that the IndoEuropean takeover was a victory not of the chariot but of the cradle.\nHis controversial theory is that the Indo-Europeans lived in Anatolia\n(part of modern Turkey) on the flanks of the Fertile Cresent region\naround 7000 B.C., where they were among the world's first farmers.\nFarming is a method for mass-producing human beings by turning\nland into bodies. Farmers' daughters and sons need more land, and\neven if they moved just **a** mile or two from their parents, they would\nquickly engulf the less fecund hunter-gatherers standing in their way.\nArcheologists agree that farming spread in a wave that began in\nTurkey around 8500 B.C. and reached Ireland and Scandinavia by\n2500 B.C. Geneticists recently discovered that a certain set of genes\nis most concentrated among modern people in Turkey and becomes\nprogressively diluted as one moves through the Balkans to northern\nEurope. This supports the theory originally proposed by the human\ngeneticist Luca Cavalli-Sforza that farming spread by the movement\nof farmers, as their offspring interbred with indigenous hunter-gatherers, rather than by the movement of farming techniques, as a fad\nadopted by the hunter-gatherers. Whether these people were the\nIndo-Europeans, and whether they spread into Iran, India, and China\nby a similar process, is still not known. It is an awesome possibility.\nEvery time we use a word like _brother,_ or form the past tense of an\nirregular verb like _break-broke_ or _drink-drank,_ we would be using\nthe preserved speech patterns of the instigators of the most important\nevent in human history, the spread of agriculture.\n\nMost of the other human languages on earth can also be grouped\ninto phyla descending from ancient tribes of astoundingly successful\nfarmers, conquerors, explorers, or nomads. Not all of Europe is Indo\n\n254 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 363,
        "parent_text": "Most of the other human languages on earth can also be grouped\ninto phyla descending from ancient tribes of astoundingly successful\nfarmers, conquerors, explorers, or nomads. Not all of Europe is Indo\n\n254 THE LANGUAGE INSTINCT\n\n\nEuropean. Finnish, Hungarian, and Estonian are Uralic languages,\nwhich together with Lappish, Samoyed, and other languages are the\nremnants of a vast nation based in central Russia about 7,000 years\nago. Altaic is generally thought to include the main languages of\nTurkey, Mongolia, the Islamic republics of the former USSR, and\nmuch of central Asia and Siberia. The earliest ancestors are uncertain,\nbut later ones include a sixth-century empire as well as the Mongolian\nempire of Genghis Khan and the Manchu dynasty. Basque is an\norphan, presumably from an island of aboriginal Europeans that\nresisted the Indo-European tidal wave.\n\nAfro-Asiatic (or Hamito-Semitic), including Arabic, Hebrew, Maltese, Berber, and many Ethiopian and Egyptian languages, dominates\nSaharan Africa and much of the Middle East. The rest of Africa is\ndivided among three groups. Khoisan includes the !Kung and other\ngroups (formerly called \"Hottentots\" and \"Bushmen\"), whose ancestors once occupied most of sub-Saharan Africa. The Niger-Congo\nphylum includes the Bantu family, spoken by farmers from western\nAfrica who pushed the Khoisan into their current small enclaves in\nsouthern and southeastern Africa. The third phylum, Nilo-Saharan,\noccupies three large patches in the southern Saharan region."
    },
    {
        "document_id": "0",
        "parent_id": 364,
        "parent_text": "In Asia, Dravidian languages such as Tamil dominate southern\nIndia and are found in pockets to the north. Dravidian speakers must\ntherefore be the descendants of a people who occupied most of the\nIndian subcontinent before the incursion of the Indo-Europeans.\nSome 40 languages between the Black Sea and the Caspian Sea belong\nto the family called Caucasian (not to be confused with the informal\nracial term for the typically light-skinned people of Europe and Asia).\nSino-Tibetan includes Chinese, Burmese, and Tibetan. Austronesian,\nhaving nothing to do with Australia _(Austr-_ means \"south\"), includes\nthe languages of Madagascar off the coast of Africa, Indonesia, Malaysia, the Philippines, New Zealand (Maori), Micronesia, Melanesia,\nand Polynesia, all the way to Hawaii—the record of people with\nextraordinary wanderlust and seafaring skill. Vietnamese and Khmer\n(the language of Cambodia) fall into Austro-Asiatic. The 200 aboriginal languages of Australia belong to a family of their own, and the\n800 of New Guinea belong to a family as well, or perhaps to a small\nnumber of families. Japanese and Korean look like linguistic orphans,\nthough a few linguists lump one or both with Altaic.\n\nWhat about the Americas? Joseph Greenberg, whom we met earlier\n\n\nThe Tower of Babel 255"
    },
    {
        "document_id": "0",
        "parent_id": 365,
        "parent_text": "What about the Americas? Joseph Greenberg, whom we met earlier\n\n\nThe Tower of Babel 255\n\n\nas the founder of the study of language universals, also classifies\nlanguages into phyla. He played a large role in unifying the 1,500\nAfrican languages into their four groups. Recently he has claimed that\nthe 200 language stocks of native Americans can be grouped into only\nthree phyla, each descending from a group of migrants who came\nover the Bering land bridge from Asia beginning 12,000 years ago or\nearlier. The Eskimos and Aleuts were the most recent immigrants.\nThey were preceded by the Na-Dene, who occupied most of Alaska\nand northwestern Canada and embrace some of the languages of the\nAmerican Southwest such as Navajo and Apache. This much is widely\naccepted. But Greenberg has also proposed that all the other languages, from Hudson Bay to Tierra del Fuego, belong to a single\nphylum, Amerind. The sweeping idea that America was settled by\nonly three migrations has received some support from recent studies\nby Cavalli-Sforza and others of modern natives' genes and tooth\npatterns, which fall into groups corresponding roughly to the three\nlanguage phyla."
    },
    {
        "document_id": "0",
        "parent_id": 366,
        "parent_text": "At this point we enter a territory of fierce controversy but potentially large rewards. Greenberg's hypothesis has been furiously attacked by other scholars of American languages. Comparative\nlinguistics is an impeccably precise domain of scholarship, where\nradical divergences between related languages over centuries or a few\nmillennia can with great confidence be traced back step by step to a\ncommon ancestor. Linguists raised in this tradition are appalled by\nGreenberg's unorthodox method of lumping together dozens of languages based on rough similarities in vocabulary, rather than carefully\ntracing sound-changes and reconstructing proto-languages. As an experimental psycholinguist who deals with the noisy data of reaction\ntimes and speech errors, I have no problem with Greenberg's use of\nmany loose correspondences, or even with the fact that some of his\ndata contain random errors. What bothers me more is his reliance on\ngut feelings of similarity rather than on actual statistics that control\nfor the number of correspondences that might be expected by chance.\nA charitable observer can always spot similarities in large vocabulary\nlists, but that does not imply that they descended from a common\nlexical ancestor. It could be a coincidence, like the fact that the word\nfor \"blow\" is _pneu_ in Greek and _pniw_ in Klamath (an American\n\n\n256 THE LANGUAGE INSTINCT\n\n\nIndian language spoken in Oregon), or the fact that the word for\n\"dog\" in the Australian aboriginal language Mbabaram happens to\nbe _dog._ (Another serious problem, which Greenberg's critics do point\nout, is that languages can resemble each other because of lateral\nborrowing rather than vertical inheritance, as in the recent exchanges\nthat led to _her negligees_ and _le weekend.)_"
    },
    {
        "document_id": "0",
        "parent_id": 367,
        "parent_text": "256 THE LANGUAGE INSTINCT\n\n\nIndian language spoken in Oregon), or the fact that the word for\n\"dog\" in the Australian aboriginal language Mbabaram happens to\nbe _dog._ (Another serious problem, which Greenberg's critics do point\nout, is that languages can resemble each other because of lateral\nborrowing rather than vertical inheritance, as in the recent exchanges\nthat led to _her negligees_ and _le weekend.)_\n\nThe odd absence of statistics also leaves in limbo a set of even more\nambitious, exciting, and controversial hypotheses about language\nfamilies and the prehistoric peoplings of continents that they would\nrepresent. Greenberg and his associate Merritt Ruhlen are joined by\na school of Russian linguists (Sergei Starostin, Aharon Dogopolsky,\nVitaly Shevoroshkin, and Vladislav Illich-Svitych) who lump languages aggressively and seek to reconstruct the very ancient language\nthat would have been the progenitor of each lump. They discern\nsimilarities among the proto-languages of Indo-European, Afro-Asiatic, Dravidian, Altaic, Uralic, and Eskimo-Aleut, as well as the orphans Japanese and Korean and a few miscellaneous language groups,\nreflecting a common ancestor proto-proto-language they call Nostratic. For example, the reconstructed Proto-Indo-European word\nfor mulberry, _mor,_ is similar to Proto-Altaic _mur_ \"berry,\" ProtoUralic _marja_ \"berry,\" and Proto-Kartvelian (Georgian) _mar-caw_\n\"strawberry.\" The Nostraticists would have them all evolve from the\nhypothetical Nostratic root _marja._ Similarly, Proto-Indo-European\n_melg_ \"to milk\" resembles Proto-Uralic _malge_ \"breast\" and Arabic\n_mlg_ \"to suckle.\" Nostratic would have been spoken by a huntergatherer population, for there are no names of domesticated species\namong the 1,600 words the linguists claim to have reconstructed.\nThe Nostratic hunter-gatherers would have occupied all of Europe,\nnorthern Africa, and northern, northeastern, western, and southern\nAsia, perhaps 15,000 years ago, from an origin in the Middle East."
    },
    {
        "document_id": "0",
        "parent_id": 368,
        "parent_text": "And various lumpers from this school have suggested other audacious superphyla and super-superphyla. One comprises Amerind and\nNostratic. Another, Sino-Caucasian, comprises Sino-Tibetan, Caucasian, and maybe Basque and Na-Dene. Lumping the lumps, Starostin\nhas suggested that Sino-Caucasian can be connected to AmerindNostratic, forming a proto-proto-proto language that has been called\n\nS C A N, covering continental Eurasia and the Americas. Austric would\nembrace Austronesian, Austro-Asiatic, and various minor languages\nin China and Thailand. In Africa, some see similarities between Niger\n\nThe Tower of Babel 2 5 7\n\n\nCongo and Nilo-Saharan that warrant a Congo-Saharan group. If one\nwere to accept all of these mergers—and some are barely distinguishable from wishful thinking—all human languages would fall into only\nsix groups: S C A N in Eurasia, the Americas, and northern Africa;\nKhoisan and Congo-Saharan in sub-Saharan Africa; Austric in Southeast Asia and the Indian and Pacific Oceans; Australian; and New\nGuinean."
    },
    {
        "document_id": "0",
        "parent_id": 369,
        "parent_text": "The Tower of Babel 2 5 7\n\n\nCongo and Nilo-Saharan that warrant a Congo-Saharan group. If one\nwere to accept all of these mergers—and some are barely distinguishable from wishful thinking—all human languages would fall into only\nsix groups: S C A N in Eurasia, the Americas, and northern Africa;\nKhoisan and Congo-Saharan in sub-Saharan Africa; Austric in Southeast Asia and the Indian and Pacific Oceans; Australian; and New\nGuinean.\n\nAncestral stocks of this geographic magnitude would have to correspond to the major expansions of the human species, and CavalliSforza and Ruhlen have argued that they do. Cavalli-Sforza examined\nminor variations in the genes of hundreds of people representing a\nfull spectrum of racial and ethnic groups. He claims that by lumping\ntogether sets of people who have similar genes, and then lumping the\nlumps, a genetic family tree of humankind can be constructed. The\nfirst bifurcation splits the sub-Saharan Africans off from everyone\nelse. The adjoining branch in turn splits into two, one embracing\nEuropeans, northeast Asians (including Japanese and Koreans), and\nAmerican Indians, the other containing southeast Asians and Pacific\nIslanders on one sub-branch, and aboriginal Australians and New\nGuineans on another. The correspondences with the hypothetical\nlanguage superphyla are reasonably clear, though not perfect. One\ninteresting parallel is that what most people think of as the Mongoloid\nor Oriental race on the basis of superficial facial features and skin\ncoloring may have no biological reality. In Cavalli-Sforza's genetic\nfamily tree, northeast Asians such as Siberians, Japanese, and Koreans\nare more similar to Europeans than to southeast Asians such as Chinese and Thai. Strikingly, this non-obvious racial grouping corresponds to the non-obvious linguistic grouping of Japanese, Korean,\nand Altaic with Indo-European in Nostratic, separate from the SinoTibetan family in which Chinese is found."
    },
    {
        "document_id": "0",
        "parent_id": 370,
        "parent_text": "The branches of the hypothetical genetic/linguistic family tree can\nbe taken to depict the history of _Homo sapiens sapiens,_ from the\nAfrican population in which mitochondrial Eve was thought to evolve\n200,000 years ago, to the migrations out of Africa 100,000 years ago\nthrough the Middle East to Europe and Asia, and from there, in the\npast 50,000 years, to Australia, the islands of the Indian and Pacific\nOceans, and the Americas. Unfortunately, the genetic and migrational\nfamily trees are almost as controversial as the linguistic one, and any\npart of this interesting story could unravel in the next few years.\n\n\n258 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 371,
        "parent_text": "A correlation between language families and human genetic groupings does _not,_ by the way, mean that there are genes that make it\neasier for some kinds of people to learn some kinds of languages.\nThis folk myth is pervasive, like the claim of some French speakers\nthat only those with Gallic blood can truly master the gender system,\nor the insistence of my Hebrew teacher that the assimilated Jewish\nstudents in his college classes innately outperformed their Gentile\nclassmates. As far as the language instinct is concerned, the correlation\nbetween genes and languages is a coincidence. People store genes in\ntheir gonads and pass them to their children through their genitals;\nthey store grammars in their brains and pass them to their children\nthrough their mouths. Gonads and brains are attached to each other\nin bodies, so when bodies move, genes and grammars move together.\nThat is the only reason that geneticists find any correlation between\nthe two. We know that the connection is easily severed, thanks to\nthe genetic experiments called immigration and conquest, in which\nchildren get their grammars from the brains of people other than\ntheir parents. Needless to say, the children of immigrants learn a\nlanguage, even one separated from their parents' language by the\ndeepest historical roots, without any disadvantage compared to agemates who come from long lineages of the language's speakers. Correlations between genes and languages are thus so crude that they are\nmeasurable only at the level of superphyla and aboriginal races. In\nthe past few centuries, colonization and immigration have completely\nscrambled the original correlations between the superphyla and the\ninhabitants of the different continents; native English speakers, to\ntake the most obvious example, include virtually every racial subgroup\non earth. Well before that, Europeans interbred with their neighbors\nand conquered each other often enough that there is almost no correlation between genes and language families within Europe (though"
    },
    {
        "document_id": "0",
        "parent_id": 372,
        "parent_text": "the past few centuries, colonization and immigration have completely\nscrambled the original correlations between the superphyla and the\ninhabitants of the different continents; native English speakers, to\ntake the most obvious example, include virtually every racial subgroup\non earth. Well before that, Europeans interbred with their neighbors\nand conquered each other often enough that there is almost no correlation between genes and language families within Europe (though\nthe ancestors of the non-Indo-European Lapps, Maltese, and Basques\nleft a few genetic mementos). For similar reasons, well-accepted language phyla can contain strange genetic bedfellows, like the black\nEthiopians and white Arabs in the Afro-Asiatic phylum, and the white\nLapps and Oriental Samoyeds in Uralic."
    },
    {
        "document_id": "0",
        "parent_id": 373,
        "parent_text": "Moving from the highly speculative to the borderline flaky, Shevoroshkin, Ruhlen, and others have been trying to reconstruct words\nancestral to the six superphyla—the vocabulary of the language of\n\n\nThe Tower of Babel 259\n\n\nAfrican Eve, \"Proto-World.\" Ruhlen has posited 31 roots, such as\n_tik_ \"one\" which would have evolved into Proto-Indo-European _deik_\n\"to point\" and then Latin _digit_ \"finger,\" Nilo-Saharan _dik_ \"one,\"\nEskimo _tik_ \"index finger,\" Kede _tong_ \"arm,\" Proto-Afro-Asiatic _tak_\n\"one,\" and Proto-Austro-Asiatic _ktig_ \"arm or hand.\" Though I am\nwilling to be patient with Nostratic and similar hypotheses pending\nthe work of a good statistician with a free afternoon, I find the\nProto-World hypothesis especially suspect. (Comparative linguists are\nspeechless.) It is not that I doubt that language evolved only once,\none of the assumptions behind the search for the ultimate mother\ntongue. It's just that one can trace words back only so far. It is\nlike the man who claimed to be selling Abraham Lincoln's ax—he\nexplained that over the years the head had to be replaced twice and\nthe handle three times. Most linguists believe that after 10,000 years\nno traces of a language remain in its descendants. This makes it\nextremely doubtful that anyone will find extant traces of the most\nrecent ancestor of all contemporary languages, or that that ancestor\nwould in turn retain traces of the language of the first modern humans,\nwho lived some 200,000 years ago."
    },
    {
        "document_id": "0",
        "parent_id": 374,
        "parent_text": "This chapter must end on a sad and urgent note. Languages are\nperpetuated by the children who learn them. When linguists see a\nlanguage spoken only by adults, they know it is doomed. By this\nreasoning, they warn of an impending tragedy in the history of humankind. The linguist Michael Krauss estimates that 150 North\nAmerican Indian languages, about 80% of the existing ones, are\nmoribund. Elsewhere, his counts are equally grim: 40 moribund languages (90% of the existing ones) in Alaska and northern Siberia,\n160 (23%) in Central and South America, 45 (70%) in Russia, 225\n(90%) in Australia, perhaps 3,000 (50%) worldwide. Only about 600\nlanguages are reasonably safe by dint of the sheer number of their\nspeakers, say, a minimum of 100,000 (though this does not _guarantee_\neven short-term survival), and this optimistic assumption still suggests\nthat between 3,600 and 5,400 languages, as many as 90% of the\nworld's total, are threatened with extinction in the next century.\n\nThe wide-scale extinction of languages is reminiscent of the current\n(though less severe) wide-scale extinction of plant and animal species.\n\n\n260 THE LANGUAGE INSTINCT\n\n\nThe causes overlap. Languages disappear by the destruction of the\nhabitats of their speakers, as well as by genocide, forced assimilation\nand assimilatory education, demographic submersion, and bombardment by electronic media, which Krauss calls \"cultural nerve gas.\"\nAside from halting the more repressive social and political causes of\ncultural annihilation, we can forestall some linguistic extinctions by\ndeveloping pedagogical materials, literature, and television in the\nindigenous language. Other extinctions can be mitigated by preserving grammars, lexicons, texts, and recorded speech samples with the\nhelp of archives and faculty positions for native speakers. In some\ncases, like Hebrew in the twentieth century, the continued ceremonial\nuse of a language together with preserved documents can be sufficient\nto revive it, given the will."
    },
    {
        "document_id": "0",
        "parent_id": 375,
        "parent_text": "Just as we cannot reasonably hope to preserve every species on\nearth, we cannot preserve every language, and perhaps should not.\nThe moral and practical issues are complex. Linguistic differences\ncan be a source of lethal divisiveness, and if a generation chooses to\nswitch to a language of the mainstream that promises them economic\nand social advancement, does some outside group have the right to\ncoerce them not to on the grounds that it finds the idea of them\nkeeping the old language pleasing? But such complexities aside, when\n3,000-odd languages are moribund, we can be sure that many of the\ndeaths are unwanted and preventable.\n\nWhy should people care about endangered languages? For linguistics and the sciences of mind and brain that encompass it, linguistic\ndiversity shows us the scope and limits of the language instinct. Just\nthink of the distorted picture we would have if only English were\navailable for study! For anthropology and human evolutionary biology, languages trace the history and geography of the species, and\nthe extinction of a language (say, Ainu, formerly spoken in Japan by\na mysterious Caucasoid people) can be like the burning of a library\nof historical documents or the extinction of the last species in a\nphylum. But the reasons are not just scientific. As Krauss writes, \"Any\nlanguage is a supreme achievement of a uniquely human collective\ngenius, as divine and endless a mystery as a living organism.\" A\nlanguage is a medium from which a culture's verse, literature, and\nsong can never be extricated. We are in danger of losing treasures\nranging from Yiddish, with far more words for \"simpleton\" than the\nEskimos were reputed to have for \"snow,\" to Damin, a ceremonial\n\n\nThe Tower of Babel 261"
    },
    {
        "document_id": "0",
        "parent_id": 376,
        "parent_text": "The Tower of Babel 261\n\n\nvariant of the Australian language Lardil, which has a unique 200word vocabulary that is learnable in a day but that can express the\nfull range of concepts in everyday speech. As the linguist Ken Hale\nhas put it, \"The loss of a language is part of the more general loss\nbeing suffered by the world, the loss of diversity in all things.\""
    },
    {
        "document_id": "0",
        "parent_id": 377,
        "parent_text": "###### 9"
    },
    {
        "document_id": "0",
        "parent_id": 378,
        "parent_text": "#### Baby Born Talking— Describes Heaven\n\nOn May 21, 1985, a periodical called the _Sun_ ran these\nintriguing headlines:\n\n\nJohn Wayne Liked to Play with Dolls\n\nPrince Charles' Blood Is Sold for $10,000\nby Dishonest Docs\n\nFamily Haunted by Ghost of Turkey\nThey Ate for Christmas\n\nBABY BORN TALKING—DESCRIBES HEAVEN\nIncredible proof of reincarnation\n\n\nThe last headline caught my eye—it seemed like the ultimate demonstration that language is innate. According to the article,\n\n\nLife in heaven is grand, a baby told an astounded obstetrical team\nseconds after birth. Tiny Naomi Montefusco literally came into the\nworld singing the praises of God's firmament. The miracle so\nshocked the delivery room team, one nurse ran screaming down the\nhall. \"Heaven is a beautiful place, so warm and so serene,\" Naomi\nsaid. \"Why did you bring me here?\" Among the witnesses was\nmother Theresa Montefusco, 18, who delivered the child under\nlocal anesthetic . . . \"I distinctly heard her describe heaven as a\nplace where no one has to work, eat, worry about clothing, or do\n\n\n262\n\n\nBaby Born Talking—Describes Heaven 263\n\n\nanything but sing God's praises. I tried to get off the delivery table\nto kneel down and pray, but the nurses wouldn't let me.\"\n\n\nScientists, of course, cannot take such reports at face value; any\nimportant finding must be replicated. A replication of the Corsican\nmiracle, this time from Taranto, Italy, occurred on October 31, 1989,\nwhen the _Sun_ (a strong believer in recycling) ran the headline \"BABY\nBORN TALKING—DESCRIBES HEAVEN. Infant's words prove\nreincarnation exists.\" A related discovery was reported on May 29,\n1990: \"BABY SPEAKS AND SAYS: I'M THE REINCARNATION\nOF NATALIE WOOD.\" Then, on September 29, 1992, a second\nreplication, reported in the same words as the original. And on June\n8, 1993, the clincher: \"AMAZING 2-HEADED BABY IS PROOF\nOF REINCARNATION. ONE HEAD SPEAKS ENGLISH—THE\nOTHER ANCIENT LATIN.\""
    },
    {
        "document_id": "0",
        "parent_id": 379,
        "parent_text": "Why do stories like Naomi's occur only in fiction, never in fact?\nMost children do not begin to talk until they are a year old, do not\ncombine words until they are one and a half, and do not converse in\nfluent grammatical sentences until they are two or three. What is\ngoing on in those years? Should we ask why it takes children so long?\nOr is a three-year-old's ability to describe earth as miraculous as a\nnewborn's ability to describe heaven?\n\nAll infants come into the world with linguistic skills. We know\nthis because of the ingenious experimental technique (discussed in\nChapter 3) in which a baby is presented with one signal over and\nover to the point of boredom, and then the signal is changed; if the\nbaby perks up, he or she must be able to tell the difference. Since\nears don't move the way eyes do, the psychologists Peter Eimas and\nPeter Jusczyk devised a different way to see what a one-month-old\nfinds interesting. They put a switch inside a rubber nipple and hooked\nup the switch to a tape recorder, so that when the baby sucked, the\ntape played. As the tape droned on with _ba ba ba ba . . ._, the infants\nshowed their boredom by sucking more slowly. But when the syllables\nchanged to _pa pa pa_ . . ., the infants began to suck more vigorously,\nto hear more syllables. Moreover, they were using the sixth sense,\nspeech perception, rather than just hearing the syllables as raw sound:\ntwo _ba's_ that differed acoustically from each other as much as a _ba_\ndiffers from a _pa,_ but that are both heard as _ba_ by adults, did not\nrevive the infants' interest. And infants must be recovering phonemes,\n\n\n264 THE LANGUAGE INSTINCT\n\n\nlike _b,_ from the syllables they are smeared across. Like adults, they\nhear the same stretch of sound as a _b_ if it appears in a short syllable\nand as a _w_ if it appears in a long syllable."
    },
    {
        "document_id": "0",
        "parent_id": 380,
        "parent_text": "264 THE LANGUAGE INSTINCT\n\n\nlike _b,_ from the syllables they are smeared across. Like adults, they\nhear the same stretch of sound as a _b_ if it appears in a short syllable\nand as a _w_ if it appears in a long syllable.\n\nInfants come equipped with these skills; they do not learn them\nby listening to their parents' speech. Kikuyu and Spanish infants\ndiscriminate English _ba's_ and _pa's,_ which are not used in Kikuyu or\nSpanish and which their parents cannot tell apart. English-learning\ninfants under the age of six months distinguish phonemes used in\nCzech, Hindi, and Inslekampx (a Native American language), but\nEnglish-speaking adults cannot, even with five hundred trials of training or a year of university coursework. Adult ears can tell the sounds\napart, though, when the consonants are stripped from the syllables\nand presented alone as chirpy sounds; they just cannot tell them apart\n_as_ _phonemes._"
    },
    {
        "document_id": "0",
        "parent_id": 381,
        "parent_text": "The _Sun_ article is a bit sketchy on the details, but we can surmise\nthat because Naomi was understood, she must have spoken in Italian,\nnot Proto-World or Ancient Latin. Other infants may enter the world\nwith some knowledge of their mother's language, too. The psychologists Jacques Mehler and Peter Jusczyk have shown that four-day-old\nFrench babies suck harder to hear French than Russian, and pick up\ntheir sucking more when a tape changes from Russian to French\nthan from French to Russian. This is not an incredible proof of\nreincarnation; the melody of mothers' speech carries through their\nbodies and is audible in the womb. The babies still prefer French\nwhen the speech is electronically filtered so that the consonant and\nvowel sounds are muffled and only the melody comes through. But\nthey are indifferent when the tapes are played backwards, which\npreserves the vowels and some of the consonants but distorts the\nmelody. Nor does the effect prove the inherent beauty of the French\nlanguage: non-French infants do not prefer French, and French infants do not distinguish Italian from English. The infants must have\nlearned something about the prosody of French (its melody, stress,\nand timing) in the womb, or in their first days out of it.\n\nBabies continue to learn the sounds of their language throughout\nthe first year. By six months, they are beginning to lump together the\ndistinct sounds that their language collapses into a single phoneme,\nwhile continuing to discriminate equivalently distinct ones that their\nlanguage keeps separate. By ten months they are no longer universal\nphoneticians but have turned into their parents; they do not distin\n\nBaby Born Talking—Describes Heaven 265"
    },
    {
        "document_id": "0",
        "parent_id": 382,
        "parent_text": "Babies continue to learn the sounds of their language throughout\nthe first year. By six months, they are beginning to lump together the\ndistinct sounds that their language collapses into a single phoneme,\nwhile continuing to discriminate equivalently distinct ones that their\nlanguage keeps separate. By ten months they are no longer universal\nphoneticians but have turned into their parents; they do not distin\n\nBaby Born Talking—Describes Heaven 265\n\n\nguish Czech or Inslekampx phonemes unless they are Czech or Inslekampx babies. Babies make this transition before they produce or\nunderstand words, so their learning cannot depend on correlating\nsound with meaning. That is, they cannot be listening for the difference in sound between a word they think means _bit_ and a word they\nthink means _beet,_ because they have learned neither word. They must\nbe sorting the sounds directly, somehow tuning their speech analysis\nmodule to deliver the phonemes used in their language. The module\ncan then serve as the front end of the system that learns words and\ngrammar.\n\nDuring the first year, babies also get their speech production systems geared up. First, ontogeny recapitulates phylogeny. A newborn\nhas a vocal tract like a nonhuman mammal. The larynx comes up like a\nperiscope and engages the nasal passage, forcing the infant to breathe\nthrough the nose and making it anatomically possible to drink and\nbreathe at the same time. By three months the larynx has descended\ndeep into the throat, opening up the cavity behind the tongue (the\npharynx) that allows the tongue to move forwards and backwards\nand produce the variety of vowel sounds used by adults."
    },
    {
        "document_id": "0",
        "parent_id": 383,
        "parent_text": "Not much of linguistic interest happens during the first two\nmonths, when babies produce the cries, grunts, sighs, clicks, stops,\nand pops associated with breathing, feeding, and fussing, or even\nduring the next three, when coos and laughs are added. Between five\nand seven months babies begin to play with sounds, rather than\nusing them to express their physical and emotional states, and their\nsequences of clicks, hums, glides, trills, hisses, and smacks begin to\nsound like consonants and vowels. Between seven and eight months\nthey suddenly begin to babble in real syllables like _ba-ba-ba, neh-neh-_\n_neh,_ and _dee-dee-dee._ The sounds are the same in all languages, and\nconsist of the phonemes and syllable patterns that are most common\nacross languages. By the end of the first year, babies vary their syllables, like _neh-nee,_ _da-dee,_ and _meh-neh,_ and produce that really cute\nsentencelike gibberish.\n\nIn recent years pediatricians have saved the lives of many babies\nwith breathing abnormalities by inserting a tube into their tracheas\n(the pediatricians are trained on cats, whose airways are similar), or\nby surgically opening a hole in their trachea below the larynx. The\ninfants are then unable to make voiced sounds during the normal\nperiod of babbling. When the normal airway is restored in the second\n\n\n266 THE LANGUAGE INSTINCT\n\n\nyear of life, those infants are seriously retarded in speech development, though they eventually catch up, with no permanent problems.\nDeaf children's babbling is later and simpler—though if their parents\nuse sign language, they babble, on schedule, with their hands!"
    },
    {
        "document_id": "0",
        "parent_id": 384,
        "parent_text": "266 THE LANGUAGE INSTINCT\n\n\nyear of life, those infants are seriously retarded in speech development, though they eventually catch up, with no permanent problems.\nDeaf children's babbling is later and simpler—though if their parents\nuse sign language, they babble, on schedule, with their hands!\n\nWhy is babbling so important? The infant is like a person who has\nbeen given a complicated piece of audio equipment bristling with\nunlabeled knobs and switches but missing the instruction manual. In\nsuch situations people resort to what hackers call frobbing—fiddling\naimlessly with the controls to see what happens. The infant has been\ngiven a set of neural commands that can move the articulators every\nwhich way, with wildly varying effects on the sound. By listening to\ntheir own babbling, babies in effect write their own instruction manual; they learn how much to move which muscle in which way to\nmake which change in the sound. This is a prerequisite to duplicating\nthe speech of their parents. Some computer scientists, inspired by the\ninfant, believe that a good robot should learn an internal software\nmodel of its articulators by observing the consequences of its own\nbabbling and flailing."
    },
    {
        "document_id": "0",
        "parent_id": 385,
        "parent_text": "Shortly before their first birthday, babies begin to understand\nwords, and around that birthday, they start to produce them. Words\nare usually produced in isolation; this one-word stage can last from\ntwo months to a year. For over a century, and all over the globe,\nscientists have kept diaries of their infants' first words, and the lists\nare almost identical. About half the words are for objects: food _(juice,_\n_cookie),_ body parts _(eye, nose),_ clothing _(diaper, sock),_ vehicles _(car,_\n_boat),_ toys _(doll, block),_ household items _(bottle, light),_ animals _(dog,_\n_kitty),_ and people _(dada, baby)._ (My nephew Eric's first word was\n_Batman.)_ There are words for actions, motions, and routines, like _up,_\n_off,_ _open, peekaboo,_ _eat,_ and _go,_ and modifiers, like _hot, allgone,_ _more,_\n_dirty,_ and _cold._ Finally, there are routines used in social interaction,\nlike _yes, no, want, bye-bye,_ and _hi_ —a few of which, like _look at that_\nand _what is that,_ are words in the sense of listemes (memorized\nchunks), but not, at least for the adult, words in the sense of morphological products and syntactic atoms. Children differ in how much\nthey name objects or engage in social interaction using memorized\nroutines. Psychologists have spent a lot of time speculating about the\ncauses of those differences (sex, age, birth order, and socioeconomic\n\n\nBaby Born Talking—Describes Heaven 267\n\n\nstatus have all been examined), but the most plausible to my mind is\nthat babies are people, only smaller. Some are interested in objects,\nothers like to shmooze.\n\nSince word boundaries do not physically exist, it is remarkable that\nchildren are so good at finding them. A baby is like the dog being\nyelled at in the two-panel cartoon by Gary Larson:\n\n\nW H A T W E S A Y T O D O G S : \"Okay, Ginger! I've had it! You stay out\nof the garbage! Understand, Ginger? Stay out of the garbage, or\nelse!\"\n\nW H A T T H E Y H E A R : \"Blah blah G I N G E R blah blah blah blah blah\nblah blah blah G I N G E R blah blah blah blah blah.\""
    },
    {
        "document_id": "0",
        "parent_id": 386,
        "parent_text": "Since word boundaries do not physically exist, it is remarkable that\nchildren are so good at finding them. A baby is like the dog being\nyelled at in the two-panel cartoon by Gary Larson:\n\n\nW H A T W E S A Y T O D O G S : \"Okay, Ginger! I've had it! You stay out\nof the garbage! Understand, Ginger? Stay out of the garbage, or\nelse!\"\n\nW H A T T H E Y H E A R : \"Blah blah G I N G E R blah blah blah blah blah\nblah blah blah G I N G E R blah blah blah blah blah.\"\n\n\nPresumably children record some words parents use in isolation, or\nin stressed final positions, like _Look-at-the_ _**BOTTLE.**_ Then they look\nfor matches to these words in longer stretches of speech, and find\nother words by extracting the residues in between the matched portions. Occasionally there are near misses, providing great entertainment to family members:\n\n\nI don't want to go to your ami. [from _Miami]_\nI am heyv! [from _Behave!]_\nDaddy, when you go tinkle you're an eight, and when I go\n\ntinkle I'm an eight, right? [from _urinate]_\nI know I sound like Larry, but who's Gitis? [from _laryngitis]_\nDaddy, why do you call your character Sam Alone? [from\n\n_Sam Malone,_ the bartender in _Cheers]_\nThe ants are my friends, they're blowing in the wind. [from\n\n_The answer,_ _my friend,_ _is blowing in the wind]_\n\n\nBut these errors are surprisingly rare, and of course adults occasionally\nmake them too, as in the Pullet Surprise and doggy-dog world of\nChapter 6. In an episode of the television show _Hill Street Blues,_\npolice officer JD Larue began to flirt with a pretty high school student.\nHis partner, Neal Washington, said, \"I have only three words to say\nto you, JD. Statue. Tory. Rape.\"\n\n\nAround eighteen months, language takes off. Vocabulary growth\njumps to the new-word-every-two-hours minimum rate that the child\n\n\n268 THE LANGUAGE INSTINCT\n\n\nwill maintain through adolescence. And syntax begins, with strings\nof the minimum length that allows it: two. Here are some examples:\n\n\n\nAll dry.\nI sit.\nNo pee.\nMore cereal.\nOther pocket\nMail come.\nOur car."
    },
    {
        "document_id": "0",
        "parent_id": 387,
        "parent_text": "Around eighteen months, language takes off. Vocabulary growth\njumps to the new-word-every-two-hours minimum rate that the child\n\n\n268 THE LANGUAGE INSTINCT\n\n\nwill maintain through adolescence. And syntax begins, with strings\nof the minimum length that allows it: two. Here are some examples:\n\n\n\nAll dry.\nI sit.\nNo pee.\nMore cereal.\nOther pocket\nMail come.\nOur car.\n\n\n\nAll messy.\nI shut.\nSee baby.\nMore hot.\nBoot off.\nAirplane allgone.\nPapa away.\n\n\n\nAll wet.\nNo bed.\nSee pretty.\nHi Calico.\nSiren by.\nBye-bye car.\nDry pants.\n\n\n\nChildren's two-word combinations are so similar in meaning the\nworld over that they read as translations of one another. Children\nannounce when objects appear, disappear, and move about, point\nout their properties and owners, comment on people doing things\nand seeing things, reject and request objects and activities, and ask\nabout who, what, and where. These microsentences already reflect\nthe language being acquired: in ninety-five percent of them, the words\nare properly ordered.\n\nThere is more going on in children's minds than in what comes out\nof their mouths. Even before they put two words together, babies\ncan comprehend a sentence using its syntax. For example, in one\nexperiment, babies who spoke only in single words were seated in\nfront of two television screens, each of which featured a pair of adults\nimprobably dressed up as Cookie Monster and Big Bird from _Sesame_\n_Street._ One screen showed Cookie Monster tickling Big Bird; the\nother showed Big Bird tickling Cookie Monster. A voiceover said,\n\"OH LOOK!!! BIG BIRD IS TICKLING COOKIE MONSTER!!\nFIND BIG BIRD TICKLING COOKIE MONSTER!!\" (or vice\nversa). The children must have understood the meaning of the ordering of subject, verb, and object—they looked more at the screen that\ndepicted the sentence in the voiceover."
    },
    {
        "document_id": "0",
        "parent_id": 388,
        "parent_text": "When children do put words together, the words seem to meet up\nwith a bottleneck at the output end. Children's two-and three-word\nutterances look like samples drawn from longer potential sentences\nexpressing a complete and more complicated idea. For example, the\npsychologist Roger Brown noted that although the children he studied\nnever produced a sentence as complicated as _Mother gave John lunch_\n\n\nBaby Born Talking—Describes Heaven 269\n\n\n_in the kitchen,_ they did produce strings containing all of its components, and in the correct order:\n\n\n\n**AGENT** **ACTION** **RECIPIENT** **OBJECT**\n(Mother gave John lunch\n\n\n\nMommy fix.\nMommy\nBaby\nGive\n\nPut\nPut\n\n**1** ride\n\nTractor go\nGive\nPut\nAdam put\n\n\n\n**LOCATION**\nin the kitchen.)\n\n\ntable.\n\n\nfloor.\n\n\nfloor.\n\n\nwindow,\nbox.\n\n\n\ndoggie.\n\n\ndoggie\n\n\n\npumpkin.\n\n\nlight,\n\n\nhorsie.\n\n\npaper,\ntruck\n\n\n\nIf we divide language development into somewhat arbitrary stages,\nlike Syllable Babbling, Gibberish Babbling, One-Word Utterances,\nand Two-Word Strings, the next stage would have to be called All\nHell Breaks Loose. Between the late twos and the mid-threes, children's language blooms into fluent grammatical conversation so rapidly that it overwhelms the researchers who study it, and no one has\nworked out the exact sequence. Sentence length increases steadily,\nand because grammar is a discrete combinatorial system, the number\nof syntactic types increases exponentially, doubling every month, reaching the thousands before the third birthday. You can get a feel for this\nexplosion by seeing how the speech of a little boy called Adam grows\nin sophistication over the period of a year, starting with his early word\ncombinations at the age of two years and three months (\"2;3\"):\n\n\n2;3: Play checkers. Big drum. I got horn. A bunny-rabbit\nwalk.\n2;4: See marching bear go? Screw part machine. That busy\nbulldozer truck.\n2;5: Now put boots on. Where wrench go? Mommy talking bout lady. What that paper clip doing?\n\n\n270 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 389,
        "parent_text": "2;3: Play checkers. Big drum. I got horn. A bunny-rabbit\nwalk.\n2;4: See marching bear go? Screw part machine. That busy\nbulldozer truck.\n2;5: Now put boots on. Where wrench go? Mommy talking bout lady. What that paper clip doing?\n\n\n270 THE LANGUAGE INSTINCT\n\n\n2;6: Write a piece a paper. What that egg doing? I lost a\nshoe. No, I don't want to sit seat.\n2;7: Where piece a paper go? Ursula has a boot on. Going\nto see kitten. Put the cigarette down. Dropped a rubber band. Shadow has hat just like that. Rintintin\ndon't fly, Mommy.\n2;8: Let me get down with the boots on. Don't be afraid\na horses. How tiger be so healthy and fly like kite?\nJoshua throw like a penguin.\n2;9: Where Mommy keep her pocket book? Show you\nsomething funny. Just like turtle make mud pie.\n2;10: Look at that train Ursula brought. I simply don't want\nput in chair. You don't have paper. Do you want little\nbit, Cromer? I can't wear it tomorrow.\n2;11: That birdie hopping by Missouri in bag. Do want\nsome pie on your face? Why you mixing baby chocolate? I finish drinking all up down my throat. I said\nwhy not you coming in? Look at that piece a paper\nand tell it. Do you want me tie that round? We going\nturn light on so you can't see.\n3;0: I going come in fourteen minutes. I going wear that\nto wedding. I see what happens. I have to save them\nnow. Those are not strong mens. They are going sleep\nin wintertime. You dress me up like a baby elephant.\n3;1: I like to play with something else. You know how to\nput it back together. I gon' make it like a rocket to\nblast off with. I put another one on the floor. You\nwent to Boston University? You want to give me some\ncarrots and some beans? Press the button and catch\nit, sir. I want some other peanuts. Why you put the\npacifier in his mouth? Doggies like to climb up."
    },
    {
        "document_id": "0",
        "parent_id": 390,
        "parent_text": "3;2: So it can't be cleaned? I broke my racing car. Do\nyou know the light wents off? What happened to the\nbridge? When it's got a flat tire it's need a go to the\nstation. I dream sometimes. I'm going to mail this so\nthe letter can't come off. I want to have some espresso.\nThe sun is not too bright. Can I have some sugar?\nCan I put my head in the mailbox so the mailman can\nknow where I are and put me in the mailbox? Can I\n\n\nBaby Born Talking—Describes Heaven 271\n\n\nkeep the screwdriver just like a carpenter keep the\nscrewdriver?\n\n\nNormal children can differ by a year or more in their rate of\nlanguage development, though the stages they pass through are generally the same regardless of how stretched out or compressed. I chose\nto show you Adam's speech because his language development is\nrather _slow_ compared with other children's. Eve, another child Brown\nstudied, was speaking in sentences like this before she was two:\n\n\nI got peanut butter on the paddle.\nI sit in my high chair yesterday.\nFraser, the doll's not in your briefcase.\nFix it with the scissor.\nSue making more coffee for Fraser.\n\n\nHer stages of language development were telescoped into just a few\nmonths."
    },
    {
        "document_id": "0",
        "parent_id": 391,
        "parent_text": "I got peanut butter on the paddle.\nI sit in my high chair yesterday.\nFraser, the doll's not in your briefcase.\nFix it with the scissor.\nSue making more coffee for Fraser.\n\n\nHer stages of language development were telescoped into just a few\nmonths.\n\nMany things are going on during this explosion. Children's sentences are getting not only longer but more complex, with deeper, bushier trees, because the children can embed one constituent inside\nanother. Whereas before they might have said _Give doggie paper_ (a\nthree-branch verb phrase) and _Big doggie_ (a two-branch noun phrase),\nthey now say _Give big doggie paper,_ with the two-branch NP embedded inside the middle branch of three-branch VP. The earlier sentences resembled telegrams, missing unstressed function words like _of,_\n_the, on,_ and _does,_ as well as inflections like _-ed, -ing,_ and _-s._ By the\nthrees, children are using these function words more often than they\nomit them, many in more than ninety percent of the sentences that\nrequire them. A full range of sentence types flower—questions with\nwords like _who, what,_ and _where,_ relative clauses, comparatives, negations, complements, conjunctions, and passives.\n\nThough many—perhaps even most—of the young three-year-old's\nsentences are ungrammatical for one reason or another, we should\nnot judge them too harshly, because there are many things that can\ngo wrong in any single sentence. When researchers focus on one\ngrammatical rule and count how often a child obeys it and how often\nhe or she flouts it, the results are astonishing: for any rule you choose,\nthree-year-olds obey it most of the time. As we have seen, children\n\n\n272 **T H E** **L A N G U A G E** **I N S T I N C T**"
    },
    {
        "document_id": "0",
        "parent_id": 392,
        "parent_text": "272 **T H E** **L A N G U A G E** **I N S T I N C T**\n\n\nrarely scramble word order and, by the age of three, come to supply\nmost inflections and function words in sentences that require them.\nThough our ears perk up when we hear errors like _mens, wents, Can_\n_you broke those?, What he can ride in?,_ _That's a furniture, Button me_\n_the rest,_ and _Going to see kitten,_ the errors occur in only 0.1% to 8%\nof the opportunities for making them; more than 90% of the time,\nthe child is on target. The psychologist Karin Stromswold analyzed\nsentences containing auxiliaries from the speech of thirteen preschoolers. The auxiliary system in English (including words like _can,_\n_should, must, be, have,_ and _do)_ is notorious among grammarians for\nits complexity. There are about twenty-four billion billion logically\npossible combinations of auxiliaries (for instance, _He have might eat;_\n_He did be eating),_ of which only a hundred are grammatical _(He might_\n\n_have eaten; He has been eating)._ Stromswold wanted to count how\nmany times children were seduced by several dozen kinds of tempting\nerrors in the auxiliary system—that is, errors that would be natural\ngeneralizations of the sentence patterns children heard from their\nparents:\n\n\n\n**PATTERN IN ADULT ENGLISH**\n\n\n**He seems happy. —> Does he seem**\n\n**happy?**\n\n\n**He did eat. —> He didn't eat.**\n\n\n**He did eat. —> Did he eat?**\n\n\n**I like going. —> He likes going.**\n\n\n**They want to sleep. —> They**\n\n**wanted to sleep.**\n\n\n**He is happy. —> He is not happy.**\n\n\n**He is happy. —> Is he happy?**\n\n\n\n**ERROR THAT MIGHT TEMPT A CHILD**\n\n\n**He is smiling. —> Does he be smiling?**\n\n**She could go. —> Does she could go?**\n\n\n**He did a few things. —> He didn't a few**\n\n**things.**\n\n**He did a few things. —> Did he a few**\n\n**things?**\n\n\n**I can go. —> He cans go.**\n\n**I am going. —> He ams (or be's) going.**\n\n\n**They are sleeping. —> They are'd (or**\n\n**be'd) sleeping.**\n\n\n**He ate something. —> He ate not**\n\n**something.**\n\n**He ate something. —> Ate he**\n\n**something?**"
    },
    {
        "document_id": "0",
        "parent_id": 393,
        "parent_text": "**ERROR THAT MIGHT TEMPT A CHILD**\n\n\n**He is smiling. —> Does he be smiling?**\n\n**She could go. —> Does she could go?**\n\n\n**He did a few things. —> He didn't a few**\n\n**things.**\n\n**He did a few things. —> Did he a few**\n\n**things?**\n\n\n**I can go. —> He cans go.**\n\n**I am going. —> He ams (or be's) going.**\n\n\n**They are sleeping. —> They are'd (or**\n\n**be'd) sleeping.**\n\n\n**He ate something. —> He ate not**\n\n**something.**\n\n**He ate something. —> Ate he**\n\n**something?**\n\n\n\nFor virtually all of these patterns, she found _no_ errors among the\n66,000 sentences in which they could have occurred.\n\n\nBaby Born Talking—Describes Heaven 273\n\n\nThe three-year-old child is grammatically correct in quality, not\njust quantity. In earlier chapters we learned of experiments showing\nthat children's movement rules are structure-dependent (\"Ask Jabba\nif the boy who is unhappy is watching Mickey Mouse\") and showing\nthat their morphological systems are organized into layers of roots,\nstems, and inflections (\"This monster likes to eat rats; what do you\ncall him?\"). Children also seem fully prepared for the Babel of languages they may face: they swiftly acquire free word order, SOV and\nVSO orders, rich systems of case and agreement, strings of agglutinated suffixes, ergative case marking, or whatever else their language\nthrows at them, with no lag relative to their English-speaking counterparts. Languages with grammatical gender like French and German\nare the bane of the Berlitz student. In his essay \"The Horrors of the\nGerman Language,\" Mark Twain noted that \"a tree is male, its buds\nare female, its leaves are neuter; horses are sexless, dogs are male,\ncats are female—tomcats included.\" He translated a conversation in\na German Sunday school book as follows:\n\n\nGretchen: Wilhelm, where is the turnip?\nWilhelm: She has gone to the kitchen.\nGretchen: Where is the accomplished and beautiful English\nmaiden?\nWilhelm: It has gone to the opera."
    },
    {
        "document_id": "0",
        "parent_id": 394,
        "parent_text": "Gretchen: Wilhelm, where is the turnip?\nWilhelm: She has gone to the kitchen.\nGretchen: Where is the accomplished and beautiful English\nmaiden?\nWilhelm: It has gone to the opera.\n\n\nBut little children learning German (and other languages with gender)\nare not horrified; they acquire gender marking quickly, make few\nerrors, and never use the association with maleness and femaleness\nas a false criterion. It is safe to say that except for constructions that\nare rare, used predominantly in written language, or mentally taxing\neven to an adult (like _The horse that the elephant tickled kissed the_\n_pig),_ all languages are acquired, with equal ease, before the child turns\nfour.\n\nThe errors children do make are rarely random garbage. Often the\nerrors follow the logic of grammar so beautifully that the puzzle is\nnot why the children make the errors, but why they sound like errors\nto adult ears at all. Let me give you two examples that I have studied\nin great detail.\n\nPerhaps the most conspicuous childhood error is to overgeneralize—\nthe child puts a regular suffix, like the plural **-s** or the past tense _-ed._\n\n\n274 THE LANGUAGE INSTINCT\n\n\nonto a word that forms its plural or its past tense in an irregular way.\nThus the child says _tooths_ and _mouses_ and comes up with verb forms\nlike these:\n\n\nMy teacher holded the baby rabbits and we patted them.\nHey, Horton heared a Who.\nI finded Renee.\nI love cut-upped egg.\nOnce upon a time a alligator was eating a dinosaur and the\ndinosaur was eating the alligator and the dinosaur was\neaten by the alligator and the alligator goed kerplunk."
    },
    {
        "document_id": "0",
        "parent_id": 395,
        "parent_text": "274 THE LANGUAGE INSTINCT\n\n\nonto a word that forms its plural or its past tense in an irregular way.\nThus the child says _tooths_ and _mouses_ and comes up with verb forms\nlike these:\n\n\nMy teacher holded the baby rabbits and we patted them.\nHey, Horton heared a Who.\nI finded Renee.\nI love cut-upped egg.\nOnce upon a time a alligator was eating a dinosaur and the\ndinosaur was eating the alligator and the dinosaur was\neaten by the alligator and the alligator goed kerplunk.\n\n\nThese forms sound wrong to us because English contains about 180\nirregular verbs like _held, heard, cut,_ and _went_ —many inherited from\nProto-Indo-European!—whose past-tense forms cannot be predicted\nby rule but have to be memorized by rote. Morphology is organized\nso that whenever a verb has an idiosyncratic form listed in the mental\ndictionary, the regular _-ed_ rule is blocked: _goed_ sounds ungrammatical\nbecause it is blocked by _went._ Elsewhere, the regular rule applies\nfreely."
    },
    {
        "document_id": "0",
        "parent_id": 396,
        "parent_text": "These forms sound wrong to us because English contains about 180\nirregular verbs like _held, heard, cut,_ and _went_ —many inherited from\nProto-Indo-European!—whose past-tense forms cannot be predicted\nby rule but have to be memorized by rote. Morphology is organized\nso that whenever a verb has an idiosyncratic form listed in the mental\ndictionary, the regular _-ed_ rule is blocked: _goed_ sounds ungrammatical\nbecause it is blocked by _went._ Elsewhere, the regular rule applies\nfreely.\n\nSo why do children make this kind of error? There is a simple\nexplanation. Since irregular forms have to be memorized and memory\nis fallible, any time the child tries to use a sentence in the past tense\nwith an irregular verb but cannot summon its past-tense form from\nmemory, the regular rule fills the vacuum. If the child wants to use\nthe past tense of _hold_ but cannot dredge up _held,_ the regular rule,\napplying by default, marks it as _holded._ We know fallible memory is\nthe cause of these errors because the irregular verbs that are used the\nleast often by parents _(drank_ and _knew,_ for instance) are the ones\ntheir children err on the most; for the more common verbs, children\nare correct most of the time. The same thing happens to adults: lowerfrequency, less-well-remembered irregular forms like _trod, strove,_\n_dwelt, rent, slew,_ and _smote_ sound odd to modern American ears and\nare likely to be regularized to _treaded, strived,_ _dwelled,_ _rended, slayed,_\nand _smited._ Since it's we grownups who are forgetting the irregular\npast, we get to declare that the forms with _-ed_ are not errors! Indeed,\nover the centuries many of these conversions have become permanent.\nOld English and Middle English had about twice as many irregular\nverbs as Modern English; if Chaucer were here today, he would tell\n\n\nBaby Born Talking—Describes Heaven 275"
    },
    {
        "document_id": "0",
        "parent_id": 397,
        "parent_text": "Baby Born Talking—Describes Heaven 275\n\n\nyou that the past tenses of _to chide, to geld, to abide,_ and _to cleave_ are\n_chid, gelt, abode,_ and _clove._ As time passes, verbs can wane in popularity, and one can imagine a time when, say, the verb _to geld_ had slipped\nso far that a majority of adults could have lived their lives seldom\nhaving heard its past-tense form _gelt._ When pressed, they would have\nused _gelded;_ the verb had become regular for them and all subsequent\ngenerations. The psychological process is no different from what\nhappens when a young child has lived his or her brief life seldom\nhaving heard the past-tense form _built_ and, when pressed, comes up\nwith _builded._ The only difference is that the child is surrounded by\ngrownups who are still using _built._ As the child lives longer and hears\n_built_ more and more times, the mental dictionary entry for _built_\nbecomes stronger and it comes to mind more and more readily,\nturning off the \"add _-ed\"_ rule each time it does.\n\nHere is another lovely set of examples of childhood grammatical\nlogic, discovered by the psychologist Melissa Bowerman:\n\n\nGo me to the bathroom before you go to bed.\nThe tiger will come and eat David and then he will be died\n\nand I won't have a little brother any more.\nI want you to take me a camel ride over your shoulders into\n\nmy room.\nBe a hand up your nose.\nDon't giggle me!\nYawny Baby—you can push her mouth open to drink her.\n\n\nThese are examples of the causative rule, found in English and many\nother languages, which takes an intransitive verb meaning \"to do\nsomething\" and converts it to a transitive verb meaning \"to cause to\ndo something\":\n\n\nThe butter melted. —> Sally melted the butter.\nThe ball bounced. —> Hiram bounced the ball.\nThe horse raced past the barn. —> The jockey raced the\nhorse past the barn.\n\n\nThe causative rule can apply to some verbs but not others; occasionally children apply it too zealously. But it is not easy, even for a\nlinguist, to say why a ball can bounce or be bounced, and a horse can"
    },
    {
        "document_id": "0",
        "parent_id": 398,
        "parent_text": "The butter melted. —> Sally melted the butter.\nThe ball bounced. —> Hiram bounced the ball.\nThe horse raced past the barn. —> The jockey raced the\nhorse past the barn.\n\n\nThe causative rule can apply to some verbs but not others; occasionally children apply it too zealously. But it is not easy, even for a\nlinguist, to say why a ball can bounce or be bounced, and a horse can\n\n\n276 THE LANGUAGE INSTINCT\n\n\nrace or be raced, but a brother can only die, not be died, and a girl\ncan only giggle, not be giggled. Only a few kinds of verbs can easily\nundergo the rule: verbs referring to a change of the physical state of\nan object, like _melt_ and _break,_ verbs referring to a manner of motion,\nlike _bounce_ and _slide,_ and verbs referring to an accompanied locomotion, like _race_ and _dance._ Other verbs, like _go_ and _die,_ refuse to\nundergo the rule in English, and verbs involving fully voluntary actions, like _cook_ and _play,_ refuse to undergo the rule in almost every\nlanguage (and children rarely err on them). Most of children's errors\nin English, in fact, would be grammatical in other languages. Englishspeaking adults, like their children, occasionally stretch the envelope\nof the rule:\n\n\nIn 1976 the Parti Quebecois began to deteriorate the health\ncare system.\nSparkle your table with Cape Cod classic glass-ware.\nWell, that decided me.\nThis new golf ball could obsolete many golf courses.\nIf she subscribes us up, she'll get a bonus.\nSunbeam whips out the holes where staling air can hide.\n\n\nSo both children and adults stretch the language a bit to express\ncausation; adults are just a tiny bit more fastidious in which verbs\nthey stretch."
    },
    {
        "document_id": "0",
        "parent_id": 399,
        "parent_text": "In 1976 the Parti Quebecois began to deteriorate the health\ncare system.\nSparkle your table with Cape Cod classic glass-ware.\nWell, that decided me.\nThis new golf ball could obsolete many golf courses.\nIf she subscribes us up, she'll get a bonus.\nSunbeam whips out the holes where staling air can hide.\n\n\nSo both children and adults stretch the language a bit to express\ncausation; adults are just a tiny bit more fastidious in which verbs\nthey stretch.\n\n\nThe three-year-old, then, is a grammatical genius—master of most\nconstructions, obeying rules far more often than flouting them, respecting language universals, erring in sensible, adultlike ways, and\navoiding many kinds of errors altogether. How do they do it? Children\nof this age are notably incompetent at most other activities. We won't\nlet them drive, vote, or go to school, and they can be flummoxed by\nno-brainer tasks like sorting beads in order of size, reasoning whether\na person could be aware of an event that took place while the person\nwas out of the room, and knowing that the volume of a liquid does\nnot change when it is poured from a short, wide glass into a tall,\nnarrow one. So they are not doing it by the sheer power of their\noverall acumen. Nor could they be imitating what they hear, or else\nthey would never say _goed_ or _Don't giggle me._ It is plausible that the\n\n\nBaby Born Talking—Describes Heaven 277\n\n\nbasic organization of grammar is wired into the child's brain, but they\nstill must reconstruct the nuances of English or Kivunjo or Ainu. So\nhow does experience interact with wiring to give a three-year-old the\ngrammar of a particular language?"
    },
    {
        "document_id": "0",
        "parent_id": 400,
        "parent_text": "We know that this experience must include, at a minimum, the\nspeech of other human beings. For several thousand years thinkers\nhave speculated about what would happen to infants deprived of\nspeech input. In the seventh century B.C., according to the historian\nHerodotus, King Psamtik I of Egypt had two infants separated from\ntheir mothers at birth and raised in silence in a shepherd's hut. The\nking's curiosity about the original language of the world allegedly was\nsatisfied two years later when the shepherd heard the infants use a\nword in Phrygian, an Indo-European language of Asia Minor. In\nthe centuries since, there have been many stories about abandoned\nchildren who have grown up in the wild, from Romulus and Remus,\nthe eventual founders of Rome, to Mowgli in Kipling's _The Jungle_\n_Book._ There have also been occasional real-life cases, like Victor, the\nWild Boy of Aveyron (the subject of a lovely film by Francois Truffaut), and, in the twentieth century, Kamala, Amala, and Ramu from\nIndia. Legend has these children raised by bears or wolves, depending\non which one has the greater affinity to humans in the prevailing\nmythology of the region, and this scenario is repeated as fact in many\ntextbooks, but I am skeptical. (In a Darwinian animal kingdom it\nwould be a spectacularly stupid bear that when faced with the good\nfortune of a baby in its lair would rear it rather than eat it. Though\nsome species can be fooled by foster offspring, like birds by cuckoos,\nbears and wolves are predators of young mammals and are unlikely\nto be so gullible.) Occasionally other modern children have grown\nup wild because depraved parents have raised them silently in dark\nrooms and attics. The outcome is always the same: the children are\nmute, and often remain so. Whatever innate grammatical abilities\nthere are, they are too schematic to generate speech, words, and\ngrammatical constructions on their own."
    },
    {
        "document_id": "0",
        "parent_id": 401,
        "parent_text": "The muteness of wild children in one sense emphasizes the role of\nnurture over nature in language development, but I think we gain\nmore insight by thinking around that tired dichotomy. If Victor or\nKamala had run out of the woods speaking fluent Phrygian or ProtoWorld, who could they have talked to? As I suggested in the preceding chapter, even if the genes themselves specify the basic design of\n\n\n278 THE LANGUAGE INSTINCT\n\n\nlanguage, they might have to store the specifics of language in the\nenvironment, to ensure that a person's language is synchronized with\neveryone else's despite the genetic uniqueness of every individual. In\nthis sense, language is like another quintessentially social activity.\nJames Thurber and E. B. White once wrote:\n\n\nThere is a very good reason why the erotic side of Man has called\nforth so much more discussion lately than has his appetite for food.\nThe reason is this: that while the urge to eat is a personal matter\nwhich concerns no one but the person hungry (or, as the German\nhas it, _der hungrig Mensch),_ the sex urge involves, for its true expression, another individual. It is this \"other individual\" that causes all\nthe trouble."
    },
    {
        "document_id": "0",
        "parent_id": 402,
        "parent_text": "There is a very good reason why the erotic side of Man has called\nforth so much more discussion lately than has his appetite for food.\nThe reason is this: that while the urge to eat is a personal matter\nwhich concerns no one but the person hungry (or, as the German\nhas it, _der hungrig Mensch),_ the sex urge involves, for its true expression, another individual. It is this \"other individual\" that causes all\nthe trouble.\n\n\nThough speech input is necessary for speech development, a mere\nsoundtrack is not sufficient. Deaf parents of hearing children were\nonce advised to have the children watch a lot of television. In no case\ndid the children learn English. Without already knowing the language,\nit is difficult for a child to figure out what the characters in those odd,\nunresponsive televised worlds are talking about. Live human speakers\ntend to talk about the here and now in the presence of children; the\nchild can be more of a mind-reader, guessing what the speaker might\nmean, especially if the child already knows many content words.\nIndeed, if you are given a translation of the content words in parents'\nspeech to children in some language whose grammar you do not\nknow, it is quite easy to infer what the parents meant. If children can\ninfer parents' meanings, they do not have to be pure cryptographers,\ntrying to crack a code from the statistical structure of the transmissions. They can be a bit more like the archeologists with the Rosetta\nStone, who had both a passage from an unknown language and its\ntranslation in a known one. For the child, the unknown language is\nEnglish (or Japanese or Inslekampx or Arabic); the known one is\nmentalese."
    },
    {
        "document_id": "0",
        "parent_id": 403,
        "parent_text": "Another reason why television soundtracks might be insufficient is\nthat they are not in Motherese. Compared with conversations among\nadults, parents' speech to children is slower, more exaggerated in\npitch, more directed to the here and now, and more grammatical (it\nis literally 99 and 44/100ths percent pure, according to one estimate).\nSurely this makes Motherese easier to learn from than the kind of\n\n\n**Baby Born Talking—Describes Heaven** 279\n\n\nelliptical, fragmentary conversation we saw in the Watergate transcripts. But as we discovered in Chapter 2, Motherese is not an\nindispensable curriculum of Language-Made-Simple lessons. In some\ncultures, parents do not talk to their children until the children are\ncapable of keeping up their end of the conversation (though other\nchildren might talk to them). Furthermore, Motherese is _not_ grammatically simple. That impression is an illusion; grammar is so instinctive\nthat we do not appreciate which constructions are complex until we\ntry to work out the rules behind them. Motherese is riddled with\nquestions containing _who, what,_ and _where,_ which are among the\nmost complicated constructions in English. For example, to assemble\nthe \"simple\" question _What did he eat?,_ based on _He ate what,_ one\nmust move the _what_ to the beginning of the sentence, leaving a\n\"trace\" that indicates its semantic role of \"thing eaten,\" insert the\nmeaningless auxiliary _do,_ make sure that the _do_ is in the tense appropriate to the verb, in this case _did,_ convert the verb to the infinitive\nform _eat,_ and invert the position of subject and auxiliary from the\nnormal _He did_ to the interrogative _Did he._ No mercifully designed\nlanguage curriculum would use these sentences in Lesson 1, but that\nis just what mothers do when speaking to their babies."
    },
    {
        "document_id": "0",
        "parent_id": 404,
        "parent_text": "A better way to think of Motherese is to liken it to the vocalizations\nthat other animals direct to their young. Motherese has interpretable\nmelodies: a rise-and-fall contour for approving, a set of sharp, staccato\nbursts for prohibiting, a rise pattern for directing attention, and\nsmooth, low legato murmurs for comforting. The psychologist Anne\nFernald has shown that these patterns are very widespread across\nlanguage communities, and may be universal. The melodies attract the\nchild's attention, mark the sounds as speech as opposed to stomach\ngrowlings or other noises, distinguish statements, questions, and imperatives, delineate major sentence boundaries, and highlight new\nwords. When given a choice, babies prefer to listen to Motherese\nthan to speech intended for adults.\n\nSurprisingly, though practice is important in training for the gymnastics of speaking, it may be superfluous in learning grammar. For\nvarious neurological reasons children are sometimes unable to articulate, but parents report that their comprehension is excellent. Karin\nStromswold recently tested one such four-year-old. Though he could\nnot speak, he could understand subtle grammatical differences. He\ncould identify which picture showed \"The dog was bitten by the\n\n\n280 THE LANGUAGE INSTINCT\n\n\ncat\" and which showed \"The cat was bitten by the dog.\" He could\ndistinguish pictures that showed \"The dogs chase the rabbit\" and\n\"The dog chases the rabbit.\" The boy also responded appropriately\nwhen Stromswold asked him, \"Show me your room,\" \"Show me your\nsister's room,\" \"Show me your sister's old room,\" \"Show me your\nold room,\" \"Show me your new room,\" \"Show me your sister's new\nroom.\""
    },
    {
        "document_id": "0",
        "parent_id": 405,
        "parent_text": "280 THE LANGUAGE INSTINCT\n\n\ncat\" and which showed \"The cat was bitten by the dog.\" He could\ndistinguish pictures that showed \"The dogs chase the rabbit\" and\n\"The dog chases the rabbit.\" The boy also responded appropriately\nwhen Stromswold asked him, \"Show me your room,\" \"Show me your\nsister's room,\" \"Show me your sister's old room,\" \"Show me your\nold room,\" \"Show me your new room,\" \"Show me your sister's new\nroom.\"\n\nIn fact, it is not surprising that grammar development does not\ndepend on overt practice, because actually saying something aloud,\nas opposed to listening to what other people say, does not provide\nthe child with information about the language he or she is trying to\nlearn. The only conceivable information about grammar that speaking\ncould provide would come from feedback from parents on whether\nthe child's utterance was grammatical and meaningful. If a parent\npunished, corrected, misunderstood, or even reacted differently to a\nchild's ungrammatical sentence, it could in theory inform the child\nthat something in his growing rule system needed to be improved. But\nparents are remarkably unconcerned about their children's grammar;\nthey care about truthfulness and good behavior. Roger Brown divided\nthe sentences of Adam, Eve, and Sarah into grammatical and ungrammatical lists. For each sentence he checked whether the parent had\nat the time expressed approval (like \"Yes, that's good\") or disapproval. The proportion was the same for grammatical sentences and\nungrammatical ones, which means that the parent's response had\ngiven the child no information about grammar. For example:\n\n\nChild: Mamma isn't boy, he a girl.\nMother: That's right.\n\nChild: And Walt Disney comes on Tuesday.\nMother: No, he does not."
    },
    {
        "document_id": "0",
        "parent_id": 406,
        "parent_text": "Child: Mamma isn't boy, he a girl.\nMother: That's right.\n\nChild: And Walt Disney comes on Tuesday.\nMother: No, he does not.\n\n\nBrown also checked whether children might learn about the state of\ntheir grammars by noticing whether they are being understood. He\nlooked at children's well-formed and badly formed questions and\nwhether their parents seemed to have answered them appropriately\n(that is, as if they understood them) or with non sequiturs. Again,\nthere was no correlation; _What you can do?_ may not be English, but\nit is perfectly understandable.\n\n\nBaby Born Talking—Describes Heaven 281\n\n\nIndeed, when fussy parents or meddling experimenters do provide\nchildren with feedback, the children tune it out. The psycholinguist\nMartin Braine once tried for several weeks to stamp out one of his\ndaughter's grammatical errors. Here is the result:\n\n\nChild: Want other one spoon, Daddy.\nFather: You mean, you want T H E O T H E R S P O O N .\nChild: Yes, I want other one spoon, please, Daddy.\nFather: Can you say \"the other spoon\"?\nChild: Other . . . one . . . spoon.\nFather: Say . . . \"other.\"\nChild: Other.\nFather: \"Spoon.\"\nChild: Spoon.\nFather: \"Other . . . Spoon.\"\nChild: Other . . . spoon. Now give me other one spoon?\n\n\nBraine wrote, \"Further tuition is ruled out by her protest, vigorously\nsupported by my wife.\"\n\nAs far as grammar learning goes, the child must be a naturalist,\npassively observing the speech of others, rather than an experimentalist, manipulating stimuli and recording the results. The implications\nare profound. Languages are infinite, childhoods finite. To become\nspeakers, children cannot just memorize; they must leap into the\nlinguistic unknown and generalize to an infinite world of as-yet-unspoken sentences. But there are untold numbers of seductive false\nleaps:\n\n\nmind —> minded; _but not_ find —> finded\nThe ice melted —> He melted the ice; _but not_ David died\n\n—> He died David\nShe seems to be asleep —> She seems asleep; _but not_ She"
    },
    {
        "document_id": "0",
        "parent_id": 407,
        "parent_text": "mind —> minded; _but not_ find —> finded\nThe ice melted —> He melted the ice; _but not_ David died\n\n—> He died David\nShe seems to be asleep —> She seems asleep; _but not_ She\n\nseems to be sleeping —> She seems sleeping\nSheila saw Mary with her best friend's husband —> Who\n\ndid Sheila see Mary with? _but not_ Sheila saw Mary and\nher best friend's husband —> Who did Sheila see Mary\nand?\n\n\nIf children could count on being corrected for making such errors,\nthey could take their chances. But in a world of grammatically oblivi\n\n282 THE LANGUAGE INSTINCT\n\n\nous parents, they must be more cautious—if they ever went too far\nand produced ungrammatical sentences together with the grammatical ones, the world would never tell them they were wrong. They\nwould speak ungrammatically all their lives—though a better way of\nputting it is that that part of the language, the prohibition against the\nsentence types that the child was using, would not last beyond a\nsingle generation. Thus any no-feedback situation presents a difficult\nchallenge to the design of a learning system, and it is of considerable\ninterest to mathematicians, psychologists, and engineers studying\nlearning in general."
    },
    {
        "document_id": "0",
        "parent_id": 408,
        "parent_text": "How is the child designed to cope with the problem? A good start\nwould be to build in the basic organization of grammar, so the child\nwould try out only the kinds of generalizations that are possible in\nthe world's languages. Dead ends like _Who did Sheila see Mary and?,_\nnot grammatical in any language, should not even occur to a child,\nand indeed, no child (or adult) we know of has ever tried it. But this\nis not enough, because the child also has to figure out how far to leap\nin the particular language being acquired, and languages vary: some\nallow many word orders, some only a few; some allow the causative\nrule to apply freely, others to only a few kinds of verb. Therefore a\nwell-designed child, when faced with several choices in how far to\ngeneralize, should, in general, be conservative: start with the smallest\nhypothesis about the language that is consistent with what parents\nsay, then expand it outward as the evidence requires. Studies of\nchildren's language show that by and large that is how they work.\nFor example, children learning English never leap to the conclusion\nthat it is a free-word-order language and speak in all orders like _give_\n\n_doggie paper;_ _give_ _paper_ _doggie,_ _paper_ _doggie_ _give;_ _doggie paper_ _give,_\nand so on. Logically speaking, though, that would be consistent with\nwhat they hear if they were willing to entertain the possibility that\ntheir parents were just taciturn speakers of Korean, Russian, or Swedish, where several orders are possible. But children learning Korean,\nRussian, and Swedish _do_ sometimes err on the side of caution and\nuse only one of the orders allowed in the language, pending further\nevidence.\n\nFurthermore, in cases where children do make errors and recover,\ntheir grammars must have some internal checks and balances, so that\nhearing one kind of sentence can catapult another out of the grammar.\nFor example, if the word-building system is organized so that an\n\n\n**Baby Born Talking—Describes Heaven** 283"
    },
    {
        "document_id": "0",
        "parent_id": 409,
        "parent_text": "Furthermore, in cases where children do make errors and recover,\ntheir grammars must have some internal checks and balances, so that\nhearing one kind of sentence can catapult another out of the grammar.\nFor example, if the word-building system is organized so that an\n\n\n**Baby Born Talking—Describes Heaven** 283\n\n\nirregular form listed in the mental dictionary blocks the application\nof the corresponding rule, hearing _held_ enough times will eventually\ndrive out _holded._\n\n\nThese general conclusions about language learning are interesting,\nbut we would understand them better if we could trace out what\nactually happens from moment to moment in children's minds as\nsentences come in and they try to distill rules from them. Viewed up\nclose, the problem of learning rules is even harder than it appears\nfrom a distance. Imagine a hypothetical child trying to extract patterns\nfrom the following sentences, without any innate guidance as to how\nhuman grammar works:\n\n\nJane eats chicken.\nJane eats fish.\nJane likes fish.\n\n\nAt first glance, patterns jump out. Sentences, the child might conclude, consist of three words: the first must be _Jane,_ the second either\n_eats_ or _likes,_ the third _chicken_ or _fish._ With these micro-rules, the\nchild can already generalize beyond the input, to the brand-new\nsentence _jane likes chicken._ So far, so good. But let's say the next two\nsentences are\n\n\nJane eats slowly.\nJane might fish.\n\n\nThe word _might_ gets added to the list of words that can appear in\nsecond position, and the word _slowly_ is added to the list that can\nappear in third position. But look at the generalizations this would\nallow:\n\n\nJane might slowly.\nJane likes slowly.\nJane might chicken.\n\n\nBad start. The same ambiguity that bedevils language parsing in the\nadult bedevils language acquisition in the child. The moral is that the\n\n\n284 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 410,
        "parent_text": "Jane eats slowly.\nJane might fish.\n\n\nThe word _might_ gets added to the list of words that can appear in\nsecond position, and the word _slowly_ is added to the list that can\nappear in third position. But look at the generalizations this would\nallow:\n\n\nJane might slowly.\nJane likes slowly.\nJane might chicken.\n\n\nBad start. The same ambiguity that bedevils language parsing in the\nadult bedevils language acquisition in the child. The moral is that the\n\n\n284 THE LANGUAGE INSTINCT\n\n\nchild must couch rules in grammatical categories like noun, verb, and\nauxiliary, not in actual words. That way, _fish_ as a noun and _fish_ as a\nverb would be kept separate, and the child would not adulterate the\nnoun rule with instances of verbs and vice versa.\n\nHow might a child assign words into categories like noun and verb?\nClearly, their meanings help. In all languages, words for objects and\npeople are nouns or noun phrases, words for actions and change of\nstate are verbs. (As we saw in Chapter 4, the converse is not true—\nmany nouns, like _destruction,_ do not refer to objects and people, and\nmany verbs, like _interest,_ do not refer to actions or changes of state.)\nSimilarly, words for kinds of paths and places are prepositions, and\nwords for qualities tend to be adjectives. Recall that children's first\nwords refer to objects, actions, directions, and qualities. This is convenient. If children are willing to guess that words for objects are nouns,\nwords for actions are verbs, and so on, they would have a leg up on\nthe rule-learning problem.\n\nBut words are not enough; they must be ordered. Imagine the child\ntrying to figure out what kind of word can occur before the verb\n_bother._ It can't be done:\n\n\nThat dog bothers me. _[dog,_ a noun]\nWhat she wears bothers me. _[wears,_ a verb]\nMusic that is too loud bothers me. _[loud,_ an adjective]\nCheering too loudly bothers me. _[loudly,_ an adverb]\nThe guy she hangs out with bothers me. _[with,_ a preposition]"
    },
    {
        "document_id": "0",
        "parent_id": 411,
        "parent_text": "But words are not enough; they must be ordered. Imagine the child\ntrying to figure out what kind of word can occur before the verb\n_bother._ It can't be done:\n\n\nThat dog bothers me. _[dog,_ a noun]\nWhat she wears bothers me. _[wears,_ a verb]\nMusic that is too loud bothers me. _[loud,_ an adjective]\nCheering too loudly bothers me. _[loudly,_ an adverb]\nThe guy she hangs out with bothers me. _[with,_ a preposition]\n\n\nThe problem is obvious. There _is_ a certain something that must come\nbefore the verb _bother,_ but that something is not a kind of word; it\nis a kind of _phrase,_ a noun phrase. A noun phrase always contains a\nhead noun, but that noun can be followed by all kinds of stuff. So it\nis hopeless to try to learn a language by analyzing sentences word by\nword. The child must look for phrases.\n\nWhat does it mean to look for phrases? A phrase is a group of\nwords. For a sentence of four words, there are eight possible ways to\ngroup the words into phrases: {That} {dog bothers me}; {That dog}\n{bothers me}; {That} {dog bothers} {me}, and so on. For a sentence\nof five words, there are sixteen possible ways; for a sentence of six\nwords, thirty-two ways; for a sentence of _n_ words, _**2n - 1**_ —a big num\n\nBaby Born Talking—Describes Heaven 285\n\n\nber for long sentences. Most of these partitionings would give the\nchild groups of words that would be useless in constructing new\nsentences, such as _wears bothers_ and _cheering too,_ but the child,\nunable to rely on parental feedback, has no way of knowing this.\nOnce again, children cannot attack the language-learning task like a\nlogician free of preconceptions; they need guidance."
    },
    {
        "document_id": "0",
        "parent_id": 412,
        "parent_text": "Baby Born Talking—Describes Heaven 285\n\n\nber for long sentences. Most of these partitionings would give the\nchild groups of words that would be useless in constructing new\nsentences, such as _wears bothers_ and _cheering too,_ but the child,\nunable to rely on parental feedback, has no way of knowing this.\nOnce again, children cannot attack the language-learning task like a\nlogician free of preconceptions; they need guidance.\n\nThis guidance could come from two sources. First, the child could\nassume that parents' speech respects the basic design of human phrase\nstructure: phrases contain heads; role-players are grouped with heads\nin the mini-phrases called X-bars; X-bars are grouped with their\nmodifiers inside X-phrases (noun phrase, verb phrase, and so on); Xphrases can have subjects. To put it crudely, the X-bar theory of\nphrase structure could be innate. Second, since the meanings of\nparents' sentences are usually guessable in context, the child could\nuse the meanings to help set up the right phrase structure. Imagine\nthat a parent says _The big dog ate ice cream._ If the child has previously\nlearned the individual words _big, dog, ate,_ and _ice cream,_ he or she\ncan guess their categories and grow the first twigs of a tree:\n\n\nA N V N\n\n\nthe big dog ate ice cream\n\n\nIn turn, nouns and verbs must belong to noun phrases and verb\nphrases, so the child can posit one for each of these words. And if\nthere is a big dog around, the child can guess that _the_ and _big_ modify\n_dog,_ and connect them properly inside the noun phrase:\n\n\nIf the child knows that the dog just ate ice cream, he or she can also\nguess that _ice cream_ and _dog_ are role-players for the verb _eat. Dog_ is\na special kind of role-player, because it is the causal agent of the\naction and the topic of the sentence; hence it is likely to be the subject\n\n\n286 THE LANGUAGE INSTINCT\n\n\nof the sentence and therefore attaches to the \" S . \" A tree for the\nsentence has been completed:\n\n\n**the** **big** **dog** **ate** **ice cream**"
    },
    {
        "document_id": "0",
        "parent_id": 413,
        "parent_text": "If the child knows that the dog just ate ice cream, he or she can also\nguess that _ice cream_ and _dog_ are role-players for the verb _eat. Dog_ is\na special kind of role-player, because it is the causal agent of the\naction and the topic of the sentence; hence it is likely to be the subject\n\n\n286 THE LANGUAGE INSTINCT\n\n\nof the sentence and therefore attaches to the \" S . \" A tree for the\nsentence has been completed:\n\n\n**the** **big** **dog** **ate** **ice cream**\n\n\nThe rules and dictionary entries can be peeled off the tree:\n\n\nS NP VP\nNP —> (det) (A) N\nVP —> V (NP)\ndog: N\nice cream: N\nate: V; eater = subject, thing eaten = object\nthe: det\nbig: A\n\n\nThis hypothetical time-lapse photography of the mind of a child at\nwork shows how a child, if suitably equipped, could learn three rules\nand five words from a single sentence in context.\n\nThe use of part-of-speech categories, X-bar phrase structure, and\nmeaning guessed from context is amazingly powerful, but amazing\npower is what a real-life child needs to learn grammar so quickly,\nespecially without parental feedback. There are many benefits to using\na small number of innate categories like N and V to organize incoming\nspeech. By calling both the subject and object phrases \"NP,\" rather\nthan, say, Phrase #1 and Phrase #2, the child automatically can apply\nhard-won knowledge about nouns in subject position to nouns in\nobject position, and vice versa. For example, our model child can\nalready generalize and use _dog_ as an object without having heard an\nadult do so, and the child tacitly knows that adjectives precede nouns\nnot just in subjects but in objects, again without direct evidence. The\n\n\nBaby Born Talking—Describes Heaven 287"
    },
    {
        "document_id": "0",
        "parent_id": 414,
        "parent_text": "Baby Born Talking—Describes Heaven 287\n\n\nchild knows that if more than one _dog_ is _dogs_ in subject position,\nmore than one _dog_ is _dogs_ in object position. I conservatively estimate\nthat English allows about eight possible phrasemates of a head noun\ninside a noun phrase, such as _John's_ dog; dogs _in the park; big_ dogs;\ndogs _that I like,_ and so on. In turn, there are about eight places in a\nsentence where the whole noun phrase can go, such as _Dog_ bites man;\nMan bites _dog; A dog's_ life; Give the boy _a dog;_ Talk to _the dog;_ and\nso on. There are three ways to inflect a noun: _dog, dogs, dog's._ And\na typical child by the time he or she is in high school has learned\nsomething like twenty thousand nouns. If children had to learn all\nthe combinations separately, they would need to listen to about 140\nmillion different sentences. At a rate of a sentence every ten seconds,\nten hours a day, it would take over a century. But by unconsciously\nlabeling all nouns as \"N\" and all noun phrases as \"NP,\" the child\nhas only to hear about twenty-five different kinds of noun phrase and\nlearn the nouns one by one, and the millions of possible combinations\nbecome available automatically."
    },
    {
        "document_id": "0",
        "parent_id": 415,
        "parent_text": "Indeed, if children are blinkered to look for only a small number\nof phrase types, they automatically gain the ability to produce an\ninfinite number of sentences, one of the quintessential properties of\nhuman grammar. Take the phrase _the tree in the park._ If the child\nmentally labels _the park_ as an NP and also labels _the tree in the park_\nas an NP, the resulting rules generate an NP inside a PP inside an\nNP—a loop that can be iterated indefinitely, as in _the tree near the_\n_ledge by the lake in the park in the city in the east of the state_ . . . In\ncontrast, a child who was free to label _in the park_ as one kind of\nphrase and _the tree in the park_ as another kind would be deprived of\nthe insight that the phrase contains an example of itself. The child\nwould be limited to reproducing that phrase structure alone. Mental\nflexibility confines children; innate constraints set them free.\n\nOnce a rudimentary but roughly accurate analysis of sentence structure has been set up, the rest of the language can fall into place.\nAbstract words—nouns that do not refer to objects and people, for\nexample—can be learned by paying attention to where they sit inside\na sentence. Since _situation_ in _The situation justifies drastic measures_\noccurs inside a phrase in NP position, it must be a noun. If the\nlanguage allows phrases to be scrambled around the sentence, like\nLatin or Warlpiri, the child can discover this feature upon coming\nacross a word that cannot be connected to a tree in the expected\n\n\n288 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 416,
        "parent_text": "288 THE LANGUAGE INSTINCT\n\n\nplace without crossing branches. The child, constrained by Universal\nGrammar, knows what to focus on in decoding case and agreement\ninflections: a noun's inflection might depend on whether it is in\nsubject or object position; a verb's might depend on tense, aspect,\nand the number, person, and gender of its subject and object. If the\nhypotheses were not confined to this small set, the task of learning\ninflections would be intractable—logically speaking, an inflection\n_could_ depend on whether the third word in the sentence referred to\na reddish or a bluish object, whether the last word was long or short,\nwhether the sentence was being uttered indoors or outdoors, and\nbillions of other fruitless possibilities that a grammatically unfettered\nchild would have to test for.\n\n\nWe can now return to the puzzle that opened the chapter: Why\naren't babies born talking? We know that part of the answer is\nthat babies have to listen to themselves to learn how to work their\narticulators, and have to listen to their elders to learn communal\nphonemes, words, and phrase orders. Some of these acquisitions\ndepend on other ones, forcing development to proceed in a sequence:\nphonemes before words, words before sentences. But any mental\nmechanism powerful enough to learn these things could probably do\nso with a few weeks or months of input. Why does the sequence have\nto take three years? Could it be any faster?\n\nPerhaps not. Complicated machines take time to assemble, and\nhuman infants may be expelled from the womb before their brains\nare complete. A human, after all, is an animal with a ludicrously large\nhead, and a woman's pelvis, through which it must pass, can be only\nso big. If human beings stayed in the womb for the proportion of\ntheir life cycle that we would expect based on extrapolation from\nother primates, they would be born at the age of eighteen months.\nThat is the age at which babies in fact begin to put words together.\nIn one sense, then babies _are_ born talking!"
    },
    {
        "document_id": "0",
        "parent_id": 417,
        "parent_text": "And we know that babies' brains do change considerably after\nbirth. Before birth, virtually all the neurons (nerve cells) are formed,\nand they migrate into their proper locations in the brain. But head\nsize, brain weight, and thickness of the cerebral cortex (gray matter),\nwhere the synapses (junctions) subserving mental computation are\nfound, continue to increase rapidly in the year after birth. Long\n\nBaby Born Talking—Describes Heaven 2 89\n\n\ndistance connections (white matter) are not complete until nine\nmonths, and they continue to grow their speed-inducing myelin insulation throughout childhood. Synapses continue to develop, peaking\nin number between nine months and two years (depending on the\nbrain region), at which point the child has fifty percent more synapses\nthan the adult! Metabolic activity in the brain reaches adult levels by\nnine to ten months, and soon exceeds it, peaking around the age of\nfour. The brain is sculpted not only by adding neural material but by\nchipping it away. Massive numbers of neurons die in utero, and the\ndying continues during the first two years before leveling off at age\nseven. Synapses wither from the age of two through the rest of childhood and into adolescence, when the brain's metabolic rate falls\nback to adult levels. Language development, then, could be on a\nmaturational timetable, like teeth. Perhaps linguistic accomplishments like babbling, first words, and grammar require minimum\nlevels of brain size, long-distance connections, and extra synapses,\nparticularly in the language centers of the brain (which we will explore\nin the next chapter).\n\nSo language seems to develop about as quickly as the growing brain\ncan handle it. What's the rush? Why is language installed so quickly,\nwhile the rest of the child's mental development seems to proceed at\na more leisurely pace? In a book on evolutionary theory often considered to be one of the most important since Darwin's, the biologist\nGeorge Williams speculates:"
    },
    {
        "document_id": "0",
        "parent_id": 418,
        "parent_text": "So language seems to develop about as quickly as the growing brain\ncan handle it. What's the rush? Why is language installed so quickly,\nwhile the rest of the child's mental development seems to proceed at\na more leisurely pace? In a book on evolutionary theory often considered to be one of the most important since Darwin's, the biologist\nGeorge Williams speculates:\n\n\nWe might imagine that Hans and Fritz Faustkeil are told on Monday, \"Don't go near the water,\" and that both go wading and are\nspanked for it. On Tuesday they are told, \"Don't play near the fire,\"\nand again they disobey and are spanked. On Wednesday they are\ntold, \"Don't tease the saber-tooth.\" This time Hans understands\nthe message, and he bears firmly in mind the consequences of\ndisobedience. He prudently avoids the saber-tooth and escapes the\nspanking. Poor Fritz escapes the spanking, too, but for a very\ndifferent reason.\n\nEven today accidental death is an important cause of mortality\nin early life, and parents who consistently spare the rod in other\nmatters may be moved to violence when a child plays with electric\nwires or chases a ball into the street. Many of the accidental deaths\nof small children would probably have been avoided if the victims\n\n\n290 THE LANGUAGE INSTINCT\n\n\nhad understood and remembered verbal instructions and had been\ncapable of effectively substituting verbal symbols for real experience. This might well have been true also under primitive conditions.\n\n\nPerhaps it is no coincidence that the vocabulary spurt and beginnings\nof grammar follow closely on the heels of the baby, quite literally—\nthe ability to walk unaccompanied appears around fifteen months."
    },
    {
        "document_id": "0",
        "parent_id": 419,
        "parent_text": "290 THE LANGUAGE INSTINCT\n\n\nhad understood and remembered verbal instructions and had been\ncapable of effectively substituting verbal symbols for real experience. This might well have been true also under primitive conditions.\n\n\nPerhaps it is no coincidence that the vocabulary spurt and beginnings\nof grammar follow closely on the heels of the baby, quite literally—\nthe ability to walk unaccompanied appears around fifteen months.\n\n\nLet's complete our exploration of the linguistic life cycle. Everyone\nknows that it is much more difficult to learn a second language in\nadulthood than a first language in childhood. Most adults never master a foreign language, especially the phonology—hence the ubiquitous foreign accent. Their development often \"fossilizes\" into\npermanent error patterns that no teaching or correction can undo.\nOf course, there are great individual differences, which depend on\neffort, attitudes, amount of exposure, quality of teaching, and plain\ntalent, but there seems to be a cap even for the best adults in the best\ncircumstances. The actress Meryl Streep is renowned in the United\nStates for her seemingly convincing accents, but I am told that in\nEngland, her British accent in _Plenty_ was considered rather awful,\nand that her Australian accent in the movie about the dingo that ate\nthe baby didn't go over too well down there, either.\n\nMany explanations have been advanced for children's superiority:\nthey exploit Motherese, make errors unself-consciously, are more\nmotivated to communicate, like to conform, are not xenophobic or\nset in their ways, and have no first language to interfere. But some of\nthese accounts are unlikely, based on what we know about how\nlanguage acquisition works. For example, children can learn a language without standard Motherese, they make few errors, and they\nget no feedback for the errors they do make. In any case, recent\nevidence is calling these social and motivational explanations into\ndoubt. Holding every other factor constant, a key factor stands out:\nsheer age."
    },
    {
        "document_id": "0",
        "parent_id": 420,
        "parent_text": "People who immigrate after puberty provide some of the most\ncompelling examples, even the apparent success stories. A few highly\ntalented and motivated individuals master much of the grammar of a\n\n\nBaby Born Talking—Describes Heaven 291\n\n\nforeign language, but not its sound pattern. Henry Kissinger, who\nimmigrated to the United States as a teenager, retains a frequently\nsatirized German accent; his brother, a few years younger, has no\naccent. Ukrainian-born Joseph Conrad, whose first language was Polish, is considered one of the best writers in English in this century,\nbut his accent was so thick his friends could barely understand him.\nEven the adults who succeed at grammar often depend on the conscious exercise of their considerable intellects, unlike children, to\nwhom language acquisition just happens. Vladimir Nabokov, another\nbrilliant writer in English, refused to lecture or be interviewed extemporaneously, insisting on writing out every word beforehand with the\nhelp of dictionaries and grammars. As he modestly explained, \"I\nthink like a genius, I write like a distinguished author, and I speak\nlike a child.\" And he had had the benefit of being raised in part by\nan English-speaking nanny."
    },
    {
        "document_id": "0",
        "parent_id": 421,
        "parent_text": "More systematic evidence comes from the psychologist Elissa Newport and her colleagues. They tested Korean- and Chinese-born students and faculty at the University of Illinois who had spent at least\nten years in the United States. The immigrants were given a list of\n276 simple English sentences, half of them containing some grammatical error like _The farmer bought two pig_ or _The little boy is speak to_\n_a policeman._ (The errors were errors with respect to the spoken\nvernacular, not \"proper\" written prose.) The immigrants who came\nto the United States between the ages of three and seven performed\nidentically to American-born students. Those who arrived between\nthe ages of eight and fifteen did increasingly worse the later they\narrived, and those who arrived between seventeen and thirty-nine did\nthe worst of all, and showed huge variability unrelated to their age\nof arrival.\n\nWhat about acquisition of the mother tongue? Cases in which\npeople make it to puberty without having learned a language are rare,\nbut they all point to the same conclusion. We saw in Chapter 2 that\ndeaf people who are not exposed to sign language until adulthood\nnever do as well as those who learned it as children. Among the wolfchildren who are found in the woods or in the homes of psychotic\nparents after puberty, some develop words, and some, like \"Genie,\"\ndiscovered in 1970 at the age of thirteen and a half in a Los Angeles\nsuburb, learn to produce immature, pidgin-like sentences:\n\n\n292 THE LANGUAGE INSTINCT\n\n\nMike paint.\nApplesauce buy store.\nNeal come happy; Neal not come sad.\nGenie have Momma have baby grow up.\nI like elephant eat peanut.\n\n\nBut they are permanently incapable of mastering the full grammar of\nthe language. In contrast, one child, Isabelle, was six and a half when\nshe and her mute, brain-damaged mother escaped from the silent\nimprisonment of her grandfather's house. A year and a half later she\nhad acquired fifteen hundred to two thousand words and produced\ncomplex grammatical sentences like"
    },
    {
        "document_id": "0",
        "parent_id": 422,
        "parent_text": "Mike paint.\nApplesauce buy store.\nNeal come happy; Neal not come sad.\nGenie have Momma have baby grow up.\nI like elephant eat peanut.\n\n\nBut they are permanently incapable of mastering the full grammar of\nthe language. In contrast, one child, Isabelle, was six and a half when\nshe and her mute, brain-damaged mother escaped from the silent\nimprisonment of her grandfather's house. A year and a half later she\nhad acquired fifteen hundred to two thousand words and produced\ncomplex grammatical sentences like\n\n\nWhy does the paste come out if one upsets the jar?\nWhat did Miss Mason say when you told her I cleaned my\nclassroom?\nDo you go to Miss Mason's school at the university?\n\n\nObviously she was well on her way to learning English as successfully\nas anyone else; the tender age at which she began made all the\ndifference.\n\nWith unsuccessful learners like Genie, there is always a suspicion\nthat the sensory deprivation and emotional scars sustained during the\nhorrific confinement somehow interfered with their ability to learn.\nBut recently a striking case of first language acquistion in a normal\nadult has surfaced. \"Chelsea\" was born deaf in a remote town in\nnorthern California. A series of inept doctors and clinicians diagnosed\nher as retarded or emotionally disturbed without recognizing her\ndeafness (a common fate for many deaf children in the past). She\ngrew up shy, dependent, and languageless but otherwise emotionally\nand neurologically normal, sheltered by a loving family who never\nbelieved she was retarded. At the age of thirty-one she was referred\nto an astonished neurologist, who had her fitted with hearing aids\nthat improved her hearing to near-normal levels. Intensive therapy\nby a rehabilitative team has brought her to a point where she scores\nat a ten-year-old level on intelligence tests, knows two thousand\nwords, holds a job in a veterinarian's office, reads, writes, communi\n\nBaby Born Talking—Describes Heaven 293"
    },
    {
        "document_id": "0",
        "parent_id": 423,
        "parent_text": "Baby Born Talking—Describes Heaven 293\n\n\ncates, and has become social and independent. She has only one\nproblem, which becomes apparent as soon as she opens her mouth:\n\n\nThe small a the hat.\nRichard eat peppers hot.\nOrange Tim car in.\nBanana the eat.\nI Wanda be drive come.\nThe boat sits water on.\nBreakfast eating girl.\nCombing hair the boy.\nThe woman is bus the going.\n\nThe girl is cone the ice cream shopping buying the man.\n\n\nDespite intensive training and impressive gains in other spheres, Chelsea's syntax is bizarre.\n\nIn sum, acquisition of a normal language is guaranteed for children\nup to the age of six, is steadily compromised from then until shortly\nafter puberty, and is rare thereafter. Maturational changes in the\nbrain, such as the decline in metabolic rate and number of neurons\nduring the early school-age years, and the bottoming out of the number of synapses and metabolic rate around puberty, are plausible\ncauses. We do know that the language-learning circuitry of the brain\nis more plastic in childhood; children learn or recover language when\nthe left hemisphere of the brain is damaged or even surgically removed\n(though not quite at normal levels), but comparable damage in an\nadult usually leads to permanent aphasia.\n\n\"Critical periods\" for specific kinds of learning are common in\nthe animal kingdom. There are windows in development in which\nducklings learn to follow large moving objects, kittens' visual neurons\nbecome tuned to vertical, horizontal, and oblique lines, and whitecrowned sparrows duplicate their fathers' songs. But why should\nlearning ever decline and fall? Why throw away such a useful skill?\n\nCritical periods seem paradoxical, but only because most of us\nhave an incorrect understanding of the biology of organisms' life\nhistories. We tend to think that genes are like the blueprints in a\nfactory and organisms are like the appliances that the factory turns\nout. Our picture is that during gestation, when the organism is built,\n\n\n294 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 424,
        "parent_text": "Critical periods seem paradoxical, but only because most of us\nhave an incorrect understanding of the biology of organisms' life\nhistories. We tend to think that genes are like the blueprints in a\nfactory and organisms are like the appliances that the factory turns\nout. Our picture is that during gestation, when the organism is built,\n\n\n294 THE LANGUAGE INSTINCT\n\n\nit is permanently fitted with the parts it will carry throughout its\nlifetime. Children and teenagers and adults and old people have arms\nand legs and a heart because arms and legs and a heart were part of\nthe infant's factory-installed equipment. When a part vanishes for no\nreason, we are puzzled.\n\nBut now try to think of the life cycle in a different way. Imagine\nthat what the genes control is not a factory sending appliances into\nthe world, but a machine shop in a thrifty theater company to which\nprops and sets and materials periodically return to be dismantled\nand reassembled for the next production. At any point, different\ncontraptions can come out of the shop, depending on current need.\nThe most obvious biological illustration is metamorphosis. In insects,\nthe genes build an eating machine, let it grow, build a container\naround it, dissolve it into a puddle of nutrients, and recycle them into\na breeding machine. Even in humans, the sucking reflex disappears,\nteeth erupt twice, and a suite of secondary sexual characteristics\nemerge in a maturational schedule. Now complete the mental backflip. Think of metamorphosis and maturational emergence not as the\nexception but as the rule. The genes, shaped by natural selection,\ncontrol bodies throughout the life span; designs hang around during\nthe times of life that they are useful, not before or after. The reason\nthat we have arms at age sixty is not because they have stuck around\nsince birth, but because arms are as useful to a sixty-year-old as they\nwere to a baby."
    },
    {
        "document_id": "0",
        "parent_id": 425,
        "parent_text": "This inversion (an exaggeration, but a useful one) flips the criticalperiod question with it. The question is no longer \"Why does a\nlearning ability disappear?\" but \"When is the learning ability\nneeded?\" We have already noted that the answer might be \"As early\nas possible,\" to allow the benefits of language to be enjoyed for as\nmuch of life as possible. Now note that learning a language—as\nopposed to _using_ a language—is perfectly useful as a one-shot skill.\nOnce the details of the local language have been acquired from the\nsurrounding adults, any further ability to learn (aside from vocabulary) is superfluous. It is like borrowing a floppy disk drive to load a\nnew computer with the software you will need, or borrowing a turntable to copy your old collection of LP's onto tape; once you are done,\nthe machines can be returned. So language-acquisition circuitry is not\nneeded once it has been used; it should be dismantled if keeping it\naround incurs any costs. And it probably does incur costs. Metaboli\n\nBaby Born Talking—Describes Heaven 295\n\n\ncally, the brain is a pig. It consumes a fifth of the body's oxygen and\nsimilarly large portions of its calories and phospholipids. Greedy\nneural tissue lying around beyond its point of usefulness is a good\ncandidate for the recycling bin. James Hurford, the world's only\ncomputational evolutionary linguist, has put these kinds of assumptions into a computer simulation of evolving humans, and finds that\na critical period for language acquisition centered in early childhood\nis the inevitable outcome."
    },
    {
        "document_id": "0",
        "parent_id": 426,
        "parent_text": "cally, the brain is a pig. It consumes a fifth of the body's oxygen and\nsimilarly large portions of its calories and phospholipids. Greedy\nneural tissue lying around beyond its point of usefulness is a good\ncandidate for the recycling bin. James Hurford, the world's only\ncomputational evolutionary linguist, has put these kinds of assumptions into a computer simulation of evolving humans, and finds that\na critical period for language acquisition centered in early childhood\nis the inevitable outcome.\n\nEven if there is some utility to our learning a second language as\nadults, the critical period for language acquisition may have evolved\nas part of a larger fact of life: the increasing feebleness and vulnerability with advancing age that biologists call \"senescence.\" Common\nsense says that the body, like all machines, must wear out with use,\nbut this is another misleading implication of the appliance metaphor.\nOrganisms are self-replenishing, self-repairing systems, and there is\nno physical reason why we should not be biologically immortal, as in\nfact lineages of cancer cells used in laboratory research are. That\nwould not mean that we would _**actually**_ be immortal. Every day there\nis a certain probability that we will fall off a cliff, catch a virulent\ndisease, be struck by lightning, or be murdered by a rival, and sooner\nor later one of those lightning bolts or bullets will have our name on\nit. The question is, is every day a lottery in which the odds of drawing\na fatal ticket are the same, or do the odds get worse and worse the\nlonger we play? Senescence is the bad news that the odds do change;\nelderly people are killed by falls and flus that their grandchildren\neasily survive. A major question in modern evolutionary biology is\nwhy this should be true, given that selection operates at every point\nof an organism's life history. Why aren't we built to be equally hale\nand hearty every day of our lives, so that we can pump out copies of\nourselves indefinitely?"
    },
    {
        "document_id": "0",
        "parent_id": 427,
        "parent_text": "The solution, from George Williams and P. B. Medawar, is ingenious. As natural selection designed organisms, it must have been\nfaced with countless choices among features that involved different\ntradeoffs of costs and benefits at different ages. Some materials might\nbe strong and light but wear out quickly, whereas others might be\nheavier but more durable. Some biochemical processes might deliver\nexcellent products but leave a legacy of accumulating pollution within\nthe body. There might be a metabolically expensive cellular repair\nmechanism that comes in most useful late in life when wear and tear\n\n\n296 THE LANGUAGE INSTINCT\n\n\nhave accumulated. What does natural selection do when faced with\nthese tradeoffs? In general, it will favor an option with benefits to the\nyoung organism and costs to the old one over an option with the same\naverage benefit spread out evenly over the life span. This asymmetry is\nrooted in the inherent asymmetry of death. If a lightning bolt kills a\nforty-year-old, there will be no fifty-year-old or sixty-year-old to worry\nabout, but there will have been a twenty-year-old and a thirty-yearold. Any bodily feature designed for the benefit of the potential overforty incarnations, at the expense of the under-forty incarnations, will\nhave gone to waste. And the logic is the same for unforeseeable death\nat any age: the brute mathematical fact is that all things being equal,\nthere is a better chance of being a young person than being an old\nperson. So genes that strengthen young organisms at the expense of\nold organisms have the odds in their favor and will tend to accumulate\nover evolutionary timespans, whatever the bodily system, and the\nresult is overall senescence.\n\nThus language acquisition might be like other biological functions.\nThe linguistic clumsiness of tourists and students might be the price\nwe pay for the linguistic genius we displayed as babies, just as the\ndecrepitude of age is the price we pay for the vigor of youth."
    },
    {
        "document_id": "0",
        "parent_id": 428,
        "parent_text": "### 10"
    },
    {
        "document_id": "0",
        "parent_id": 429,
        "parent_text": "#### Language Organs and Grammar Genes\n\n**Ability** to Learn Grammar Laid to Gene by Researcher.\"\nThis 1992 headline appeared not in a supermarket tabloid but in an\nAssociated Press news story, based on a report at the annual meeting\nof the principal scientific association in the United States. The report\nhad summarized evidence that Specific Language Impairment runs\nin families, focusing on the British family we met in Chapter 2 in\nwhich the inheritance pattern is particularly clear. The syndicated\ncolumnists James J. Kilpatrick and Erma Bombeck were incredulous.\nKilpatrick's column began:\n\n\nB E T T E R G R A M M A R T H R O U G H G E N E T I C S\n\nResearchers made a stunning announcement the other day at a\nmeeting of the American Association for the Advancement of Science. Are you ready? Genetic biologists have identified the grammar\ngene.\n\nYes! It appears from a news account that Steven Pinker of MIT\nand Myrna Gopnik of McGill University have solved a puzzle that\nhas baffled teachers of English for years. Some pupils master grammar with no more than a few moans of protest. Others, given the\nsame instruction, persist in saying that Susie invited her and I to\nthe party. It is all a matter of heredity. This we can handle.\n\nA single dominant gene, the biologists believe, controls the ability\nto learn grammar. A child who says \"them marbles is mine\" is not\nnecessarily stupid. He has all his marbles. The child is simply a little\nshort on chromosomes.\n\n\n**2 9 7**\n\n\n298 THE LANGUAGE INSTINCT\n\n\nIt boggles the mind. Before long the researchers will isolate the\ngene that controls spelling . . . [the column continues] . . . neatness. . . . The read-a-book gene . . . a gene to turn down the boom\nbox . . . another to turn off the TV . . . politeness . . . chores . ..\nhomework . . .\n\n\nBombeck wrote:\n\n\nP O O R G R A M M A R ? I T A R E I N T H E G E N E S"
    },
    {
        "document_id": "0",
        "parent_id": 430,
        "parent_text": "**2 9 7**\n\n\n298 THE LANGUAGE INSTINCT\n\n\nIt boggles the mind. Before long the researchers will isolate the\ngene that controls spelling . . . [the column continues] . . . neatness. . . . The read-a-book gene . . . a gene to turn down the boom\nbox . . . another to turn off the TV . . . politeness . . . chores . ..\nhomework . . .\n\n\nBombeck wrote:\n\n\nP O O R G R A M M A R ? I T A R E I N T H E G E N E S\n\nIt was not much of a surprise to read that kids who are unable\nto learn grammar are missing a dominant gene. . . . At one time in\nhis career, my husband taught high school English. He had 37\ngrammar-gene deficients in his class at one time. What do you think\nthe odds of that happening are? They didn't have a clue where\nthey were. A comma could have been a petroglyph. A subjective\ncomplement was something you said to a friend when her hair came\nout right. A dangling participle was not their problem. . ..\n\nWhere is that class of young people today, you ask? They are all\nmajor sports figures, rock stars and television personalities who\nmake millions spewing out words such as \"bummer,\" \"radical\" and\n\"awesome\" and thinking they are complete sentences."
    },
    {
        "document_id": "0",
        "parent_id": 431,
        "parent_text": "Where is that class of young people today, you ask? They are all\nmajor sports figures, rock stars and television personalities who\nmake millions spewing out words such as \"bummer,\" \"radical\" and\n\"awesome\" and thinking they are complete sentences.\n\n\nThe syndicated columns, third-hand newspaper stories, editorial\ncartoons, and radio shows following the symposium gave me a quick\neducation about how scientific discoveries get addled by journalists\nworking under deadline pressure. To set the record straight: the\ndiscovery of the family with the inherited language disorder belongs\nto Gopnik; the reporter who generously shared the credit with me\nwas confused by the fact that I chaired the session and thus introduced\nGopnik to the audience. No grammar gene was identified; a defective\ngene was inferred, from the way the syndrome runs in the family. A\nsingle gene is thought to _disrupt_ grammar, but that does not mean a\nsingle gene _controls_ grammar. (Removing the distributor wire prevents\na car from moving, but that does not mean a car is controlled by its\ndistributor wire.) And of course, what is disrupted is the ability to\nconverse normally in everyday English, not the ability to learn the\nstandard written dialect in school.\n\nBut even when they know the facts, many people share the colum\n\nLanguage Organs and Grammar Genes 299\n\n\nnists' incredulity. Could there really be a gene tied to something as\nspecific as grammar? The very idea is an assault on the deeply rooted\nbelief that the brain is a general-purpose learning device, void and\nwithout form prior to experience of the surrounding culture. And if\nthere are grammar genes, what do they do? Build the grammar organ,\npresumably—a metaphor, from Chomsky, that many find just as\npreposterous."
    },
    {
        "document_id": "0",
        "parent_id": 432,
        "parent_text": "Language Organs and Grammar Genes 299\n\n\nnists' incredulity. Could there really be a gene tied to something as\nspecific as grammar? The very idea is an assault on the deeply rooted\nbelief that the brain is a general-purpose learning device, void and\nwithout form prior to experience of the surrounding culture. And if\nthere are grammar genes, what do they do? Build the grammar organ,\npresumably—a metaphor, from Chomsky, that many find just as\npreposterous.\n\nBut if there is a language instinct, it has to be embodied somewhere\nin the brain, and those brain circuits must have been prepared for\ntheir role by the genes that built them. What kind of evidence could\nshow that there are genes that build parts of brains that control\ngrammar? The ever-expanding toolkit of the geneticist and neurobiologist is mostly useless. Most people do not want their brains impaled\nby electrodes, injected with chemicals, rearranged by surgery, or\nremoved for slicing and staining. (As Woody Allen said, \"The brain\nis my second-favorite organ.\") So the biology of language remains\npoorly understood. But accidents of nature and ingenious indirect\ntechniques have allowed neurolinguists to learn a surprising amount.\nLet's try to home in on the putative grammar gene, beginning with a\nbird's-eye view of the brain and zooming in on smaller and smaller\ncomponents.\n\n\nWe can narrow down our search at the outset by throwing away\nhalf the brain. In 1861 the French physician Paul Broca dissected the\nbrain of an aphasic patient who had been nicknamed \"Tan\" by\nhospital workers because that was the only syllable he uttered. Broca\ndiscovered a large cyst producing a lesion in Tan's left hemisphere.\nThe next eight cases of aphasia he observed also had left-hemisphere\nlesions, too many to be attributed to chance. Broca concluded that\n\"the faculty for articulate language\" resides in the left hemisphere."
    },
    {
        "document_id": "0",
        "parent_id": 433,
        "parent_text": "In the 130 years since, Broca's conclusion has been confirmed by\nmany kinds of evidence. Some of it comes from the convenient fact\nthat the right half of the body and of perceptual space is controlled\nby the left hemisphere of the brain and vice versa. Many people with\naphasia suffer weakness or paralysis on the right side, including Tan\nand the recovered aphasic of Chapter 2, who awoke thinking that he\nhad slept on his right arm. The link is summed up in Psalms 137:5-6:\n\n\n300 THE LANGUAGE INSTINCT\n\n\nIf I forget thee, O Jerusalem, let my right hand forget her\ncunning.\nIf I do not remember thee, let my tongue cleave to the\nroof of my mouth.\n\n\nNormal people recognize words more accurately when the words are\nflashed to the right side of their visual field than when they are flashed\nto the left, even when the language is Hebrew, which is written from\nright to left. When different words are presented simultaneously to\nthe two ears, the person can make out the word coming into the right\near better. In some cases of otherwise incurable epilepsy, surgeons\ndisconnect the two cerebral hemispheres by cutting the bundle of\nfibers running between them. After surgery the patients live completely normal lives, except for a subtlety discovered by the neuroscientist Michael Gazzaniga: when the patients are kept still, they can\ndescribe events taking place in their right visual field and can name\nobjects in their right hand, but cannot describe events taking place\nin their left visual field or name objects placed in their left hand\n(though the right hemisphere can display its awareness of those events\nby nonverbal means like gesturing and pointing). The left half of their\nworld has been disconnected from their language center."
    },
    {
        "document_id": "0",
        "parent_id": 434,
        "parent_text": "When neuroscientists look directly at the brain, using a variety\nof techniques, they can actually see language in action in the left\nhemisphere. The anatomy of the normal brain—its bulges and\ncreases—is slightly asymmetrical. In some of the regions associated\nwith language, the differences are large enough to be seen with the\nnaked eye. Computerized Axial Tomography (CT or CAT) and Magnetic Resonance Imaging (MRI) use a computer algorithm to reconstruct a picture of the living brain in cross-section. Aphasics' brains\nalmost always show lesions in the left hemisphere. Neurologists can\ntemporarily paralyze one hemisphere by injecting sodium amytal into\nthe carotid artery. A patient with a sleeping right hemisphere can\ntalk; a patient with a sleeping left hemisphere cannot. During brain\nsurgery, patients can remain conscious under local anesthetic because\nthe brain has no pain receptors. The neurosurgeon Wilder Penfield\nfound that small electric shocks to certain parts of the left hemisphere\ncould silence the patient in mid-sentence. (Neurosurgeons do these\nmanipulations not out of curiosity but to be sure that they are not\ncutting out vital parts of the brain along with the diseased ones.) In\n\n\nLanguage Organs and Grammar Genes 301\n\n\na technique used on normal research subjects, electrodes are pasted\nall over the scalp, and the subjects' electroencephalograms (EEG's)\nare recorded as they read or hear words. There are recognizable\njumps in the electrical signal that are synchronized with each word,\nand they are more prominent in the electrodes pasted on the left side\nof the skull than in those on the right (though this finding is tricky\nto interpret, because an electrical signal generated deep in one part\nof the brain can radiate out of another part)."
    },
    {
        "document_id": "0",
        "parent_id": 435,
        "parent_text": "In a new technique called Positron Emission Tomography (PET),\na volunteer is injected with mildly radioactive glucose or water, or\ninhales a radioactive gas, comparable in dosage to a chest X-ray, and\nputs his head inside a ring of gamma-ray detectors. The parts of the\nbrain that are more active burn more glucose and have more oxygenated blood sent their way. Computer algorithms can reconstruct\nwhich parts of the brain are working harder from the pattern of\nradiation that emanates from the head. An actual picture of metabolic\nactivity within a slice of the brain can be displayed in a computergenerated photograph, with the more active areas showing up in\nbright reds and yellows, the quiet areas in dark indigos. By subtracting\nan image of the brain when its owner is watching meaningless patterns\nor listening to meaningless sounds from an image when the owner is\nunderstanding words or speech, one can see which areas of the brain\n\"light up\" during language processing. The hot spots, as expected,\nare on the left side.\n\nWhat exactly is engaging the left hemisphere? It is not merely\nspeechlike sounds, or wordlike shapes, or movements of the mouth,\nbut abstract _language._ Most aphasic people—Mr. Ford from Chapter\n2, for example—can blow out candles and suck on straws, but their\nwriting suffers as much as their speech; this shows that it is not mouth\ncontrol but language control that is damaged. Some aphasics remain\nfine singers, and many are superb at swearing. In perception, it has\nlong been known that tones are discriminated better when they are\nplayed to the left ear, which is connected most strongly to the right\nhemisphere. But this is only true if the tones are perceived as musical\nsounds like hums; when the ears are Chinese or Thai and the same\ntones are features of phonemes, the advantage is to the right ear and\nthe left hemisphere it feeds.\n\nIf a person is asked to shadow someone else's speech (repeat it as\nthe talker is talking) and, simultaneously, to tap a finger of the right\n\n\n302 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 436,
        "parent_text": "If a person is asked to shadow someone else's speech (repeat it as\nthe talker is talking) and, simultaneously, to tap a finger of the right\n\n\n302 THE LANGUAGE INSTINCT\n\n\nor the left hand, the person has a harder time tapping with the right\nfinger than with the left, because the right finger competes with\nlanguage for the resources of the left hemisphere. Remarkably, the\npsychologist Ursula Bellugi and her colleagues have shown that the\nsame thing happens when deaf people shadow one-handed signs in\nAmerican Sign Language: they find it harder to tap with their right\nfinger than with their left finger. The gestures must be tying up the\nleft hemispheres, but it is not because they are gestures; it is because\nthey are _linguistic_ gestures. When a person (either a signer or a\nspeaker) has to shadow a goodbye wave, a thumbs-up sign, or a\nmeaningless gesticulation, the fingers of the right hand and the left\nhand are slowed down equally."
    },
    {
        "document_id": "0",
        "parent_id": 437,
        "parent_text": "The study of aphasia in the deaf leads to a similar conclusion. Deaf\nsigners with damage to their left hemispheres suffer from forms of\nsign aphasia that are virtually identical to the aphasia of hearing\nvictims with similar lesions. For example, Mr. Ford's sign-language\ncounterparts are unimpaired at nonlinguistic tasks that place similar\ndemands on the eyes and hands, such as gesturing, pantomiming,\nrecognizing faces, and copying designs. Injuries to the right hemisphere of deaf signers produce the opposite pattern: they remain\nflawless at signing but have difficulty performing visuospatial tasks,\njust like hearing patients with injured right hemispheres. It is a fascinating discovery. The right hemisphere is known to specialize in\nvisuospatial abilities, so one might have expected that sign language,\nwhich depends on visuospatial abilities, would be computed in the\nright hemisphere. Bellugi's findings show that language, whether by\near and mouth or by eye and hand, is controlled by the left hemisphere. The left hemisphere must be handling the abstract rules and\ntrees underlying language, the grammar and the dictionary and the\nanatomy of words, and not merely the sounds and the mouthings at\nthe surface.\n\n\nWhy is language so lopsided? A better question is, why is the rest\nof a person so symmetrical? Symmetry is an inherently improbable\narrangement of matter. If you were to fill in the squares of an 8 x 8\ncheckerboard at random, the odds are less than one in a billion that\nthe pattern would be bilaterally symmetrical. The molecules of life\nare asymmetrical, as are most plants and many animals. Making a\n\n\nLanguage Organs and Grammar Genes 303"
    },
    {
        "document_id": "0",
        "parent_id": 438,
        "parent_text": "Why is language so lopsided? A better question is, why is the rest\nof a person so symmetrical? Symmetry is an inherently improbable\narrangement of matter. If you were to fill in the squares of an 8 x 8\ncheckerboard at random, the odds are less than one in a billion that\nthe pattern would be bilaterally symmetrical. The molecules of life\nare asymmetrical, as are most plants and many animals. Making a\n\n\nLanguage Organs and Grammar Genes 303\n\n\nbody bilaterally symmetrical is difficult and expensive. Symmetry is\nso demanding that among animals with a symmetrical design, any\ndisease or weakness can disrupt it. As a result, organisms from scorpion flies to barn swallows to human beings find symmetry sexy (a\nsign of a fit potential mate) and gross asymmetry a sign of deformity.\nThere must be something in an animal's lifestyle that makes a symmetrical design worth its price. The crucial lifestyle feature is mobility:\nthe species with bilaterally symmetrical body plans are the ones that\nare designed to move in straight lines. The reasons are obvious. A\ncreature with an asymmetrical body would veer off in circles, and a\ncreature with asymmetrical sense organs would eccentrically monitor\none side of its body even though equally interesting things can happen\non either side. Though locomoting organisms are symmetrical sideto-side, they are not (apart from Dr. Dolittle's Push-mi-pull-yu) symmetrical front-and-back. Thrusters apply force best in one direction,\nso it is easier to build a vehicle that can move in one direction and\nturn than a vehicle that can move equally well in forward and reverse\n(or that can scoot off in any direction at all, like a flying saucer).\nOrganisms are not symmetrical up-and-down because gravity makes\nup different from down."
    },
    {
        "document_id": "0",
        "parent_id": 439,
        "parent_text": "The symmetry in sensory and motor organs is reflected in the brain,\nmost of which, at least in nonhumans, is dedicated to processing\nsensation and programming action. The brain is divided into maps\nof visual, auditory, and motor space that literally reproduce the structure of real space: if you move over a small amount in the brain, you\nfind neurons that correspond to a neighboring region of the world as\nthe animal senses it. So a symmetrical body and a symmetrical perceptual world is controlled by a brain that is itself almost perfectly\nsymmetrical.\n\nNo biologist has explained why the left brain controls right space\nand vice versa. It took a psycholinguist, Marcel Kinsbourne, to come\nup with the only speculation that is even remotely plausible. All\nbilaterally symmetrical invertebrates (worms, insects, and so on) have\nthe more straightforward arrangement in which the left side of the\ncentral nervous system controls the left side of the body and the right\nside controls the right side. Most likely, the invertebrate that was the\nancestor of the chordates (animals with a stiffening rod around their\nspinal cords, including fish, amphibians, birds, reptiles, and mammals) had this arrangement as well. But all the chordates have \"contra\n\n304 THE LANGUAGE INSTINCT\n\n\nlateral\" control: right brain controls left body and left brain controls right body. What could have led to the rewiring? Here is Kinsbourne's idea. Imagine that you are a creature with the left-brain-leftbody arrangement. Now turn your head around to look behind you,\na full 180 degrees back, like an owl. (Stop at 180 degrees; don't go\naround and around like the girl in _The Exorcist.)_ Now imagine that\nyour head is stuck in that position. Your nerve cables have been given\na half-twist, so the left brain would control your right body and vice\nversa."
    },
    {
        "document_id": "0",
        "parent_id": 440,
        "parent_text": "Now, Kinsbourne is not suggesting that some primordial rubbernecker literally got its head stuck, but that changes in the genetic\ninstructions for building the creature resulted in the half-twist during\nembryonic development—a torsion that one can actually see happening during the development of snails and some flies. This may sound\nlike a perverse way to build an organism, but evolution does it all the\ntime, because it never works from a fresh drawing board but has to\ntinker with what is already around. For example, our sadistically\ndesigned S-shaped spines are the product of bending and straightening the arched backbones of our quadrupedal forebears. The Picassoesque face of the flounder was the product of warping the head of\na kind of fish that had opted to cling sideways to the ocean floor,\nbringing around the eye that had been staring uselessly into the sand.\nSince Kinsbourne's hypothetical creature left no fossils and has been\nextinct for over half a billion years, no one knows why it would have\nundergone the rotation. (Perhaps one of _its_ ancestors had changed its\nposture, like the flounder, and subsequently righted itself. Evolution,\nwhich has no foresight, may have put its head back into alignment\nwith its body by giving the head another quarter-twist in the same\ndirection, rather than by the more sensible route of undoing the\noriginal quarter-twist.) But it does not really matter; Kinsbourne is\nonly proposing that such a rotation must have taken place; he is not\nclaiming he can reconstruct why it happened. (In the case of the snail,\nwhere the rotation is accompanied by a bending, like one of the arms\nof a pretzel, scientists are more knowledgeable. As my old biology\ntextbook explains, \"While the head and foot remain stationary, the\nvisceral mass is rotated through an angle of 180°, so that the anus . . .\nis carried upward and finally comes to lie [above] the head. . . . The\nadvantages of this arrangement are clear enough in an animal that\nlives in a shell with only one opening.\")"
    },
    {
        "document_id": "0",
        "parent_id": 441,
        "parent_text": "Language Organs and Grammar Genes 305\n\n\nIn support of the theory, Kinsbourne notes that invertebrates have\ntheir main neural cables laid along their bellies and their hearts in\ntheir backs, whereas chordates have their neural cables laid along their\nbacks and their hearts in their chests. This is exactly what one would\nexpect from a 180-degree head-to-body turn in the transition from\none group to the other, and Kinsbourne could not find any reports\nof an animal that has only one or two out of the three reversals that\nhis theory says must have happened together. Major changes in body\narchitecture affect the entire design of the animal and can be very\ndifficult to undo. We are the descendants of that twisted creature,\nand half a billion years later, a stroke in the left hemisphere leaves\nthe right arm tingly.\n\nThe benefits of a symmetrical body plan all have to do with sensing\nand moving in the bilaterally indifferent environment. For body systems that do not interact directly with the environment, the symmetrical blueprint can be overridden. Internal organs such as the heart,\nliver, and stomach are good examples; they are not in contact with\nthe layout of the external world, and they are grossly asymmetrical.\nThe same thing happens on a much smaller scale in the microscopic\ncircuitry of the brain."
    },
    {
        "document_id": "0",
        "parent_id": 442,
        "parent_text": "The benefits of a symmetrical body plan all have to do with sensing\nand moving in the bilaterally indifferent environment. For body systems that do not interact directly with the environment, the symmetrical blueprint can be overridden. Internal organs such as the heart,\nliver, and stomach are good examples; they are not in contact with\nthe layout of the external world, and they are grossly asymmetrical.\nThe same thing happens on a much smaller scale in the microscopic\ncircuitry of the brain.\n\nThink about the act of deliberately manipulating some captive\nobject. The actions are not being keyed to the environment; the\nmanipulator is putting the object anywhere it wants. So the organism's\nforelimbs, and the brain centers controlling them, do not have to be\nsymmetrical in order to react to events appearing unpredictably on\none side or the other; they can be tailored to whatever configuration\nis most efficient to carry out the action. Manipulating an object often\nbenefits from a division of labor between the limbs, one holding the\nobject, the other acting on it. The result is the asymmetrical claws of\nlobsters, and the asymmetrical brains that control paws and hands in\na variety of species. Humans are by far the most adept manipulators\nin the animal kingdom, and we are the species that displays the\nstrongest and most consistent limb preference. Ninety percent of\npeople in all societies and periods in history are right-handed, and\nmost are thought to possess one or two copies of a dominant gene\nthat imposes the right-hand (left-brain) bias. Possessors of two copies\nof the recessive version of the gene develop without this strong righthand bias; they turn into the rest of the right-handers and into the\nleft-handers and ambidextrics.\n\n\n306 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 443,
        "parent_text": "306 THE LANGUAGE INSTINCT\n\n\nProcessing information that is spread out over time but not space is\nanother function where symmetry serves no purpose. Given a certain\namount of neural tissue necessary to perform such a function, it makes\nmore sense to put it all in one place with short interconnections,\nrather than have half of it communicate with the other half over a\nslow, noisy, long-distance connection between the hemispheres. Thus\nthe control of song is strongly lateralized in the left hemispheres of\nmany birds, and the production and recognition of calls and squeaks\nis somewhat lateralized in monkeys, dolphins, and mice.\n\nHuman language may have been concentrated in one hemisphere\nbecause it, too, is coordinated in time but not environmental space:\nwords are strung together in order but do not have to be aimed in\nvarious directions. Possibly, the hemisphere that already contained\ncomputational microcircuitry necessary for control of the fine, deliberate, sequential manipulation of captive objects was the most natural\nplace in which to put language, which also requires sequential control.\nIn the lineage leading to humans, that happened to be the left hemisphere. Many cognitive psychologists believe that a variety of mental\nprocesses requiring sequential coordination and arrangement of parts\nco-reside in the left hemisphere, such as recognizing and imagining\nmultipart objects and engaging in step-by-step logical reasoning. Gazzaniga, testing the two hemispheres of a split-brain patient separately,\nfound that the newly isolated left hemisphere had the same IQ as the\nentire connected brain before surgery!"
    },
    {
        "document_id": "0",
        "parent_id": 444,
        "parent_text": "Linguistically, most left-handers are not mirror images of the righty\nmajority. The left hemisphere controls language in virtually all righthanders (97%), but the right hemisphere controls language in a minority of left-handers, only about 19%. The rest have language in the\nleft hemisphere (68%) or redundantly in both. In all of these lefties,\nlanguage is more evenly distributed between the hemispheres than it\nis in righties, and thus the lefties are more likely to withstand a stroke\non one side of the brain without suffering from aphasia. There is some\nevidence that left-handers, though better at mathematical, spatial,\nand artistic activities, are more susceptible to language impairment,\ndyslexia, and stuttering. Even righties with left-handed relatives (presumably, those righties possessing only one copy of the dominant\nright-bias gene) appear to parse sentences in subtly different ways\nthan pure righties.\n\n\nLanguage Organs and Grammar Genes 307"
    },
    {
        "document_id": "0",
        "parent_id": 445,
        "parent_text": "Language Organs and Grammar Genes 307\n\n\nLanguage, of course, does not use up the entire left half of the brain.\nBroca observed that Tan's brain was mushy and deformed in the regions\nimmediately above the Sylvian fissure—the huge cleavage that separates\nthe distinctively human temporal lobe from the rest of the brain. The\narea in which Tan's damage began is now called Broca's area, and several\nother anatomical regions hugging both sides of the Sylvian fissure affect\nlanguage when they are damaged. The most prominent are shown as\nthe large gray blobs in the diagram (see page 308). In about 98% of the\ncases where brain damage leads to language problems, the damage is\nsomewhere on the banks of the Sylvian fissure of the left hemisphere.\nPenfield found that most of the spots that disrupted language when he\nstimulated them were there, too. Though the language areas appear to\nbe separated by large gulfs, this may be an illusion. The cerebral cortex\n(gray matter) is a large sheet of two-dimensional tissue that has been\nwadded up to fit inside the spherical skull. Just as crumpling a newspaper\ncan appear to scramble the pictures and text, a side view of a brain is\na misleading picture of which regions are adjacent. Gazzaniga's coworkers have developed a technique that uses MRI pictures of brain\nslices to reconstruct what the person's cortex would look like if somehow\nit could be unwrinkled into a flat sheet. They found that all the areas\nthat have been implicated in language are adjacent in one continuous\nterritory. This region of the cortex, the left perisylvian region, can be\nconsidered to be the language organ.\n\nLet us zoom in closer. Tan and Mr. Ford, in whom Broca's area was\ndamaged, suffered from a syndrome of slow, labored, ungrammatical\nspeech called Broca's aphasia. Here is another example, from a man\ncalled Peter Hogan. In the first passage he describes what brought\nhim into the hospital; in the second, his former job in a paper mill:"
    },
    {
        "document_id": "0",
        "parent_id": 446,
        "parent_text": "Let us zoom in closer. Tan and Mr. Ford, in whom Broca's area was\ndamaged, suffered from a syndrome of slow, labored, ungrammatical\nspeech called Broca's aphasia. Here is another example, from a man\ncalled Peter Hogan. In the first passage he describes what brought\nhim into the hospital; in the second, his former job in a paper mill:\n\n\nYes . . . ah . . . Monday . . . ah . . . Dad and Peter Hogan, and Dad\n. . . ah . . . hospital. . . and ah . . . Wednesday . . . Wednesday nine\no'clock and ah Thursday . . . ten o'clock ah doctors . . . two . . . two\n. . . an doctors and . . . ah . . . teeth . . . yah . . . And a doctor an\ngirl . . . and gums, an I.\n\nLower Falls . . . Maine . . . Paper. Four hundred tons a day! And\nah . . . sulphur machines, and ah . . . wood . . . Two weeks and eight\n\n\n308 THE LANGUAGE INSTINCT\n\n\nhours. Eight hours . . . no! Twelve hours, fifteen hours . . . workin\n. . . workin . . .workin! Yes, and ah . . . sulphur. Sulphur and . . .\nAh wood. Ah . . . handlin! And ah sick, four years ago."
    },
    {
        "document_id": "0",
        "parent_id": 447,
        "parent_text": "Lower Falls . . . Maine . . . Paper. Four hundred tons a day! And\nah . . . sulphur machines, and ah . . . wood . . . Two weeks and eight\n\n\n308 THE LANGUAGE INSTINCT\n\n\nhours. Eight hours . . . no! Twelve hours, fifteen hours . . . workin\n. . . workin . . .workin! Yes, and ah . . . sulphur. Sulphur and . . .\nAh wood. Ah . . . handlin! And ah sick, four years ago.\n\n\nBroca's area is adjacent to the part of the motor-control strip\ndedicated to the jaws, lip, and tongue, and it was once thought\nthat Broca's area is involved in the production of language (though\nobviously not speech per se, because writing and signing are just as\naffected). But the area seems to be implicated in grammatical processing in general. A defect in grammar will be most obvious in the\noutput, because any slip will lead to a sentence that is conspicuously\ndefective. Comprehension, on the other hand, can often exploit the\nredundancy in speech to come up with sensible interpretations with\nlittle in the way of actual parsing. For example, one can understand\n_The dog hit the man_ or _The apple that the boy is eating is red_ just by\nknowing that dogs bite men, boys eat apples, and apples are red.\nEven _The car pushes the truck_ can be guessed at because the cause is\nmentioned before the effect. For a century, Broca's aphasics fooled\nneurologists by using these shortcuts. Their trickery was finally unmasked when psycholinguists asked them to act out sentences that\ncould be understood only by their syntax, like _The car is pushed by_\n_the truck_ or _The girl whom the boy is pushing is tall._ The patients gave\nthe correct interpretation half the time and its opposite half the\ntime—a mental coin flip.\n\nThere are other reasons to believe that the front portion of the\n\n\nLanguage Organs and Grammar Genes 309"
    },
    {
        "document_id": "0",
        "parent_id": 448,
        "parent_text": "There are other reasons to believe that the front portion of the\n\n\nLanguage Organs and Grammar Genes 309\n\n\nperisylvian cortex, where Broca's area is found, is involved in grammatical processing. When people read a sentence, electrodes pasted\nover the front of their left hemispheres pick up distinctive patterns\nof electrical activity at the point in the sentence at which it becomes\nungrammatical. Those electrodes also pick up changes during the\nportions of a sentence in which a moved phrase must be held in\nmemory while the reader awaits its trace, like _What did you say_ (trace)\n_to John?_ Several studies using PET and other techniques to measure\nblood flow have shown that this region lights up when people listen\nto speech in a language they know, tell stories, or understand complex\nsentences. Various control tasks and subtractions confirm that it is\nprocessing the structure of sentences, not just thinking about their\ncontent, that engages this general area. A recent and very carefully\ndesigned experiment by Karin Stromswold and the neurologists David Caplan and Nat Alpert obtained an even more precise picture; it\nshowed one circumscribed _part_ of Broca's area lighting up."
    },
    {
        "document_id": "0",
        "parent_id": 449,
        "parent_text": "So is Broca's area the grammar organ? Not really. Damage to\nBroca's area alone usually does not produce long-lasting severe aphasia; the surrounding areas and underlying white matter (which connects Broca's area to other brain regions) must be damaged as well.\nSometimes symptoms of Broca's aphasia can be produced by a stroke\nor Parkinson's disease that damages the basal ganglia, complex neural\ncenters buried inside the frontal lobes that are otherwise needed for\nskilled movement. The labored speech output of Broca's aphasics\nmay be distinct from the lack of grammar in their speech, and may\nimplicate not Broca's area but hidden parts of the cortex nearby that\ntend to be damaged by the same lesions. And, most surprisingly of\nall, some kinds of grammatical abilities seem to survive damage to\nBroca's area. When asked to distinguish grammatical from ungrammatical sentences, some Broca's aphasics can detect even subtle violations of the rules of syntax, as in pairs like these:\n\n\nJohn was finally kissed Louise.\nJohn was finally kissed by Louise.\n\nI want you will go to the store now.\nI want you to go to the store now.\n\nDid the old man enjoying the view?\nDid the old man enjoy the view?\n\n\n310 THE LANGUAGE INSTINCT\n\n\nStill, aphasics do not detect all ungrammaticalities, nor do all aphasics\ndetect them, so the role of Broca's area in language is maddeningly\nunclear. Perhaps the area underlies grammatical processing by converting messages in mentalese into grammatical structures and vice\nversa, in part by communicating via the basal ganglia with the prefrontal lobes, which subserve abstract reasoning and knowledge.\n\nBroca's area is also connected by a band of fibers to a second\nlanguage organ, Wernicke's area. Damage to Wernicke's area produces a very different syndrome of aphasia. Howard Gardner describes his encounter with a Mr. Gorgan:\n\n\n\"What brings you to the hospital?\" I asked the 72-year old retired\nbutcher four weeks after his admission to the hospital."
    },
    {
        "document_id": "0",
        "parent_id": 450,
        "parent_text": "Broca's area is also connected by a band of fibers to a second\nlanguage organ, Wernicke's area. Damage to Wernicke's area produces a very different syndrome of aphasia. Howard Gardner describes his encounter with a Mr. Gorgan:\n\n\n\"What brings you to the hospital?\" I asked the 72-year old retired\nbutcher four weeks after his admission to the hospital.\n\n\"Boy, I'm sweating, I'm awful nervous, you know, once in a while\nI get caught up, I can't mention the tarripoi, a month ago, quite a\nlittle, I've done a lot well, I impose a lot, while, on the other hand,\nyou know what I mean, I have to run around, look it over, trebbin\nand all that sort of stuff.\"\n\nI attempted several times to break in, but was unable to do so\nagainst this relentlessly steady and rapid outflow. Finally, I put up\nmy hand, rested it on Gorgan's shoulder, and was able to gain a\nmoment's reprieve.\n\n\"Thank you, Mr. Gorgan. I want to ask you a few—\"\n\"Oh sure, go ahead, any old think you want. If I could I would.\nOh, I'm taking the word the wrong way to say, all of the barbers\nhere whenever they stop you it's going around and around, if you\nknow what I mean, that is tying and tying for repucer, repuceration,\nwell, we were trying the best that we could while another time it\nwas with the beds over there the same thing . . . \"\n\n\nWernicke's aphasia is in some ways the complement of Broca's. Patients utter fluent streams of more-or-less grammatical phrases, but\ntheir speech makes no sense and is filled with neologisms and word\nsubstitutions. Unlike many Broca's patients, Wernicke's patients have\nconsistent difficulty naming objects; they come up with related words\nor distortions of the sound of the correct one:\n\n\ntable: \"chair\"\nelbow: \"knee\"\n\n\nLanguage Organs and Grammar Genes 311\n\n\nclip: \"plick\"\nbutter: \"tubber\"\nceiling: \"leasing\"\nankle: \"ankley, no mankle, no kankle\"\ncomb: \"close, saw it, cit it, cut, the comb, the came\"\npaper: \"piece of handkerchief, pauper, hand pepper, piece\n\nof hand paper\"\nfork: \"tonsil, teller, tongue, fung\""
    },
    {
        "document_id": "0",
        "parent_id": 451,
        "parent_text": "table: \"chair\"\nelbow: \"knee\"\n\n\nLanguage Organs and Grammar Genes 311\n\n\nclip: \"plick\"\nbutter: \"tubber\"\nceiling: \"leasing\"\nankle: \"ankley, no mankle, no kankle\"\ncomb: \"close, saw it, cit it, cut, the comb, the came\"\npaper: \"piece of handkerchief, pauper, hand pepper, piece\n\nof hand paper\"\nfork: \"tonsil, teller, tongue, fung\"\n\n\nA striking symptom of Wernicke's aphasia is that the patients show\nfew signs of comprehending the speech around them. In a third kind\nof aphasia, the connection between Wernicke's area and Broca's is\ndamaged, and these patients are unable to repeat sentences. In a\nfourth kind, Broca's and Wernicke's and the link between them are\nintact but they are an island cut off from the rest of the cortex, and\nthese patients eerily repeat what they hear without understanding\nit or ever speaking spontaneously. For these reasons, and because\nWernicke's area is adjacent to the part of the cortex that processes\nsound, the area was once thought to underlie language comprehension. But that would not explain why the speech of these patients\nsounds so psychotic. Wernicke's area seems to have a role in looking\nup words and funneling them to other areas, notably Broca's, that\nassemble or parse them syntactically. Wernicke's aphasia, perhaps, is\nthe product of an intact Broca's area madly churning out phrases\nwithout the intended message and intended words that Wernicke's\narea ordinarily supplies. But to be honest, no one really knows what\neither Broca's area or Wernicke's area is for."
    },
    {
        "document_id": "0",
        "parent_id": 452,
        "parent_text": "Wernicke's area, together with the two shaded areas adjacent to it\nin the diagram (the angular and supramarginal gyri), sit at the crossroads of three lobes of the brain, and hence are ideally suited to\nintegrating streams of information about visual shapes, sounds, bodily\nsensations (from the \"somatosensory\" strip), and spatial relations\n(from the parietal lobe). It would be a logical place to store links\nbetween the sounds of words and the appearance and geometry of\nwhat they refer to. Indeed, damage to this general vicinity often causes\na syndrome that is called _anomia,_ though a more mnemonic label\nmight be \"no-name-ia,\" which is literally what it means. The neuropsychologist Kathleen Baynes describes \"HW,\" a business executive\nwho suffered a stroke in this general area. He is highly intelligent,\n\n\n312 THE LANGUAGE INSTINCT\n\n\narticulate, and conversationally adept but finds it virtually impossible\nto retrieve nouns from his mental dictionary, though he can understand them. Here is how he responded when Baynes asked him to\ndescribe a picture of a boy falling from a stool as he reaches into a\njar on a shelf and hands a cookie to his sister:"
    },
    {
        "document_id": "0",
        "parent_id": 453,
        "parent_text": "312 THE LANGUAGE INSTINCT\n\n\narticulate, and conversationally adept but finds it virtually impossible\nto retrieve nouns from his mental dictionary, though he can understand them. Here is how he responded when Baynes asked him to\ndescribe a picture of a boy falling from a stool as he reaches into a\njar on a shelf and hands a cookie to his sister:\n\n\nFirst of all this is falling down, just about, and is gonna fall down\nand they're both getting something to eat. . . but the trouble is this\nis gonna let go and they're both gonna fall down . . . I can't see well\nenough but I believe that either she or will have some food that's\nnot good for you and she's to get some for her, too . . . and that\nyou get it there because they shouldn't go up there and get it unless\nyou tell them that they could have it. And so this is falling down\nand for sure there's one they're going to have for food and, and this\ndidn't come out right, the, uh, the stuff that's uh, good for, it's not\ngood for you but it, but you love, um mum mum [smacks lips] . . .\nand that so they've . . . see that, I can't see whether it's in there or\nnot... I think she's saying, I want two or three, I want one, I think,\nI think so, and so, so she's gonna get this one for sure it's gonna\nfall down there or whatever, she's gonna get that one and, and\nthere, he's gonna get one himself or more, it all depends with this\nwhen they fall down . . . and when it falls down there's no problem,\nall they got to do is fix it and go right back up and get some more.\n\n\nHW uses noun phrases perfectly but cannot retrieve the nouns to put\ninside them: he uses pronouns, gerunds like _falling down,_ and a few\ngeneric nouns like _food_ and _stuff,_ referring to particular objects with\nconvoluted circumlocutions. Verbs tend to pose less of a problem for\nanomics; they are much harder for Broca's aphasics, presumably\nbecause verbs are intimately linked to syntax."
    },
    {
        "document_id": "0",
        "parent_id": 454,
        "parent_text": "HW uses noun phrases perfectly but cannot retrieve the nouns to put\ninside them: he uses pronouns, gerunds like _falling down,_ and a few\ngeneric nouns like _food_ and _stuff,_ referring to particular objects with\nconvoluted circumlocutions. Verbs tend to pose less of a problem for\nanomics; they are much harder for Broca's aphasics, presumably\nbecause verbs are intimately linked to syntax.\n\nThere are other indications that these regions in the rear of the\nperisylvian are implicated in storing and retrieving words. When\npeople read perfectly grammatical sentences and come across a word\nthat makes no sense, like _The boys heard Joe's orange about Africa,_\nelectrodes pasted near the back of the skull pick up a change in their\nEEG's (although, as I have mentioned, it is only a guess that the blips\nare coming from below the electrodes). When people put their heads\nin the PET scanner, this general part of the brain lights up when they\n\n\nLanguage Organs and Grammar Genes 313\n\n\nhear words (and pseudo-words, like _tweal)_ and even when they read\nwords on a screen and have to decide whether the words rhyme—a\ntask requiring them to imagine the word's sounds.\n\n\nA very gross anatomy of the language sub-organs within the perisylvian might be: front of the perisylvian (including Broca's area), grammatical processing; rear of the perisylvian (including Wernicke's and\nthe three-lobe junction), the sounds of words, especially nouns, and\nsome aspects of their meaning. Can we zoom in still closer, and locate\nsmaller areas of brain that carry out more circumscribed language\ntasks? The answer is no and yes. No, there are no smaller patches of\nbrain that one can draw a line around and label as some linguistic\nmodule—at least, not today. But yes, there must be portions of cortex\nthat carry out circumscribed tasks, because brain damage can lead\nto language deficits that are startlingly specific. It is an intriguing\nparadox."
    },
    {
        "document_id": "0",
        "parent_id": 455,
        "parent_text": "Here are some examples. Although impairments of what I have\nbeen calling the sixth sense, speech perception, can arise from damage\nto most areas of the left perisylvian (and speech perception causes\nseveral parts of the perisylvian to light up in PET studies), there is a\nspecific syndrome called Pure Word Deafness that is exactly what it\nsounds like: the patients can read and speak, and can recognize\nenvironmental sounds like music, slamming doors, and animal cries,\nbut cannot recognize spoken words; words are as meaningless as if\nthey were from a foreign language. Among patients with problems in\ngrammar, some do not display the halting articulation of Broca's\naphasia but produce fluent ungrammatical speech. Some aphasics\nleave out verbs, inflections, and function words; others use the wrong\nones. Some cannot comprehend complicated sentences involving\ntraces (like _The man_ _who the woman kissed_ (trace) _hugged the child)_\nbut can comprehend complex sentences involving reflexives (like _The_\n_girl said that the woman washed herself)._ Other patients do the reverse.\nThere are Italian patients who mangle their language's inflectional\nsuffixes (similar to the _-ing, -s,_ and _-ed_ of English) but are almost\nflawless with its derivational suffixes (similar to _-able, -ness,_ and _-er)._\n\nThe mental thesaurus, in particular, is sometimes torn into pieces\nwith clean edges. Among anomic patients (those who have trouble\n\n\n314 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 456,
        "parent_text": "The mental thesaurus, in particular, is sometimes torn into pieces\nwith clean edges. Among anomic patients (those who have trouble\n\n\n314 THE LANGUAGE INSTINCT\n\n\nusing nouns), different patients have problems with different kinds\nof nouns. Some can use concrete nouns but not abstract nouns. Some\ncan use abstract nouns but not concrete nouns. Some can use nouns\nfor nonliving things but have trouble with nouns for living things;\nothers can use nouns for living things but have trouble with nouns\nfor nonliving things. Some can name animals and vegetables but not\nfoods, body parts, clothing, vehicles, or furniture. There are patients\nwho have trouble with nouns for anything but animals, patients who\ncannot name body parts, patients who cannot name objects typically\nfound indoors, patients who cannot name colors, and patients who\nhave trouble with proper names. One patient could not name fruits\nor vegetables: he could name an abacus and a sphinx but not an apple\nor a peach. The psychologist Edgar Zurif, jesting the neurologist's\nhabit of giving a fancy name to every syndrome, has suggested that it\nbe called anomia for bananas, or \"banananomia.\"\n\nDoes this mean that the brain has a produce section? No one has\nfound one, nor centers for inflections, traces, phonology, and so\non. Pinning brain areas to mental functions has been frustrating.\nFrequently one finds two patients with lesions in the same general\narea but with different kinds of impairment, or two patients with\nthe same impairment but lesions in different areas. Sometimes a\ncircumscribed impairment, like the inability to name animals, can be\ncaused by massive lesions, brain-wide degeneration, or a blow to the\nhead. And about ten percent of the time a patient with a lesion in the\ngeneral vicinity of Wernicke's area can have a Broca-like aphasia, and\na patient with lesions near Broca's area can have a Wernicke-like\naphasia."
    },
    {
        "document_id": "0",
        "parent_id": 457,
        "parent_text": "Why has it been so hard to draw an atlas of the brain with areas\nfor different parts of language? According to one school of thought,\nit is because there aren't any; the brain is a meatloaf. Except for\nsensation and movement, mental processes are patterns of neuronal\nactivity that are widely distributed, hologram-style, all over the brain.\nBut the meatloaf theory is hard to reconcile with the amazingly specific\ndeficits of many brain-damaged patients, and it is becoming obsolete\nin this \"decade of the brain.\" Using tools that are getting more\nsophisticated each month, neurobiologists are charting vast territories\nthat once bore the unhelpful label \"association cortex\" in the old\ntextbooks, and are delineating dozens of new regions with their own\n\n\nLanguage Organs and Grammar Genes 315\n\n\nfunctions or styles of processing, like visual areas specializing in object\nshape, spatial layout, color, 3D stereo-vision, simple motion, and\ncomplex motion.\n\nFor all we know, the brain might have regions dedicated to processes as specific as noun phrases and metrical trees; our methods for\nstudying the human brain are still so crude that we would be unable\nto find them. Perhaps the regions look like little polka dots or blobs\nor stripes scattered around the general language areas of the brain.\nThey might be irregularly shaped squiggles, like gerrymandered political districts. In different people, the regions might be pulled and\nstretched onto different bulges and folds of the brain. (All of these\narrangements are found in brain systems we understand better, like\nthe visual system.) If so, the enormous bomb craters that we call brain\nlesions, and the blurry snapshots we call PET scans, would leave their\nwhereabouts unknown."
    },
    {
        "document_id": "0",
        "parent_id": 458,
        "parent_text": "There is already some evidence that the linguistic brain might be\norganized in this tortuous way. The neurosurgeon George Ojemann,\nfollowing up on Penfield's methods, electrically stimulated different\nsites in conscious, exposed brains. He found that stimulating within\na site no more than a few millimeters across could disrupt a single\nfunction, like repeating or completing a sentence, naming an object,\nor reading a word. But these dots were scattered over the brain\n(largely, but not exclusively, in the perisylvian regions) and were\nfound in different places in different individuals.\n\nFrom the standpoint of what the brain is designed to do, it would\nnot be surprising if language subcenters are idiosyncratically tangled\nor scattered over the cortex. The brain is a special kind of organ, the\norgan of computation, and unlike an organ that moves stuff around\nin the physical world such as the hip or the heart, the brain does not\nneed its functional parts to have nice cohesive shapes. As long as the\nconnectivity of the neural microcircuitry is preserved, its parts can be\nput in different places and do the same thing, just as the wires connecting a set of electrical components can be haphazardly stuffed into a\ncabinet, or the headquarters of a corporation can be located anywhere\nif it has good communication links to its plants and warehouses. This\nseems especially true of words: lesions or electrical stimulation over\nwide areas of the brain can cause naming difficulties. A word is a\nbundle of different kinds of information. Perhaps each word is like\n\n\n316 THE LANGUAGE INSTINCT\n\n\na hub that can be positioned anywhere in a large region, as long as\nits spokes extend to the parts of the brain storing its sound, its syntax,\nits logic, and the appearance of the things it stands for."
    },
    {
        "document_id": "0",
        "parent_id": 459,
        "parent_text": "316 THE LANGUAGE INSTINCT\n\n\na hub that can be positioned anywhere in a large region, as long as\nits spokes extend to the parts of the brain storing its sound, its syntax,\nits logic, and the appearance of the things it stands for.\n\nThe developing brain may take advantage of the disembodied nature of computation to position language circuits with some degree\nof flexibility. Say a variety of brain areas have the potential to grow\nthe precise wiring diagrams for language components. An initial bias\ncauses the circuits to be laid down in their typical sites; the alternative\nsites are then suppressed. But if those first sites get damaged within\na certain critical period, the circuits can grow elsewhere. Many neurologists believe that this is why the language centers are located in\nunexpected places in a significant minority of people. Birth is traumatic, and not just for the familiar psychological reasons. The birth\ncanal squeezes the baby's head like a lemon, and newborns frequently\nsuffer small strokes and other brain insults. Adults with anomalous\nlanguage areas may be the recovered victims of these primal injuries.\nNow that MRI machines are common in brain research centers, visiting journalists and philosophers are sometimes given pictures of\ntheir brains to take home as a souvenir. Occasionally the picture will\nreveal a walnut-sized dent, which, aside from some teasing from\nfriends who say they knew it all along, bespeaks no ill effects."
    },
    {
        "document_id": "0",
        "parent_id": 460,
        "parent_text": "There are other reasons why language functions have been so hard\nto pin down in the brain. Some kinds of linguistic knowledge might\nbe stored in multiple copies, some of higher quality than others,\nin several places. Also, by the time stroke victims can be tested\nsystematically, they have often recovered some of their facility with\nlanguage, in part by compensating with general reasoning abilities.\nAnd neurologists are not like electronics technicians who can wiggle\na probe into the input or output line of some component to isolate\nits function. They must tap the whole patient via his or her eyes and\nears and mouth and hands, and there are many computational waystations between the stimulus they present and the response they\nobserve. For example, naming an object involves recognizing it, looking up its entry in the mental dictionary, accessing its pronunciation,\narticulating it, and perhaps also monitoring the output for errors by\nlistening to it. A naming problem could arise if any of these processes\ntripped up.\n\nThere is some hope that we will have better localization of mental\n\n\nLanguage Organs and Grammar Genes 317\n\n\nprocesses soon, because more precise brain-imaging technologies are\nrapidly being developed. One example is Functional MRI, which\ncan measure—with much more precision than PET—how hard the\ndifferent parts of the brain are working during different kinds of\nmental activity. Another is Magneto-Encephalography, which is like\nEEG but can pinpoint the part of the brain that an electromagnetic\nsignal is coming from."
    },
    {
        "document_id": "0",
        "parent_id": 461,
        "parent_text": "Language Organs and Grammar Genes 317\n\n\nprocesses soon, because more precise brain-imaging technologies are\nrapidly being developed. One example is Functional MRI, which\ncan measure—with much more precision than PET—how hard the\ndifferent parts of the brain are working during different kinds of\nmental activity. Another is Magneto-Encephalography, which is like\nEEG but can pinpoint the part of the brain that an electromagnetic\nsignal is coming from.\n\n\nWe will never understand language organs and grammar genes by\nlooking only for postage-stamp-sized blobs of brain. The computations underlying mental life are caused by the wiring of the intricate\nnetworks that make up the cortex, networks with millions of neurons,\neach neuron connected to thousands of others, operating in thousandths of a second. What would we see if we could crank up the\nmicroscope and peer into the microcircuitry of the language areas?\nNo one knows, but I would like to give you an educated guess.\nIronically, this is both the aspect of the language instinct that we\nknow the least about and the aspect that is the most important,\nbecause it is there that the actual causes of speaking and understanding lie. I will present you with a dramatization of what grammatical\ninformation processing might be like from a neuron's-eye view. It is\nnot something that you should take particularly seriously; it is simply\na demonstration that the language instinct is compatible in principle\nwith the billiard-ball causality of the physical universe, not just mysticism dressed up in a biological metaphor."
    },
    {
        "document_id": "0",
        "parent_id": 462,
        "parent_text": "Neural network modeling is based on a simplified toy neuron. This\nneuron can do just a few things. It can be active or inactive. When\nactive, it sends a signal down its axon (output wire) to the other cells\nit is connected to; the connections are called synapses. Synapses can\nbe excitatory or inhibitory and can have various degrees of strength.\nThe neuron at the receiving end adds up any signals coming in from\nexcitatory synapses, subtracts any signals coming in from inhibitory\nsynapses, and if the sum exceeds a threshold, the receiving neuron\nbecomes active itself.\n\nA network of these toy neurons, if large enough, can serve as a\ncomputer, calculating the answer to any problem that can be specified\nprecisely, just like the page-crawling Turing Machine in Chapter 3\n\n\n318 THE LANGUAGE INSTINCT\n\n\nthat could deduce that Socrates is mortal. That is because toy neurons\ncan be wired together in a few simple ways that turn them into \"logic\ngates,\" devices that can compute the logical relations \"and,\" \"or,\"\nand \"not\" that underlie deduction. The meaning of the logical relation\n\"and\" is that the statement \"A and B\" is true if A is true and if B is\ntrue. An A N D gate that computes that relation would be one that\nturns itself on if all of its inputs are on. If we assume that the threshold\nfor our toy neurons is .5, then a set of incoming synapses whose\nweights are each less than .5 but that sum to greater than .5, say .4\nand .4, will function as an A N D gate, such as the one on the left\nhere:"
    },
    {
        "document_id": "0",
        "parent_id": 463,
        "parent_text": "The meaning of the logical relation \"or\" is that a statement \"A or B\" is\ntrue if A is true or if B is true. Thus an OR gate must turn on if at least\none of its inputs is on. To implement it, each synaptic weight must be\ngreater than the neuron's threshold, say .6, like the middle circuit in\nthe diagram. Finally, the meaning of the logical relation \"not\" is that a\nstatement \"Not A\" is true if A is false, and vice versa. Thus a N O T gate\nshould turn its output off if its input is on, and vice versa. It is implemented\nby an inhibitory synapse, shown on the right, whose negative weight is\nsufficient to turn off an output neuron that is otherwise always on.\n\nHere is how a network of neurons might compute a moderately\ncomplex grammatical rule. The English inflection _-s_ as in _Bill walks_\nis a suffix that should be applied under the following conditions:\nwhen the subject is in the third person A N D singular A N D the action\nis in the present tense A N D is done habitually (this is its \"aspect,\" in\nlingo)—but N O T if the verb is irregular like _do, have, say,_ or _he_ (for\nexample, we say _Bill is,_ not _Bill he's)._ A network of neural gates that\ncomputes these logical relations looks like this:\n\n\nLanguage Organs and Grammar Genes 319"
    },
    {
        "document_id": "0",
        "parent_id": 464,
        "parent_text": "Language Organs and Grammar Genes 319\n\n\nFirst, there is a bank of neurons standing for inflectional features on\nthe lower left. The relevant ones are connected via an A N D gate to a\nneuron that stands for the combination third person, singular number, present tense, and habitual aspect (labeled \"3sph\"). That neuron\nexcites a neuron corresponding to the _-s_ inflection, which in turn\nexcites the neuron corresponding to the phoneme z in a bank of\nneurons that represent the pronunciations of suffixes. If the verb is\nregular, this is all the computation that is needed for the suffix; the\npronunciation of the stem, as specified in the mental dictionary, is\nsimply copied over verbatim to the stem neurons by connections I\nhave not drawn in. (That is, the form for _to hit_ is just _hit + s;_ the\nform for _to wug_ is just _wug + s.)_ For irregular verbs like _be,_ this\nprocess must be blocked, or else the neural network would produce\nthe incorrect _he's._ So the 3sph combination neuron also sends a signal\nto a neuron that stands for the entire irregular form _is._ If the person\nwhose brain we are modeling is intending to use the verb _be,_ a neuron\nstanding for the verb _be_ is already active, and it, too, sends activation\nto the _is_ neuron. Because the two inputs to _is_ are connected as an\nA N D gate, both must be on to activate _is._ That is, if and only if the\nperson is thinking of _be_ and third-person-singular-present-habitual at\n\n\n3 2 0 THE LANGUAGE INSTINCT\n\n\nthe same time, the _is_ neuron is activated. The _is_ neuron inhibits the\n_-s_ inflection via a N O T gate formed by an inhibitory synapse, preventing _ises_ or _be's,_ but activates the vowel _i_ and the consonant _z_ in\nthe bank of neurons standing for the stem. (Obviously I have omitted\nmany neurons and many connections to the rest of the brain.)"
    },
    {
        "document_id": "0",
        "parent_id": 465,
        "parent_text": "I have hand-wired this network, but the connections are specific\nto English and in a real brain would have to have been learned.\nContinuing our neural network fantasy for a while, try to imagine\nwhat this network might look like in a baby. Pretend that each of the\npools of neurons is innately there. But wherever I have drawn an\narrow from a single neuron in one poo! to a single neuron in another,\nimagine a suite of arrows, from every neuron in one pool to every\nneuron in another. This corresponds to the child innately \"expecting\"\nthere to be, say, suffixes for persons, numbers, tenses, and aspects,\nas well as possible irregular words for those combinations, but not\nknowing exactly which combinations, suffixes, or irregulars are found\nin the particular language. Learning them corresponds to strengthening some of the synapses at the arrowheads (the ones I happen to\nhave drawn in) and letting the others stay invisible. This could work\nas follows. Imagine that when the infant hears a word with a _z_ in its\nsuffix, the _z_ neuron in the suffix pool at the right edge of the diagram\ngets activated, and when the infant thinks of third person, singular\nnumber, present tense, and habitual aspect (parts of his construal of\nthe event), those four neurons at the left edge get activated, too. If\nthe activation spreads backwards as well as forwards, and if a synapse\ngets strengthened every time it is activated at the same time that its\noutput neuron is already active, then all the synapses lining the paths\nbetween \"3rd,\" \"singular,\" \"present,\" \"habitual\" at one end, and\n\"z\" at the other end, get strengthened. Repeat the experience enough\ntimes, and the partly specified neonate network gets tuned into the\nadult one I have pictured."
    },
    {
        "document_id": "0",
        "parent_id": 466,
        "parent_text": "Let's zoom in even closer. What primal solderer laid down the\npools of neurons and the innate potential connections among them?\nThis is one of the hottest topics in contemporary neuroscience, and\nwe are beginning to get the glimmerings of how embryonic brains get\nwired. Not the language areas of humans, of course, but the eyeballs\nof fruit flies and the thalamuses of ferrets and the visual cortexes of\ncats and monkeys. Neurons destined for particular cortical areas are\nborn in specific areas along the walls of the ventricles, the fluid-filled\n\n\n**Language Organs and Grammar Genes** 321"
    },
    {
        "document_id": "0",
        "parent_id": 467,
        "parent_text": "**Language Organs and Grammar Genes** 321\n\n\ncavities at the center of the cerebral hemispheres. They then creep\noutward toward the skull into their final resting place in the cortex\nalong guy wires formed by the glial cells (the support cells that,\ntogether with neurons, constitute the bulk of the brain). The connections between neurons in different regions of the cortex are often laid\ndown when the intended target area releases some chemical, and the\naxons growing every which way from the source area \"sniff out\" that\nchemical and follow the direction in which its concentration increases,\nlike plant roots growing toward sources of moisture and fertilizer.\nThe axons also sense the presence of specific molecules on the glial\nsurfaces on which they creep, and can steer themselves like Hansel\nand Gretel following the trail of bread crumbs. Once the axons reach\nthe general vicinity of their target, more precise synaptic connections\ncan be formed because the growing axons and the target neurons\nbear certain molecules on their surfaces that match each other like a\nlock and key and adhere in place. These initial connections are often\nquite sloppy, though, with neurons exuberantly sending out axons\nthat grow toward, and connect to, all kinds of inappropriate targets.\nThe inappropriate ones die off, either because their targets fail to\nprovide some chemical necessary for their survival, or because the\nconnections they form are not used enough once the brain turns on\nin fetal development."
    },
    {
        "document_id": "0",
        "parent_id": 468,
        "parent_text": "Try to stay with me in this neuro-mythological quest: we are beginning to approach the \"grammar genes.\" The molecules that guide,\nconnect, and preserve neurons are proteins. A protein is specified by\na gene, and a gene is a sequence of bases in the DNA string found\nin a chromosome. A gene is turned on by \"transcription factors\" and\nother regulatory molecules—gadgets that latch on to a sequence of\nbases somewhere on a DNA molecule and unzip a neighboring\nstretch, allowing that gene to be transcribed into RNA, which is\nthen translated into protein. Generally these regulatory factors are\nthemselves proteins, so the process of building an organism is an\nintricate cascade of DNA making proteins, some of which interact\nwith other DNA to make more proteins, and so on. Small differences\nin the timing or amount of some protein can have large effects on the\norganism being built.\n\nThus a single gene rarely specifies some identifiable part of an\norganism. Instead, it specifies the release of some protein at specific\ntimes in development, an ingredient of an unfathomably complex\n\n\n322 THE LANGUAGE INSTINCT\n\n\nrecipe, usually having some effect in molding a suite of parts that are\nalso affected by many other genes. Brain wiring in particular has a\ncomplex relationship to the genes that lay it down. A surface molecule\nmay not be used in a single circuit but in many circuits, each guided\nby a specific combination. For example, if there are three proteins,\nX, Y, and Z, that can sit on a membrane, one axon might glue itself\nto a surface that has X and Y and not Z, and another might glue itself\nto a surface that has Y and Z but not X. Neuroscientists estimate that\nabout thirty thousand genes, the majority of the human genome, are\nused to build the brain and nervous system."
    },
    {
        "document_id": "0",
        "parent_id": 469,
        "parent_text": "And it all begins with a single cell, the fertilized egg. It contains\ntwo copies of each chromosome, one from the mother, one from the\nfather. Each parental chromosome was originally assembled in the\nparents' gonads by randomly splicing together parts of the chromosomes of the two grandparents.\n\nWe have arrived at a point at which we can define what grammar\ngenes would be. The grammar genes would be stretches of DNA that\ncode for proteins, or trigger the transcription of proteins, in certain\ntimes and places in the brain, that guide, attract, or glue neurons into\nnetworks that, in combination with the synaptic tuning that takes\nplace during learning, are necessary to compute the solution to some\ngrammatical problem (like choosing an affix or a word).\n\n\nSo do grammar genes really exist, or is the whole idea just loopy?\nCan we expect the scenario in the 1990 editorial cartoon by Brian\nDuffy? A pig, standing upright, asks a farmer, \"What's for dinner?\nNot me, I hope.\" The farmer says to his companion, \"That's the one\nthat received the human gene implant.\"\n\nFor any grammar gene that exists in every human being, there is\ncurrently no way to verify its existence directly. As in many cases in\nbiology, genes are easiest to identify when they correlate with some\ndifference between individuals, often a difference implicated in some\npathology.\n\nWe certainly know that there is something in the sperm and egg\nthat affects the language abilities of the child that grows out of their\nunion. Stuttering, dyslexia (a difficulty in reading that is often related\nto a difficulty in mentally snipping syllables into their phonemes), and\nSpecific Language Impairment (SLI) all run in families. This does not\n\n\nLanguage Organs and Grammar Genes 323"
    },
    {
        "document_id": "0",
        "parent_id": 470,
        "parent_text": "We certainly know that there is something in the sperm and egg\nthat affects the language abilities of the child that grows out of their\nunion. Stuttering, dyslexia (a difficulty in reading that is often related\nto a difficulty in mentally snipping syllables into their phonemes), and\nSpecific Language Impairment (SLI) all run in families. This does not\n\n\nLanguage Organs and Grammar Genes 323\n\n\nprove that they are genetic (recipes and wealth also run in families),\nbut these three syndromes probably are. In each case there is no\nplausible environmental agent that could act on afflicted family members while sparing the normal ones. And the syndromes are far more\nlikely to affect both members of a pair of identical twins, who share\nan environment and all their DNA, than both members of a pair of\nfraternal twins, who share an environment and only half of their DNA.\nFor example, identical four-year-old twins tend to mispronounce the\nsame words more often than fraternal twins, and if a child has Specific\nLanguage Impairment, there is an eighty percent chance that an\nidentical twin will have it too, but only a thirty-five percent chance\nthat a fraternal twin will have it. It would be interesting to see whether\nadopted children resemble their biological family members, who\nshare their DNA but not their environments. I am unaware of any\nadoption study that tests for SLI or dyslexia, but one study has found\nthat a measure of early language ability in the first year of life (a\nmeasure that combines vocabulary, vocal imitation, word combinations, jabbering, and word comprehension) was correlated with the\ngeneral cognitive ability and memory of the birth mother, but not of\nthe adoptive mother or father."
    },
    {
        "document_id": "0",
        "parent_id": 471,
        "parent_text": "The K family, three generations of SLI sufferers, whose members\nsay things like _Carol is cry in the church_ and can not deduce the plural\nof _wug,_ is currently one of the most dramatic demonstrations that\ndefects in grammatical abilities might be inherited. The attentiongrabbing hypothesis about a single dominant autosomal gene is based\non the following Mendelian reasoning. The syndrome is suspected of\nbeing genetic because there is no plausible environmental cause that\nwould single out some family members and spare their agemates (in\none case, one fraternal twin was affected, the other not), and because\nthe syndrome has struck fifty-three percent of the family members\nbut strikes no more than about three percent of the population at\nlarge. (In principle, the family could just have been unlucky; after all,\nthey were not randomly selected from the population but came to\nthe geneticists' attention only _because_ of the high concentration of the\nsyndrome. But it is unlikely.) A single gene is thought to be responsible because if several genes were responsible, each eroding language\nability by a bit, there would be several degrees of disability among\nthe family members, depending on how many of the damaging genes\nthey inherited. But the syndrome seems to be all-or-none: the school\n\n\n324 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 472,
        "parent_text": "324 THE LANGUAGE INSTINCT\n\n\nsystem and family members all agree on who does and who does not\nhave the impairment, and in most of Gopnik's tests the impaired\nmembers cluster together at the low end of the scale while the normal\nmembers cluster at the high end, with no overlap. The gene is thought\nto be autosomal (not on the X chromosome) and dominant because\nthe syndrome struck males and females with equal frequency, and in\nall cases the spouse of an impaired parent, whether husband or wife,\nwas normal. If the gene were recessive and autosomal, it would be\nnecessary to have two impaired parents to inherit the syndrome. If it\nwere recessive and on the X chromosome, only males would have it;\nfemales would be carriers. And if it were dominant and on the X\nchromosome, an impaired father would pass it on to all of his daughters and none of his sons, because sons get their X chromosome from\ntheir mother, and daughters get one from each parent. But one of the\ndaughters of an impaired man was normal.\n\nThis single gene is not, repeat not, responsible for all the circuitry\nunderlying grammar, contrary to the Associated Press, James Kilpatrick, et al. Remember that a single defective component can bring\na complex machine to a halt even when the machine needs many\nproperly functioning parts to work. In fact, it is possible that the\nnormal version of the gene does not build grammar circuitry at all.\nMaybe the defective version manufactures a protein that gets in the\nway of some chemical process necessary for laying down the language\ncircuits. Maybe it causes some adjacent area in the brain to overgrow\nits own territory and spill into the territory ordinarily allotted to\nlanguage."
    },
    {
        "document_id": "0",
        "parent_id": 473,
        "parent_text": "But the discovery is still quite interesting. Most of the languageimpaired family members were average in intelligence, and there are\nsufferers in other families who are way above average; one boy studied\nby Gopnik was tops in his math class. So the syndrome shows that\nthere must be some pattern of genetically guided events in the development in the brain (namely, the events disrupted in this syndrome)\nthat is specialized for the wiring in of linguistic computation. And\nthese construction sites seem to involve circuitry necessary for the\nprocessing of grammar in the mind, not just the articulation of speech\nsounds by the mouth or the perception of speech sounds by the\near. Though the afflicted family members as children suffered from\ndifficulties in articulating speech and developed language late, most\nof them outgrew the articulation problems, and their lasting deficits\n\n\nLanguage Organs and Grammar Genes 325\n\n\ninvolve grammar. For example, although the impaired family members often leave off the _-ed_ and _-s_ suffixes, it is not because they\ncannot hear or say those sounds; they easily discriminate between _car_\nand _card,_ and never pronounce _nose_ as _no._ In other words, they treat\na sound differently when it is a permanent part of a word and when\nit is added to a word by a rule of grammar."
    },
    {
        "document_id": "0",
        "parent_id": 474,
        "parent_text": "Language Organs and Grammar Genes 325\n\n\ninvolve grammar. For example, although the impaired family members often leave off the _-ed_ and _-s_ suffixes, it is not because they\ncannot hear or say those sounds; they easily discriminate between _car_\nand _card,_ and never pronounce _nose_ as _no._ In other words, they treat\na sound differently when it is a permanent part of a word and when\nit is added to a word by a rule of grammar.\n\nEqually interestingly, the impairment does not wipe out any part\nof grammar completely, nor does it compromise all parts equally.\nThough the impaired family members had trouble changing the tense\nof test sentences and applying suffixes in their spontaneous speech,\nthey were not hopeless; they just performed far less accurately than\ntheir unimpaired relatives. These probabilistic deficits seemed to be\nconcentrated in morphology and the features it manipulates, like\ntense, person, and number; other aspects of grammar were less affected. The impaired members could, for example, detect verb phrase\nviolations in sentences like _The nice girl gives_ and _The girl eats a_\n_cookie to the boy,_ and could act out many complex commands. The\nlack of an exact correspondence between a gene and a single function\nis exactly what we would expect, knowing how genes work."
    },
    {
        "document_id": "0",
        "parent_id": 475,
        "parent_text": "So for now there is suggestive evidence for grammar genes, in the\nsense of genes whose effects seem most specific to the development\nof the circuits underlying parts of grammar. The chromosomal locus\nof the putative gene is completely unknown, as is its effect on the\nstructure of the brain. But blood samples are being drawn from\nthe family for genetic analysis, and MRI scans of brains from other\nindividuals with Specific Language Impairment have already been\nfound to lack the asymmetry in the perisylvian areas that we find in\nlinguistically normal brains. Other researchers on language disorders,\nsome excited by Gopnik's claims, others skeptical of them, have\nbegun to screen their patients with careful tests of their grammatical\nabilities and their family histories. They are seeking to determine how\ncommonly Specific Language Impairment is inherited and how many\ndistinct syndromes of the impairment there might be. You can expect\nto read about some interesting discoveries about the neurology and\ngenetics of language in the next few years.\n\n\nIn modern biology, it is hard to discuss genes without discussing\ngenetic variation. Aside from identical twins, no two people—in fact,\n\n\n326 THE LANGUAGE INSTINCT\n\n\nno two sexually reproducing organisms—are genetically identical. If\nthis were not true, evolution as we know it could not have happened.\nIf there are language genes, then, shouldn't normal people be innately\ndifferent from one another in their linguistic abilities? Are they? Must\nI qualify everything I have said about language and its development,\nbecause no two people have the same language instinct?"
    },
    {
        "document_id": "0",
        "parent_id": 476,
        "parent_text": "326 THE LANGUAGE INSTINCT\n\n\nno two sexually reproducing organisms—are genetically identical. If\nthis were not true, evolution as we know it could not have happened.\nIf there are language genes, then, shouldn't normal people be innately\ndifferent from one another in their linguistic abilities? Are they? Must\nI qualify everything I have said about language and its development,\nbecause no two people have the same language instinct?\n\nIt is easy to get carried away with the geneticists' discovery that\nmany of our genes are as distinctive as our fingerprints. After all, you\ncan open up any page of _Gray's Anatomy_ and expect to find a depiction of organs and their parts and arrangements that will be true of\nany normal person. (Everyone has a heart with four chambers, a\nliver, and so on.) The biological anthropologist John Tooby and the\ncognitive psychologist Leda Cosmides have resolved the apparent\nparadox."
    },
    {
        "document_id": "0",
        "parent_id": 477,
        "parent_text": "It is easy to get carried away with the geneticists' discovery that\nmany of our genes are as distinctive as our fingerprints. After all, you\ncan open up any page of _Gray's Anatomy_ and expect to find a depiction of organs and their parts and arrangements that will be true of\nany normal person. (Everyone has a heart with four chambers, a\nliver, and so on.) The biological anthropologist John Tooby and the\ncognitive psychologist Leda Cosmides have resolved the apparent\nparadox.\n\nTooby and Cosmides argue that differences between people must\nbe minor quantitative variations, not qualitatively different designs.\nThe reason is sex. Imagine that two people were really built from\nfundamentally different designs: either physical designs, like the structure of the lungs, or neurological designs, like the circuitry underlying\nsome cognitive process. Complex machines require many finely meshing parts, which in turn require many genes to build them. But the\nchromosomes are randomly snipped, spliced, and shuffled during the\nformation of sex cells, and then are paired with other chimeras at\nfertilization. If two people really had different designs, their offspring\nwould inherit a mishmash of fragments from the genetic blueprints\nof each—as if the plans for two cars were cut up with scissors and\nthe pieces taped back together without our caring about which scrap\noriginally came from which car. If the cars are of different designs,\nlike a Ferrari and a jeep, the resulting contraption, if it could be built\nat all, would certainly not get anywhere. Only if the two designs were\nextremely similar to begin with could the new pastiche work."
    },
    {
        "document_id": "0",
        "parent_id": 478,
        "parent_text": "That is why the variation that geneticists tell us about is microscopic—differences in the exact sequence of molecules in proteins\nwhose overall shape and function are basically the same, kept within\nnarrow limits of variation by natural selection. That variation is there\nfor a purpose: by shuffling the genes each generation, lineages of\norganisms can stay one step ahead of the microscopic, rapidly evolving\ndisease parasites that fine-tune themselves to infiltrate the chemical\nenvironments of their hosts. But above the germ's-eye view, at the\n\n\n**Language Organs and G r a m m a r Genes** 327\n\n\nmacroscopic level of functioning biological machinery visible to an\nanatomist or psychologist, variation from one individual to another\nmust be quantitative and minor; thanks to natural selection, all normal\npeople must be qualitatively the same.\n\nBut this does not mean that individual differences are boring.\nGenetic variation can open our eyes to the degree of structure and\ncomplexity that the genes ordinarily give to the mind. If genes just\nequipped a mind with a few general information-processing devices\nlike a short-term memory and a correlation detector, some people\nmight be better than others at holding things in memory or learning\ncontingencies, and that would be about it. But if the genes built a\nmind with many elaborate parts dedicated to particular tasks, the\nunique genetic hand that is dealt to each person would give rise to\nan unprecedented profile of innate cognitive quirks.\n\nI quote from a recent article in _Science:_"
    },
    {
        "document_id": "0",
        "parent_id": 479,
        "parent_text": "I quote from a recent article in _Science:_\n\n\nWhen Oskar Stohr and Jack Yufe arrived in Minnesota to participate in University of Minnesota psychologist Thomas J. Bouchard,\nJr.'s study of identical twins reared apart, they were both sporting\nblue double-breasted epauletted shirts, mustaches, and wirerimmed glasses. Identical twins separated at birth, the two men, in\ntheir late 40s, had met once before two decades earlier. Nonetheless,\nOskar, raised as a Catholic in Germany, and Jack, reared by his\nJewish father in Trinidad, proved to have much in common in their\ntastes and personalities—including hasty tempers and idiosyncratic\nsenses of humor (both enjoyed surprising people by sneezing in\nelevators).\n\n\nAnd both flushed the toilet both before and after using it, kept rubber\nbands around their wrists, and dipped buttered toast in their coffee.\n\nMany people are skeptical of such anecdotes. Are the parallels just\ncoincidences, the overlap that is inevitable when two biographies are\nscrutinized in enough detail? Clearly not. Bouchard and his behavior\ngeneticist colleagues D. Lykken, M. McGue, and A. Tellegen are\nrepeatedly astonished by the spooky similarities they discover in their\nidentical twins reared apart but that never appear in their fraternal\ntwins reared apart. Another pair of identical twins meeting for the\nfirst time discovered that they both used Vademecum toothpaste,\nCanoe shaving lotion, Vitalis hair tonic, and Lucky Strike cigarettes.\n\n\n328 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 480,
        "parent_text": "328 THE LANGUAGE INSTINCT\n\n\nAfter the meeting they sent each other identical birthday presents\nthat crossed in the mail. One pair of women habitually wore seven\nrings. Another pair of men pointed out (correctly) that a wheel bearing in Bouchard's car needed replacing. And quantitative research\ncorroborates the hundreds of anecdotes. Not only are very general\ntraits like IQ, extroversion, and neuroticism partly heritable, but so\nare specific ones like degree of religious feeling, vocational interests,\nand opinions about the death penalty, disarmament, and computer\nmusic."
    },
    {
        "document_id": "0",
        "parent_id": 481,
        "parent_text": "Could there really be a gene for sneezing in elevators? Presumably\nnot, but there does not have to be. Identical twins share all their\ngenes, not just one of them. So there are fifty thousand genes for\nsneezing in elevators—which are also fifty thousand genes for liking\nblue double-breasted epauletted shirts, using Vitalis hair tonic, wearing seven rings, and all the rest. The reason is that the relationship\nbetween particular genes and particular psychological traits is doubly\nindirect. First, a single gene does not build a single brain module; the\nbrain is a delicately layered souffle in which each gene product is an\ningredient with a complex effect on many properties of many circuits.\nSecond, a single brain module does not produce a single behavioral\ntrait. Most of the traits that capture our attention emerge out of\nunique combinations of kinks in many different modules. Here is an\nanalogy. Becoming an all-star basketball player requires many physical\nadvantages, like height, large hands, excellent aim, good peripheral\nvision, lots of fast-twitch muscle tissue, efficient lungs, and springy\ntendons. Though these traits are probably genetic to a large degree,\nthere does not have to be a basketball gene; those men for whom the\ngenetic slot machine stopped at three cherries play in the NBA, while\nthe more numerous seven-foot klutzes and five-foot sharpshooters go\ninto some other line of work. No doubt the same is true of any\ninteresting behavioral trait like sneezing in elevators (which is no\nodder than an aptitude for shooting a ball through a hoop with\nsomeone's hand in your face). Perhaps the sneezing-in-elevators gene\ncomplex is the one that specifies just the right combination of thresholds and cross-connections among the modules governing humor,\nreactions to enclosed spaces, sensitivity to the mental states of others\nsuch as their anxiety and boredom, and the sneezing reflex."
    },
    {
        "document_id": "0",
        "parent_id": 482,
        "parent_text": "No one has ever studied heritable variation in language, but I have\na strong suspicion of what it is like. I would expert the basic design\n\n\nLanguage Organs and Grammar Genes 329\n\n\nof language, from X-bar syntax to phonological rules and vocabulary\nstructure, to be uniform across the species; how else could children\nlearn to talk and adults understand one another? But the complexity\nof language circuitry leaves plenty of scope for quantitative variation\nto combine into unique linguistic profiles. Some module might be\nrelatively stunted or hypertrophied. Some normally unconscious representation of sound or meaning or grammatical structure might be\nmore accessible to the rest of the brain. Some connection between\nlanguage circuitry and the intellect or emotions might be faster or\nslower.\n\nThus **I** predict that there are idiosyncratic combinations of genes\n(detectable in identical twins reared apart) behind the raconteur, the\npunster, the accidental poet, the sweet-talker, the rapier-like wit,\nthe sesquipedalian, the word-juggler, the owner of the gift of gab, the\nReverend Spooner, the Mrs. Malaprop, the Alexander Haig, the woman\n(and her teenage son!) **I** once tested who can talk backwards, and\nthe student at the back of every linguistics classroom who objects that\n\n_**Who**_ _**do**_ _**you**_ _**believe**_ _**the**_ _**claim**_ _**that John**_ _**saw?**_ doesn't sound so bad.\nBetween 1988 and 1992, many people suspected that the chief executive of the United States and his second-in-command were not playing\nwith a full linguistic deck:\n\n\nI am less interested in what the definition is. You might argue\ntechnically, are we in a recession or not. But when there's this kind\nof sluggishness and concern—definitions, heck with it.\n\nI'm all for Lawrence Welk. Lawrence Welk is a wonderful man. He\nused to be, or was, or—wherever he is now, bless him.\n\n—George Bush\n\n\nHawaii has always been a very pivotal role in the Pacific. It is IN\nthe Pacific. It is a part of the United States that is an island that is\nright here."
    },
    {
        "document_id": "0",
        "parent_id": 483,
        "parent_text": "I am less interested in what the definition is. You might argue\ntechnically, are we in a recession or not. But when there's this kind\nof sluggishness and concern—definitions, heck with it.\n\nI'm all for Lawrence Welk. Lawrence Welk is a wonderful man. He\nused to be, or was, or—wherever he is now, bless him.\n\n—George Bush\n\n\nHawaii has always been a very pivotal role in the Pacific. It is IN\nthe Pacific. It is a part of the United States that is an island that is\nright here.\n\n[Speaking to the United Negro College Fund, whose motto is \"A\nmind is a terrible thing to waste\":] What a terrible thing to have\nlost one's mind. Or not to have a mind at all. How true that is.\n\n—Dan Quayle\n\n\nAnd who knows what unrepeatable amalgam of genes creates the\nlinguistic genius?\n\n\n330 THE LANGUAGE INSTINCT\n\n\nIf people don't want to come out to the ballpark, nobody's going\n\nto stop them.\nYou can observe a lot just by watching.\nIn baseball, you don't know nothing.\nNobody goes there anymore. It's too crowded.\nIt ain't over till it's over.\nIt gets late early this time of year.\n\n—Yogi Berra\n\n\nAnd N U H is the letter I use to spell Nutches\nWho live in small caves, known as Nitches, for hutches.\nThese Nutches have troubles, the biggest of which is\nThe fact there are many more Nutches than Nitches.\nEach Nutch in a Nitch knows that some other Nutch\nWould like to move into his Nitch very much.\nSo each Nutch in a Nitch has to watch that small Nitch\nOr Nutches who haven't got Nitches will snitch.\n\n—Dr. Seuss\n\n\nLolita, light of my life, fire of my loins. My sin, my soul. Lo-lee-ta:\nthe tip of the tongue taking a trip of three steps down the palate to\ntap, at three, on the teeth. Lo. Lee. Ta.\n\n—Vladimir Nabokov\n\n\nI have a dream that one day this nation will rise up and live out\nthe true meaning of its creed: \"We hold these truths to be selfevident, that all men are created equal.\""
    },
    {
        "document_id": "0",
        "parent_id": 484,
        "parent_text": "—Dr. Seuss\n\n\nLolita, light of my life, fire of my loins. My sin, my soul. Lo-lee-ta:\nthe tip of the tongue taking a trip of three steps down the palate to\ntap, at three, on the teeth. Lo. Lee. Ta.\n\n—Vladimir Nabokov\n\n\nI have a dream that one day this nation will rise up and live out\nthe true meaning of its creed: \"We hold these truths to be selfevident, that all men are created equal.\"\n\nI have a dream that one day on the red hills of Georgia the sons\nof former slaves and the sons of former slaveowners will be able to\nsit down together at the table of brotherhood.\n\nI have a dream that one day even the state of Mississippi, a state\nsweltering with the people's injustice, sweltering with the heat of\noppression, will be transformed into an oasis of freedom and justice.\n\nI have a dream that my four little children will one day live in a\nnation where they will not be judged by the color of their skin but\nby the content of their character.\n\n—Martin Luther King, Jr.\n\n\nThis goodly frame, the earth, seems to me a sterile promontory, this\nmost excellent canopy, the air, look you, this brave o'erhanging\nfirmament, this majestical roof fretted with golden fire, why, it\nappears no other thing to me than a foul and pestilent congregation\n\n\nLanguage Organs and Grammar Genes 331\n\n\nof vapours. What a piece of work is a man! how noble in reason!\nhow infinite in faculty! in form and moving how express and admirable! in action how like an angel! in apprehension how like a god!\nthe beauty of the world! the paragon of animals! And yet, to me,\nwhat is this quintessence of dust?\n\n—William Shakespeare"
    },
    {
        "document_id": "0",
        "parent_id": 485,
        "parent_text": "### 11"
    },
    {
        "document_id": "0",
        "parent_id": 486,
        "parent_text": "#### The Big Bang\n\n**The** elephant's trunk is six feet long and one foot thick and\ncontains sixty thousand muscles. Elephants can use their trunks to\nuproot trees, stack timber, or carefully place huge logs in position\nwhen recruited to build bridges. An elephant can curl its trunk\naround a pencil and draw characters on letter-size paper. With the\ntwo muscular extensions at the tip, it can remove a thorn, pick up a\npin or a dime, uncork a bottle, slide the bolt off a cage door and hide\nit on a ledge, or grip a cup so firmly, without breaking it, that only\nanother elephant can pull it away. The tip is sensitive enough for a\nblindfolded elephant to ascertain the shape and texture of objects. In\nthe wild, elephants use their trunks to pull up clumps of grass and\ntap them against their knees to knock off the dirt, to shake coconuts\nout of palm trees, and to powder their bodies with dust. They use\ntheir trunks to probe the ground as they walk, avoiding pit traps,\nand to dig wells and siphon water from them. Elephants can walk\nunderwater on the beds of deep rivers or swim like submarines for\nmiles, using their trunks as snorkels. They communicate through their\ntrunks by trumpeting, humming, roaring, piping, purring, rumbling,\nand making a crumpling-metal sound by rapping the trunk against\nthe ground. The trunk is lined with chemoreceptors that allow the\nelephant to smell a python hidden in the grass or food a mile away.\n\nElephants are the only living animals that possess this extraordinary\norgan. Their closest living terrestrial relative is the hyrax, a mammal\nthat you would probably not be able to tell from a large guinea pig.\nUntil now you have probably not given the uniqueness of the ele\n\n332\n\n\nThe Big Bang 333"
    },
    {
        "document_id": "0",
        "parent_id": 487,
        "parent_text": "Elephants are the only living animals that possess this extraordinary\norgan. Their closest living terrestrial relative is the hyrax, a mammal\nthat you would probably not be able to tell from a large guinea pig.\nUntil now you have probably not given the uniqueness of the ele\n\n332\n\n\nThe Big Bang 333\n\n\nphant's trunk a moment's thought. Certainly no biologist has made a\nfuss about it. But now imagine what might happen if some biologists\nwere elephants. Obsessed with the unique place of the trunk in\nnature, they might ask how it could have evolved, given that no other\norganism has a trunk or anything like it. One school might try to\nthink up ways to narrow the gap. They would first point out that the\nelephant and the hyrax share about 90% of their DNA and thus\ncould not be all that different. They might say that the trunk must\nnot be as complex as everyone thought; perhaps the number of\nmuscles had been miscounted. They might further note that the hyrax\nreally does have a trunk, but somehow it has been overlooked; after\nall, the hyrax does have nostrils. Though their attempts to train\nhyraxes to pick up objects with their nostrils have failed, some might\ntrumpet their success at training the hyraxes to push toothpicks\naround with their tongues, noting that stacking tree trunks or drawing\non blackboards differ from it only in degree. The opposite school,\nmaintaining the uniqueness of the trunk, might insist that it appeared\nall at once in the offspring of a particular trunkless elephant ancestor,\nthe product of a single dramatic mutation. Or they might say that the\ntrunk somehow arose as an automatic by-product of the elephant's\nhaving evolved a large head. They might add another paradox for\ntrunk evolution: the trunk is absurdly more intricate and well coordinated than any ancestral elephant would have needed."
    },
    {
        "document_id": "0",
        "parent_id": 488,
        "parent_text": "These arguments might strike us as peculiar, but every one of them\nhas been made by scientists of a different species about a complex\norgan that that species alone possesses, language. As we shall see in\nthis chapter, Chomsky and some of his fiercest opponents agree on\none thing: that a uniquely human language instinct seems to be incompatible with the modern Darwinian theory of evolution, in which\ncomplex biological systems arise by the gradual accumulation over\ngenerations of random genetic mutations that enhance reproductive\nsuccess. Either there is no language instinct, or it must have evolved\nby other means. Since **I** have been trying to convince you that there\nis a language instinct but would certainly forgive you if you would\nrather believe Darwin than believe me, **I** would also like to convince\nyou that you need not make that choice. Though we know few details\nabout how the language instinct evolved, there is no reason to doubt\nthat the principal explanation is the same as for any other complex\ninstinct or organ, Darwin's theory of natural selection.\n\n\n334 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 489,
        "parent_text": "334 THE LANGUAGE INSTINCT\n\n\nLanguage is obviously as different from other animals' communication\nsystems as the elephant's trunk is different from other animals' nostrils.\nNonhuman communication systems are based on one of three designs:\na finite repertory of calls (one for warnings of predators, one for claims\nto territory, and so on), a continuous analog signal that registers the\nmagnitude of some state (the livelier the dance of the bee, the richer the\nfood source that it is telling its hivemates about), or a series of random\nvariations on a theme (a birdsong repeated with a new twist each time:\nCharlie Parker with feathers). As we have seen, human language has a\nvery different design. The discrete combinatorial system called \"grammar\" makes human language infinite (there is no limit to the number of\ncomplex words or sentences in a language), digital (this infinity is\nachieved by rearranging discrete elements in particular orders and combinations, not by varying some signal along a continuum like the mercury\nin a thermometer), and compositional (each of the infinite combinations\nhas a different meaning predictable from the meanings of its parts and\nthe rules and principles arranging them).\n\nEven the seat of human language in the brain is special. The vocal\ncalls of primates are controlled not by their cerebral cortex but by\nphylogenetically older neural structures in the brain stem and limbic\nsystem, structures that are heavily involved in emotion. Human vocalizations other than language, like sobbing, laughing, moaning, and\nshouting in pain, are also controlled subcortically. Subcortical structures even control the swearing that follows the arrival of a hammer\non a thumb, that emerges as an involuntary tic in Tourette's syndrome,\nand that can survive as Broca's aphasics' only speech. Genuine language, as we saw in the preceding chapter, is seated in the cerebral\ncortex, primarily the left perisylvian region."
    },
    {
        "document_id": "0",
        "parent_id": 490,
        "parent_text": "Some psychologists believe that changes in the vocal organs and in\nthe neural circuitry that produces and perceives speech sounds are\nthe _only_ aspects of language that evolved in our species. On this view,\nthere are a few general learning abilities found throughout the animal\nkingdom, and they work most efficiently in humans. At some point\nin history language was invented and refined, and we have been\nlearning it ever since. The idea that species-specific behavior is caused\nby anatomy and general intelligence is captured in the Gary Larson\n_Far Side_ cartoon in which two bears hide behind a tree near a human\n\n\nThe Big Bang 335\n\n\ncouple relaxing on a blanket. One says: \"C'mon! Look at these\nfangs! . . . Look at these claws! . . . You think we're supposed to eat\njust honey and berries?\"\n\nAccording to this view, chimpanzees are the second-best learners\nin the animal kingdom, so they should be able to acquire a language\ntoo, albeit a simpler one. All it takes is a teacher. In the 1930s\nand 1940s two psychologist couples adopted baby chimpanzees. The\nchimps became part of the family and learned to dress, use the toilet,\nbrush their teeth, and wash the dishes. One of them, Gua, was raised\nalongside a boy of the same age but never spoke a word. The other,\nViki, was given arduous training in speech, mainly by the foster\nparents' molding the puzzled chimp's lips and tongue into the right\nshapes. With a lot of practice, and often with the help of her own\nhands, Viki learned to make three utterances that charitable listeners\ncould hear as _papa, mama,_ and _cup,_ though she often confused them\nwhen she got excited. She could respond to some stereotyped formulas, like _Kiss me_ and _Bring me the dog,_ but stared blankly when asked\nto act out a novel combination like _Kiss the dog._"
    },
    {
        "document_id": "0",
        "parent_id": 491,
        "parent_text": "But Gua and Viki were at a disadvantage: they were forced to use\ntheir vocal apparatus, which was not designed for speech and which\nthey could not voluntarily control. Beginning in the late 1960s, several\nfamous projects claimed to have taught language to baby chimpanzees\nwith the help of more user-friendly media. (Baby chimps are used\nbecause the adults are not the hairy clowns in overalls you see on\ntelevision, but strong, vicious wild animals who have bitten fingers off\nseveral well-known psychologists.) Sarah learned to string magnetized\nplastic shapes on a board. Lana and Kanzi learned to press buttons\nwith symbols on a large computer console or point to them on a\nportable tablet. Washoe and Koko (a gorilla) were said to have acquired American Sign Language. According to their trainers, these\napes learned hundreds of words, strung them together in meaningful\nsentences, and coined new phrases, like _water bird_ for a swan and\n_cookie rock_ for a stale Danish. \"Language is no longer the exclusive\ndomain of man,\" said Koko's trainer, Francine (Penny) Patterson.\n\nThese claims quickly captured the public's imagination and were\nplayed up in popular science books and magazines and television\nprograms like _National Geographic, Nova, Sixty Minutes,_ and _20/20._\nNot only did the projects seem to consummate our age-old yearning\nto talk to the animals, but the photo opportunities of attractive women\n\n\n336 THE LANGUAGE INSTINCT\n\n\ncommuning with apes, evocative of the beauty-and-the-beast archetype, were not lost on the popular media. Some of the projects were\ncovered by _People, Life,_ and _Penthouse_ magazines, and they were\nfictionalized in a bad movie starring Holly Hunter called _Animal_\n_Behavior_ and in a famous Pepsi commercial."
    },
    {
        "document_id": "0",
        "parent_id": 492,
        "parent_text": "336 THE LANGUAGE INSTINCT\n\n\ncommuning with apes, evocative of the beauty-and-the-beast archetype, were not lost on the popular media. Some of the projects were\ncovered by _People, Life,_ and _Penthouse_ magazines, and they were\nfictionalized in a bad movie starring Holly Hunter called _Animal_\n_Behavior_ and in a famous Pepsi commercial.\n\nMany scientists have also been captivated, seeing the projects as a\nhealthy deflation of our species' arrogant chauvinism. I have seen\npopular-science columns that list the acquisition of language by chimpanzees as one of the major scientific discoveries of the century. In a\nrecent, widely excerpted book, Carl Sagan and Ann Druyan have\nused the ape language experiments as part of a call for us to reassess\nour place in nature:\n\n\nA sharp distinction between human beings and \"animals\" is essential if we are to bend them to our will, make them work for us, wear\nthem, eat them—without any disquieting tinges of guilt or regret.\nWith untroubled consciences, we can render whole species extinct—as we do today to the tune of 100 species a day, Their loss\nis of little import: Those beings, we tell ourselves, are not like us.\nAn unbridgeable gap has thus a practical role to play beyond the\nmere stroking of human egos. Isn't there much to be proud of in\nthe lives of monkeys and apes? Shouldn't we be glad to acknowledge\na connection with Leakey, Imo, or Kanzi? Remember those macaques who would rather go hungry than profit from harming their\nfellows; might we have a more optimistic view of the human future\nif we were sure our ethics were up to their standards? And, viewed\nfrom this perspective, how shall we judge our treatment of monkeys\nand apes?"
    },
    {
        "document_id": "0",
        "parent_id": 493,
        "parent_text": "This well-meaning but misguided reasoning could only have come\nfrom writers who are not biologists. Is it really \"humility\" for us to\nsave species from extinction because we think they are like us? Or\nbecause they seem like a bunch of nice guys? What about all the\ncreepy, nasty, selfish animals who do not remind us of ourselves, or\nour image of what we would like to be—can we go ahead and wipe\nthem out? And Sagan and Druyan are no friends of the apes if they\nthink the reason we should treat the apes fairly is that they can be\ntaught human language. Like many other writers, Sagan and Druyan\nare far too credulous about the claims of the chimpanzee trainers.\n\n\nThe Big Bang 337"
    },
    {
        "document_id": "0",
        "parent_id": 494,
        "parent_text": "The Big Bang 337\n\n\nPeople who spend a lot of time with animals are prone to developing indulgent attitudes about their powers of communication. My\ngreat-aunt Bella insisted in all sincerity that her Siamese cat Rusty\nunderstood English. Many of the claims of the ape trainers were not\nmuch more scientific. Most of the trainers were schooled in the\nbehaviorist tradition of B. F. Skinner and are ignorant of the study\nof language; they latched on to the most tenuous resemblance between chimp and child and proclaimed that their abilities are fundamentally the same. The more enthusiastic trainers went over the heads\nof scientists and made their engaging case directly to the public on\nthe _Tonight Show_ and _National Geographic._ Patterson in particular\nhas found ways to excuse Koko's performance on the grounds that\nthe gorilla is fond of puns, jokes, metaphors, and mischievous lies.\nGenerally the stronger the claims about the animal's abilities, the\nskimpier the data made available to the scientific community for\nevaluation. Most of the trainers have refused all requests to share\ntheir raw data, and Washoe's trainers, Beatrice and Alan Gardner,\nthreatened to sue another researcher because he used frames of one\nof their films (the only raw data available to him) in a critical scientific\narticle. That researcher, Herbert Terrace, together with the psychologists Laura Ann Petitto, Richard Sanders, and Tom Bever, had tried\nto teach ASL to one of Washoe's relatives, whom they named Nim\nChimpsky. They carefully tabulated and analyzed his signs, and Petitto, with the psychologist Mark Seidenberg, also scrutinized the\nvideotapes and what published data there were on the other signing\napes, whose abilities were similar to Nim's. More recently, Joel Wallman has written a history of the topic called _Aping Language._ The\nmoral of their investigations is: Don't believe everything you hear on\nthe _Tonight Show._"
    },
    {
        "document_id": "0",
        "parent_id": 495,
        "parent_text": "To begin with, the apes did _not_ \"learn American Sign Language.\"\nThis preposterous claim is based on the myth that ASL is a crude\nsystem of pantomimes and gestures rather than a full language with\ncomplex phonology, morphology, and syntax. In fact the apes had\nnot learned _any_ true ASL signs. The one deaf native signer on the\nWashoe team later made these candid remarks:\n\n\nEvery time the chimp made a sign, we were supposed to write it\ndown in the log. . . . They were always complaining because my log\ndidn't show enough signs. All the hearing people turned in logs\n\n\n338 THE LANGUAGE INSTINCT\n\n\nwith long lists of signs. They always saw more signs than I did....\nI watched really carefully. The chimp's hands were moving constantly. Maybe I missed something, but I don't think so. I just wasn't\nseeing any signs. The hearing people were logging every movement\nthe chimp made as a sign. Every time the chimp put his finger in\nhis mouth, they'd say \"Oh, he's making the sign for _drink,\"_ and\nthey'd give him some milk. . . . When the chimp scratched itself,\nthey'd record it as the sign for _scratch. . . ._ When [the chimps] want\nsomething, they reach. Sometimes [the trainers would] say, \"Oh,\namazing, look at that, it's exactly like the ASL sign for _give_ !\" It\nwasn't.\n\n\nTo arrive at their vocabulary counts in the hundreds, the investigators\nwould also \"translate\" the chimps' pointing as a sign for _you,_ their\nhugging as a sign for _hug,_ their picking, tickling, and kissing as signs\nfor _pick, tickle,_ and _kiss._ Often the same movement would be credited\nto the chimps as different \"words,\" depending on what the observers\nthought the appropriate word would be in the context. In the experiments in which the chimps interacted with a computer console, the\nkey that the chimp had to press to initialize the computer was\ntranslated as the word _please._ Petitto estimates that with more standard criteria the true vocabulary count would be closer to 25 than 125."
    },
    {
        "document_id": "0",
        "parent_id": 496,
        "parent_text": "Actually, what the chimps were really doing was more interesting\nthan what they were claimed to be doing. Jane Goodall, visiting the\nproject, remarked to Terrace and Petitto that every one of Nim's socalled signs was familiar to her from her observations of chimps in\nthe wild. The chimps were relying heavily on the gestures in their\nnatural repertoire, rather than learning true arbitrary ASL signs with\ntheir combinatorial phonological structure of hand shapes, motions,\nlocations, and orientations. Such backsliding is common when humans train animals. Two enterprising students of B. F. Skinner, Keller\nand Marian Breland, took his principles for shaping the behavior of\nrats and pigeons with schedules of reward and turned them into\na lucrative career of training circus animals. They recounted their\nexperiences in a famous article called \"The Misbehavior of Organisms,\" a play on Skinner's book _The Behavior of Organisms._ In some\nof their acts the animals were trained to insert poker chips in little\njuke boxes and vending machines for a food reward. Though the\ntraining schedules were the same for the various animals, their species\n\nThe Big Bang 339\n\n\nspecific instincts bled through. The chickens spontaneously pecked\nat the chips, the pigs tossed and rooted them with their snouts, and\nthe raccoons rubbed and washed them."
    },
    {
        "document_id": "0",
        "parent_id": 497,
        "parent_text": "The Big Bang 339\n\n\nspecific instincts bled through. The chickens spontaneously pecked\nat the chips, the pigs tossed and rooted them with their snouts, and\nthe raccoons rubbed and washed them.\n\nThe chimp's abilities at anything one would want to call grammar\nwere next to nil. Signs were not coordinated into the well-defined\nmotion contours of ASL and were not inflected for aspect, agreement,\nand so on—a striking omission, since inflection is the primary means\nin ASL of conveying who did what to whom and many other kinds\nof information. The trainers frequently claim that the chimps have\nsyntax, because pairs of signs are sometimes placed in one order more\noften than chance would predict, and because the brighter chimps\ncan act out sequences like _Would you please carry the cooler to Penny._\nBut remember from the Loebner Prize competition (for the most\nconvincing computer simulation of a conversational partner) how\neasy it is to fool people into thinking that their interlocutors have\nhumanlike talents. To understand the request, the chimp could ignore\nthe symbols _would, you, please, carry, the,_ and _to;_ all the chimp had\nto notice was the order of the two nouns (and in most of the tests,\nnot even that, because it is more natural to carry a cooler to a person\nthan a person to a cooler). True, some of the chimps can carry out\nthese commands more reliably than a two-year-old child, but this says\nmore about temperament than about grammar: the chimps are highly\ntrained animal acts, and a two-year-old is a two-year-old.\n\nAs far as spontaneous output is concerned, there is no comparison.\nOver several years of intensive training, the average length of the\nchimps' \"sentences\" remains constant. With nothing more than exposure to speakers, the average length of a child's sentences shoots off\nlike a rocket. Recall that typical sentences from a two-year-old child\nare _Look at that train Ursula brought_ and _We going turn light on so_\n_you can't see._ Typical sentences from a language-trained chimp are:"
    },
    {
        "document_id": "0",
        "parent_id": 498,
        "parent_text": "As far as spontaneous output is concerned, there is no comparison.\nOver several years of intensive training, the average length of the\nchimps' \"sentences\" remains constant. With nothing more than exposure to speakers, the average length of a child's sentences shoots off\nlike a rocket. Recall that typical sentences from a two-year-old child\nare _Look at that train Ursula brought_ and _We going turn light on so_\n_you can't see._ Typical sentences from a language-trained chimp are:\n\n\nNim eat Nim eat.\nDrink eat me Nim.\nMe gum me gum.\nTickle me Nim play.\nMe eat me eat.\nMe banana you banana me you give.\nYou me banana me banana you.\nBanana me me me eat.\n\n\n340 THE LANGUAGE INSTINCT\n\n\nGive orange me give eat orange me eat orange give me eat\norange give me you.\n\n\nThese jumbles bear scant resemblance to children's sentences. (By\nwatching long enough, of course, one is bound to find random combinations in the chimps' gesturing that can be given sensible interpretations, like _water bird)._ But the strings _do_ resemble animal behavior in\nthe wild. The zoologist E. O. Wilson, summing up a survey of animal\ncommunication, remarked on its most striking property: animals, he\nsaid, are \"repetitious to the point of inanity.\""
    },
    {
        "document_id": "0",
        "parent_id": 499,
        "parent_text": "Even putting aside vocabulary, phonology, morphology, and syntax, what impresses one the most about chimpanzee signing is that\nfundamentally, deep down, chimps just don't \"get it.\" They know\nthat the trainers like them to sign and that signing often gets them\nwhat they want, but they never seem to feel in their bones what\nlanguage is and how to use it. They do not take turns in conversation\nbut instead blithely sign simultaneously with their partner, frequently\noff to the side or under a table rather than in the standardized signing\nspace in front of the body. (Chimps also like to sign with their feet,\nbut no one blames them for taking advantage of this anatomical gift.)\nThe chimps seldom sign spontaneously; they have to be molded,\ndrilled, and coerced. Many of their \"sentences,\" especially the ones\nshowing systematic ordering, are direct imitations of what the trainer\nhas just signed, or minor variants of a small number of formulas that\nthey have been trained on thousands of times. They do not even\nclearly get the idea that a particular sign might refer to a kind of\nobject. Most of the chimps' object signs can refer to any aspect of the\nsituation with which an object is typically associated. _Toothbrush_\ncan mean \"toothbrush,\" \"toothpaste,\" \"brushing teeth,\" \"I want my\ntoothbrush,\" or \"It's time for bed.\" _Juice_ can mean \"juice,\" \"where\njuice is usually kept,\" or \"Take me to where the juice is kept.\" Recall\nfrom Ellen Markman's experiments in Chapter 5 that children use\nthese \"thematic\" associations when sorting pictures into groups, but\nthey ignore them when learning word meanings: to them, a _dax_ is a\ndog or another dog, not a dog or its bone. Also, the chimps rarely\nmake statements that comment on interesting objects or actions;\nvirtually all their signs are demands for something they want, usually\nfood or tickling. I cannot help but think of a moment with my twoyear-old niece Eva that captures how different are the minds of child\n\n\nThe Big Bang 341"
    },
    {
        "document_id": "0",
        "parent_id": 500,
        "parent_text": "The Big Bang 341\n\n\nand chimp. One night the family was driving on an expressway, and\nwhen the adult conversation died down, a tiny voice from the back\nseat said, \"Pink.\" **I** followed her gaze, and on the horizon several\nmiles away I could make out a pink neon sign. She was commenting\non its color, just for the sake of commenting on its color."
    },
    {
        "document_id": "0",
        "parent_id": 501,
        "parent_text": "Within the field of psychology, most of the ambitious claims about\nchimpanzee language are a thing of the past. Nim's trainer Herbert\nTerrace, as mentioned, turned from enthusiast to whistle-blower.\nDavid Premack, Sarah's trainer, does not claim that what she acquired\nis comparable to human language; he uses the symbol system as\na tool to do chimpanzee cognitive psychology. The Gardners and\nPatterson have distanced themselves from the community of scientific\ndiscourse for over a decade. Only one team is currently making\nclaims about language. Sue Savage-Rumbaugh and Duane Rumbaugh\nconcede that the chimps they trained at the computer console did\nnot learn much. But they are now claiming that a different variety of\nchimpanzee does much better. Chimpanzees come from some half a\ndozen mutually isolated \"islands\" of forest in the west African continent, and the groups have diverged over the past million years to the\npoint where some of the groups are sometimes classified as belonging\nto different species. Most of the trained chimps were \"common chimps\";\nKanzi is a \"pygmy chimp\" or \"bonobo,\" and he learned to bang on\nvisual symbols on a portable tablet. Kanzi, says Savage-Rumbaugh, does\nsubstantially better at learning symbols (and at understanding spoken\nlanguage) than common chimps. Why he would be expected to do so\nmuch better than members of his sibling species is not clear; contrary\nto some reports in the press, pygmy chimps are no more closely related\nto humans than common chimps are. Kanzi is said to have learned his\ngraphic symbols without having been laboriously trained on them—but\nhe was at his mother's side watching while _she_ was laboriously trained\non them (unsuccessfully). He is said to use the symbols for purposes\nother than requesting—but at best only four percent of the time. He is\nsaid to use three-symbol \"sentences\"—but they are really fixed formulas\nwith no internal structure and are not even three symbols long. The socalled sentences are all chains like the symbol for chase followed by the"
    },
    {
        "document_id": "0",
        "parent_id": 502,
        "parent_text": "graphic symbols without having been laboriously trained on them—but\nhe was at his mother's side watching while _she_ was laboriously trained\non them (unsuccessfully). He is said to use the symbols for purposes\nother than requesting—but at best only four percent of the time. He is\nsaid to use three-symbol \"sentences\"—but they are really fixed formulas\nwith no internal structure and are not even three symbols long. The socalled sentences are all chains like the symbol for chase followed by the\nsymbol for hide followed by a point to the person Kanzi wants to do\nthe chasing and hiding. Kanzi's language abilities, if one is being charitable, are above those of his common cousins by a just-noticeable difference, but no more."
    },
    {
        "document_id": "0",
        "parent_id": 503,
        "parent_text": "342 THE LANGUAGE INSTINCT\n\n\nWhat an irony it is that the supposed attempt to bring _Homo_\n_sapiens_ down a few notches in the natural order has taken the form\nof us humans hectoring another species into emulating our instinctive\nform of communication, or some artificial form we have invented,\nas if that were the measure of biological worth. The chimpanzees'\nresistance is no shame on them; a human would surely do no better\nif trained to hoot and shriek like a chimp, a symmetrical project that\nmakes about as much scientific sense. In fact, the idea that some\nspecies needs our intervention before its members can display a useful\nskill, like some bird that could not fly until given a human education,\nis far from humble!\n\n\nSo human language differs dramatically from natural and artificial\nanimal communication. What of it? Some people, recalling Darwin's\ninsistence on the gradualness of evolutionary change, seem to believe\nthat a detailed examination of chimps' behavior is unnecessary: they\nmust have some form of language, as a matter of principle. Elizabeth\nBates, a vociferous critic of Chomskyan approaches to language, writes:\n\n\nIf the basic structural principles of language cannot be learned (bottom\nup) or derived (top down), there are only two possible explanations\nfor their existence: either Universal Grammar was endowed to us\ndirectly by the Creator, or else our species has undergone a mutation\nof unprecedented magnitude, a cognitive equivalent of the Big\nBang.... We have to abandon any strong version of the discontinuity\nclaim that has characterized generative grammar for thirty years. We\nhave to find some way to ground symbols and syntax in the mental\nmaterial that we share with other species."
    },
    {
        "document_id": "0",
        "parent_id": 504,
        "parent_text": "But, in fact, if human language is unique in the modern animal\nkingdom, as it appears to be, the implications for a Darwinian account\nof its evolution would be as follows: none. A language instinct unique\nto modern humans poses no more of a paradox than a trunk unique\nto modern elephants. No contradiction, no Creator, no big bang.\n\nModern evolutionary biologists are alternately amused and annoyed by a curious fact. Though most educated people profess to\nbelieve in Darwin's theory, what they really believe in is a modified\nversion of the ancient theological notion of the Great Chain of Being:\n\n\n**The Big Bang** 343\n\n\nthat all species are arrayed in a linear hierarchy with humans at the top.\nDarwin's contribution, according to this belief, was showing that each\nspecies on the ladder evolved from the species one rung down, instead\nof being allotted its rung by God. Dimly remembering their high school\nbiology classes that took them on a tour of the phyla from \"primitive\"\nto \"modern,\" people think roughly as follows: amoebas begat sponges\nwhich begat jellyfish which begat flatworms which begat trout which\nbegat frogs which begat lizards which begat dinosaurs which begat\nanteaters which begat monkeys which begat chimpanzees which begat\nus. (I have skipped a few steps for the sake of brevity.)\n\n\n**The Wrong Theory**\n\n\nHence the paradox: humans enjoy language while their neighbors on\nthe adjacent rung have nothing of the kind. We expect a fade-in, but\nwe see a big bang.\n\nBut evolution did not make a ladder; it made a bush. We did\nnot evolve from chimpanzees. We and chimpanzees evolved from a\ncommon ancestor, now extinct. The human-chimp ancestor evolved\nnot from monkeys but from an even older ancestor of the two, also\nextinct. And so on, back to our single-celled forebears. Paleontologists like to say that to a first approximation, all species are extinct\n\n\n344 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 505,
        "parent_text": "But evolution did not make a ladder; it made a bush. We did\nnot evolve from chimpanzees. We and chimpanzees evolved from a\ncommon ancestor, now extinct. The human-chimp ancestor evolved\nnot from monkeys but from an even older ancestor of the two, also\nextinct. And so on, back to our single-celled forebears. Paleontologists like to say that to a first approximation, all species are extinct\n\n\n344 THE LANGUAGE INSTINCT\n\n\n(ninety-nine percent is the usual estimate). The organisms we see\naround us are distant cousins, not great-grandparents; they are a few\nscattered twig-tips of an enormous tree whose branches and trunk\nare no longer with us. Simplifying a lot:\n\n\n**Amoebas Jellyfish Flatworms Trout Lizards Anteaters Chimps** _**H. sapiens**_ **Monkeys Sponges**\n\n\nZooming in on our branch, we see chimpanzees off on a separate\nsub-branch, not sitting on top of us.\n\n\nThe Big Bang 345\n\n\nWe also see that a form of language could first have emerged at the\nposition of the arrow, after the branch leading to humans split off\nfrom the one leading to chimpanzees. The result would be languageless chimps and approximately five to seven million years in\nwhich language could have gradually evolved. Indeed, we should\nzoom in even closer, because species do not mate and produce baby\nspecies; organisms mate and produce baby organisms. Species are an\nabbreviation for chunks of a vast family tree composed of individuals,\nsuch as the _particular_ gorilla, chimp, australopithecine, _erectus,_ archaic\n_sapiens,_ Neanderthal, and modern _sapiens_ I have named in this family\ntree:\n\n\nSo if the first trace of a proto-language ability appeared in the ancestor\nat the arrow, there could have been on the order of 350,000 generations between then and now for the ability to have been elaborated\n\n\n346 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 506,
        "parent_text": "So if the first trace of a proto-language ability appeared in the ancestor\nat the arrow, there could have been on the order of 350,000 generations between then and now for the ability to have been elaborated\n\n\n346 THE LANGUAGE INSTINCT\n\n\nand fine-tuned to the Universal Grammar we see today. For all we\nknow, language could have had a gradual fade-in, even if no extant\nspecies, not even our closest living relatives the chimpanzees, have it.\nThere were plenty of organisms with intermediate language abilities,\nbut they are all dead."
    },
    {
        "document_id": "0",
        "parent_id": 507,
        "parent_text": "346 THE LANGUAGE INSTINCT\n\n\nand fine-tuned to the Universal Grammar we see today. For all we\nknow, language could have had a gradual fade-in, even if no extant\nspecies, not even our closest living relatives the chimpanzees, have it.\nThere were plenty of organisms with intermediate language abilities,\nbut they are all dead.\n\nHere is another way to think about it. People see chimpanzees, the\nliving species closest to us, and are tempted to conclude that they, at\nthe very least, must have some ability that is ancestral to language.\nBut because the evolutionary tree is a tree of individuals, not species,\n\"the living species closest to us\" has no special status; what that\nspecies is depends on the accidents of extinction. Try the following\nthought experiment. Imagine that anthropologists discover a relict\npopulation of _Homo habilis_ in some remote highland. _Habilis_ would\nnow be our closest living relatives. Would that take the pressure off\nchimps, so it is not so important that they have something like language after all? Or do it the other way around. Imagine that some\nepidemic wiped out all the apes several thousand years ago. Would\nDarwin be in danger unless we showed that monkeys had language?\nIf you are inclined to answer yes, just push the thought experiment\none branch up: imagine that in the past some extraterrestrials developed a craze for primate fur coats, and hunted and trapped all the\nprimates to extinction except hairless us. Would insectivores like\nhedgehogs have to shoulder the proto-language burden? What if the\naliens went for mammals in general? Or developed a taste for vertebrate flesh, sparing us because they like the sitcom reruns that we\ninadvertently broadcast into space? Would we then have to look for\ntalking starfish? Or ground syntax in the mental material we share\nwith sea cucumbers?"
    },
    {
        "document_id": "0",
        "parent_id": 508,
        "parent_text": "Obviously not. Our brains, and chimpanzee brains, and anteater\nbrains, have whatever wiring they have; the wiring cannot change\ndepending on which other species a continent away happen to survive\nor go extinct. The point of these thought experiments is that the\ngradualness that Darwin made so much about applies to lineages of\nindividual organisms in a bushy family tree, not to entire living species\nin a great chain. For reasons that we will cover soon, an ancestral ape\nwith nothing but hoots and grunts is unlikely to have given birth to\na baby who could learn English or Kivunjo. But it did not have\nto; there was a chain of several hundred thousand generations of\ngrandchildren in which such abilities could gradually blossom. To\n\n\nThe Big Bang 347\n\n\ndetermine when in fact language began, we have to look at people,\nand look at animals, and note what we see; we cannot use the idea\nof phyletic continuity to legislate the answer from the armchair."
    },
    {
        "document_id": "0",
        "parent_id": 509,
        "parent_text": "The Big Bang 347\n\n\ndetermine when in fact language began, we have to look at people,\nand look at animals, and note what we see; we cannot use the idea\nof phyletic continuity to legislate the answer from the armchair.\n\nThe difference between bush and ladder also allows us to put a lid\non a fruitless and boring debate. That debate is over what qualifies\nas True Language. One side lists some qualities that human language\nhas but that no animal has yet demonstrated: reference, use of symbols\ndisplaced in time and space from their referents, creativity, categorical\nspeech perception, consistent ordering, hierarchical structure, infinity, recursion, and so on. The other side finds some counterexample\nin the animal kingdom (perhaps budgies can discriminate speech\nsounds, or dolphins or parrots can attend to word order when carrying out commands, or some songbird can improvise indefinitely\nwithout repeating itself) and then gloats that the citadel of human\nuniqueness has been breached. The Human Uniqueness team relinquishes that criterion but emphasizes others or adds new ones to the\nlist, provoking angry objections that they are moving the goalposts.\nTo see how silly this all is, imagine a debate over whether flatworms\nhave True Vision or houseflies have True Hands. Is an iris critical?\nEyelashes? Fingernails? Who cares? This is a debate for dictionarywriters, not scientists. Plato and Diogenes were not doing biology\nwhen Plato defined man as a \"featherless biped\" and Diogenes refuted him with a plucked chicken."
    },
    {
        "document_id": "0",
        "parent_id": 510,
        "parent_text": "The fallacy in all this is that there is some line to be drawn across\nthe ladder, the species on the rungs above it being credited with some\nglorious trait, those below lacking it. In the tree of life, traits like eyes\nor hands or infinite vocalizations can arise on any branch, or several\ntimes on different branches, some leading to humans, some not. There\nis an important scientific issue at stake, but it is not whether some\nspecies possesses the true version of a trait as opposed to some pale\nimitation or vile impostor. The issue is which traits are _homologous_\nto which other ones.\n\nBiologists distinguish two kinds of similarity. \"Analogous\" traits\nare ones that have a common function but arose on different branches\nof the evolutionary tree and are in an important sense not \"the same\"\norgan. The wings of birds and the wings of bees are a textbook\nexample; they are both used for flight and are similar in some ways\nbecause anything used for flight has to be built in those ways, but\nthey arose independently in evolution and have nothing in common\n\n\n348 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 511,
        "parent_text": "Biologists distinguish two kinds of similarity. \"Analogous\" traits\nare ones that have a common function but arose on different branches\nof the evolutionary tree and are in an important sense not \"the same\"\norgan. The wings of birds and the wings of bees are a textbook\nexample; they are both used for flight and are similar in some ways\nbecause anything used for flight has to be built in those ways, but\nthey arose independently in evolution and have nothing in common\n\n\n348 THE LANGUAGE INSTINCT\n\n\nbeyond their use in flight. \"Homologous\" traits, in contrast, may or\nmay not have a common function, but they descended from a common\nancestor and hence have some common structure that bespeaks their\nbeing \"the same\" organ. The wing of a bat, the front leg of ahorse,\nthe flipper of a seal, the claw of a mole, and the hand of a human\nhave very different functions, but they are all modifications of the\nforelimb of the ancestor of all mammals, and as a result they share\nnonfunctional traits like the number of bones and the ways they are\nconnected. To distinguish analogy from homology, biologists usually\nlook at the overall architecture of the organs and focus on their most\nuseless properties—the useful ones could have arisen independently\nin two lineages _because_ they are useful (a nuisance to taxonomists\ncalled convergent evolution). We deduce that bat wings are really\nhands because we can see the wrist and count the joints in the fingers,\nand because that is not the only way that nature could have built a\nwing."
    },
    {
        "document_id": "0",
        "parent_id": 512,
        "parent_text": "The interesting question is whether human language is homologous\nto—biologically \"the same thing\" as—anything in the modern animal\nkingdom. Discovering a similarity like sequential ordering is pointless,\nespecially when it is found on a remote branch that is surely not\nancestral to humans (birds, for example). Here primates are relevant,\nbut the ape-trainers and their fans are playing by the wrong rules.\nImagine that their wildest dreams are realized and some chimpanzee\ncan be taught to produce real signs, to group and order them consistently to convey meaning, to use them spontaneously to describe\nevents, and so on. Does that show that the human ability to learn\nlanguage evolved from the chimp ability to learn the artificial sign\nsystem? Of course not, any more than a seagull's wings show that it\nevolved from mosquitos. Any resemblance between the chimps' symbol system and human language would not be a legacy of their common ancestor; the features of the symbol system were deliberately\ndesigned by the scientists and acquired by the chimps because it was\nuseful to them then and there. To check for homology, one would\nhave to find some signature trait that reliably emerges both in ape\nsymbol systems and in human language, and that is not so indispensable to communication that it was likely to have emerged twice, once\nin the course of human evolution and once in the lab meetings of the\npsychologists as they contrived the system to teach their apes. One\ncould look for such signatures in development, checking the apes for\n\n\nThe Big Bang 349"
    },
    {
        "document_id": "0",
        "parent_id": 513,
        "parent_text": "The Big Bang 349\n\n\nsome echo of the standard human sequence from syllable babbling\nto jargon babbling to first words to two-word sequences to a grammar\nexplosion. One could look at the developed grammar, seeing if apes\ninvent or favor some specimen of nouns and verbs, inflections, X-bar\nsyntax, roots and stems, auxiliaries in second position inverting to\nform questions, or other distinctive aspects of universal human grammar. (These structures are not so abstract as to be undetectable; they\nleapt out of the data when linguists first looked at American Sign\nLanguage and Creoles, for example.) And one could look at neuroanatomy, checking for control by the left perisylvian regions of the\ncortex, with grammar more anterior, dictionary more posterior. This\nline of questioning, routine in biology since the nineteenth century,\nhas never been applied to chimp signing, though one can make a\ngood prediction of what the answers would be.\n\n\nHow plausible is it that the ancestor to language first appeared\nafter the branch leading to humans split off from the branch leading\nto chimps? Not very, says Philip Lieberman, one of the scientists who\nbelieve that vocal tract anatomy and speech control are the only\nthings that were modified in evolution, not a grammar module: \"Since\nDarwinian natural selection involves small incremental steps that enhance the present function of the specialized module, the evolution\nof a 'new' module is logically impossible.\" Now, something has gone\nseriously awry in this argument. Humans evolved from single-celled\nancestors. Single-celled ancestors had no arms, legs, heart, eyes, liver,\nand so on. Therefore eyes and livers are logically impossible."
    },
    {
        "document_id": "0",
        "parent_id": 514,
        "parent_text": "The point that the argument misses is that although natural selection involves incremental steps that enhance functioning, the enhancements do not have to be to an existing module. They can slowly build\na module out of some previously nondescript stretch of anatomy, or\nout of the nooks and crannies between existing modules, which the\nbiologists Stephen Jay Gould and Richard Lewontin call \"spandrels,\"\nfrom the architectural term for the space between two arches. An\nexample of a new module is the eye, which has arisen de novo some\nforty separate times in animal evolution. It can begin in an eyeless\norganism with a patch of skin whose cells are sensitive to light. The\npatch can deepen into a pit, cinch up into a sphere with a hole in\nfront, grow a translucent cover over the hole, and so on, each step\n\n\n350 THE LANGUAGE INSTINCT\n\n\nallowing the owner to detect events a bit better. An example of a\nmodule growing out of bits that were not originally a module is the\nelephant's trunk. It is a brand-new organ, but homologies suggest\nthat it evolved from a fusion of the nostrils and some of the upper\nlip muscles of the extinct elephant-hyrax common ancestor, followed\nby radical complications and refinements."
    },
    {
        "document_id": "0",
        "parent_id": 515,
        "parent_text": "350 THE LANGUAGE INSTINCT\n\n\nallowing the owner to detect events a bit better. An example of a\nmodule growing out of bits that were not originally a module is the\nelephant's trunk. It is a brand-new organ, but homologies suggest\nthat it evolved from a fusion of the nostrils and some of the upper\nlip muscles of the extinct elephant-hyrax common ancestor, followed\nby radical complications and refinements.\n\nLanguage could have arisen, and probably did arise, in a similar\nway: by a revamping of primate brain circuits that originally had no\nrole in vocal communication, and by the addition of some new ones.\nThe neuroanatomists Al Galaburda and Terrence Deacon have discovered areas in monkey brains that correspond in location, inputoutput cabling, and cellular composition to the human language areas.\nFor example, there are homologues to Wernicke's and Broca's areas\nand a band of fibers connecting the two, just as in humans. The\nregions are not involved in producing the monkeys' calls, nor are they\ninvolved in producing their gestures. The monkey seems to use the\nregions corresponding to Wernicke's area and its neighbors to recognize sound sequences and to discriminate the calls of other monkeys\nfrom its own calls. The Broca's homologues are involved in control\nover the muscles of the face, mouth, tongue, and larynx, and various\nsubregions of these homologues receive inputs from the parts of the\nbrain dedicated to hearing, the sense of touch in the mouth, tongue,\nand larynx, and areas in which streams of information from all the\nsenses converge. No one knows exactly why this arrangement is found\nin monkeys and, presumably, their common ancestor with humans,\nbut the arrangement would have given evolution some parts it could\ntinker with to produce the human language circuitry, perhaps exploiting the confluence of vocal, auditory, and other signals there."
    },
    {
        "document_id": "0",
        "parent_id": 516,
        "parent_text": "Brand-new circuits in this general territory could have arisen, too.\nNeuroscientists charting the cortex with electrodes have occasionally\nfound mutant monkeys who have one extra visual map in their brains\ncompared to standard monkeys (visual maps are the postage-stampsized brain areas that are a bit like internal graphics buffers, registering the contours and motions of the visible world in a distorted\npicture). A sequence of genetic changes that duplicate a brain map\nor circuit, reroute its inputs and outputs, and frob, twiddle, and tweak\nits internal connections could manufacture a genuinely new brain\nmodule.\n\nBrains can be rewired only if the genes that control their wiring\n\n\nThe Big Bang 351\n\n\nhave changed. This brings up another bad argument about why chimp\nsigning must be like human language. The argument is based on the\nfinding that chimpanzees and humans share 98% to 99% of their\nDNA, a factoid that has become as widely circulated as the supposed\nfour hundred Eskimo words for snow (the comic strip _Zippy_ recently\nquoted the figure as \"99.9%\"). The implication is that we must be\n99% similar to chimpanzees."
    },
    {
        "document_id": "0",
        "parent_id": 517,
        "parent_text": "The Big Bang 351\n\n\nhave changed. This brings up another bad argument about why chimp\nsigning must be like human language. The argument is based on the\nfinding that chimpanzees and humans share 98% to 99% of their\nDNA, a factoid that has become as widely circulated as the supposed\nfour hundred Eskimo words for snow (the comic strip _Zippy_ recently\nquoted the figure as \"99.9%\"). The implication is that we must be\n99% similar to chimpanzees.\n\nBut geneticists are appalled at such reasoning and take pains to\nstifle it in the same breath that they report their results. The recipe\nfor the embryological souffle is so baroque that small genetic changes\ncan have enormous effects on the final product. And a 1% difference\nis not even so small. In terms of the information content in the DNA\nit is 10 megabytes, big enough for Universal Grammar with lots of\nroom left over for the rest of the instructions on how to turn a chimp\ninto a human. Indeed, a 1% difference in total DNA does not even\nmean that only 1% of human and chimpanzee genes are different. It\ncould, in theory, mean that 100% of human and chimpanzee genes\nare different, each by 1%. DNA is a discrete combinatorial code, so\na 1% difference in the DNA for a gene can be as significant as a\n100% difference, just as changing one bit in every byte, or one letter\nin every word, can result in a new text that is 100% different, not\n10% or 20% different. The reason, for DNA, is that even a single\namino-acid substitution can change the shape of a protein enough to\nalter its function completely; this is what happens in many fatal\ngenetic diseases. Data on genetic similarity are useful in figuring\nout how to connect up a family tree (for example, whether gorillas\nbranched off from a common ancestor of humans and chimps or\nhumans branched off from a common ancestor of chimps and gorillas)\nand perhaps even to date the divergences using a \"molecular clock.\"\nBut they say nothing about how similar the organisms' brains and\nbodies are."
    },
    {
        "document_id": "0",
        "parent_id": 518,
        "parent_text": "The ancestral brain could have been rewired only if the new circuits\nhad some effect on perception and behavior. The first steps toward\nhuman language are a mystery. This did not stop philosophers in the\nnineteenth century from offering fanciful speculations, such as that\nspeech arose as imitations of animal sounds or as oral gestures that\nresembled the objects they represented, and linguists subsequently\n\n\n352 THE LANGUAGE INSTINCT\n\n\ngave these speculations pejorative names like the bow-wow theory and\nthe ding-dong theory. Sign language has frequently been suggested as\nan intermediate, but that was before scientists discovered that sign\nlanguage was every bit as complex as speech. Also, signing seems to\ndepend on Broca's and Wernicke's areas, which are in close proximity\nto vocal and auditory areas in the cortex, respectively. To the extent\nthat brain areas for abstract computation are placed near the centers\nthat process their inputs and outputs, this would suggest that speech\nis more basic. If I were forced to think about intermediate steps, I\nmight ponder the vervet monkey alarm calls studied by Cheney and\nSeyfarth, one of which warns of eagles, one of snakes, and one of\nleopards. Perhaps a set of quasi-referential calls like these came under\nthe voluntary control of the cerebral cortex, and came to be produced\nin combination for complicated events; the ability to analyze combinations of calls was then applied to the parts of each call. But I admit\nthat this idea has no more evidence in its favor than the ding-dong\ntheory (or than Lily Tomlin's suggestion that the first human sentence\nwas \"What a hairy back!\")."
    },
    {
        "document_id": "0",
        "parent_id": 519,
        "parent_text": "Also unknown is when, in the lineage beginning at the chimphuman common ancestor, proto-language first evolved, or the rate at\nwhich it developed into the modern language instinct. In the tradition\nof the drunk looking for his keys under the lamppost because that is\nwhere the light is best, many archaeologists have tried to infer our\nextinct ancestors' language abilities from their tangible remnants such\nas stone tools and dwellings. Complex artifacts are thought to reflect a\ncomplex mind which could benefit from complex language. Regional\nvariation in tools is thought to suggest cultural transmission, which\ndepends in turn on generation-to-generation communication, perhaps\nvia language. However, I suspect that any investigation that depends\non what an ancient group left behind will seriously underestimate\nthe antiquity of language. There are many modern hunter-gatherer\npeoples with sophisticated language and technology, but their baskets, clothing, baby slings, boomerangs, tents, traps, bows and arrows,\nand poisoned spears are not made of stone and would rot into nothing\nquickly after their departure, obscuring their linguistic competence\nfrom future archaeologists.\n\nThus the first traces of language could have appeared as early as\n_Australopithecus afarensis_ (first discovered as the famous \"Lucy\" fos\n\nThe Big Bang 353"
    },
    {
        "document_id": "0",
        "parent_id": 520,
        "parent_text": "Thus the first traces of language could have appeared as early as\n_Australopithecus afarensis_ (first discovered as the famous \"Lucy\" fos\n\nThe Big Bang 353\n\n\nsil), at 4 million years old our most ancient fossilized ancestor. Or\nperhaps even earlier; there are few fossils from the time between the\nhuman-chimp split 5 to 7 million years ago and _A. afarensis._ Evidence\nfor a lifestyle into which language could plausibly be woven gets\nbetter with later species. _Homo habilis,_ which lived about 2.5 to 2\nmillion years ago, left behind caches of stone tools that may have\nbeen home bases or local butchering stations; in either case they\nsuggest some degree of cooperation and acquired technology. _Habilis_\nwas also considerate enough to have left us some of their skulls, which\nbear faint imprints of the wrinkle patterns of their brains. Broca's\narea is large and prominent enough to be visible, as are the supramarginal and angular gyri (the language areas shown in the brain diagram\nin Chapter 10), and these areas are larger in the left hemisphere. We\ndo not, however, know whether habilines used them for language;\nremember that even monkeys have a small homologue to Broca's area.\n_Homo erectus,_ which spread from Africa across much of the old world\nfrom 1.5 million to 500,000 years ago (all the way to China and\nIndonesia), controlled fire and almost everywhere used the same\nsymmetrical, well-crafted stone hand-axes. It is easy to imagine some\nform of language contributing to such successes, though again we\ncannot be sure."
    },
    {
        "document_id": "0",
        "parent_id": 521,
        "parent_text": "Modern _Homo sapiens,_ which is thought to have appeared about\n200,000 years ago and to have spread out of Africa 100,000 years\nago, had skulls like ours and much more elegant and complex tools,\nshowing considerable regional variation. It is hard to believe that\nthey lacked language, given that biologically they _were_ us, and all\nbiologically modern humans have language. This elementary fact, by\nthe way, demolishes the date most commonly given in magazine\narticles and textbooks for the origin of language: 30,000 years ago,\nthe age of the gorgeous cave art and decorated artifacts of CroMagnon humans in the Upper Paleolithic. The major branches of\nhumanity diverged well before then, and all their descendants have\nidentical language abilities; therefore the language instinct was probably in place well before the cultural fads of the Upper Paleolithic\nemerged in Europe. Indeed, the logic used by archaeologists (who\nare largely unaware of psycholinguistics) to pin language to that date\nis faulty. It depends on there being a single \"symbolic\" capacity\nunderlying art, religion, decorated tools, and language, which we now\n\n\n354 THE LANGUAGE INSTINCT\n\n\nknow is false (just think of linguistic idiot savants like Denyse and\nCrystal from Chapter 2, or, for that matter, any normal three-yearold)."
    },
    {
        "document_id": "0",
        "parent_id": 522,
        "parent_text": "354 THE LANGUAGE INSTINCT\n\n\nknow is false (just think of linguistic idiot savants like Denyse and\nCrystal from Chapter 2, or, for that matter, any normal three-yearold).\n\nOne other ingenious bit of evidence has been applied to language\norigins. Newborn babies, like other mammals, have a larynx that can\nrise up and engage the rear opening of the nasal cavity, allowing air\nto pass from nose to lungs avoiding the mouth and throat. Babies\nbecome human at three months when their larynx descends to a\nposition low in their throats. This gives the tongue the space to move\nboth up and down and back and forth, changing the shape of two\nresonant cavities and defining a large number of possible vowels. But\nit comes at a price. In _The Origin of Species_ Darwin noted \"the strange\nfact that every particle of food and drink which we swallow has to\npass over the orifice of the trachea, with some risk of falling into the\nlungs.\" Until the recent invention of the Heimlich maneuver, choking\non food was the sixth leading cause of accidental death in the United\nStates, claiming six thousand victims a year. The positioning of the\nlarynx deep in the throat, and the tongue far enough low and back\nto articulate a range of vowels, also compromised breathing and\nchewing. Presumably the communicative benefits outweighed the\nphysiological costs."
    },
    {
        "document_id": "0",
        "parent_id": 523,
        "parent_text": "Lieberman and his colleagues have tried to reconstruct the vocal\ntracts of extinct hominids by deducing where the larynx and its\nassociated muscles could have fit into the space at the base of their\nfossilized skulls. They argue that all species prior to modern _Homo_\n_sapiens,_ including Neanderthals, had a standard mammalian airway\nwith its reduced space of possible vowels. Lieberman suggests that\nuntil modern _Homo sapiens,_ language must have been quite rudimentary. But Neanderthals have their loyal defenders and Lieberman's\nclaim remains controversial. In any case, e lengeege weth e smell\nnember ef vewels cen remeen quete expresseve, so we cannot conclude that a hominid with a restricted vowel space had little language.\n\n\nSo far I have talked about when and how the language instinct\nmight have evolved, but not why. In a chapter of _The Origin of Species,_\nDarwin painstakingly argued that his theory of natural selection could\naccount for the evolution of instincts as well as bodies. If language is\n\n\nThe Big Bang 355\n\n\nlike other instincts, presumably it evolved by natural selection, the\nonly successful scientific explanation of complex biological traits.\n\nChomsky, one might think, would have everything to gain by\ngrounding his controversial theory about a language organ in the firm\nfoundation of evolutionary theory, and in some of his writings he has\nhinted at a connection. But more often he is skeptical:"
    },
    {
        "document_id": "0",
        "parent_id": 524,
        "parent_text": "The Big Bang 355\n\n\nlike other instincts, presumably it evolved by natural selection, the\nonly successful scientific explanation of complex biological traits.\n\nChomsky, one might think, would have everything to gain by\ngrounding his controversial theory about a language organ in the firm\nfoundation of evolutionary theory, and in some of his writings he has\nhinted at a connection. But more often he is skeptical:\n\n\nIt is perfectly safe to attribute this development [of innate mental\nstructure] to \"natural selection,\" so long as we realize that there is\nno substance to this assertion, that it amounts to nothing more\nthan a belief that there is some naturalistic explanation for these\nphenomena. . . . In studying the evolution of mind, we cannot guess\nto what extent there are physically possible alternatives to, say,\ntransformational generative grammar, for an organism meeting certain other physical conditions characteristic of humans. Conceivably, there are none—or very few—in which case talk about\nevolution of the language capacity is beside the point.\n\n\nCan the problem [the evolution of language] be addressed today?\nIn fact, little is known about these matters. Evolutionary theory is\ninformative about many things, but it has little to say, as of now,\nabout questions of this nature. The answers may well lie not so\nmuch in the theory of natural selection as in molecular biology, in\nthe study of what kinds of physical systems can develop under the\nconditions of life on earth and why, ultimately because of physical\nprinciples. It surely cannot be assumed that every trait is specifically\nselected. In the case of such systems as language . . . it is not easy\neven to imagine a course of selection that might have given rise to\nthem."
    },
    {
        "document_id": "0",
        "parent_id": 525,
        "parent_text": "What could he possibly mean? Could there be a language organ that\nevolved by a process different from the one we have always been told\nis responsible for the other organs? Many psychologists, impatient\nwith arguments that cannot be fit into a slogan, pounce on such\nstatements and ridicule Chomsky as a crypto-creationist. They are\nwrong, though I think Chomsky is wrong too.\n\nTo understand the issues, we first must understand the logic of\nDarwin's theory of natural selection. Evolution and natural selection\n\n\n356 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 526,
        "parent_text": "To understand the issues, we first must understand the logic of\nDarwin's theory of natural selection. Evolution and natural selection\n\n\n356 THE LANGUAGE INSTINCT\n\n\nare not the same thing. Evolution, the fact that species change over\ntime because of what Darwin called \"descent with modification,\" was\nalready widely accepted in Darwin's time but was attributed to many\nnow-discredited processes such as Lamarck's inheritance of acquired\ncharacteristics and some internal urge or drive to develop in a direction of increasing complexity culminating in humans. What Darwin\nand Alfred Wallace discovered and emphasized was a particular cause\nof evolution, natural selection. Natural selection applies to any set of\nentities with the properties of _multiplication, variation,_ and _heredity._\nMultiplication means that the entities copy themselves, that the copies\nare also capable of copying themselves, and so on. Variation means\nthat the copying is not perfect; errors crop up from time to time, and\nthese errors may give an entity traits that enable it to copy itself at\nhigher or lower rates relative to other entities. Heredity means that a\nvariant trait produced by a copying error reappears in subsequent\ncopies, so the trait is perpetuated in the lineage. Natural selection is\nthe mathematically necessary outcome that any traits that foster superior replication will tend to spread through the population over many\ngenerations. As a result, the entities will come to have traits that\nappear to have been designed for effective replication, including traits\nthat are means to this end, like the ability to gather energy and\nmaterials from the environment and to safeguard them from competitors. These replicating entities are what we recognize as \"organisms,\"\nand the replication-enhancing traits they accumulated by this process\nare called \"adaptations.\""
    },
    {
        "document_id": "0",
        "parent_id": 527,
        "parent_text": "At this point many people feel proud of themselves for spotting\nwhat they think is a fatal flaw. \"Aha! The theory is circular! All it\nsays is that traits that lead to effective replication lead to effective\nreplication. Natural selection is 'the survival of the fittest' and the\ndefinition of 'the fittest' is 'those who survive.' \" Not!! The power of\nthe theory of natural selection is that it connects two independent\nand very different ideas. The first idea is the appearance of design.\nBy \"appearance of design\" **I** mean something that an engineer could\nlook at and surmise that its parts are shaped and arranged so as to\ncarry out some function. Give an optical engineer an eyeball from an\nunknown species, and the engineer could immediately tell that it is\ndesigned for forming an image of the surroundings: it is built like a\ncamera, with a transparent lens, contractable diaphragm, and so on.\nMoreover, an image-forming device is not just any old piece of bric\n\nThe Big Bang 357\n\n\na-brac but a tool that is useful for finding food and mates, escaping\nfrom enemies, and so on. Natural selection explains how this design\ncame to be, using a _second_ idea: the actuarial statistics of reproduction\nin the organism's ancestors. Take a good look at the two ideas:\n\n\n1. A part of an organism appears to have been engineered\nto enhance its reproduction.\n2. That organism's ancestors reproduced more effectively\nthan their competitors."
    },
    {
        "document_id": "0",
        "parent_id": 528,
        "parent_text": "The Big Bang 357\n\n\na-brac but a tool that is useful for finding food and mates, escaping\nfrom enemies, and so on. Natural selection explains how this design\ncame to be, using a _second_ idea: the actuarial statistics of reproduction\nin the organism's ancestors. Take a good look at the two ideas:\n\n\n1. A part of an organism appears to have been engineered\nto enhance its reproduction.\n2. That organism's ancestors reproduced more effectively\nthan their competitors.\n\n\nNote that (1) and (2) are logically independent. They are about different things: engineering design, and birth and death rates. They are\nabout different organisms: the one you're interested in, and its ancestors. You can say that an organism has good vision and that good\nvision should help it reproduce (1), without knowing how well that\norganism, or any organism, in fact reproduces (2). Since \"design\"\nmerely implies an enhanced _probability_ of reproduction, a particular\norganism with well-designed vision may, in fact, not reproduce at all.\nMaybe it will be struck by lightning. Conversely, it may have a myopic\nsibling that in fact reproduces better, if, for instance, the same lightning bolt killed a predator who had the sibling in its sights. The\ntheory of natural selection says that (2), the ancestors' birth and death\nrates, is the explanation for (1), the organism's engineering design—\nso it is not circular in the least."
    },
    {
        "document_id": "0",
        "parent_id": 529,
        "parent_text": "This means that Chomsky was too flip when he dismissed natural\nselection as having no substance, as nothing more than a belief that\nthere is some naturalistic explanation for a trait. In fact, it is not so\neasy to show that a trait is a product of selection. The trait has to be\nhereditary. It has to enhance the probability of reproduction of the\norganism, relative to organisms without the trait, in an environment\nlike the one its ancestors lived in. There has to have been a sufficiently\nlong lineage of similar organisms in the past. And because natural\nselection has no foresight, each intermediate stage in the evolution of\nan organ must have conferred some reproductive advantage on its\npossessor. Darwin noted that his theory made strong predictions and\ncould easily be falsified. All it would take is the discovery of a trait\nthat showed signs of design but that appeared somewhere other than\nat the end of a lineage of replicators that could have used it to help\nin their replication. One example would be the existence of a trait\n\n\n358 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 530,
        "parent_text": "358 THE LANGUAGE INSTINCT\n\n\ndesigned only for the beauty of nature, such as a beautiful but cumbersome peacock tail evolving in moles, whose potential mates are too\nblind to be attracted to it. Another would be a complex organ that\ncan exist in no useful intermediate form, such as a part-wing that\ncould not have been useful for anything until it was one hundred\npercent of its current size and shape. A third would be an organism\nthat was not produced by an entity that can replicate, such as some\ninsert that spontaneously grew out of rocks, like a crystal. A fourth\nwould be a trait designed to benefit an organism other than the one\nthat caused the trait to appear, such as horses evolving saddles. In\nthe comic strip _Li'l Abner,_ the cartoonist Al Capp featured selfless\norganisms called shmoos that laid chocolate cakes instead of eggs\nand that cheerfully barbecued themselves so that people could\nenjoy their delicious boneless meat. The discovery of a real-life\nshmoo would instantly refute Darwin."
    },
    {
        "document_id": "0",
        "parent_id": 531,
        "parent_text": "Hasty dismissals aside, Chomsky raises a real issue when he brings\nup alternatives to natural selection. Thoughtful evolutionary theorists\nsince Darwin have been adamant that not every beneficial trait is an\nadaptation to be explained by natural selection. When a flying fish\nleaves the water, it is extremely adaptive for it to reenter the water.\nBut we do not need natural selection to explain this happy event;\ngravity will do just fine. Other traits, too, need an explanation different from selection. Sometimes a trait is not an adaptation in itself but\na consequence of something else that is an adaptation. There is no\nadvantage to our bones being white instead of green, but there is an\nadvantage to our bones being rigid; building them out of calcium is\none way to make them rigid, and calcium happens to be white.\nSometimes a trait is constrained by its history, like the S-bend in our\nspine that we inherited when four legs became bad and two legs good.\nMany traits may just be impossible to grow within the constraints of\na body plan and the way the genes build the body. The biologist\nJ.B.S. Haldane once said that there are two reasons why humans do\nnot turn into angels: moral imperfection and a body plan that cannot\naccommodate both arms and wings. And sometimes a trait comes\nabout by dumb luck. If enough time passes in a small population of\norganisms, all kinds of coincidences will be preserved in it, a process\n\n\nThe Big Bang 359\n\n\ncalled genetic drift. For example, in a particular generation all the\nstripeless organisms might be hit by lightning or die without issue;\nstripedness will reign thereafter, whatever its advantages or disadvantages."
    },
    {
        "document_id": "0",
        "parent_id": 532,
        "parent_text": "The Big Bang 359\n\n\ncalled genetic drift. For example, in a particular generation all the\nstripeless organisms might be hit by lightning or die without issue;\nstripedness will reign thereafter, whatever its advantages or disadvantages.\n\nStephen Jay Gould and Richard Lewontin have accused biologists\n(unfairly, most believe) of ignoring these alternative forces and putting\ntoo much stock in natural selection. They ridicule such explanations\nas \"just-so stories,\" an allusion to Kipling's whimsical tales of how\nvarious animals got their body parts. Gould and Lewontin's essays\nhave been influential in the cognitive sciences, and Chomsky's skepticism that natural selection can explain human language is in the spirit\nof their critique."
    },
    {
        "document_id": "0",
        "parent_id": 533,
        "parent_text": "But Gould and Lewontin's potshots do not provide a useful model\nof how to reason about the evolution of a complex trait. One of\ntheir goals was to undermine theories of human behavior that they\nenvisioned as having right-wing political implications. The critiques\nalso reflect their day-to-day professional concerns. Gould is a paleontologist, and paleontologists study organisms after they have turned\ninto rocks. They look more at grand patterns in the history of life\nthan at the workings of an individual's long-defunct organs. When\nthey discover, for example, that the dinosaurs were extinguished by\nan asteroid slamming into the earth and blacking out the sun, small\ndifferences in reproductive advantages understandably seem beside\nthe point. Lewontin is a geneticist, and geneticists tend to look at the\nraw code of the genes and their statistical variation in a population,\nrather than the complex organs they build. Adaptation can seem like\na minor force to them, just as someone examining the 1's and 0's of\na computer program in machine language without knowing what the\nprogram does might conclude that the patterns are without design.\nThe mainstream in modern evolutionary biology is better represented\nby biologists like George Williams, John Maynard Smith, and Ernst\nMayr, who are concerned with the design of whole living organisms.\nTheir consensus is that natural selection has a very special place in\nevolution, and that the existence of alternatives does _not_ mean that\nthe explanation of a biological trait is up for grabs, depending only\non the taste of the explainer.\n\nThe biologist Richard Dawkins has explained this reasoning lucidly\nin his book _The Blind Watchmaker._ Dawkins notes that the fundamen\n\n360 THE LANGUAGE INSTINCT\n\n\ntal problem of biology is to explain \"complex design.\" The problem\nwas appreciated well before Darwin. The theologian William Paley\nwrote:"
    },
    {
        "document_id": "0",
        "parent_id": 534,
        "parent_text": "The biologist Richard Dawkins has explained this reasoning lucidly\nin his book _The Blind Watchmaker._ Dawkins notes that the fundamen\n\n360 THE LANGUAGE INSTINCT\n\n\ntal problem of biology is to explain \"complex design.\" The problem\nwas appreciated well before Darwin. The theologian William Paley\nwrote:\n\n\nIn crossing a heath, suppose I pitched my foot against a _stone,_ and\nwere asked how the stone came to be there; I might possibly answer,\nthat, for anything I knew to the contrary, it had lain there for ever:\nnor would it perhaps be very easy to show the absurdity of this\nanswer. But suppose I had found a _watch_ upon the ground, and it\nshould be inquired how the watch happened to be in that place; I\nshould hardly think of the answer which I had before given, that\nfor anything I knew, the watch might have always been there."
    },
    {
        "document_id": "0",
        "parent_id": 535,
        "parent_text": "Paley noted that a watch has a delicate arrangement of tiny gears and\nsprings that function together to indicate the time. Bits of rock do\nnot spontaneously exude metal which forms itself into gears and\nsprings which then hop into an arrangement that keeps time. We are\nforced to conclude that the watch had an artificer who designed the\nwatch with the goal of timekeeping in mind. But an organ like an eye\nis even more complexly and purposefully designed than a watch. The\neye has a transparent protective cornea, a focusing lens, a lightsensitive retina at the focal plane of the lens, an iris whose diameter\nchanges with the illumination, muscles that move one eye in tandem\nwith the other, and neural circuits that detect edges, color, motion,\nand depth. It is impossible to make sense of the eye without noting\nthat it appears to have been designed for seeing—if for no other\nreason than that it displays an uncanny resemblance to the man-made\ncamera. If a watch entails a watchmaker and a camera entails a.\ncameramaker, then an eye entails an eyemaker, namely God. Biologists today do not disagree with Paley's laying out of the problem.\nThey disagree only with his solution. Darwin is history's most important biologist because he showed how such \"organs of extreme\nperfection and complication\" could arise from the purely physical\nprocess of natural selection.\n\nAnd here is the key point. Natural selection is not just a scientifically\nrespectable alternative to divine creation. It is the _only_ alternative that\ncan explain the evolution of a complex organ like the eye. The reason\nthat the choice is so stark—God or natural selection—is that structures that can do what the eye does are extremely low-probability\n\n\nThe Big Bang 361"
    },
    {
        "document_id": "0",
        "parent_id": 536,
        "parent_text": "And here is the key point. Natural selection is not just a scientifically\nrespectable alternative to divine creation. It is the _only_ alternative that\ncan explain the evolution of a complex organ like the eye. The reason\nthat the choice is so stark—God or natural selection—is that structures that can do what the eye does are extremely low-probability\n\n\nThe Big Bang 361\n\n\narrangements of matter. By an unimaginably large margin, most objects thrown together out of generic stuff, even generic animal stuff,\ncannot bring an image into focus, modulate incoming light, and detect\nedges and depth boundaries. The animal stuff in an eye seems to have\nbeen assembled with the goal of seeing in mind—but in whose mind,\nif not God's? How else could the mere _goal_ of seeing well _cause_\nsomething to see well? The very special power of natural selection is\nto remove the paradox. What causes eyes to see well now is that they\ndescended from a long line of ancestors that saw a bit better than\ntheir rivals, which allowed them to out-reproduce those rivals. The\nsmall random improvements in seeing were retained and combined\nand concentrated over the eons, leading to better and better eyes.\nThe ability of _many_ ancestors to see a _bit_ better in the _past_ causes a\n_single_ organism to see _extremely_ well _now._"
    },
    {
        "document_id": "0",
        "parent_id": 537,
        "parent_text": "Another way of putting it is that natural selection is the only process\nthat can steer a lineage of organisms along the path in the astronomically vast space of possible bodies leading from a body with no eye\nto a body with a functioning eye. The alternatives to natural selection\ncan, in contrast, only grope randomly. The odds that the coincidences\nof genetic drift would result in just the right genes coming together\nto build a functioning eye are infinitesimally small. Gravity alone may\nmake a flying fish fall into the ocean, a nice big target, but gravity\nalone cannot make bits of a flying fish embryo fall into place to make\na flying fish eye. When one organ develops, a bulge of tissue or\nsome nook or cranny can come along for free, the way an S-bend\naccompanies an upright spine. But you can bet that such a cranny\nwill not just happen to have a functioning lens and a diaphragm and a\nretina all perfectly arranged for seeing. It would be like the proverbial\nhurricane that blows through a junkyard and assembles a Boeing 747.\nFor these reasons, Dawkins argues that natural selection is not only\nthe correct explanation for life on earth but is bound to be the correct\nexplanation for anything we would be willing to call \"life\" anywhere\nin the universe.\n\nAnd adaptive complexity, by the way, is also the reason that the\nevolution of complex organs tends to be slow and gradual. It is not\nthat large mutations and rapid change violate some law of evolution.\nIt is only that complex engineering requires precise arrangements of\ndelicate parts, and if the engineering is accomplished by accumulating\nrandom changes, those changes had better be small. Complex organs\n\n\n362 THE LANGUAGE INSTINCT\n\n\nevolve by small steps for the same reason that a watchmaker does not\nuse a sledgehammer and a surgeon does not use a meat cleaver."
    },
    {
        "document_id": "0",
        "parent_id": 538,
        "parent_text": "362 THE LANGUAGE INSTINCT\n\n\nevolve by small steps for the same reason that a watchmaker does not\nuse a sledgehammer and a surgeon does not use a meat cleaver.\n\n\nSo we now know which biological traits to credit to natural selection and which ones to other evolutionary processes. What about\nlanguage? In my mind, the conclusion is inescapable. Every discussion\nin this book has underscored the adaptive complexity of the language\ninstinct. It is composed of many parts: syntax, with its discrete combinatorial system building phrase structures; morphology, a second\ncombinatorial system building words; a capacious lexicon; a revamped vocal tract; phonological rules and structures; speech perception; parsing algorithms; learning algorithms. Those parts are\nphysically realized as intricately structured neural circuits, laid down\nby a cascade of precisely timed genetic events. What these circuits\nmake possible is an extraordinary gift: the ability to dispatch an\ninfinite number of precisely structured thoughts from head to head\nby modulating exhaled breath. The gift is obviously useful for reproduction—think of Williams' parable of little Hans and Fritz being\nordered to stay away from the fire and not to play with the sabertooth. Randomly jigger a neural network or mangle a vocal tract, and\nyou will not end up with a system with these capabilities. The language\ninstinct, like the eye, is an example of what Darwin called \"that\nperfection of structure and co-adaptation which justly excites our\nadmiration,\" and as such it bears the unmistakable stamp of nature's\ndesigner, natural selection.\n\nIf Chomsky maintains that grammar shows signs of complex design\nbut is skeptical that natural selection manufactured it, what alternative\ndoes he have in mind? What he repeatedly mentions is physical law.\nJust as the flying fish is compelled to return to the water and calciumfilled bones are compelled to be white, human brains might, for all\nwe know, be compelled to contain circuits for Universal Grammar.\nHe writes:"
    },
    {
        "document_id": "0",
        "parent_id": 539,
        "parent_text": "If Chomsky maintains that grammar shows signs of complex design\nbut is skeptical that natural selection manufactured it, what alternative\ndoes he have in mind? What he repeatedly mentions is physical law.\nJust as the flying fish is compelled to return to the water and calciumfilled bones are compelled to be white, human brains might, for all\nwe know, be compelled to contain circuits for Universal Grammar.\nHe writes:\n\n\nThese skills [for example, learning a grammar] may well have arisen\nas a concomitant of structural properties of the brain that developed\nfor other reasons. Suppose that there was selection for bigger brains,\nmore cortical surface, hemispheric specialization for analytic processing, or many other structural properties that can be imagined.\n\n\nThe Big Bang 363\n\n\nThe brain that evolved might well have all sorts of special properties\nthat are not individually selected; there would be no miracle in this,\nbut only the normal workings of evolution. We have no idea, at\npresent, how physical laws apply when 10 1 0 neurons are placed in\nan object the size of a basketball, under the special conditions that\narose during human evolution.\n\n\nWe may not, just as we don't know how physical laws apply under\nthe special conditions of hurricanes sweeping through junkyards, but\nthe possibility that there is an undiscovered corollary of the laws of\nphysics that causes brains of human size and shape to develop the\ncircuitry for Universal Grammar seems unlikely for many reasons.\n\nAt the microscopic level, what set of physical laws could cause a\nsurface molecule guiding an axon along a thicket of glial cells to\ncooperate with millions of other such molecules to solder together\njust the kinds of circuits that would compute something as useful to\nan intelligent social species as grammatical language? The vast majority of the astronomical number of ways of wiring together a large\nneural network would surely lead to something else: bat sonar, or\nnest-building, or go-go dancing, or, most likely of all, random neural\nnoise."
    },
    {
        "document_id": "0",
        "parent_id": 540,
        "parent_text": "At the level of the whole brain, the remark that there has been\nselection for bigger brains is, to be sure, common in writings about\nhuman evolution (especially from paleoanthropologists). Given that\npremise, one might naturally think that all kinds of computational\nabilities might come as a by-product. But if you think about it for a\nminute, you should quickly see that the premise has it backwards.\nWhy would evolution ever have selected for sheer bigness of brain,\nthat bulbous, metabolically greedy organ? A large-brained creature\nis sentenced to a life that combines all the disadvantages of balancing\na watermelon on a broomstick, running in place in a down jacket,\nand, for women, passing a large kidney stone every few years. Any\nselection on brain size itself would surely have favored the pinhead.\nSelection for more powerful computational abilities (language, perception, reasoning, and so on) must have given us a big brain as a\nby-product, not the other way around!\n\nBut even given a big brain, language does not fall out the way that\nflying fish fall out of the air. We see language in dwarfs whose heads\nare much smaller than a basketball. We also see it in hydrocephalics\n\n\n364 THE LANGUAGE INSTINCT\n\n\nwhose cerebral hemispheres have been squashed into grotesque\nshapes, sometimes a thin layer lining the skull like the flesh of a\ncoconut, but who are intellectually and linguistically normal. Conversely, there are Specific Language Impairment victims with brains\nof normal size and shape and with intact analytic processing (recall\nthat one of Gopnik's subjects was fine with math and computers).\nAll the evidence suggests that it is the precise wiring of the brain's\nmicrocircuitry that makes language happen, not gross size, shape, or\nneuron packing. The pitiless laws of physics are unlikely to have done\nus the favor of hooking up that circuitry so that we could communicate with one another in words."
    },
    {
        "document_id": "0",
        "parent_id": 541,
        "parent_text": "Incidentally, to attribute the basic design of the language instinct\nto natural selection is not to indulge in just-so storytelling that can\nspuriously \"explain\" any trait. The neuroscientist William Calvin, in\nhis book _The Throwing Madonna,_ explains the left-brain specialization for hand control, and consequently for language, as follows.\nFemale hominids held their baby on their left side so the baby would\nbe calmed by their heartbeat. This forced the mothers to use their\nright arm for throwing stones at small prey. Therefore the race became\nright-handed and left-brained. Now, this really _is_ a just-so story. In\nall human societies that hunt, it is the men who do the hunting, not\nthe women. Moreover, as a former boy I can attest that hitting an\nanimal with a rock is not so easy. Calvin's throwing madonna is about\nas likely as Roger Clemens hurling split-fingered fastballs over the\nplate with a squirming infant on his hip. In the second edition to his\nbook Calvin had to explain to readers that he only meant it as a joke;\nhe was trying to show that such stories are no less plausible than\nserious adaptationist explanations. But such blunt-edged satire misses\nthe point almost as much as if it had been intended as serious. The\nthrowing madonna is qualitatively different from genuine adaptationist explanations, for not only is it instantly falsified by empirical\nand engineering considerations, but it is a nonstarter for a key theoretical reason: natural selection is an explanation for the extremely\nimprobable. If brains are lateralized at all, lateralization on the left is\nnot extremely improbable—its chances are exactly fifty percent! We\ndo not need a circuitous tracing of left brains to anything else, for\nhere the alternatives to selection are perfectly satisfying. It is a good\nillustration of how the logic of natural selection allows us to distinguish legitimate selectionist accounts from just-so stories.\n\n\nThe Big Bang 365"
    },
    {
        "document_id": "0",
        "parent_id": 542,
        "parent_text": "The Big Bang 365\n\n\nTo be fair, there are genuine problems in reconstructing how the\nlanguage faculty might have evolved by natural selection, though the\npsychologist Paul Bloom and I have argued that the problems are all\nresolvable. As P. B. Medawar noted, language could not have begun\nin the form it supposedly took in the first recorded utterance of the\ninfant Lord Macaulay, who after having been scalded with hot tea\nallegedly said to his hostess, \"Thank you, madam, the agony is sensibly\nabated.\" If language evolved gradually, there must have been a sequence of intermediate forms, each useful to its possessor, and this\nraises several questions.\n\nFirst, if language involves, for its true expression, another individual,\nwho did the first grammar mutant talk to? One answer might be: the\nfifty percent of the brothers and sisters and sons and daughters who\nshared the new gene by common inheritance. But a more general answer\nis that the neighbors could have partly understood what the mutant was\nsaying even if they lacked the new-fangled circuitry, just using overall\nintelligence. Though we cannot parse strings like _skid crash hospital,_ we\ncan figure out what they probably mean, and English speakers can often\ndo a reasonably good job understanding Italian newspaper stories based\non similar words and background knowledge. If a grammar mutant is\nmaking important distinctions that can be decoded by others only with\nuncertainty and great mental effort, it could set up a pressure for them to\nevolve the matching system that allows those distinctions to be recovered\nreliably by an automatic, unconscious parsing process. As I mentioned\nin Chapter 8, natural selection can take skills that are acquired with\neffort and uncertainty and hardwire them into the brain. Selection could\nhave ratcheted up language abilities by favoring the speakers in each\ngeneration that the hearers could best decode, and the hearers who\ncould best decode the speakers."
    },
    {
        "document_id": "0",
        "parent_id": 543,
        "parent_text": "A second problem is what an intermediate grammar would have\nlooked like. Bates asks:\n\n\nWhat protoform can we possibly envision that could have given\nbirth to constraints on the extraction of noun phrases from an\nembedded clause? What could it conceivably mean for an organism\nto possess half a symbol, or three quarters of a rule? . . . monadic\nsymbols, absolute rules and modular systems must be acquired as\n\n\n366 THE LANGUAGE INSTINCT\n\n\na whole, on a yes-or-no basis—a process that cries out for a Creationist explanation."
    },
    {
        "document_id": "0",
        "parent_id": 544,
        "parent_text": "366 THE LANGUAGE INSTINCT\n\n\na whole, on a yes-or-no basis—a process that cries out for a Creationist explanation.\n\n\nThe question is rather odd, because it assumes that Darwin literally\nmeant that organs must evolve in successively larger fractions (half,\nthree quarters, and so on). Bates' rhetorical question is like asking\nwhat it could conceivably mean for an organism to possess half a\nhead or three quarters of an elbow. Darwin's real claim, of course, is\nthat organs evolve in successively more complex forms. Grammars of\nintermediate _complexity_ are easy to imagine; they could have symbols\nwith a narrower range, rules that are less reliably applied, modules\nwith fewer rules, and so on. In a recent book Derek Bickerton answers\nBates even more concretely. He gives the term \"protolanguage\" to\nchimp signing, pidgins, child language in the two-word stage, and the\nunsuccessful partial language acquired after the critical period by\nGenie and other wolf-children. Bickerton suggests that _Homo erectus_\nspoke in protolanguage. Obviously there is still a huge gulf between\nthese relatively crude systems and the modern adult language instinct,\nand here Bickerton makes the jaw-dropping additional suggestion\nthat a single mutation in a single woman, African Eve, simultaneously\nwired in syntax, resized and reshaped the skull, and reworked the\nvocal tract. But we can extend the first half of Bickerton's argument\nwithout accepting the second half, which is reminiscent of hurricanes\nassembling jetliners. The languages of children, pidgin speakers, immigrants, tourists, aphasics, telegrams, and headlines show that there\nis a vast continuum of viable language systems varying in efficiency\nand expressive power, exactly what the theory of natural selection\nrequires.\n\nA third problem is that each step in the evolution of a language\ninstinct, up to and including the most recent ones, must enhance\nfitness. David Premack writes:"
    },
    {
        "document_id": "0",
        "parent_id": 545,
        "parent_text": "A third problem is that each step in the evolution of a language\ninstinct, up to and including the most recent ones, must enhance\nfitness. David Premack writes:\n\n\nI challenge the reader to reconstruct the scenario that would confer\nselective fitness on recursiveness. Language evolved, it is conjectured, at a time when humans or protohumans were hunting mastodons. . . . Would it be a great advantage for one of our ancestors\nsquatting alongside the embers, to be able to remark: \"Beware of\nthe short beast whose front hoof Bob cracked when, having forgot\n\nThe Big Bang 367\n\n\nten his own spear back at camp, he got in a glancing blow with the\ndull spear he borrowed from Jack\"?\"\n\nHuman language is an embarrassment for evolutionary theory\nbecause it is vastly more powerful than one can account for in terms\nof selective fitness. A semantic language with simple mapping rules,\nof a kind one might suppose that the chimpanzee would have,\nappears to confer all the advantages one normally associates with\ndiscussions of mastodon hunting or the like. For discussions of that\nkind, syntactic classes, structure-dependent rules, recursion and the\nrest, are overly powerful devices, absurdly so.\n\n\nI am reminded of a Yiddish expression, \"What's the matter, is the\nbride too beautiful?\" The objection is a bit like saying that the cheetah\nis much faster than it has to be, or that the eagle does not need such\ngood vision, or that the elephant's trunk is an overly powerful device,\nabsurdly so. But it is worth taking up the challenge.\n\nFirst, bear in mind that selection does not need great advantages.\nGiven the vastness of time, tiny advantages will do. Imagine a mouse\nthat was subjected to a minuscule selection pressure for increased\nsize—say, a one percent reproductive advantage for offspring that\nwere one percent bigger. Some arithmetic shows that the mouse's\ndescendants would evolve to the size of an elephant in a few thousand\ngenerations, an evolutionary eyeblink."
    },
    {
        "document_id": "0",
        "parent_id": 546,
        "parent_text": "First, bear in mind that selection does not need great advantages.\nGiven the vastness of time, tiny advantages will do. Imagine a mouse\nthat was subjected to a minuscule selection pressure for increased\nsize—say, a one percent reproductive advantage for offspring that\nwere one percent bigger. Some arithmetic shows that the mouse's\ndescendants would evolve to the size of an elephant in a few thousand\ngenerations, an evolutionary eyeblink.\n\nSecond, if contemporary hunter-gatherers are any guide, our ancestors were not grunting cave men with little more to talk about than\nwhich mastodon to avoid. Hunter-gatherers are accomplished toolmakers and superb amateur biologists with detailed knowledge of the\nlife cycles, ecology, and behavior of the plants and animals they\ndepend on. Language would surely have been useful in anything\nresembling such a lifestyle. It is possible to imagine a superintelligent\nspecies whose isolated members cleverly negotiated their environment\nwithout communicating with one another, but what a waste! There\nis a fantastic payoff in trading hard-won knowledge with kin and\nfriends, and language is obviously a major means of doing so.\n\nAnd grammatical devices designed for communicating precise information about time, space, objects, and who did what to whom\nare not like the proverbial thermonuclear fly-swatter. Recursion in\nparticular is extremely useful; it is not, as Premack implies, confined\n\n\n368 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 547,
        "parent_text": "And grammatical devices designed for communicating precise information about time, space, objects, and who did what to whom\nare not like the proverbial thermonuclear fly-swatter. Recursion in\nparticular is extremely useful; it is not, as Premack implies, confined\n\n\n368 THE LANGUAGE INSTINCT\n\n\nto phrases with tortuous syntax. Without recursion you can't say _the_\n_man's hat_ or _I think he left._ Recall that all you need for recursion is\nan ability to embed a noun phrase inside another noun phrase or a\nclause within a clause, which falls out of rules as simple as \"NP —>\ndet N PP\" and \"PP P NP.\" With this ability a speaker can pick\nout an object to an arbitrarily fine level of precision. These abilities\ncan make a big difference. It makes a difference whether a far-off\nregion is reached by taking the trail that is in front of the large tree\nor the trail that the large tree is in front of. It makes a difference\nwhether that region has animals that you can eat or animals that can\neat you. It makes a difference whether it has fruit that is ripe or fruit\nthat was ripe or fruit that will be ripe. It makes a difference whether\nyou can get there if you walk for three days or whether you can get\nthere and walk for three days.\n\nThird, people everywhere depend on cooperative efforts for survival,\nforming alliances by exchanging information and commitments. This\ntoo puts complex grammar to good use. It makes a difference whether\nyou understand me as saying that if you give me some of your fruit I\nwill share meat that I will get, or that you should give me some fruit\nbecause I shared meat that I got, or that if you don't give me some fruit\nI will take back the meat that I got. And once again, recursion is far\nfrom being an absurdly powerful device. Recursion allows sentences like\n_He knows that she thinks that he is flirting with Mary_ and other means\nof conveying gossip, an apparently universal human vice."
    },
    {
        "document_id": "0",
        "parent_id": 548,
        "parent_text": "But could these exchanges really produce the rococo complexity\nof human grammar? Perhaps. Evolution often produces spectacular\nabilities when adversaries get locked into an \"arms race,\" like the\nstruggle between cheetahs and gazelles. Some anthropologists believe\nthat human brain evolution was propelled more by a cognitive arms\nrace among social competitors than by mastery of technology and the\nphysical environment. After all, it doesn't take that much brain power\nto master the ins and outs of a rock or to get the better of a berry.\nBut outwitting and second-guessing an organism of approximately\nequal mental abilities with non-overlapping interests, at best, and\nmalevolent intentions, at worst, makes formidable and ever-escalating\ndemands on cognition. And a cognitive arms race clearly could propel\na linguistic one. In all cultures, social interactions are mediated by\npersuasion and argument. How a choice is framed plays a large role\nin determining which alternative people choose. Thus there could\n\n\nThe Big Bang 369\n\n\neasily have been selection for any edge in the ability to frame an offer\nso that it appears to present maximal benefit and minimal cost to the\nnegotiating partner, and in the ability to see through such attempts\nand to formulate attractive counterproposals.\n\nFinally, anthropologists have noted that tribal chiefs are often both\ngifted orators and highly polygynous—a splendid prod to any imagination that cannot conceive of how linguistic skills could make a\nDarwinian difference. I suspect that evolving humans lived in a world\nin which language was woven into the intrigues of politics, economics,\ntechnology, family, sex, and friendship that played key roles in individual reproductive success. They could no more live with a MeTarzan-you-Jane level of grammar than we could."
    },
    {
        "document_id": "0",
        "parent_id": 549,
        "parent_text": "The brouhaha raised by the uniqueness of language has many\nironies. The spectacle of humans trying to ennoble animals by forcing\nthem to mimic human forms of communication is one. The pains that\nhave been taken to portray language as innate, complex, and useful\nbut not a product of the one force in nature that can make innate\ncomplex useful things is another. Why should language be considered\nsuch a big deal? It has allowed humans to spread out over the planet\nand wreak large changes, but is that any more extraordinary than\ncoral that build islands, earthworms that shape the landscape by\nbuilding soil, or the photosynthesizing bacteria that first released\ncorrosive oxygen into the atmosphere, an ecological catastrophe of\nits time? Why should talking humans be considered any weirder than\nelephants, penguins, beavers, camels, rattlesnakes, hummingbirds,\nelectric eels, leaf-mimicking insects, giant sequoias, Venus flytraps,\necholocating bats, or deep-sea fish with lanterns growing out of their\nheads? Some of these creatures have traits unique to their species,\nothers do not, depending only on the accidents of which of their\nrelatives have become extinct. Darwin emphasized the genealogical\nconnectedness of all living things, but evolution is descent _with modi-_\n_fication,_ and natural selection has shaped the raw materials of bodies\nand brains to fit them into countless differentiated niches. For Darwin, such is the \"grandeur in this view of life\": \"that whilst this planet\nhas gone cycling on according to the fixed law of gravity, from so\nsimple a beginning endless forms most beautiful and wonderful have\nbeen, and are being, evolved.\""
    },
    {
        "document_id": "0",
        "parent_id": 550,
        "parent_text": "### 12"
    },
    {
        "document_id": "0",
        "parent_id": 551,
        "parent_text": "#### The Language Mavens\n\n**Imagine** that you are watching a nature documentary. The\nvideo shows the usual gorgeous footage of animals in their natural\nhabitats. But the voiceover reports some troubling facts. Dolphins do\nnot execute their swimming strokes properly. White-crowned sparrows carelessly debase their calls. Chickadees' nests are incorrectly\nconstructed, pandas hold bamboo in **the** wrong paw, the song of the\nhumpback whale contains several well-known errors, and monkeys'\ncries have been in a state of chaos and degeneration for hundreds of\nyears. Your reaction would probably be, What on earth could it mean\nfor the song of the humpback whale to contain an \"error\"? Isn't the\nsong of the humpback whale whatever the humpback whale decides\nto sing? Who is this announcer, anyway?\n\nBut for human language, most people think that the same pronouncements not only are meaningful but are cause for alarm. Johnny\ncan't construct a grammatical sentence. As educational standards\ndecline and pop culture disseminates the inarticulate ravings and\nunintelligible patois of surfers, jocks, and valley girls, we are turning\ninto a nation of functional illiterates: misusing _hopefully,_ confusing\n_lie_ and _lay,_ treating _data_ as a singular noun, letting our participles\ndangle. English itself will steadily decay unless we get back to basics\nand start to respect our language again.\n\nTo a linguist or psycholinguist, of course, language is like the song\nof the humpback whale. The way to determine whether a construction\nis \"grammatical\" is to find people who speak the language and ask\nthem. So when people are accused of speaking \"ungrammatically\" in\n\n\n370\n\n\nThe Language Mavens 371"
    },
    {
        "document_id": "0",
        "parent_id": 552,
        "parent_text": "To a linguist or psycholinguist, of course, language is like the song\nof the humpback whale. The way to determine whether a construction\nis \"grammatical\" is to find people who speak the language and ask\nthem. So when people are accused of speaking \"ungrammatically\" in\n\n\n370\n\n\nThe Language Mavens 371\n\n\ntheir own language, or of consistently violating a \"rule,\" there must\nbe some different sense of \"grammatical\" and \"rule\" in the air. In\nfact, the pervasive belief that people do not know their own language\nis a nuisance in doing linguistic research. A linguist's question to an\ninformant about some form in his or her speech (say, whether the\nperson uses _sneaked_ or _snuck)_ is often lobbed back with the ingenuous\ncounterquestion \"Gee, I better not take a chance; which is correct?\"\n\nIn this chapter I had better resolve this contradiction for you.\nRecall columnist Erma Bombeck, incredulous at the very idea of a\ngrammar gene because her husband taught thirty-seven high school\nstudents who thought that \"bummer\" was a sentence. You, too, might\nbe wondering: if language is as instinctive as spinning a web, if every\nthree-year-old is a grammatical genius, if the design of syntax is coded\nin our DNA and wired into our brains, why is the English language\nin such a mess? Why does the average American sound like a gibbering fool every time he opens his mouth or puts pen to paper?\n\nThe contradiction begins in the fact that the words \"rule,\" \"grammatical,\" and \"ungrammatical\" have very different meanings to a\nscientist and to a layperson. The rules people learn (or, more likely,\nfail to learn) in school are called _prescriptive_ rules, prescribing how\none \"ought\" to talk. Scientists studying language propose _descriptive_\nrules, describing how people _do_ talk. They are completely different\nthings, and there is a good reason that scientists focus on descriptive\nrules."
    },
    {
        "document_id": "0",
        "parent_id": 553,
        "parent_text": "The contradiction begins in the fact that the words \"rule,\" \"grammatical,\" and \"ungrammatical\" have very different meanings to a\nscientist and to a layperson. The rules people learn (or, more likely,\nfail to learn) in school are called _prescriptive_ rules, prescribing how\none \"ought\" to talk. Scientists studying language propose _descriptive_\nrules, describing how people _do_ talk. They are completely different\nthings, and there is a good reason that scientists focus on descriptive\nrules.\n\nTo a scientist, the fundamental fact of human language is its sheer\nimprobability. Most objects in the universe—lakes, rocks, trees,\nworms, cows, cars—cannot talk. Even in humans, the utterances in\na language are an infinitesimal fraction of the noises people's mouths\nare capable of making. I can arrange a combination of words that\nexplains how octopuses make love or how to remove cherry stains;\nrearrange the words in even the most minor way, and the result is a\nsentence with a different meaning or, most likely of all, word salad.\nHow are we to account for this miracle? What would it take to build\na device that could duplicate human language?\n\nObviously, you need to build in some kind of rules, but what\nkind? Prescriptive rules? Imagine trying to build a talking machine by\ndesigning it to obey rules like \"Don't split infinitives\" or \"Never\nbegin a sentence with _because.\"_ It would just sit there. In fact, we\nalready have machines that don't split infinitives; they're called screw\n\n372 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 554,
        "parent_text": "Obviously, you need to build in some kind of rules, but what\nkind? Prescriptive rules? Imagine trying to build a talking machine by\ndesigning it to obey rules like \"Don't split infinitives\" or \"Never\nbegin a sentence with _because.\"_ It would just sit there. In fact, we\nalready have machines that don't split infinitives; they're called screw\n\n372 THE LANGUAGE INSTINCT\n\n\ndrivers, bathtubs, cappuccino-makers, and so on. Prescriptive rules\nare useless without the much more fundamental rules that create the\nsentences and define the infinitives and list the word _because_ to begin\nwith, the rules of Chapters 4 and 5. These rules are never mentioned\nin style manuals or school grammars because the authors correctly\nassume that anyone capable of reading the manuals must already have\nthe rules. No one, not even a valley girl, has to be told not to say\n_Apples the eat boy_ or _The child seems sleeping_ or _Who did you meet_\n_John and?_ or the vast, vast majority of the millions of trillions of\nmathematically possible combinations of words. So when a scientist\nconsiders all the high-tech mental machinery needed to arrange words\ninto ordinary sentences, prescriptive rules are, at best, inconsequential\nlittle decorations. The very fact that they have to be drilled shows\nthat they are alien to the natural workings of the language system.\nOne can choose to obsess over prescriptive rules, but they have no\nmore to do with human language than the criteria for judging cats at\na cat show have to do with mammalian biology."
    },
    {
        "document_id": "0",
        "parent_id": 555,
        "parent_text": "So there is no contradiction in saying that every normal person can\nspeak grammatically (in the sense of systematically) and ungrammatically (in the sense of nonprescriptively), just as there is no contradiction in saying that a taxi obeys the laws of physics but breaks the laws\nof Massachusetts. But this raises a question. Someone, somewhere,\nmust be making decisions about \"correct English\" for the rest of us.\nWho? There is no English Language Academy, and this is just as\nwell; the purpose of the Academie Francaise is to amuse journalists\nfrom other countries with bitterly argued decisions that the French\ngaily ignore. Nor were there any Founding Fathers at some English\nLanguage Constitutional Conference at the beginning of time. The\nlegislators of \"correct English,\" in fact, are an informal network of\ncopy-editors, dictionary usage panelists, style manual and handbook\nwriters, English teachers, essayists, columnists, and pundits. Their\nauthority, they claim, comes from their dedication to implementing\nstandards that have served the language well in the past, especially in\nthe prose of its finest writers, and that maximize its clarity, logic,\nconsistency, conciseness, elegance, continuity, precision, stability, integrity, and expressive range. (Some of them go further and say that\nthey are actually safeguarding the ability to _think_ clearly and logically.\nThis radical Whorfianism is common among language pundits, not\nsurprisingly; who would settle for being a schoolmarm when one can\n\n\nThe Language Mavens 373\n\n\nbe an upholder of rationality itself?) William Safire, who writes the\nweekly column \"On Language\" for _The New York Times Magazine,_\ncalls himself a \"language maven,\" from the Yiddish word meaning\nexpert, and this gives us a convenient label for the entire group."
    },
    {
        "document_id": "0",
        "parent_id": 556,
        "parent_text": "The Language Mavens 373\n\n\nbe an upholder of rationality itself?) William Safire, who writes the\nweekly column \"On Language\" for _The New York Times Magazine,_\ncalls himself a \"language maven,\" from the Yiddish word meaning\nexpert, and this gives us a convenient label for the entire group.\n\nTo whom I say: Maven, shmaven! _Kibbitzers_ and _nudniks_ is more\nlike it. For here are the remarkable facts. Most of the prescriptive\nrules of the language mavens make no sense on any level. They are\nbits of folklore that originated for screwball reasons several hundred\nyears ago and have perpetuated themselves ever since. For as long as\nthey have existed, speakers have flouted them, spawning identical\nplaints about the imminent decline of the language century after\ncentury. All the best writers in English at all periods, including Shakespeare and most of the mavens themselves, have been among the\nflagrant flouters. The rules conform neither to logic nor to tradition,\nand if they were ever followed they would force writers into fuzzy,\nclumsy, wordy, ambiguous, incomprehensible prose, in which certain\nthoughts are not expressible at all. Indeed, most of the \"ignorant\nerrors\" these rules are supposed to correct display an elegant logic\nand an acute sensitivity to the grammatical texture of the language,\nto which the mavens are oblivious."
    },
    {
        "document_id": "0",
        "parent_id": 557,
        "parent_text": "The scandal of the language mavens began in the eighteenth century. London had become the political and financial center of England, and England had become the center of a powerful empire. The\nLondon dialect was suddenly an important world language. Scholars\nbegan to criticize it as they would any artistic or civil institution, in\npart to question the customs, hence authority, of court and aristocracy. Latin was still considered the language of enlightenment and\nlearning (not to mention the language of a comparably vast empire),\nand it was offered as an ideal of precision and logic to which English\nshould aspire. The period also saw unprecedented social mobility,\nand anyone who desired education and self-improvement and who\nwanted to distinguish himself as cultivated had to master the best\nversion of English. These trends created a demand for handbooks\nand style manuals, which were soon shaped by market forces. Casting\nEnglish grammar into the mold of Latin grammar made the books\nuseful as a way of helping young students learn Latin. And as the\ncompetition became cutthroat, the manuals tried to outdo one another by including greater numbers of increasingly fastidious rules\nthat no refined person could afford to ignore. Most of the hobgoblins\n\n\n374 THE LANGUAGE INSTINCT\n\n\nof contemporary prescriptive grammar (don't split infinitives, don't\nend a sentence with a preposition) can be traced back to these eighteenth-century fads."
    },
    {
        "document_id": "0",
        "parent_id": 558,
        "parent_text": "374 THE LANGUAGE INSTINCT\n\n\nof contemporary prescriptive grammar (don't split infinitives, don't\nend a sentence with a preposition) can be traced back to these eighteenth-century fads.\n\nOf course, forcing modern speakers of English to not—whoops,\nnot to split an infinitive because it isn't done in Latin makes about as\nmuch sense as forcing modern residents of England to wear laurels\nand togas. Julius Caesar could not have split an infinitive if he had\nwanted to. In Latin the infinitive is a single word like _facere_ or _dicere,_\na syntactic atom. English is a different kind of language. It is an\n\"isolating\" language, building sentences around many simple words\ninstead of a few complicated ones. The infinitive is composed of\ntwo words—a complementizer, _to,_ and a verb, like _go._ Words, by\ndefinition, are rearrangeable units, and there is no conceivable reason\nwhy an adverb should not come between them:\n\n\nSpace—the final frontier . . . These are the voyages of the starship\n_Enterprise._ Its five-year mission: to explore strange new worlds, to\nseek out new life and new civilizations, to boldly go where no man\nhas gone before.\n\n\nTo _go boldly_ where no man has gone before? Beam me up, Scotty;\nthere's no intelligent life down here. As for outlawing sentences that\nend with a preposition (impossible in Latin for good reasons having\nto do with its case-marking system, reasons that are irrelevant in casepoor English)—as Winston Churchill would have said, it is a rule up\nwith which we should not put."
    },
    {
        "document_id": "0",
        "parent_id": 559,
        "parent_text": "To _go boldly_ where no man has gone before? Beam me up, Scotty;\nthere's no intelligent life down here. As for outlawing sentences that\nend with a preposition (impossible in Latin for good reasons having\nto do with its case-marking system, reasons that are irrelevant in casepoor English)—as Winston Churchill would have said, it is a rule up\nwith which we should not put.\n\nBut once introduced, a prescriptive rule is very hard to eradicate,\nno matter how ridiculous. Inside the educational and writing establishments, the rules survive by the same dynamic that perpetuates\nritual genital mutilations and college fraternity hazing: I had to go\nthrough it and am none the worse, so why should you have it any\neasier? Anyone daring to overturn a rule by example must always\nworry that readers will think he or she is ignorant of the rule, rather\nthan challenging it. (I confess that this has deterred me from splitting\nsome splitworthy infinitives.) Perhaps most importantly, since prescriptive rules are so psychologically unnatural that only those with\naccess to the right schooling can abide by them, they serve as shibboleths, differentiating the elite from the rabble.\n\n\nThe Language Mavens 375\n\n\nThe concept of shibboleth (Hebrew for \"torrent\") comes from the\nBible:\n\n\nAnd the Gileadites took the passages of Jordan before the Ephraimites: and it was so, that when those Ephraimites which were\nescaped said, Let me go over; that the men of Gilead said unto him,\nArt thou an Ephraimite? If he said, Nay; Then said they unto him,\nSay now Shibboleth: and he said Sibboleth: for he could not frame\nto pronounce it right. Then they took him, and slew him at the\npassages of the Jordan: and there fell at that time of the Ephraimites\nforty and two thousand. (Judges 12:5-6)"
    },
    {
        "document_id": "0",
        "parent_id": 560,
        "parent_text": "And the Gileadites took the passages of Jordan before the Ephraimites: and it was so, that when those Ephraimites which were\nescaped said, Let me go over; that the men of Gilead said unto him,\nArt thou an Ephraimite? If he said, Nay; Then said they unto him,\nSay now Shibboleth: and he said Sibboleth: for he could not frame\nto pronounce it right. Then they took him, and slew him at the\npassages of the Jordan: and there fell at that time of the Ephraimites\nforty and two thousand. (Judges 12:5-6)\n\n\nThis is the kind of terror that has driven the prescriptive grammar\nmarket in the United States during the past century. Throughout the\ncountry people have spoken a dialect of English, some of whose\nfeatures date to the early modern English period, that H. L. Mencken\ncalled The American Language. It had the misfortune of not becoming the standard of government and education, and large parts of the\n\"grammar\" curriculum in American schools have been dedicated to\nstigmatizing it as ungrammatical, sloppy speech. Familiar examples\nare _aks a question, workin', ain't, I don't see no birds, he don't, them_\n_boys, we was,_ and past-tense forms like _drug, seen, clumb, drownded,_\nand _growed._ For ambitious adults who had been unable to complete\nschool, there were full-page magazine ads for correspondence\ncourses, containing lists of examples under screaming headlines like\n\"DO YOU MAKE ANY OF THESE EMBARRASSING MISTAKES?\"\n\n\nFrequently the language mavens claims that nonstandard American\nEnglish is not just different but less sophisticated and logical. The\ncase, they would have to admit, is hard to make for nonstandard\nirregular verbs like _drag-drug_ (and even more so for regularizations\nlike _feeled_ and _growed)._ After all, in \"correct\" English, Richard Lederer notes, \"Today we speak, but first we spoke; some faucets leak,\nbut never loke. Today we write, but first we wrote; we bite our\ntongues, but never bote.\" At first glance, the mavens would seem to\nhave a better argument when it comes to the leveling of inflectional"
    },
    {
        "document_id": "0",
        "parent_id": 561,
        "parent_text": "376 THE LANGUAGE INSTINCT\n\n\ndistinctions in _He don't_ and _We was._ But then, this has been the trend\nin Standard English for centuries. No one gets upset that we no longer\ndistinguish the second person singular form of verbs, like _sayest._\nAnd by this criterion it is the nonstandard dialects that are superior,\nbecause they provide their speakers with second person plural pronouns like _y'all_ and _youse,_ and Standard English does not.\nAt this point, defenders of the standard are likely to pull out the\nnotorious double negative, as in J _can't get no satisfaction._ Logically\nspeaking, the two negatives cancel each other out, they teach; Mr.\nJagger is actually saying that he is satisfied. The song should be\nentitled \"I Can't Get _Any_ Satisfaction.\" But this reasoning is not\nsatisfactory. Hundreds of languages require their speakers to use a\nnegative element somewhere within the \"scope,\" as linguists call it,\nof a negated verb. The so-called double negative, far from being a\ncorruption, was the norm in Chaucer's Middle English, and negation\nin standard French—as in _]e ne sais pas,_ where _ne_ and _pas_ are both\nnegative—is a familiar contemporary example. Come to think of it,\nStandard English is really no different. What do _any, even,_ and _at all_\nmean in the following sentences?\n\n\nI didn't buy any lottery tickets.\nI didn't eat even a single French fry.\nI didn't eat fried food at all today.\n\n\nClearly, not much: you can't use them alone, as the following strange\nsentences show:\n\n\nI bought any lottery tickets.\nI ate even a single French fry.\nI ate fried food at all today."
    },
    {
        "document_id": "0",
        "parent_id": 562,
        "parent_text": "I didn't buy any lottery tickets.\nI didn't eat even a single French fry.\nI didn't eat fried food at all today.\n\n\nClearly, not much: you can't use them alone, as the following strange\nsentences show:\n\n\nI bought any lottery tickets.\nI ate even a single French fry.\nI ate fried food at all today.\n\n\nWhat these words are doing is exactly what _no_ is doing in nonstandard\nAmerican English, such as in the equivalent _I didn't buy no lottery_\n_tickets_ —agreeing with the negated verb. The slim difference is that\nnonstandard English co-opted the word _no_ as the agreement element,\nwhereas Standard English co-opted the word _any;_ aside from that,\nthey are pretty much translations. And one more point has to be\nmade. In the grammar of standard English, a double negative does\n_not_ assert the corresponding affirmative. No one would dream of\n\n\nThe Language Mavens 377\n\n\nsaying _I can't get no satisfaction_ out of the blue to boast that he easily\nattains contentment. There are circumstances in which one might use\nthe construction to deny a preceding negation in the discourse, but\ndenying a negation is not the same as asserting an affirmative, and\neven then one could probably only use it by putting heavy stress on\nthe negative element, as in the following contrived example:\n\n\nAs hard as I try not to be smug about the misfortunes of\nmy adversaries, I must admit that I can't get _no_ satisfaction out of his tenure denial.\n\n\nSo the implication that use of the nonstandard form would lead to\nconfusion is pure pedantry."
    },
    {
        "document_id": "0",
        "parent_id": 563,
        "parent_text": "As hard as I try not to be smug about the misfortunes of\nmy adversaries, I must admit that I can't get _no_ satisfaction out of his tenure denial.\n\n\nSo the implication that use of the nonstandard form would lead to\nconfusion is pure pedantry.\n\nA tin ear for prosody (stress and intonation) and an obliviousness\nto the principles of discourse and rhetoric are important tools of the\ntrade for the language maven. Consider an alleged atrocity committed\nby today's youth: the expression _I could care less._ The teenagers are\ntrying to express disdain, the adults note, in which case they should\nbe saying _I couldn't care less._ If they could care less than they do, that\nmeans that they really do care, the opposite of what they are trying\nto say. But if these dudes would stop ragging on teenagers and scope\nout the construction, they would see that their argument is bogus.\nListen to how the two versions are pronounced:\n\n\nCOULDN'T care I\nLE CARE\ni ESS. LE\ncould ESS.\n\n\nThe melodies and stresses are completely different, and for a good\nreason. The second version is not illogical, it's _sarcastic._ The point of\nsarcasm is that by making an assertion that is manifestly false or\naccompanied by ostentatiously mannered intonation, one deliberately\nimplies its opposite. A good paraphrase is, \"Oh yeah, as if there was\nsomething in the world that I care less about.\"\n\nSometimes an alleged grammatical \"error\" is logical not only in the\nsense of \"rational\" but in the sense of respecting distinctions made\nby the formal logician. Consider this alleged barbarism, brought up\nby nearly every language maven:\n\n\n378 THE LANGUAGE INSTINCT\n\n\nEveryone returned to their seats.\nAnyone who thinks a Yonex racquet has improved their\n\ngame, raise your hand.\nIf anyone calls, tell them I can't come to the phone.\nSomeone dropped by but they didn't say what they wanted.\nNo one should have to sell their home to pay for medical"
    },
    {
        "document_id": "0",
        "parent_id": 564,
        "parent_text": "378 THE LANGUAGE INSTINCT\n\n\nEveryone returned to their seats.\nAnyone who thinks a Yonex racquet has improved their\n\ngame, raise your hand.\nIf anyone calls, tell them I can't come to the phone.\nSomeone dropped by but they didn't say what they wanted.\nNo one should have to sell their home to pay for medical\n\ncare.\nHe's one of those guys who's always patting themself on\nthe back. [an actual quote from Holden Caulfield in\nJ. D. Salinger's _Catcher in the Rye]_\n\n\nThey explain: _everyone_ means _every one,_ a singular subject, which\nmay not serve as the antecedent of a plural pronoun like _them_ later\nin the sentence. \"Everyone returned to _his_ seat,\" they insist. \"If\nanyone calls, tell _him_ I can't come to the phone.\"\n\nIf you were the target of these lessons, at this point you might be\ngetting a bit uncomfortable. _Everyone returned to his seat_ makes it\nsound like Bruce Springsteen was discovered during intermission to\nbe in the audience, and everyone rushed back and converged on his\nseat to await an autograph. If there is a good chance that a caller may\nbe female, it is odd to ask one's roommate to tell _him_ anything (even\nif you are not among the people who are concerned about \"sexist\nlanguage\"). Such feelings of disquiet—a red flag to any serious linguist—are well founded in this case. The next time you get corrected\nfor this sin, ask Mr. Smartypants how you should fix the following:\n\n\nMary saw everyone before John noticed them."
    },
    {
        "document_id": "0",
        "parent_id": 565,
        "parent_text": "Mary saw everyone before John noticed them.\n\n\nNow watch him squirm as he mulls over the downright unintelligible\n\"improvement,\" _Mary saw_ _everyone before ]ohn_ _noticed him._\nThe logical point that you, Holden Caulfield, and everyone but the\nlanguage mavens intuitively grasp is that _everyone_ and _they_ are not\nan \"antecedent\" and a \"pronoun\" referring to the same person in\nthe world, which would force them to agree in number. They are a\n\"quantifier\" and a \"bound variable,\" a different logical relationship.\n_Everyone returned to their seats_ means \"For all X, X returned to X's\nseat.\" The \"X\" does not refer to any particular person or group of\npeople; it is simply a placeholder that keeps track of the roles that\nplayers play across different relationships. In this case, the X that\n\n\nThe Language Mavens 379\n\n\ncomes back to a seat is the same X that owns the seat that X comes\nback to. The _their_ there does not, in fact, have plural number, because\nit refers neither to one thing nor to many things; it does not refer at\nall. The same goes for the hypothetical caller: there may be one, there\nmay be none, or the phone might ring off the hook with would-be\nsuitors; all that matters is that every time there is a caller, if there is\na caller, that caller, and not someone else, should be put off."
    },
    {
        "document_id": "0",
        "parent_id": 566,
        "parent_text": "comes back to a seat is the same X that owns the seat that X comes\nback to. The _their_ there does not, in fact, have plural number, because\nit refers neither to one thing nor to many things; it does not refer at\nall. The same goes for the hypothetical caller: there may be one, there\nmay be none, or the phone might ring off the hook with would-be\nsuitors; all that matters is that every time there is a caller, if there is\na caller, that caller, and not someone else, should be put off.\n\nOn logical grounds, then, variables are not the same thing as the\nmore familiar \"referential\" pronouns that trigger number agreement\n_(he_ meaning some particular guy, _they_ meaning some particular bunch\nof guys). Some languages are considerate and offer their speakers\ndifferent words for referential pronouns and for variables. But English\nis stingy; a referential pronoun must be drafted into service to lend\nits name when a speaker needs to use a variable. Since these are not\nreal referential pronouns but only homonyms of them, there is no\nreason that the vernacular decision to borrow _they, their, them_ for\nthe task is any worse than the prescriptivists' recommendation of _he,_\n_him, his._ Indeed, _they_ has the advantage of embracing both sexes and\nfeeling right in a wider variety of sentences.\n\nThrough the ages, language mavens have deplored the way English\nspeakers convert nouns into verbs. The following verbs have all been\ndenounced in this century:\n\n\n\nto host\nto chair\nto progress\nto contact\n\n\n\nto caveat\nto nuance\nto dialogue\nto parent\n\n\n\nto input\nto access\nto showcase\nto intrigue\nto impact"
    },
    {
        "document_id": "0",
        "parent_id": 567,
        "parent_text": "Through the ages, language mavens have deplored the way English\nspeakers convert nouns into verbs. The following verbs have all been\ndenounced in this century:\n\n\n\nto host\nto chair\nto progress\nto contact\n\n\n\nto caveat\nto nuance\nto dialogue\nto parent\n\n\n\nto input\nto access\nto showcase\nto intrigue\nto impact\n\n\n\nAs you can see, they range from varying degrees of awkwardness to\nthe completely unexceptionable. In fact, easy conversion of nouns to\nverbs has been part of English grammar for centuries; it is one of the\nprocesses that make English English. I have estimated that about a\nfifth of all English verbs were originally nouns. Considering just the\nhuman body, you can _head a committee, scalp the missionary, eye a_\n_babe,_ _nose around the office,_ _mouth_ _the lyrics,_ _gum the biscuit,_ _begin_\n_teething,_ _tongue each note on the flute, jaw at the referee,_ _neck in the_\n_back seat,_ _back a candidate, arm the militia, shoulder the burden, elbow_\n_your way in, hand him a toy, finger the culprit,_ _knuckle_ _under,_ _thumb_\n\n\n380 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 568,
        "parent_text": "380 THE LANGUAGE INSTINCT\n\n\n_a ride,_ _wrist it into the net,_ _belly up to the bar,_ _stomach someone's_\n_complaints,_ _rib your drinking_ _buddies,_ _knee_ _the goalie,_ _leg_ _it across_\n_town, heel on command, foot the bill, toe the line,_ and several others\nthat I cannot print in a family language book.\nWhat's the problem? The concern seems to be that fuzzy-minded\nspeakers are slowly eroding the distinction between nouns and verbs.\nBut once again, the person in the street is not getting any respect.\nRemember a phenomenon we encountered in Chapter 5: the past\ntense of the baseball term _to fly out_ is _flied,_ not _flew;_ similarly, we say\n_ringed the city,_ not _rang,_ and _grandstanded,_ not _grandstood._ These are\nverbs that came from nouns _(a pop fly, a ring around the city, a_\n_grandstand)._ Speakers are tacitly sensitive to this derivation. The reason they avoid irregular forms like _flew out_ is that their mental dictionary entry for the baseball verb _to fly_ is different from their mental\ndictionary entry for the ordinary verb _to fly_ (what birds do). One is\nrepresented as a verb based on a noun root; the other, as a verb with\na verb root. Only the verb root is allowed to have the irregular pasttense form _flew,_ because only for verb roots does it make sense to\nhave _any_ past-tense form. The phenomenon shows that when people\nuse a noun as a verb, they are making their mental dictionaries more\nsophisticated, not less so—it's not that words are losing their identities as verbs versus nouns; rather, there are verbs, there are nouns,\nand there are verbs based on nouns, and people store each one with\na different mental tag."
    },
    {
        "document_id": "0",
        "parent_id": 569,
        "parent_text": "The most remarkable aspect of the special status of verbs-fromnouns is that everyone unconsciously respects it. Remember from\nChapter 5 that if you make up a new verb based on a noun, like\nsomeone's name, it is always regular, even if the new verb sounds the\nsame as an existing verb that is irregular. (For example, Mae Jemison,\nthe beautiful black female astronaut, _out-Sally-Rided Sally Ride,_ not\n_out-Sally-Rode Sally Ride.)_ My research team has tried this test, using\nabout twenty-five new verbs made out of nouns, on hundreds of\npeople—college students, respondents to an ad we placed in a tabloid\nnewspaper asking for volunteers without college education, schoolage children, even four-year-olds. They all behave like good intuitive\ngrammarians: they inflect verbs that come from nouns differently\nfrom plain old verbs.\n\nSo is there anyone, anywhere, who does not grasp the principle?\n\n\nThe Language Mavens 381\n\n\nYes—the language mavens. Look up _broadcasted_ in Theodore Bernstein's _The Careful Writer,_ and here is what you will find:\n\n\nIf you think you have correctly forecasted the immediate future of\nEnglish and have casted your lot with the permissivists, you may\nbe receptive to _broadcasted,_ at least in radio usage, as are some\ndictionaries. The rest of us, however, will decide that no matter\nhow desirable it may be to convert all irregular verbs into regular\nones, this cannot be done by ukase, nor can it be accomplished\novernight. We shall continue to use _broadcast_ as the past tense and\nparticiple, feeling that there is no reason for _broadcasted_ other than\none of analogy or consistency or logic, which the permissivists\nthemselves so often scorn. Nor is this position inconsistent with our\nposition on _flied,_ the baseball term, which has a real reason for\nbeing. The fact—the inescapable fact—is that there are some irregular verbs."
    },
    {
        "document_id": "0",
        "parent_id": 570,
        "parent_text": "Bernstein's \"real reason\" for _flied_ is that it has a specialized meaning\nin baseball, but that is the wrong reason; _see a bet, cut a deal,_ and\n_take the count_ all have specialized meanings, but they get to keep\ntheir irregular pasts _saw, cut,_ and _took,_ rather than switching to _seed,_\n_cutted, taked._ No, the real reason is that _to fly out_ means _to hit a fly,_\nand _a fly_ is a noun. And the reason that people say _broadcasted_ is the\nsame: not that they want to convert all irregular verbs into regular\nones overnight, but that they mentally analyze the verb _to broadcast_\nas \"to make a broadcast,\" that is, as coming from the much more\ncommon noun _a broadcast._ (The original meaning of the verb, \"to\ndisperse seeds,\" is now obscure except among gardeners.) As a verb\nbased on a noun, _to broadcast_ is not eligible to have its own idiosyncratic past-tense form, so nonmavens sensibly apply the \"add _-ed\"_\nrule.\n\nI am obliged to discuss one more example: the much-vilified _hope-_\n_fully. A_ sentence like _Hopefully, the treaty will pass_ is said to be a\ngrave error. The adverb _hopefully_ comes from the adjective _hopeful,_\nmeaning \"in a manner full of hope.\" Therefore, the mavens say, it\nshould be used only when the sentence refers to a person who is\ndoing something in a hopeful manner. If it is the writer or reader\nwho is hopeful, one should say _It is hoped that the treaty will pass,_ or\n\n\n382 THE LANGUAGE INSTINCT\n\n\n_If hopes are realized,_ _the treaty_ _will pass,_ or _I hope that the treaty will_\n_pass._\n\nNow consider the following:\n\n1. It is simply not true that an English adverb must indicate the\nmanner in which the actor performs the action. Adverbs come in two\nkinds: \"verb phrase\" adverbs like _carefully,_ which do refer to the\nactor, and \"sentence\" adverbs like _frankly,_ which indicate the attitude\nof the speaker toward the content of the sentence. Other examples\nof sentence adverbs include:\n\n\n\naccordingly\nadmittedly\nalarmingly\namazingly\nbasically\n\nbluntly\ncandidly\nconfidentially"
    },
    {
        "document_id": "0",
        "parent_id": 571,
        "parent_text": "Now consider the following:\n\n1. It is simply not true that an English adverb must indicate the\nmanner in which the actor performs the action. Adverbs come in two\nkinds: \"verb phrase\" adverbs like _carefully,_ which do refer to the\nactor, and \"sentence\" adverbs like _frankly,_ which indicate the attitude\nof the speaker toward the content of the sentence. Other examples\nof sentence adverbs include:\n\n\n\naccordingly\nadmittedly\nalarmingly\namazingly\nbasically\n\nbluntly\ncandidly\nconfidentially\n\n\n\ncuriously\ngenerally\nhappily\nhonestly\nideally\nincidentally\nintriguingly\nmercifully\n\n\n\noddly\nparenthetically\npredictably\nroughly\nseriously\nstrikingly\nsupposedly\nunderstandably\n\n\n\nNote that many of these fine sentence adverbs, like _happily, honestly,_\nand _mercifully,_ come from verb phrase adverbs, and they are virtually\nnever ambiguous in context. The use of _hopefully_ as a sentence adverb, which has been around in writing at least since the 1930s\n(according to the _Oxford English Dictionary)_ and in speech well before\nthen, is a perfectly sensible application of this derivational process.\n\n2. The suggested alternatives _It is hoped that_ and _If hopes are_\n_realized_ display four famous sins of bad writing: passive voice, needless words, vagueness, pomposity.\n\n3. The suggested alternatives do not mean the same thing as _hope-_\n_fully,_ so the ban would leave certain thoughts unexpressible. _Hope-_\n_fully_ makes a hopeful prediction, whereas _I hope that_ and _It is hoped_\n_that_ merely describe certain people's mental states. Thus you can say\n_I hope that the treaty will pass, but it isn't likely,_ but it would be odd\nto say _Hopefully,_ _the treaty will pass, but it isn't likely._\n4. We are supposed to use _hopefully_ only as a verb phrase adverb,\nas in the following:\n\n\nHopefully, Larry hurled the ball toward the basket with one\nsecond left in the game.\n\n\nThe Language Mavens 383\n\n\nHopefully, Melvin turned the record over and sat back\ndown on the couch eleven centimeters closer to Ellen."
    },
    {
        "document_id": "0",
        "parent_id": 572,
        "parent_text": "Hopefully, Larry hurled the ball toward the basket with one\nsecond left in the game.\n\n\nThe Language Mavens 383\n\n\nHopefully, Melvin turned the record over and sat back\ndown on the couch eleven centimeters closer to Ellen.\n\n\nCall me uncouth, call me ignorant, but these sentences do not belong\nto any language that I speak.\n\nImagine that one day someone announced that everyone has been\nmaking a grievous error. The correct name for the city in Ohio that\npeople call Cleveland is really Cincinnati, and the correct name for\nthe city that people call Cincinnati is really Cleveland. The expert\ngives no reasons, but insists that that is what is correct, and that\nanyone who cares about the language must immediately change the\nway that he (yes, _he,_ not _they)_ refers to the cities, regardless of the\nconfusion and expense. You would surely think that this person is\ninsane. But when a columnist or editor makes a similar pronouncement about _hopefully,_ he is called an upholder of literacy and high\nstandards.\n\n\nI have debunked nine myths of the generic language maven, and\nnow I would like to examine the mavens themselves. People who set\nthemselves up as language experts differ in their goals, expertise, and\ncommon sense, and it is only fair to discuss them as individuals.\n\nThe most common kind of maven is the wordwatcher (a term\ninvented by the biologist and wordwatcher Lewis Thomas). Unlike\nlinguists, wordwatchers train their binoculars on the especially capricious, eccentric, and poorly documented words and idioms that get\nsighted from time to time. Sometimes a wordwatcher is a scholar in\nsome other field, like Thomas or Quine, who indulges a lifelong\nhobby by writing a charming book on word origins. Sometimes it is a\njournalist assigned to the Question & Answer column of a newspaper.\nHere is a recent example from _Ask the Globe:_\n\n\nQ. When we want to irritate someone, why do we say we want \"to\nget his goat\"? _J.E., Boston_"
    },
    {
        "document_id": "0",
        "parent_id": 573,
        "parent_text": "Q. When we want to irritate someone, why do we say we want \"to\nget his goat\"? _J.E., Boston_\n\nA. Slang experts aren't entirely sure, but some claim the expression\ncomes from an old race track tradition of putting a goat in the same\nstall as a high-strung racing thoroughbred to keep the horse calm.\nNineteenth century gamblers sometimes stole the goat to unnerve\n\n\n384 THE LANGUAGE INSTINCT\n\n\nthe horse and throw the race. Hence, the expression \"get your\ngoat.\"\n\n\nThis kind of explanation is satirized in Woody Allen's \"Slang Origins\".\n\n\nHow many of you have wondered where certain slang expressions\ncome from? Like \"She's the cat's pajamas,\" or to \"take it on the\nlam.\" Neither have I. And yet for those who are interested in this\nsort of thing I have provided a brief guide to a few of the more\ninteresting origins.\n\n.. . \"Take it on the lam\" is English in origin. Years ago, in\nEngland, \"lamming\" was a game played with dice and a large tube\nof ointment. Each player in turn threw dice and then skipped\naround the room until he hemorrhaged. If a person threw seven or\nunder he would say the word \"quintz\" and proceed to turn in a\nfrenzy. If he threw over seven, he was forced to give every player a\nportion of his feathers and was given a good \"lamming.\" Three\n\"lammings\" and a player was \"kwirled\" or declared a moral bankrupt. Gradually any game with feathers was called \"lamming\" and\nfeathers became \"lams.\" To \"take it on the lam\" meant to put on\nfeathers and later, to escape, although the transition is unclear."
    },
    {
        "document_id": "0",
        "parent_id": 574,
        "parent_text": "This passage captures my reaction to the wordwatchers. I don't think\nthey do any harm, but (a) I never completely believe their explanations, and (b) in most cases I don't really care. Years ago a columnist\nrecounted the origin of the word _pumpernickel._ During one of his\ncampaigns in central Europe Napoleon stopped at an inn and was\nserved a loaf of coarse, dark, sour bread. Accustomed to the delicate\nwhite baguettes of Paris, he sneered, \"C'est pain pour Nicole,\" Nicole\nbeing his horse. When the columnist was challenged (the dictionaries\nsay the word comes from colloquial German, meaning \"farting goblin\"), he confessed that he and some buddies had made up the story\nin a bar the night before. For me, wordwatching for its own sake has\nall the intellectual excitement of stamp collecting, with the added\ntwist that an undetermined number of your stamps are counterfeit.\n\nAt the opposite end of the temperamental spectrum one finds the\nJeremiahs, expressing their bitter laments and righteous prophecies\nof doom. An eminent dictionary editor, language columnist, and usage\nexpert once wrote, quoting a poet:\n\n\nThe Language Mavens 385\n\n\nAs a poet, there is only one political duty and that is to defend one's\nlanguage from corruption. And that is particularly serious now. It\nis being corrupted. When it is corrupted, people lose faith in what\nthey hear, and that leads to violence.\n\n\nThe linguist Dwight Bolinger, gently urging this man to get a grip,\nhad to point out that \"the same number of muggers would leap out\nof the dark if everyone conformed overnight to every prescriptive rule\never written.\"\n\nIn recent years the loudest Jeremiah has been the critic John Simon,\nwhose venomous film and theater reviews are distinguished by their\nlengthy denunciations of actresses' faces. Here is a representative\nopening to one of his language columns:"
    },
    {
        "document_id": "0",
        "parent_id": 575,
        "parent_text": "The linguist Dwight Bolinger, gently urging this man to get a grip,\nhad to point out that \"the same number of muggers would leap out\nof the dark if everyone conformed overnight to every prescriptive rule\never written.\"\n\nIn recent years the loudest Jeremiah has been the critic John Simon,\nwhose venomous film and theater reviews are distinguished by their\nlengthy denunciations of actresses' faces. Here is a representative\nopening to one of his language columns:\n\n\nThe English language is being treated nowadays exactly as slave\ntraders once handled the merchandise in their slave ships, or as the\ninmates of concentration camps were dealt with by their Nazi jailers.\n\n\nThe grammatical error that inspired this tasteless comparison, incidentally, was Tip O'Neill's redundantly referring to his \"fellow colleagues,\" which Simon refers to as \"the rock bottom of linguistic\nineptitude.\" Speaking of Black English Vernacular, Simon writes:\n\n\nWhy should we consider some, usually poorly educated, subculture's notion of the relationship between sound and meaning? And\nhow could a grammar—any grammar—possibly describe that relationship?\n\nAs for \"I be,\" \"you be,\" \"he be,\" etc., which should give us all\nthe heebie-jeebies, these may indeed be comprehensible, but they\ngo against all accepted classical and modern grammars and are the\nproduct not of a language with roots in history but of ignorance of\nhow language works.\n\n\nThere is no point in refuting this malicious know-nothing, for he is\nnot participating in any sincere discussion. Simon has simply discovered the trick used with great effectiveness by certain comedians,\ntalk-show hosts, and punk-rock musicians: people of modest talent\ncan attract the attention of the media, at least for a while, by being\nunrelentingly offensive.\n\n\n386 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 576,
        "parent_text": "There is no point in refuting this malicious know-nothing, for he is\nnot participating in any sincere discussion. Simon has simply discovered the trick used with great effectiveness by certain comedians,\ntalk-show hosts, and punk-rock musicians: people of modest talent\ncan attract the attention of the media, at least for a while, by being\nunrelentingly offensive.\n\n\n386 THE LANGUAGE INSTINCT\n\n\nThe third kind of language maven is the entertainer, who shows\noff his collection of palindromes, puns, anagrams, rebuses, malapropisms, Goldwynisms, eponyms, sesquipedalia, howlers, and bloopers.\nEntertainers like Willard Espy, Dimitri Borgman, Gyles Brandreth,\nand Richard Lederer write books with titles like _Words at Play, Lan-_\n\n_guage on Vacation,_ _The Joy of Lex,_ and _Anguished English._ These\nrollicking exhibitions of linguistic zaniness are all in good fun, but\nwhen reading them I occasionally feel like Jacques Cousteau at a\ndolphin show, longing that these magnificent creatures be allowed to\nshake off their hula skirts and display their far more interesting natural\ntalents in a dignified setting. Here is a typical example from Lederer:\n\n\nWhen we take the time to explore the paradoxes and vagaries of\nEnglish, we find that hot dogs can be cold, darkrooms can be lit,\nhomework can be done in school, nightmares can take place in\nbroad daylight while morning sickness and daydreaming can take\nplace at night...."
    },
    {
        "document_id": "0",
        "parent_id": 577,
        "parent_text": "When we take the time to explore the paradoxes and vagaries of\nEnglish, we find that hot dogs can be cold, darkrooms can be lit,\nhomework can be done in school, nightmares can take place in\nbroad daylight while morning sickness and daydreaming can take\nplace at night....\n\nSometimes you have to believe that all English speakers should\nbe committed to an asylum for the verbally insane. In what other\nlanguage do people drive in a parkway and park in a driveway? In\nwhat other language do people recite at a play and play at a recital? . . . How can a slim chance and a fat chance be the same,\nwhile a wise man and a wise guy are opposites? . **. . Doughnut holes:**\nAren't these little treats _doughnut balls?_ The holes are what's left in\nthe original doughnut. . **. . They're head over heels in love.** That's\nnice, but all of us do almost everything _head over heels._ If we are\ntrying to create an image of people doing cartwheels and somersaults, why don't we say, _They're heels over head in love?_\n\n\nObjection! (1) Everyone senses the difference between a compound, which can have a conventional meaning of its own, like any\nother word, and a phrase, whose meaning is determined by the meanings of its parts and the rules that put them together. A compound\nis pronounced with one stress pattern _(darkroom)_ and a phrase is\npronounced with another _(dark room)._ The supposedly \"crazy\" expressions, like _hot dog_ and _morning sickness,_ are obviously compounds, not phrases, so cold hot dogs and nighttime morning sickness\ndo not violate grammatical logic in the least. (2) Isn't it obvious that\n\n\nThe Language Mavens 387"
    },
    {
        "document_id": "0",
        "parent_id": 578,
        "parent_text": "The Language Mavens 387\n\n\n_fat chance_ and _wise guy_ are sarcastic? (3) _Donut holes,_ the trade name\nof a product of Dunkin' Donuts, is intentionally whimsical—did\nsomeone not get the joke? (4) The preposition _over_ has several meanings, including a static arrangement, as in _Bridge over troubled water,_\nand the path of a moving object, as in _The quick brown fox jumped_\n_over the lazy dog. Head over heels_ involves the second meaning, describing the motion, not the position, of the inamorato's head.\n\nI must also say something in defense of the college students, welfare\napplicants, and Joe Sixpacks whose language is so often held up to\nridicule by the entertainers. Cartoonists and dialogue writers know\nthat you can make anyone look like a bumpkin by rendering his\nspeech quasi-phonetically instead of with conventional spelling\n(\"sez,\" \"cum,\" \"wimmin,\" \"hafta,\" \"crooshul,\" and so on). Lederer\noccasionally resorts to this cheap trick in \"Howta Reckanize American\nSlurvian,\" which deplores unremarkable examples of English phonological processes like \"coulda\" and \"could of\" _(could have),_ \"forced\"\n\n_(forest),_ \"granite\" _(granted),_ \"neck store\" _(next door),_ and \"then\"\n_(than)._ As we saw in Chapter 6, everyone but a science fiction robot\nslurs their speech (yes, _their_ speech, dammit) in systematic ways.\n\nLederer also reproduces lists of \"howlers\" from student term papers, automobile insurance claim forms, and welfare applications,\nfamiliar to many people as faded mimeos tacked on the bulletin\nboards of university and government offices:\n\n\nIn accordance with your instructions I have given birth to\n\ntwins in the enclosed envelope.\nMy husband got his project cut off two weeks ago and I\n\nhaven't had any relief since.\nAn invisible car came out of nowhere, struck my car, and\n\nvanished.\nThe pedestrian had no idea which direction to go, so I ran\nover him.\nArtificial insemination is when the farmer does it to the cow\n\ninstead of the bull.\nThe girl tumbled down the stairs and lay prostitute on the"
    },
    {
        "document_id": "0",
        "parent_id": 579,
        "parent_text": "In accordance with your instructions I have given birth to\n\ntwins in the enclosed envelope.\nMy husband got his project cut off two weeks ago and I\n\nhaven't had any relief since.\nAn invisible car came out of nowhere, struck my car, and\n\nvanished.\nThe pedestrian had no idea which direction to go, so I ran\nover him.\nArtificial insemination is when the farmer does it to the cow\n\ninstead of the bull.\nThe girl tumbled down the stairs and lay prostitute on the\n\nbottom.\nMoses went up on Mount Cyanide to get the ten commandments. He died before he ever reached Canada.\n\n\n388 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 580,
        "parent_text": "vanished.\nThe pedestrian had no idea which direction to go, so I ran\nover him.\nArtificial insemination is when the farmer does it to the cow\n\ninstead of the bull.\nThe girl tumbled down the stairs and lay prostitute on the\n\nbottom.\nMoses went up on Mount Cyanide to get the ten commandments. He died before he ever reached Canada.\n\n\n388 THE LANGUAGE INSTINCT\n\n\nThese lists are good for a few laughs, but there is something you\nshould know before you conclude that the teeming masses are comically inept at writing. Most of the howlers are probably fabrications.\nThe folklorist Jan Brunvand has documented hundreds of \"urban\nlegends,\" intriguing stories that everyone swears happened to a friend\nof a friend ( \" F O A F \" is the technical term), and that circulate for years\nin nearly identical form in city after city, but that can never be\ndocumented as real events. The Hippie Baby Sitter, Alligators in the\nSewers, the Kentucky Fried Rat, and Halloween Sadists (the ones\nwho put razor blades in apples) are some of the more famous tales.\nThe howlers, it turns out, are examples of a subgenre called xeroxlore.\nThe employee who posts one of these lists admits that he did not\ncompile the items himself but took them from a list someone gave\nhim, which were taken from another list, which excerpted letters that\nsomeone in some office somewhere _really did receive._ Nearly identical\nlists have been circulating since World War I, and have been independently credited to offices in New England, Alabama, Salt Lake City,\nand so on. As Brunvand notes, the chances seem slim that the same\namusing double entendres are made in so many separate locations\nover so many years. The advent of electronic mail has quickened the\ncreation and dissemination of these lists, and I receive one every now\nand again. But I smell intentional facetiousness (whether it is from\nthe student or the professor is not clear), not accidentally hilarious\nincompetence, in howlers like \"adamant: pertaining to original sin\"\nand \"gubernatorial: having to do with peanuts.\""
    },
    {
        "document_id": "0",
        "parent_id": 581,
        "parent_text": "The final kind of maven is the sage, typified by the late Theodore\nBernstein, a _New York Times_ editor and the author of the delightful\nhandbook _The Careful Writer,_ and William Safire. They are known\nfor taking a moderate, common-sense approach to matters of usage,\nand they tease their victims with wit rather than savaging them with\ninvective. I enjoy reading the sages, and have nothing but awe for a\npen like Safire's that can summarize the content of an anti-pornography statute as \"It isn't the teat, it's the tumidity.\" But the sad fact is\nthat even a sage like Safire, the closest thing we have to an enlightened\nlanguage pundit, misjudges the linguistic sophistication of the common speaker and as a result misses the target in many of his commen\n\nThe Language Mavens 389\n\n\ntaries. To prove this charge, I will walk you through a single column\nof his, from _The New York Times Magazine_ of October 4, 1992.\n\nThe column had three stories, discussing six examples of questionable usage. The first story was a nonpartisan analysis of supposed\npronoun case errors made by the two candidates in the 1992 U.S.\npresidential election. George Bush had recently adopted the slogan\n\"Who do you trust?,\" alienating schoolteachers across the nation who\nnoted that _who_ is a \"subject pronoun\" (nominative or subjective case)\nand the question is asking about the object of _trust_ (accusative or\nobjective case). One would say _You do trust him,_ not _You do trust he,_\nand so the question word should be _whom,_ not _who._"
    },
    {
        "document_id": "0",
        "parent_id": 582,
        "parent_text": "This, of course, is one of the standard prescriptivist complaints\nabout common speech. In reply, one might point out that the _who/_\n_whom_ distinction is a relic of the English case system, abandoned\nby nouns centuries ago and found today only among pronouns in\ndistinctions like _he/him._ Even among pronouns, the old distinction\nbetween subject _ye_ and object _you_ has vanished, leaving _you_ to play\nboth roles and _ye_ as sounding completely archaic. _Whom_ has outlived\n_ye_ but is clearly moribund; it now sounds pretentious in most spoken\ncontexts. No one demands of Bush that he say _Whom do ye trust?_ If\nthe language can bear the loss of _ye,_ using _you_ for both subjects and\nobjects, why insist on clinging to _whom,_ when everyone uses _who_ for\nboth subjects and objects?\n\nSafire, with his enlightened attitude toward usage, recognizes the\nproblem and proposes\n\n\nSafire's Law of Who/Whom, which forever solves the problem\ntroubling writers and speakers caught between the pedantic and\nthe incorrect: \"When _whom_ is correct, recast the sentence.\" Thus,\ninstead of changing his slogan to \"Whom do you trust?\"—making\nhim sound like a hypereducated Yalie stiff—Mr. Bush would win\nback the purist vote with \"Which candidate do you trust?\"\n\n\nBut Safire's recommendation is Solomonic in the sense of being an\nunacceptable pseudo-compromise. Telling people to avoid a problematic construction sounds like common sense, but in the case of object\nquestions with _who,_ it demands an intolerable sacrifice. People ask\nquestions about the objects of verbs and prepositions _a lot._ Here are\n\n\n390 THE LANGUAGE INSTINCT\n\n\njust a few examples I culled from transcripts of conversations between\nparents and their children:\n\n\nI know, but who did we see at the other store?\nWho did we see on the way home?\nWho did you play with outside tonight?\nAbe, who did you play with today at school?\nWho did you sound like?"
    },
    {
        "document_id": "0",
        "parent_id": 583,
        "parent_text": "390 THE LANGUAGE INSTINCT\n\n\njust a few examples I culled from transcripts of conversations between\nparents and their children:\n\n\nI know, but who did we see at the other store?\nWho did we see on the way home?\nWho did you play with outside tonight?\nAbe, who did you play with today at school?\nWho did you sound like?\n\n\n(Imagine replacing any of these with _whom!)_ Safire's advice is to\nchange such questions to _Which person_ or _Which child._ But the advice\nwould have people violate the most important maxim of good prose:\nOmit needless words. It also would force them to overuse the word\n_which,_ described by one stylist as \"the ugliest word in the English\nlanguage.\" Finally, it subverts the supposed goal of rules of usage,\nwhich is to allow people to express their thoughts as clearly and\nprecisely as possible. A question like _Who did we see on the way_\n_home?_ can embrace one person, many people, or any combination or\nnumber of adults, babies, children, and familiar dogs. Any specific\nsubstitution like _Which person?_ forecloses some of these possibilities,\ncontrary to the question-asker's intent. And how in the world would\nyou apply Safire's Law to the famous refrain\n\n\nWho're you gonna call? GHOSTBUSTERS!\n\n\nExtremism in defense of liberty is no vice. Safire should have taken\nhis observation about the pedantic sound of _whom_ to its logical\nconclusion and advised the president that there is no reason to change\nthe slogan, at least no grammatical reason.\nTurning to the Democrats, Safire gets on Bill Clinton's case, as he\nputs it, for asking voters to \"give Al Gore and I a chance to bring\nAmerica back.\" No one would say _give I a break,_ because the indirect\nobject of _give_ must have accusative case. So it should be _give Al Gore_\n\n_and me_ _a_ _chance._\nProbably no \"grammatical error\" has received as much scorn as\n\"misuse\" of pronoun case inside conjunctions (phrases containing\ntwo elements joined by _and_ or _or)._ What teenager has not been\n\n\nThe Language Mavens 391"
    },
    {
        "document_id": "0",
        "parent_id": 584,
        "parent_text": "_and me_ _a_ _chance._\nProbably no \"grammatical error\" has received as much scorn as\n\"misuse\" of pronoun case inside conjunctions (phrases containing\ntwo elements joined by _and_ or _or)._ What teenager has not been\n\n\nThe Language Mavens 391\n\n\ncorrected for saying _Me and Jennifer are going to the mall? A_ colleague\nof mine recalls that when she was twelve, her mother would not allow\nher to have her ears pierced until she stopped saying it. The standard\nstory is that the accusative pronoun _me_ does not belong in subject\nposition—no one would say _Me is going to the mall_ —so it should be\n_Jennifer and I._ People tend to misremember the advice as \"When\nin doubt, 'say so-and-so and I,' not 'so-and-so and me,' \" so they\nunthinkingly overapply it—a process linguists call hypercorrection—\nresulting in \"mistakes\" like _give Al Gore and I a chance_ and the even\nmore despised _between you and I._\n\nBut if the person on the street is so good at avoiding _Me is going_\nand _Give I a break,_ and if even Ivy League professors and former\nRhodes Scholars can't seem to avoid _Me and Jennifer are going_ and\n_Give Al and I a chance,_ might it not be the mavens that misunderstand\nEnglish grammar, not the speakers? The mavens' case about case rests\non one assumption: if an entire conjunction phrase has a grammatical\nfeature like subject case, every word inside that phrase has to have\nthat grammatical feature, too. But that is just false."
    },
    {
        "document_id": "0",
        "parent_id": 585,
        "parent_text": "_Jennifer_ is singular; you say _Jennifer is,_ not _Jennifer are._ The pronoun _She_ is singular; you say _She is,_ not _She are._ But the conjunction\n_She and Jennifer_ is not singular, it's plural; you say _She and Jennifer_\n_are,_ not _She and Jennifer is._ So if a conjunction can have a different\ngrammatical _number_ from the pronouns inside it (She and Jennifer\n_are),_ why must it have the same grammatical _case_ as the pronouns\ninside it (Give Al Gore and I a chance)? The answer is that it need\nnot. A conjunction is an example of a \"headless\" construction. Recall\nthat the head of a phrase is the word that stands for the whole phrase.\nIn the phrase _the tall blond man with one black shoe,_ the head is the\nword _man,_ because the entire phrase gets its properties from _man—_\nthe phrase refers to a kind of man, and is third person singular,\nbecause that's what _man_ is. But a conjunction has no head; it is not\nthe same as any of its parts. If John and Marsha met, it does not mean\nthat John met and that Marsha met. If voters give Clinton and Gore\na chance, they are not giving Gore his own chance, added on to the\nchance they are giving Clinton; they are giving the entire ticket a\nchance. So just because _Me and Jennifer_ is a subject that requires\nsubject case, it does not mean that _Me_ is a subject that requires subject\ncase, and just because _Al Gore and I_ is an object that requires object\ncase, it does not mean that I is an object that requires object case.\n\n\n392 THE LANGUAGE INSTINCT\n\n\nOn grammatical grounds, the pronoun is free to have any case it\nwants. The linguist Joseph Emonds has analyzed the _Me and Jennifer/_\n_Between you and I_ phenomenon in great technical detail. He concludes that the language that the mavens want us to speak is not only\nnot English, it is not a possible human language!\nIn the second story of his column, Safire replies to a diplomat who\nreceived a government warning about \"crimes against tourists (primarily\nrobberies, muggings, and pick-pocketings).\" The diplomat writes,"
    },
    {
        "document_id": "0",
        "parent_id": 586,
        "parent_text": "Note the State Department's choice of _pick-pocketings._ Is the doer\nof such deeds a _pickpocket_ or a _pocket-picker?_\n\n\nSafire replies, \"The sentence should read 'robberies, muggings and\npocket-pickings.' One picks pockets; no one pockets picks.\"\nSignificantly, Safire did not answer the question. If the perpetrator\nwere called a _pocket-picker,_ which is the most common kind of compound in English, then indeed the crime would be _pocket-picking._\nBut the name for the perpetrator is not really up for grabs; we all\nagree that he is called a _pickpocket._ And if he is called a pickpocket,\nnot a pocket-picker, then what he does can perfectly well be called\npick-pocketing, not pocket-picking, thanks to the ever-present English noun-to-verb conversion process, just as a cook cooks, a chair\nchairs, and a host hosts. The fact that no one pockets picks is a red\nherring—who said anything about a _pick-pocketer?_\n\nThe thing that is confusing Safire is that _pickpocket_ is a special kind\nof compound, because it is headless—it is not a kind of pocket, as\none would expect, but a kind of person. And though it is exceptional,\nit is not unique; there is a whole family of such exceptions. One of\nthe delights of English is its colorful cast of characters denoted by\nheadless compounds, compounds that describe a person by what he\n\n_does_ or _has_ rather than by what he _is:_\n\n\n\nbird-brain\nblockhead\nboot-black\nbutterfingers\ncut-throat\ndead-eye\negghead\n\n\n\nfour-eyes\ngoof-off\nhard-hat\nheart-throb\nheavyweight\nhigh-brow\nhunchback\n\n\n\nlazy-bones\nloudmouth\nlow-life\nne'er-do-well\n\npip-squeak\nredneck\n\nscarecrow\n\n\nThe Language Mavens 393\n\n\n\nfathead\nflatfoot\n\n\n\nkilljoy\nknow-nothing\n\n\n\nscofflaw\nwetback\n\n\n\nThis list (sounding vaguely like a dramatis personae from Damon\nRunyon) shows that virtually everything in language falls into systematic patterns, even the seeming exceptions, if only you bother to look\nfor them.\n\nThe third story deconstructs a breathless quote from Barbra Streisand, describing tennis star Andre Agassi:"
    },
    {
        "document_id": "0",
        "parent_id": 587,
        "parent_text": "lazy-bones\nloudmouth\nlow-life\nne'er-do-well\n\npip-squeak\nredneck\n\nscarecrow\n\n\nThe Language Mavens 393\n\n\n\nfathead\nflatfoot\n\n\n\nkilljoy\nknow-nothing\n\n\n\nscofflaw\nwetback\n\n\n\nThis list (sounding vaguely like a dramatis personae from Damon\nRunyon) shows that virtually everything in language falls into systematic patterns, even the seeming exceptions, if only you bother to look\nfor them.\n\nThe third story deconstructs a breathless quote from Barbra Streisand, describing tennis star Andre Agassi:\n\n\nHe's very, very intelligent; very, very, sensitive, very evolved; more\nthan his linear years. . . . He plays like a Zen master. It's very in the\nmoment.\n\n\nSafire first speculates on the origin of Streisand's use of _evolved:_ \"Its\nchange from the active to passive voice—from 'he _evolved from_ the\nMissing Link' to 'He _is evolved'_ —was probably influenced by the\nadoption of _involved_ as a compliment.\"\n\nThese kinds of derivations have been studied intensively in linguistics, but Safire shows here that he does not understand how they\nwork. He seems to think that people change words by being vaguely\nreminded of rhyming ones— _evolved_ from _involved,_ a kind of malapropism. But in fact people are not that sloppy and literal-minded.\nThe lexical creations we have looked at— _Let me caveat that; They_\n\n_deteriorated the_ _health_ _care_ _system;_ _Boggs flied_ _out_ _to_ _center field_ —are\nbased not on rhymes but on abstract rules that change a word's partof-speech category and its cast of role-players, in the same precise\nways across dozens or hundreds of words. For example, the transitive\n_to deteriorate the health care system_ comes from the intransitive _the_\n_health care system deteriorated_ in the same way that the transitive _to_\n_break the glass_ comes from the intransitive _the glass broke._ Let's see,\nthen, where _evolved_ might have come from.\n\nSafire's suggestion that it is an active-to-passive switch based on\n_involved_ does not work at all. For _involved,_ we can perhaps imagine\na derivation from the active voice:"
    },
    {
        "document_id": "0",
        "parent_id": 588,
        "parent_text": "Safire's suggestion that it is an active-to-passive switch based on\n_involved_ does not work at all. For _involved,_ we can perhaps imagine\na derivation from the active voice:\n\n\nRaising the child involved John. (active) —>\nJohn was involved in raising his child. (passive) —>\nJohn is very involved.\n\n\n394 THE LANGUAGE INSTINCT\n\n\nBut for _evolved,_ the parallel derivation would require a passive sentence, and before that an active sentence, that do not exist (I have\nmarked them with asterisks):\n\n\n*Many experiences evolved John. —>\n*John was evolved by many experiences. (or) *John was\nevolved in many experiences. —>\nJohn is very evolved.\n\n\nAlso, if you're involved, it means that something involves you (you're\nthe object), whereas if you're evolved, it means that you have been\ndoing some evolving (you're the subject).\nThe problem is that the conversion of _evolved from_ to _very evolved_\nis not a switch from the active voice of a verb to the passive voice, as\nin _Andre beat Boris —> Boris was beaten by Andre._ The source Safire\nmentions, _evolved from,_ is intransitive in modern English, with no\ndirect object. To passivize a verb in English you convert the direct\nobject into a subject, so _is evolved_ could only have been passivized\nfrom _Something evolved Andre,_ which does not exist. Safire's explanation is like saying you can take _Bill bicycled from Lexington_ and change\nit to _Bill is bicycled_ and then to _Bill is very bicycled._"
    },
    {
        "document_id": "0",
        "parent_id": 589,
        "parent_text": "This breakdown is a good illustration of one of the main scandals\nof the language mavens: they show lapses in the most elementary\nproblems of grammatical analysis, like figuring out the part-of-speech\ncategory of a word. Safire refers to the active and passive voice, two\nforms of a verb. But is Barbra using _evolved_ as a verb? One of the\nmajor discoveries of modern generative grammar is that the part of\nspeech of a word—noun, verb, adjective—is not a label assigned by\nconvenience but an actual mental category that can be verified by\nexperimental assays, just as a chemist can verify whether a gem is a\ndiamond or zirconium. These tests are a standard homework problem\nin the introductory course that linguists everywhere call Baby Syntax.\nThe method is to find as many constructions as you can in which\nwords that are clear-cut examples of a category, and no other kind\nof word, can appear. Then when you are faced with a word whose\ncategory you do not know, you can see whether it can appear in that\nset of constructions with some natural interpretation. By these tests\nwe can determine, for example, that the language maven Jacques\n\n\nThe Language Mavens 395\n\n\nBarzun earned an \"F\" when he called a possessive noun like _Welling-_\n_ton's_ an adjective (as before, I have placed asterisks beside the phrases\nthat sound wrong):\n\n\nR E A L A D J E C T I V E I M P O S T E R\n\n\n\n1. _very_ X: very intelligent *very Wellington's\n\n\n\n2. _seems_ X: He seems *This seems\nintelligent Wellington's\n\n\n\n3. _How_ X: How intelligent is *How Wellington's is\n\n\n\nhe? this ring?\n4. _more_ X _than:_ more intelligent *more Wellington's\nthan than\n\n\n\n5. _a_ Adj X Adj N: a funny, intelligent *a funny, Wellington's\nold friend old friend\n\n\n\n6. _un-X:_ unintelligent *un-Wellington's\n\n\n\nNow let's apply this kind of test to Barbra's _evolved,_ comparing\nit to a clear-cut verb in the passive voice like _was kissed by a_\n_passionate lover_ (odd-sounding constructions are marked with an\nasterisk):"
    },
    {
        "document_id": "0",
        "parent_id": 590,
        "parent_text": "3. _How_ X: How intelligent is *How Wellington's is\n\n\n\nhe? this ring?\n4. _more_ X _than:_ more intelligent *more Wellington's\nthan than\n\n\n\n5. _a_ Adj X Adj N: a funny, intelligent *a funny, Wellington's\nold friend old friend\n\n\n\n6. _un-X:_ unintelligent *un-Wellington's\n\n\n\nNow let's apply this kind of test to Barbra's _evolved,_ comparing\nit to a clear-cut verb in the passive voice like _was kissed by a_\n_passionate lover_ (odd-sounding constructions are marked with an\nasterisk):\n\n\n1. very evolved / *very kissed\n2. He seems evolved / *He seems kissed\n3. How evolved is he? / *How kissed is he?\n4. He is more evolved now than he was last year / *He is\nmore kissed now than he was yesterday\n5. a thoughtful, evolved, sweet friend / *a tall, kissed,\nthoughtful man\n6. He was unevolved / *He was unkissed by a passionate\nlover\n\n\nObviously, _evolved_ does not behave like the passive voice of a verb;\nit behaves like an adjective. Safire was misled because adjectives can\nlook like verbs in the passive voice and are clearly related to them,\nbut they are not the same thing. This is the source of the running\njoke in the Bob Dylan song \"Rainy Day Women #12 & 35\":\n\n\nThey'll stone you when you're riding in your car.\nThey'll stone you when you're playing your guitar.\n\n\n396 THE LANGUAGE INSTINCT\n\n\nBut I would not feel so all alone.\nEverybody must get stoned.\n\n\nThis discovery steers us toward the real source of _evolved._ Since it\nis an adjective, not a verb in the passive voice, we no longer have to\nworry about the absence of the corresponding active voice sentence.\nTo trace its roots, we must find a rule in English that creates adjectives\nfrom intransitive verbs. There is such a rule. It applies to the participle\nform of a certain class of intransitive verbs that refer to a change of\nstate (what linguists call \"unaccusative\" verbs), and creates a corresponding adjective:"
    },
    {
        "document_id": "0",
        "parent_id": 591,
        "parent_text": "time that has elapsed —> elapsed time\na leaf that has fallen —> a fallen leaf\na man who has traveled widely —> a widely traveled man\na testicle that has not descended into the scrotum —> an\n\nundescended testicle\na Christ that has risen from the dead —> a risen Christ\na window that has stuck —> a stuck window\nthe snow which has drifted —> the drifted snow\na Catholic who has lapsed —> a lapsed Catholic\na lung that has collapsed —> a collapsed lung\na writer who has failed —> a failed writer\n\n\nTake this rule and apply it to _a tennis player who has evolved,_ and\nyou get _an evolved player._ This solution also allows us to make sense\nof Streisand's meaning. When a verb is converted from the active to\nthe passive voice, the verb's meaning is conserved. _Dog bites man =_\n_Man is bitten by dog._ But when a verb is converted to an adjective,\nthe adjective can acquire idiosyncratic nuances. Not every woman\nwho has fallen is a fallen woman, and if someone stones you you are\nnot necessarily stoned. We all evolved from a missing link, but not\nall of us are evolved in the sense of being more spiritually sophisticated\nthan our contemporaries.\n\nSafire then rebukes Streisand for _more than his linear years._ He says,\n\n\n_Linear_ means \"direct, uninterrupted\"; it has gained a pejorative\nvogue sense of \"unimaginative,\" as in _linear thinking,_ in contrast to\n\n\nThe Language Mavens 397\n\n\ninsightful, inspired leaps of genius. I think what Ms. Streisand had\nin mind was \"beyond his chronological years,\" which is better\nexpressed as simply \"beyond his years.\" You can see what she was\ngetting at—the years lined up in an orderly fashion—but even in\nthe anything-goes world of show-biz lingo, not everything goes.\nStrike the set on _linear._"
    },
    {
        "document_id": "0",
        "parent_id": 592,
        "parent_text": "The Language Mavens 397\n\n\ninsightful, inspired leaps of genius. I think what Ms. Streisand had\nin mind was \"beyond his chronological years,\" which is better\nexpressed as simply \"beyond his years.\" You can see what she was\ngetting at—the years lined up in an orderly fashion—but even in\nthe anything-goes world of show-biz lingo, not everything goes.\nStrike the set on _linear._\n\n\nLike many language mavens, Safire underestimates the precision and\naptness of slang, especially slang borrowed from technical fields.\nStreisand obviously is not using the sense of _linear_ from Euclidean\ngeometry, meaning \"the shortest route between two points,\" and the\nassociated image of years lined up in an orderly fashion. She is using\nthe sense taken from analytic geometry, meaning \"proportional\" or\n\"additive.\" If you take a piece of graph paper and plot the distance\ntraveled at constant speed against the time that has elapsed, you get\na straight line. This is called a linear relationship; for every hour that\npasses, you've traveled another 55 miles. In contrast, if you plot the\namount of money in your compound-interest account, you get a\nnonlinear curve that swerves upward; as you leave your money in\nlonger, the amount of interest you accrue in a year gets larger and\nlarger. Streisand is implying that Agassi's level of evolvedness is not\nproportional to his age: whereas most people fall on a straight line\nthat assigns them X spiritual units of evolvedness for every year they\nhave lived, this young man's evolvedness has been compounding, and\nhe floats above the line, with more units than his age would ordinarily\nentitle him to. Now, I cannot be sure that this is what Streisand had\nin mind (at the time of this writing, she has not replied to my inquiry),\nbut this sense of _linear_ is common in contemporary techno-pop cant\n(like _feedback,_ _systems,_ _holism,_ _interface,_ and _synergistic),_ and it is\nunlikely that she blundered into a perfectly apt usage by accident, as\nSafire's analysis would imply."
    },
    {
        "document_id": "0",
        "parent_id": 593,
        "parent_text": "Finally, Safire comments on _very in the moment:_\n\n\nThis _very_ calls attention to the use of a preposition or a noun as a\nmodifier, as in \"It's very _in,\"_ or \"It's very _New York,\"_ or the\nultimate fashion compliment, \"It's very _you.\"_ To be very _in the_\n_moment_ (perhaps a variation of _of the moment_ or _up to the minute)_\nappears to be a loose translation of the French _au courant,_ variously\ntranslated as \"up to date, fashionable, with-it.\"\n\n\n398 THE LANGUAGE INSTINCT\n\n\nOnce again, by patronizing Streisand's language, Safire has misanalyzed both its form and its meaning. He has not noticed that: (1) The\nword _very_ is not connected to the preposition _in;_ it's connected to\nthe entire prepositional phrase _in the moment._ (2) Streisand is not\nusing the intransitive _in,_ with its special sense of \"fashionable\"; she\nis using the conventional transitive _in_ with a noun phrase object, _the_\n_moment._ (3) Her use of a prepositional phrase as if it was an adjective\nto describe some mental or emotional state follows a common pattern\nin English: _under the weather,_ _out of character,_ _off the wall,_ _in the_\n_dumps, out to lunch, on the ball, in good spirits, on top of the world,_\n_out of his mind,_ and _in love._ (4) It's unlikely that Streisand was trying\nto say that Agassi is _au courant_ or fashionable; that would be a putdown implying shallowness, not a compliment. Her reference to Zen\nmakes her meaning entirely clear: that Agassi is very good at shutting\nout distractions and concentrating on the game or person he is involved with at that moment."
    },
    {
        "document_id": "0",
        "parent_id": 594,
        "parent_text": "So these are the language mavens. Their foibles can be blamed on\ntwo blind spots. One is a gross underestimation of the linguistic\nwherewithal of the common person. I am not saying that everything\nthat comes out of a person's mouth or pen is perfectly rule-governed\n(remember Dan Quayle). But the language mavens would have a\nmuch better chance of not embarrassing themselves if they saved\nthe verdict of linguistic incompetence for the last resort rather than\njumping to it as a first conclusion. People come out with laughable\nverbiage when they feel they are in a forum demanding an elevated,\nformal style and know that their choice of words could have momentous consequences for them. That is why the fertile sources of howlers\ntend to be politicians' speeches, welfare application letters, and student term papers (assuming there is some grain of truth in the reports). In less self-conscious settings, common people, no matter\nhow poorly educated, obey sophisticated grammatical laws, and can\nexpress themselves with a vigor and grace that captivates those who\nlisten seriously—linguists, journalists, oral historians, novelists with\nan ear for dialogue.\n\nThe other blind spot of the language mavens is their complete\nignorance of the modern science of language—and I don't mean just\nthe formal apparatus of Chomskyan theory, but basic knowledge of\nwhat kinds of constructions and idioms are found in English, and\nhow people use them and pronounce them. In all fairness, much of the\n\n\nThe Language Mavens 399\n\n\nblame falls on members of my own profession for being so reluctant to\napply our knowledge to the practical problems of style and usage and\nto everyone's natural curiosity about why people talk the way they\ndo. With a few exceptions like Joseph Emonds, Dwight Bolinger,\nRobin Lakoff, James McCawley, and Geoffrey Nunberg, mainstream\nAmerican linguists have left the field entirely to the mavens—or, as\nBolinger calls them, the shamans. He has summed up the situation:"
    },
    {
        "document_id": "0",
        "parent_id": 595,
        "parent_text": "The Language Mavens 399\n\n\nblame falls on members of my own profession for being so reluctant to\napply our knowledge to the practical problems of style and usage and\nto everyone's natural curiosity about why people talk the way they\ndo. With a few exceptions like Joseph Emonds, Dwight Bolinger,\nRobin Lakoff, James McCawley, and Geoffrey Nunberg, mainstream\nAmerican linguists have left the field entirely to the mavens—or, as\nBolinger calls them, the shamans. He has summed up the situation:\n\n\nIn language there are no licensed practitioners, but the woods are\nfull of midwives, herbalists, colonic irrigationists, bonesetters, and\ngeneral-purpose witch doctors, some abysmally ignorant, others\nwith a rich fund of practical knowledge—whom we shall lump\ntogether and call _shamans._ They require our attention not only\nbecause they fill a lack but because they are almost the only people\nwho make the news when language begins to cause trouble and\nsomeone must answer the cry for help. Sometimes their advice is\nsound. Sometimes it is worthless, but still it is sought because no\none knows where else to turn. We are living in an African village\nand Albert Schweitzer has not arrived yet.\n\n\nSo what should be done about usage? Unlike some academics in\nthe 1960s, I am not saying that instruction in standard English grammar and composition is a tool to perpetuate an oppressive white\npatriarchal capitalist status quo and that The People should be liberated to write however they please. Some aspects of how people express themselves in some settings _are_ worth trying to change. What I\nam calling for is innocuous: a more thoughtful discussion of language\nand how people use it, replacing _bubbe-maises_ (old wives' tales) with\nthe best scientific knowledge available. It is especially important that\nwe not underestimate the sophistication of the actual cause of any\ninstance of language use: the human mind."
    },
    {
        "document_id": "0",
        "parent_id": 596,
        "parent_text": "It is ironic that the jeremiads wailing about how sloppy language\nleads to sloppy thought are themselves hairballs of loosely associated\nfactoids and tangled non sequiturs. All the examples of verbal behavior that the complainer takes exception to for any reason are packed\ntogether in one unappealing mass and coughed up as proof of The\nDecline of the Language: teenage slang, sophistry, regional variations\nin pronunciation and diction, bureaucratic bafflegab, poor spelling\n\n\n400 THE LANGUAGE INSTINCT\n\n\nand punctuation, pseudo-errors like _hopefully,_ badly crafted prose,\ngovernment euphemism, nonstandard grammar like _ain't,_ misleading\nadvertising, and so on (not to mention deliberate witticisms that go\nover the complainer's head).\n\nI hope to have convinced you of two things. Many prescriptive\nrules of grammar are just plain dumb and should be deleted from the\nusage handbooks. And most of standard English is just that, standard,\nin the same sense that certain units of currency or household voltages\nare said to be standard. It is just common sense that people should\nbe given every encouragement and opportunity to learn the dialect\nthat has become the standard one in their society and to employ it in\nmany formal settings. But there is no need to use terms like \"bad\ngrammar,\" \"fractured syntax,\" and \"incorrect usage\" when referring\nto rural and black dialects. Though I am no fan of \"politically correct\"\neuphemism (in which, according to the satire, _white woman_ should\nbe replaced by _melanin-impoverished person of gender),_ using terms\nlike \"bad grammar\" for \"nonstandard\" is both insulting and scientifically inaccurate."
    },
    {
        "document_id": "0",
        "parent_id": 597,
        "parent_text": "As for slang, I'm all for it! Some people worry that slang will\nsomehow \"corrupt\" the language. We should be so lucky. Most slang\nlexicons are preciously guarded by their subcultures as membership\nbadges. When given a glimpse into one of these lexicons, no true\nlanguage-lover can fail to be dazzled by the brilliant wordplay and\nwit: from medical students _(Zorro-belly,_ _crispy critter, prune),_ rappers\n_(jaw-jacking, dissing),_ college students _(studmuffin, veg out, blow off),_\nsurfers _(gnarlacious,_ _geeklified),_ and hackers _(to flame,_ _core-dump,_\n_crufty)._ When the more passe terms get cast off and handed down\nto the mainstream, they often fill expressive gaps in the language\nbeautifully. I don't know how I ever did without _to flame_ (protest selfrighteously), _to dis_ (express disrespect for), and _to blow off_ (dismiss an\nobligation), and there are thousands of now-unexceptionable English\nwords like _clever, fun, sham,_ _banter,_ _mob, stingy,_ _bully, junkie,_ and\n_jazz_ that began life as slang. It is especially hypocritical to oppose\nlinguistic innovations reflexively and at the same time to decry the\nloss of distinctions like _lie_ versus _lay_ on the pretext of preserving\nexpressive power. Vehicles for expressing thought are being created\nfar more quickly than they are being lost.\n\nThere is probably a good explanation for the cult of inarticulateness, where speech is punctuated with _you know, like, sort of, I mean,_\n\n\nThe Language Mavens 401"
    },
    {
        "document_id": "0",
        "parent_id": 598,
        "parent_text": "There is probably a good explanation for the cult of inarticulateness, where speech is punctuated with _you know, like, sort of, I mean,_\n\n\nThe Language Mavens 401\n\n\nand so on. Everyone maintains a number of ways of speaking that are\nappropriate to different contexts defined by the status and solidarity\nthey feel with respect to their interlocutor. It seems that younger\nAmericans try to maintain lower levels of social distance than older\ngenerations are used to. I know many gifted prose stylists my age\nwhose one-on-one speech is peppered with _sort of_ and _you know,_\ntheir attempt to avoid affecting the stance of the expert who feels\nentitled to lecture the conversational partner with confident pronouncements. Some people find it grating, but most speakers can\nturn it off at will, and I find it no worse than the other extreme,\ncertain older academics who hold court during social gatherings,\npontificating eloquently to their trapped junior audiences."
    },
    {
        "document_id": "0",
        "parent_id": 599,
        "parent_text": "The aspect of language use that is most worth changing is the clarity\nand style of written prose. Expository writing requires language to\nexpress far more complex trains of thought than it was biologically\ndesigned to do. Inconsistencies caused by limitations of short-term\nmemory and planning, unnoticed in conversation, are not as tolerable\nwhen preserved on a page that is to be perused more leisurely. Also,\nunlike a conversational partner, a reader will rarely share enough\nbackground assumptions to interpolate all the missing premises that\nmake language comprehensible. Overcoming one's natural egocentrism and trying to anticipate the knowledge state of a generic reader\nat every stage of the exposition is one of the most important tasks in\nwriting well. All this makes writing a difficult craft that must be\nmastered through practice, instruction, feedback, and—probably\nmost important—intensive exposure to good examples. There are\nexcellent manuals of composition that discuss these and other skills\nwith great wisdom, like Strunk and White's _The Elements of Style_\nand Williams's _Style: Toward Clarity and Grace._ What is most relevant\nto my point is how removed their practical advice is from the trivia\nof split infinitives and slang. For example, a banal but universally\nacknowledged key to good writing is to revise extensively. Good\nwriters go through anywhere from two to twenty drafts before releasing a paper. Anyone who does not appreciate this necessity is going\nto be a bad writer. Imagine a Jeremiah exclaiming, \"Our language\ntoday is threatened by an insidious enemy: the youth are not revising\ntheir drafts enough times.\" Kind of takes the fun out, doesn't it? It's\nnot something that can be blamed on television, rock music, shopping\nmall culture, overpaid athletes, or any of the other signs of the decay\n\n\n402 THE LANGUAGE INSTINCT\n\n\nof civilization. But if it's clear writing that we want, this is the kind\nof homely remedy that is called for."
    },
    {
        "document_id": "0",
        "parent_id": 600,
        "parent_text": "402 THE LANGUAGE INSTINCT\n\n\nof civilization. But if it's clear writing that we want, this is the kind\nof homely remedy that is called for.\n\nFinally, a confession. When I hear someone use _disinterested_ to\nmean \"apathetic,\" I am apt to go into a rage. _Disinterested_ (I suppose\nI must explain that it means \"unbiased\") is such a lovely word: it is\never-so-subtly different from _impartial_ or _unbiased_ in implying that\nthe person has no stake in the matter, not that he is merely committed\nto being even-handed out of personal principle. It gets this fine meaning from its delicate structure: _interest_ means \"stake,\" as in _conflict_\n_of interest_ and _financial interest;_ adding _-ed_ to a noun can make it\npertain to someone that owns the referent of that noun, as in _moneyed,_\n_one-eyed,_ or _hook-nosed; dis-_ negates the combination. The grammatical logic reveals itself in the similarly structured _disadvantaged, disaf-_\n_fected,_ _disillusioned,_ _disjointed,_ and _dispossessed._ Since we already\nhave the word _uninterested,_ there can be no reason to rob discerning\nlanguage-lovers of _disinterested_ by merging their meanings, except as\na tacky attempt to sound more high-falutin'. And don't get me started\non _fortuitous_ and _parameter . . ._"
    },
    {
        "document_id": "0",
        "parent_id": 601,
        "parent_text": "Chill out, Professor. The original, eighteenth-century meaning of\n_disinterested_ turns out to be—yes, \"uninterested.\" And that, too,\nmakes grammatical sense. The adjective _interested_ meaning \"engaged\" (related to the participle of the verb _to interest)_ is far more\ncommon than the noun _interest_ meaning \"stake,\" so _dis-_ can be\nanalyzed as simply negating that adjective, as in _discourteous, dishon-_\n_est,_ _disloyal,_ _disreputable,_ and the parallel _dissatisfied_ and _distrusted._\nBut these rationalizations are beside the point. Every component of\na language changes over time, and at any moment a language is\nenduring many losses. But since the human mind does not change\nover time, the richness of a language is always being replenished.\nWhenever any of us gets grumpy about some change in usage, we\nwould do well to read the words of Samuel Johnson in the preface\nto his 1755 _Dictionary,_ a reaction to the Jeremiahs of his day:\n\n\nThose who have been persuaded to think well of my design, require\nthat it should fix our language, and put a stop to those alterations\nwhich time and chance have hitherto been suffered to make in it\nwithout opposition. With this consequence I will confess that I have\nflattered myself for a while; but now begin to fear that I have\nindulged expectations which neither reason nor experience can\n\n\nThe Language Mavens 403"
    },
    {
        "document_id": "0",
        "parent_id": 602,
        "parent_text": "Those who have been persuaded to think well of my design, require\nthat it should fix our language, and put a stop to those alterations\nwhich time and chance have hitherto been suffered to make in it\nwithout opposition. With this consequence I will confess that I have\nflattered myself for a while; but now begin to fear that I have\nindulged expectations which neither reason nor experience can\n\n\nThe Language Mavens 403\n\n\njustify. When we see men grow old and die at a certain time one\nafter another, from century to century, we laugh at the elixir that\npromises to prolong life to a thousand years; and with equal justice\nmay the lexicographer be derided, who being able to produce no\nexample of a nation that has preserved their words and phrases\nfrom mutability, shall imagine that his dictionary can embalm his\nlanguage, and secure it from corruption and decay, that it is in his\npower to change sublunary nature, and clear the world at once from\nfolly, vanity, and affectation. With this hope, however, academies\nhave been instituted, to guard the avenues of their languages, to\nretain fugitives, and to repulse intruders; but their vigilance and\nactivity have hitherto been vain; sounds are too volatile and subtle\nfor legal restraints; to enchain syllables, and to lash the wind, are\nequally the undertakings of pride, unwilling to measure its desires\nby its strength."
    },
    {
        "document_id": "0",
        "parent_id": 603,
        "parent_text": "### 13"
    },
    {
        "document_id": "0",
        "parent_id": 604,
        "parent_text": "#### Mind Design\n\nin this book I asked why you should believe that there\nis a language instinct. Now that I have done my best to convince you\nthat there is one, it is time to ask why you should care. Having a\nlanguage, of course, is part of what it means to be human, so it is\nnatural to be curious. But having hands that are not occupied in\nlocomotion is even more important to being human, and chances are\nyou would never have made it to the last chapter of a book about the\nhuman hand. People are more than curious about language; they are\npassionate. The reason is obvious. Language is the most accessible\npart of the mind. People want to know about language because they\nhope this knowledge will lead to insight about human nature.\n\nThis tie-in animates linguistic research, raising the stakes in arcane\ntechnical disagreements and attracting the attention of scholars from\nfar-flung disciplines. Jerry Fodor, the philosopher and experimental\npsycholinguist, studies whether sentence parsing is an encapsulated\nmental module or blends in with general intelligence, and he is more\nhonest than most in discussing his interest in the controversy:\n\n\n\"But look,\" you might ask, \"why do you care about modules so\nmuch? You've got tenure; why don't you take off and go sailing?\"\nThis is a perfectly reasonable question and one that I often ask\nmyself. . . . Roughly, the idea that cognition saturates perception\nbelongs with (and is, indeed, historically connected with) the idea\nin the philosophy of science that one's observations are comprehensively determined by one's theories; with the idea in anthropology\n\n\n404\n\n\nMind Design 405"
    },
    {
        "document_id": "0",
        "parent_id": 605,
        "parent_text": "\"But look,\" you might ask, \"why do you care about modules so\nmuch? You've got tenure; why don't you take off and go sailing?\"\nThis is a perfectly reasonable question and one that I often ask\nmyself. . . . Roughly, the idea that cognition saturates perception\nbelongs with (and is, indeed, historically connected with) the idea\nin the philosophy of science that one's observations are comprehensively determined by one's theories; with the idea in anthropology\n\n\n404\n\n\nMind Design 405\n\n\nthat one's values are comprehensively determined by one's culture;\nwith the idea in sociology that one's epistemic commitments, including especially one's science, are comprehensively determined by\none's class affiliations; and with the idea in linguistics that one's\nmetaphysics is comprehensively determined by one's syntax [i.e.,\nthe Whorfian hypothesis—SP]. All these ideas imply a kind of\nrelativistic holism: because perception is saturated by cognition,\nobservation by theory, values by culture, science by class, and metaphysics by language, rational criticism of scientific theories, ethical\nvalues, metaphysical world-views, or whatever can take place only\n_within_ the framework of assumptions that—as a matter of geographical, historical, or sociological accident—the interlocutors\nhappen to share. What you can't do is rationally criticize the framework."
    },
    {
        "document_id": "0",
        "parent_id": 606,
        "parent_text": "The thing is: I _hate_ relativism. I hate relativism more than I hate\nanything else, excepting, maybe, fiberglass powerboats. More to the\npoint, I think that relativism is very probably false. What it overlooks, to put it briefly and crudely, is the fixed structure of human\nnature. (This is not, of course, a novel insight; on the contrary,\nthe _malleability_ of human nature is a doctrine that relativists are\ninvariably much inclined to stress; see, for example, John\nDewey. . . .) Well, in cognitive psychology the claim that there is a\nfixed structure of human nature traditionally takes the form of an\ninsistence on the heterogeneity of cognitive mechanisms and the\nrigidity of the cognitive architecture that effects their encapsulation.\nIf there are faculties and modules, then not everything affects everything else; not everything is plastic. Whatever the All is, at least\nthere is more than One of it.\n\n\nFor Fodor, a sentence perception module that delivers the speaker's\nmessage verbatim, undistorted by the listener's biases and expectations, is emblematic of a universally structured human mind, the same\nin all places and times, that would allow people to agree on what is\njust and true as a matter of objective reality rather than of taste,\ncustom, and self-interest. It is a bit of a stretch, but no one can deny\nthat there is a connection. Modern intellectual life is suffused with a\nrelativism that denies that there is such a thing as a universal human\nnature, and the existence of a language instinct in any form challenges\nthat denial.\n\nThe doctrine underlying that relativism, the Standard Social Sci\n\n406 THE LANGUAGE INSTINCT\n\n\nence Model (SSSM), began to dominate intellectual life in the 1920s.\nIt was a fusion of an idea from anthropology and an idea from\npsychology."
    },
    {
        "document_id": "0",
        "parent_id": 607,
        "parent_text": "The doctrine underlying that relativism, the Standard Social Sci\n\n406 THE LANGUAGE INSTINCT\n\n\nence Model (SSSM), began to dominate intellectual life in the 1920s.\nIt was a fusion of an idea from anthropology and an idea from\npsychology.\n\n\n1. Whereas animals are rigidly controlled by their biology, human behavior is determined by culture, an autonomous system\nof symbols and values. Free from biological constraints, cultures can vary from one another arbitrarily and without limit.\n2. Human infants are born with nothing more than a few reflexes\nand an ability to learn. Learning is a general-purpose process,\nused in all domains of knowledge. Children learn their culture\nthrough indoctrination, reward and punishment, and role\nmodels.\n\n\nThe SSSM has not only been the foundation of the study of humankind within the academy, but serves as the secular ideology of\nour age, the position on human nature that any decent person should\nhold. The alternative, sometimes called \"biological determinism,\" is\nsaid to assign people to fixed slots in the socio-political-economic\nhierarchy, and to be the cause of many of the horrors of recent\ncenturies: slavery, colonialism, racial and ethnic discrimination, economic and social castes, forced sterilization, sexism, genocide. Two\nof the most famous founders of the SSSM, the anthropologist Margaret Mead and the psychologist John Watson, clearly had these social\nimplications in mind:\n\n\nWe are forced to conclude that human nature is almost unbelievably\nmalleable, responding accurately and contrastingly to contrasting\ncultural conditions. . . . The members of either or both sexes may,\nwith more or less success in the case of different individuals, be\neducated to approximate [any temperament]. . . . If we are to\nachieve a richer culture, rich in contrasting values, we must recognize the whole gamut of human potentialities, and so weave a less\narbitrary social fabric, one in which each diverse human gift will\nfind a fitting place. [Mead, 1935]"
    },
    {
        "document_id": "0",
        "parent_id": 608,
        "parent_text": "Give me a dozen healthy infants, well-formed, and my own specified\nworld to bring them up in and I'll guarantee to take any one at\nrandom and train him to become any type of specialist I might\nselect—doctor, lawyer, artist, merchant-chief, and yes, even beggar\n\nMind Design 407\n\n\nman and thief, regardless of his talents, penchants, tendencies, abilities, vocations, and race of his ancestors. [Watson, 1925]\n\n\nAt least in the rhetoric of the educated, the SSSM has attained total\nvictory. In polite intellectual conversations and respectable journalism, any generalization about human behavior is carefully prefaced\nwith SSSM shibboleths that distance the speaker from history's distasteful hereditarians, from medieval kings to Archie Bunker. \"Our\nsociety,\" the discussions begin, even if no other society has been\nexamined. \"Socializes us,\" they continue, even if the experiences of\nthe child are never considered. \"To the role . . .\" they conclude,\nregardless of the aptness of the metaphor of \"role,\" a character or\npart arbitrarily assigned to be played by a performer.\n\nVery recently, the newsmagazines tell us that \"the pendulum is\nswinging back.\" As they describe the appalled pacifist feminist parents of a three-year-old gun nut son and a four-year-old Barbie-dollobsessed daughter, they remind the reader that hereditary factors\ncannot be ignored and that all behavior is an interaction between\nnature and nurture, whose contributions are as inseparable as the\nlength and width of a rectangle in determining its area.\n\nI would be depressed if what we have learned about the language\ninstinct were folded into the mindless dichotomies of heredity-environment (a.k.a. nature-nurture, nativism-empiricism, innate-acquired, biology-culture), the unhelpful bromides about inextricably\nintertwined interactions, or the cynical image of a swaying pendulum\nof scientific fashion. I think that our understanding of language offers\na more satisfying way of studying the human mind and human nature."
    },
    {
        "document_id": "0",
        "parent_id": 609,
        "parent_text": "I would be depressed if what we have learned about the language\ninstinct were folded into the mindless dichotomies of heredity-environment (a.k.a. nature-nurture, nativism-empiricism, innate-acquired, biology-culture), the unhelpful bromides about inextricably\nintertwined interactions, or the cynical image of a swaying pendulum\nof scientific fashion. I think that our understanding of language offers\na more satisfying way of studying the human mind and human nature.\n\nTo begin with, we can discard the pre-scientific, magical model in\nwhich the issues are usually framed:\n\n\nThe \"controversy\" over whether heredity, environment, or some interaction between the two causes behavior is just incoherent. The\norganism has vanished; there is an environment without someone to\n\n\n408 THE LANGUAGE INSTINCT\n\n\nperceive it, behavior without a behaver, learning without a learner.\nAs Alice thought to herself when the Cheshire Cat vanished quite\nslowly, ending with the grin which remained some time after the rest\nof it had gone: \"Well! I've often seen a cat without a grin, but a grin\nwithout a cat! It's the most curious thing I ever saw in all my life!\"\n\nThe following model is also simplistic, but it is a much better\nbeginning:\n\n\nFor we can now do justice to the complexity of the human brain, the\nimmediate cause of all perception, learning, and behavior. Learning\nis not an alternative to innateness; without an innate mechanism to\ndo the learning, it could not happen at all. The insights we have\ngained about the language instinct make this clear."
    },
    {
        "document_id": "0",
        "parent_id": 610,
        "parent_text": "The following model is also simplistic, but it is a much better\nbeginning:\n\n\nFor we can now do justice to the complexity of the human brain, the\nimmediate cause of all perception, learning, and behavior. Learning\nis not an alternative to innateness; without an innate mechanism to\ndo the learning, it could not happen at all. The insights we have\ngained about the language instinct make this clear.\n\nFirst, to reassure the nervous: yes, there are important roles for\nboth heredity and environment. A child brought up in Japan ends up\nspeaking Japanese; the same child, if brought up in the United States,\nwould end up speaking English. So we know that the environment\nplays a role. If a child is inseparable from a pet hamster when growing\nup, the child ends up speaking a language, but the hamster, exposed\nto the same environment, does not. So we know that heredity plays\na role. But there is much more to say.\n\n - Since people can understand and speak an infinite number of\nnovel sentences, it makes no sense to try to characterize their \"behavior\" directly—no two people's language behavior is the same, and a\nperson's potential behavior cannot even be listed. But an infinite\nnumber of sentences can be generated by a finite rule system, a\ngrammar, and it does make sense to study the mental grammar and\nother psychological mechanisms underlying language behavior.\n\n  - Language comes so naturally to us that we tend to be blase about\n\n\nMind Design 409\n\n\nit, like urban children who think that milk just comes from a truck.\nBut a close-up examination of what it takes to put words together\ninto ordinary sentences reveals that mental language mechanisms\nmust have a complex design, with many interacting parts.\n\n - Under this microscope, the babel of languages no longer appear\nto vary in arbitrary ways and without limit. One now sees a common\ndesign to the machinery underlying the world's language, a Universal\nGrammar."
    },
    {
        "document_id": "0",
        "parent_id": 611,
        "parent_text": "Mind Design 409\n\n\nit, like urban children who think that milk just comes from a truck.\nBut a close-up examination of what it takes to put words together\ninto ordinary sentences reveals that mental language mechanisms\nmust have a complex design, with many interacting parts.\n\n - Under this microscope, the babel of languages no longer appear\nto vary in arbitrary ways and without limit. One now sees a common\ndesign to the machinery underlying the world's language, a Universal\nGrammar.\n\n - Unless this basic design is built in to the mechanism that learns a\nparticular grammar, learning would be impossible. There are many\npossible ways of generalizing from parents' speech to the language as\na whole, and children home in on the right ones, fast.\n\n - Finally, some of the learning mechanisms appear to be designed\nfor language itself, not for culture and symbolic behavior in general.\nWe have seen Stone Age people with high-tech grammars, helpless\ntoddlers who are competent grammarians, and linguistic idiot savants.\nWe have seen a logic of grammar that cuts across the logic of common\nsense: the _it_ of _It is raining_ that behaves like the _John_ of _John is_\n_running,_ the _mice-eaters_ who eat _mice_ differing from the _rat-eaters_\nwho eat _rats._"
    },
    {
        "document_id": "0",
        "parent_id": 612,
        "parent_text": "- Finally, some of the learning mechanisms appear to be designed\nfor language itself, not for culture and symbolic behavior in general.\nWe have seen Stone Age people with high-tech grammars, helpless\ntoddlers who are competent grammarians, and linguistic idiot savants.\nWe have seen a logic of grammar that cuts across the logic of common\nsense: the _it_ of _It is raining_ that behaves like the _John_ of _John is_\n_running,_ the _mice-eaters_ who eat _mice_ differing from the _rat-eaters_\nwho eat _rats._\n\nThe lessons of language have not been lost on the sciences of the\nrest of the mind. An alternative to the Standard Social Science Model\nhas emerged, with roots in Darwin and William James and with\ninspiration from the research on language by Chomsky and the psychologists and linguists in his wake. It has been applied to visual\nperception by the computational neuroscientist David Marr and the\npsychologist Roger Shepard, and has been elaborated by the anthropologists Dan Sperber, Donald Symons, and John Tooby, the linguist\nRay Jackendoff, the neuroscientist Michael Gazzaniga, and the psychologists Leda Cosmides, Randy Gallistel, Frank Keil, and Paul\nRozin. Tooby and Cosmides, in their important recent essay \"The\nPsychological Foundations of Culture,\" call it the Integrated Causal\nModel, because it seeks to explain how evolution caused the emergence of a brain, which causes psychological processes like knowing\nand learning, which cause the acquisition of the values and knowledge\nthat make up a person's culture. It thus integrates psychology and\nanthropology into the rest of the natural sciences, especially neuroscience and evolutionary biology. Because of this last connection, they\nalso call it Evolutionary Psychology.\n\n\n410 THE LANGUAGE INSTINCT\n\n\nEvolutionary psychology takes many of the lessons of human language and applies them to the rest of the psyche:"
    },
    {
        "document_id": "0",
        "parent_id": 613,
        "parent_text": "410 THE LANGUAGE INSTINCT\n\n\nEvolutionary psychology takes many of the lessons of human language and applies them to the rest of the psyche:\n\n•Just as language is an improbable feat requiring intricate mental\nsoftware, the other accomplishments of mental life that we take for\ngranted, like perceiving, reasoning, and acting, require their own wellengineered mental software. Just as there is a universal design to the\ncomputations of grammar, there is a universal design to the rest of\nthe human mind—an assumption that is not just a hopeful wish for\nhuman unity and brotherhood, but an actual discovery about the\nhuman species that is well motivated by evolutionary biology and\ngenetics.\n\n - Evolutionary psychology does not disrespect learning but seeks\nto explain it. In Moliere's play _Le Malade Imaginaire,_ the learned\ndoctor is asked to explain how opium puts people to sleep, and cites\nits \"sleep-producing power.\" Leibniz similarly ridiculed thinkers who\ninvoke\n\n\nexpressly occult qualities or faculties which they imagined to be like\nlittle demons or goblins capable of producing unceremoniously that\nwhich is demanded, just as if watches marked the hours by a certain\nhorodeictic faculty without having need of wheels, or as if mills\ncrushed grains by a fractive faculty without needing anything resembling millstones.\n\n\nIn the Standard Social Science Model, \"learning\" has been invoked\nin just these ways; in evolutionary psychology, there is no learning\nwithout some innate mechanism that makes the learning happen."
    },
    {
        "document_id": "0",
        "parent_id": 614,
        "parent_text": "In the Standard Social Science Model, \"learning\" has been invoked\nin just these ways; in evolutionary psychology, there is no learning\nwithout some innate mechanism that makes the learning happen.\n\n - Learning mechanisms for different spheres of human experience—language, morals, food, social relations, the physical world,\nand so on—are often found to work at cross-purposes. A mechanism\ndesigned to learn the right thing in one of these domains learns\nexactly the wrong thing in the others. This suggests that learning\nis accomplished not by some single general-purpose device but by\ndifferent modules, each keyed to the peculiar logic and laws of one\ndomain. People are flexible, not because the environment pounds or\nsculpts their minds into arbitrary shapes, but because their minds\ncontain so many different modules, each with provisions to learn in\nits own way.\n\n\nMind Design 411\n\n\n - Since biological systems with signs of complex engineering are\nunlikely to have arisen from accidents or coincidences, their organization must come from natural selection, and hence should have functions useful for survival and reproduction in the environments in\nwhich humans evolved. (This does not mean, however, that all aspects\nof mind are adaptations, or that the mind's adaptations are necessarily\nbeneficial in evolutionarily novel environments like twentieth-century\ncities.)\n\n - Finally, culture is given its due, but not as some disembodied\nghostly process or fundamental force of nature. \"Culture\" refers to\nthe process whereby particular kinds of learning contagiously spread\nfrom person to person in a community and minds become coordinated into shared patterns, just as \"a language\" or \"a dialect\" refers\nto the process whereby the different speakers in a community acquire\nhighly similar mental grammars."
    },
    {
        "document_id": "0",
        "parent_id": 615,
        "parent_text": "- Finally, culture is given its due, but not as some disembodied\nghostly process or fundamental force of nature. \"Culture\" refers to\nthe process whereby particular kinds of learning contagiously spread\nfrom person to person in a community and minds become coordinated into shared patterns, just as \"a language\" or \"a dialect\" refers\nto the process whereby the different speakers in a community acquire\nhighly similar mental grammars.\n\n\nA good place to begin discussing this new view of mind design is\nthe place we began in discussing the language instinct: universality.\nLanguage, I noted early on, is universal among human societies, and\nas far as we know has been throughout the history of our species.\nThough languages are mutually unintelligible, beneath this superficial\nvariation lies the single computational design of Universal Grammar,\nwith its nouns and verbs, phrase structures and word structures, cases\nand auxiliaries, and so on.\n\nAt first glance, the ethnographic record seems to offer a stark\ncontrast. Anthropology in this century has taken us through a mindbroadening fairground of human diversity. But might this carnival of\ntaboos, kinship systems, shamanry, and all the rest be as superficial\nas the difference between _dog_ and _bund,_ hiding a universal human\nnature?\n\nThe culture of anthropologists themselves makes one apprehensive\nabout their leitmotif that anything goes. One of America's most prominent, Clifford Geertz, has exhorted his colleagues to be \"merchants\nof astonishment\" who \"hawk the anomalous, peddle the strange.\"\n\"If we wanted only home truths,\" he adds, \"we should have stayed\nat home.\" But this is an attitude that guarantees that anthropologists\nwill miss any universal pattern in human ways. In fact, it can lead to\n\n\n412 THE LANGUAGE INSTINCT\n\n\noutright error as the commonplace is cloaked as the anomalous, as in\nthe Great Eskimo Vocabulary Hoax. As one young anthropologist\nwrote to me:"
    },
    {
        "document_id": "0",
        "parent_id": 616,
        "parent_text": "412 THE LANGUAGE INSTINCT\n\n\noutright error as the commonplace is cloaked as the anomalous, as in\nthe Great Eskimo Vocabulary Hoax. As one young anthropologist\nwrote to me:\n\n\nThe Eskimo vocabulary story will get its own section in a project\nof mine—a book whose working title is _One Hundred Years of_\n_Anthropological Malpractice._ I have been collecting instances of\ngross professional incompetence for years now: all of the anthropological chestnuts that turn out not to be true, but maintain their\npresence in textbooks anyway as the intellectual commonplaces of\nthe field. Samoan free sex and the resultant lack of crime and\nfrustration, the sex-reversed cultures like the \"gentle\" Arapesh (the\nmen are head-hunters), the \"stone-age\" pristine Tasaday (a fabrication of the corrupt Philippine Minister of Culture—nearby villagers,\ndressed down as matriarchal \"primitives\"), the ancient matriarchies\nduring the dawn of civilization, the fundamentally different Hopi\nconcept of time, the cultures that everyone knows are out there\nwhere everything is the reverse of here, etc., etc.\n\nOne of the unifying threads will be that complete cultural relativism makes anthropologists far more credulous of almost any absurdity (Casteneda's Don Juan novels—which I really enjoyed by the\nway—are in many textbooks as sober fact) than almost any ordinary\nperson would be, equipped only with common sense. In other\nwords, their professional \"expertise\" has made them complete and\ntotal gulls. Just as fundamentalism disposes you to accept accounts\nof miracles, being of the trained anthropologist faith disposes you\nto believe in any exotic account from Elsewhere. In fact, a lot of\nthis nonsense is part of the standard intellectual equipment of every\neducated social scientist, providing a permanent obstacle to balanced reasoning about various psychological and social phenomena.\nI figure it will make me permanently unemployable, so I am not\naiming to finish it any time soon."
    },
    {
        "document_id": "0",
        "parent_id": 617,
        "parent_text": "The allusion to Samoan free sex pertains to Derek Freeman's 1983\nbombshell showing how Margaret Mead got the facts wrong in her\nclassic book, _Coming of Age in Samoa._ (Among other things, her bored\nteenage informants enjoyed pulling her leg.) The other accusations are\ncarefully documented in a recent review, _Human Universals,_ written\nby another anthropologist, Donald E. Brown, who was trained in\nthe standard ethnographic tradition. Brown has noted that behind\n\n\nMind Design 413\n\n\nanthropologists' accounts of the strange behavior of foreign peoples\nthere are clear but abstract universals of human experience, such\nas rank, politeness, and humor. Indeed, anthropologists could not\nunderstand or live within other human groups unless they shared a\nrich set of common assumptions with them, what Dan Sperber calls\na metaculture. Tooby and Cosmides note:\n\n\nLike fish unaware of the existence of water, anthropologists swim\nfrom culture to culture interpreting through universal human metaculture. Metaculture informs their every thought, but they have not\nyet noticed its existence. . . . When anthropologists go to other\ncultures, the experience of variation awakens them to things they\nhad previously taken for granted in their own culture. Similarly,\nbiologists and artificial intelligence researchers are \"anthropologists\" who travel to places where minds are far stranger than anywhere any ethnographer has ever gone."
    },
    {
        "document_id": "0",
        "parent_id": 618,
        "parent_text": "Inspired by Chomsky's Universal Grammar (UG), Brown has tried\nto characterize the Universal People (UP). He has scrutinized archives\nof ethnography for universal patterns underlying the behavior of all\ndocumented human cultures, keeping a skeptical eye out both for\nclaims of the exotic belied by the ethnographers' own reports, and\nfor claims of the universal based on flimsy evidence. The outcome is\nstunning. Far from finding arbitrary variation, Brown was able to\ncharacterize the Universal People in gloriously rich detail. His findings\ncontain something to startle almost anyone, and so I will reproduce\nthe substance of them here. According to Brown, the Universal People\nhave the following:\n\nValue placed on articulateness. Gossip. Lying. Misleading. Verbal\nhumor. Humorous insults. Poetic and rhetorical speech forms. Narrative and storytelling. Metaphor. Poetry with repetition of linguistic\nelements and three-second lines separated by pauses. Words for days,\nmonths, seasons, years, past, present, future, body parts, inner states\n(emotions, sensations, thoughts), behavioral propensities, flora, fauna,\nweather, tools, space, motion, speed, location, spatial dimensions,\nphysical properties, giving, lending, affecting things and people, numbers (at the very least \"one,\" \"two,\" and \"more than two\"), proper\nnames, possession. Distinctions between mother and father. Kinship\ncategories, defined in terms of mother, father, son, daughter, and age\n\n\n414 THE LANGUAGE INSTINCT\n\n\nsequence. Binary distinctions, including male and female, black and\nwhite, natural and cultural, good and bad. Measures. Logical relations\nincluding \"not,\" \"and,\" \"same,\" \"equivalent,\" \"opposite,\" general\nversus particular, part versus whole. Conjectural reasoning (inferring\nthe presence of absent and invisible entities from their perceptible\ntraces)."
    },
    {
        "document_id": "0",
        "parent_id": 619,
        "parent_text": "414 THE LANGUAGE INSTINCT\n\n\nsequence. Binary distinctions, including male and female, black and\nwhite, natural and cultural, good and bad. Measures. Logical relations\nincluding \"not,\" \"and,\" \"same,\" \"equivalent,\" \"opposite,\" general\nversus particular, part versus whole. Conjectural reasoning (inferring\nthe presence of absent and invisible entities from their perceptible\ntraces).\n\nNonlinguistic vocal communication such as cries and squeals. Interpreting intention from behavior. Recognized facial expressions of\nhappiness, sadness, anger, fear, surprise, disgust, and contempt. Use\nof smiles as a friendly greeting. Crying. Coy flirtation with the eyes.\nMasking, modifying, and mimicking facial expressions. Displays of\naffection.\n\nSense of self versus other, responsibility, voluntary versus involuntary behavior, intention, private inner life, normal versus abnormal\nmental states. Empathy. Sexual attraction. Powerful sexual jealousy.\nChildhood fears, especially of loud noises, and, at the end of the first\nyear, strangers. Fear of snakes. \"Oedipal\" feelings (possessiveness of\nmother, coolness toward her consort). Face recognition. Adornment\nof bodies and arrangement of hair. Sexual attractiveness, based in\npart on signs of health and, in women, youth. Hygiene. Dance. Music.\nPlay, including play fighting.\n\nManufacture of, and dependence upon, many kinds of tools, many\nof them permanent, made according to culturally transmitted motifs,\nincluding cutters, pounders, containers, string, levers, spears. Use of\nfire to cook food and for other purposes. Drugs, both medicinal and\nrecreational. Shelter. Decoration of artifacts."
    },
    {
        "document_id": "0",
        "parent_id": 620,
        "parent_text": "Manufacture of, and dependence upon, many kinds of tools, many\nof them permanent, made according to culturally transmitted motifs,\nincluding cutters, pounders, containers, string, levers, spears. Use of\nfire to cook food and for other purposes. Drugs, both medicinal and\nrecreational. Shelter. Decoration of artifacts.\n\nA standard pattern and time for weaning. Living in groups, which\nclaim a territory and have a sense of being a distinct people. Families\nbuilt around a mother and children, usually the biological mother,\nand one or more men. Institutionalized marriage, in the sense of\npublicly recognized right of sexual access to a woman eligible for\nchildbearing. Socialization of children (including toilet training) by\nsenior kin. Children copying their elders. Distinguishing of close kin\nfrom distant kin, and favoring of close kin. Avoidance of incest between mothers and sons. Great interest in the topic of sex.\n\nStatus and prestige, both assigned (by kinship, age, sex) and\nachieved. Some degree of economic inequality. Division of labor by\nsex and age. More child care by women. More aggression and violence\nby men. Acknowledgment of differences between male and female\n\n\nMind Design 415\n\n\nnatures. Domination by men in the public political sphere. Exchange\nof labor, goods, and services. Reciprocity, including retaliation. Gifts.\nSocial reasoning. Coalitions. Government, in the sense of binding\ncollective decisions about public affairs. Leaders, almost always nondictatorial, perhaps ephemeral. Laws, rights, and obligations, including laws against violence, rape, and murder. Punishment. Conflict,\nwhich is deplored. Rape. Seeking of redress for wrongs. Mediation.\nIn-group/out-group conflicts. Property. Inheritance of property.\nSense of right and wrong. Envy."
    },
    {
        "document_id": "0",
        "parent_id": 621,
        "parent_text": "Etiquette. Hospitality. Feasting. Diurnality. Standards of sexual\nmodesty. Sex generally in private. Fondness for sweets. Food taboos.\nDiscreetness in elimination of body wastes. Supernatural beliefs.\nMagic to sustain and increase life, and to attract the opposite sex.\nTheories of fortune and misfortune. Explanations of disease and\ndeath. Medicine. Rituals, including rites of passage. Mourning the\ndead. Dreaming, interpreting dreams.\n\nObviously, this is not a list of instincts or innate psychological\npropensities; it is a list of complex interactions between a universal\nhuman nature and the conditions of living in a human body on this\nplanet. Nor, I hasten to add, is it a characterization of the inevitable,\na demarcation of the possible, or a prescription of the desirable. A\nlist of human universals a century ago could have included the absence\nof ice cream, oral contraceptives, movies, rock and roll, women's\nsuffrage, and books about the language instinct, but that would not\nhave stood in the way of these innovations.\n\nLike the identical twins reared apart who dipped buttered toast in\ntheir coffee, Brown's Universal People jolts our preconceptions about\nhuman nature. And just as the discoveries about twins do not call for\na buttered-toast-in-coffee gene, the discoveries about universals do\nnot implicate a universal toilet-training instinct. A theory of the universal mind is doubtless going to be as abstractly related to the\nUniversal People as X-bar theory is related to a list of universals of\nword order. But it seems certain that any such theory will have to put\nmore in the human head than a generalized tendency to learn or to\ncopy an arbitrary role model.\n\n\nWith the assumption of an infinitely variable human nature from\nanthropology out of the way, let's look at the assumption of an\n\n\n416 THE LANGUAGE INSTINCT\n\n\ninfinitely acquisitive learning ability from psychology. How might we\nmake sense of the concept of a general, multipurpose learning device?"
    },
    {
        "document_id": "0",
        "parent_id": 622,
        "parent_text": "With the assumption of an infinitely variable human nature from\nanthropology out of the way, let's look at the assumption of an\n\n\n416 THE LANGUAGE INSTINCT\n\n\ninfinitely acquisitive learning ability from psychology. How might we\nmake sense of the concept of a general, multipurpose learning device?\n\nExplicit pedagogy—learning by being told—is one kind of generalpurpose learning, but most would agree it is the least important. Few\npeople have been convinced by arguments like \"No one ever teaches\nchildren how Universal Grammar works, but they respect it anyway;\ntherefore it must be innate.\" Most learning, everyone agrees, takes\nplace outside of classroom lessons, by generalizing from examples.\nChildren generalize from role models, or from their own behaviors\nthat are rewarded or not rewarded. The power comes from the generalization according to similarity. A child who echoed back a parent's\nsentences verbatim would be called autistic, not a powerful learner;\nchildren generalize to sentences that are _similar_ to their parents', not\nto those sentences exactly. Likewise, a child who observes that barking German shepherds bite should generalize to barking Doberman\npinschers and other similar dogs.\n\nSimilarity is thus the mainspring of a hypothetical general multipurpose learning device, and there is the rub. In the words of the logician\nNelson Goodman, similarity is \"a pretender, an imposter, a quack.\"\nThe problem is that similarity is in the mind of the beholder—just\nwhat we are trying to explain—not in the world. Goodman writes:"
    },
    {
        "document_id": "0",
        "parent_id": 623,
        "parent_text": "Similarity is thus the mainspring of a hypothetical general multipurpose learning device, and there is the rub. In the words of the logician\nNelson Goodman, similarity is \"a pretender, an imposter, a quack.\"\nThe problem is that similarity is in the mind of the beholder—just\nwhat we are trying to explain—not in the world. Goodman writes:\n\n\nConsider baggage at an airport check-in station. The spectator may\nnotice shape, size, color, material, and even make of luggage; the\npilot is more concerned with weight, and the passenger with destination and ownership. Which pieces of baggage are more alike than\nothers depends not only upon what properties they share, but upon\nwho makes the comparison, and when. Or suppose we have three\nglasses, the first two filled with colorless liquid, the third with a\nbright red liquid. I might be likely to say the first two are more like\neach other than either is like the third. But it happens that the first\nglass is filled with water and the third with water colored by a drop\nof vegetable dye, while the second is filled with hydrochloric acid—\nand I am thirsty.\n\n\nThe unavoidable implication is that a sense of \"similarity\" must be\ninnate. This much is not controversial; it is simple logic. In behaviorist\npsychology, when a pigeon is rewarded for pecking a key in the\npresence of a red circle, it pecks more to a red ellipse, or to a pink\n\n\nMind Design 417\n\n\ncircle, than it does to a blue square. This \"stimulus generalization\"\nhappens automatically, without extra training, and it entails an innate\n\"similarity space\"; otherwise the animal would generalize to everything or to nothing. These subjective spacings of stimuli are necessary\nfor learning, so they cannot all be learned themselves. Thus even\nthe behaviorist is \"cheerfully up to his neck\" in innate similaritydetermining mechanisms, as the logician W. V. O. Quine pointed out\n(and his colleague B. F. Skinner did not demur)."
    },
    {
        "document_id": "0",
        "parent_id": 624,
        "parent_text": "For language acquisition, what is the innate similarity space that\nallows children to generalize from sentences in their parents' speech\nto the \"similar\" sentences that define the rest of English? Obviously,\n\"Red is more similar to pink than to blue,\" or \"Circle is more similar\nto ellipse than to triangle,\" is of no help. It must be some kind of\nmental computation that makes _John likes fish_ similar to _Mary eats_\n_apples,_ but not similar to _John might fish;_ otherwise the child would\nsay _John might apples._ It must make _The dog seems sleepy_ similar to\n_The men seem happy,_ but not similar to _The dog seems sleeping,_ so\nthat the child will avoid that false leap. That is, the \"similarity\"\nguiding the child's generalization has to be an analysis of speech into\nnouns and verbs and phrases, computed by the Universal Grammar\nbuilt into the learning mechanisms. Without such innate computation\ndefining which sentence is similar to which other ones, the child\nwould have no way of correctly generalizing—any sentence is \"similar,\" in one sense, to nothing but a verbatim repetition of itself, and\nalso \"similar,\" in another sense, to any random rearrangement of\nthose words, and \"similar,\" in still other senses, to all kinds of other\ninappropriate word strings. This is why it is no paradox to say that\nflexibility in learned _behavior_ requires innate constraints on the _mind._\nThe chapter on language acquisition (see p. 287) offers a good example: the ability of children to generalize to an infinite number of\npotential sentences depends on their analyzing parental speech using\na fixed set of mental categories."
    },
    {
        "document_id": "0",
        "parent_id": 625,
        "parent_text": "So learning a grammar from examples requires a special similarity\nspace (defined by Universal Grammar). So does learning the meanings\nof words from examples, as we saw in Quine's _gavagai_ problem, in\nwhich a word-learner has no logical basis for knowing whether _gavagai_\nmeans \"rabbit,\" \"hopping rabbit,\" or \"undetached rabbit parts.\"\nWhat does this say about learning everything else? Here is how Quine\nreports, and defuses, what he calls the \"scandal of induction\":\n\n\n418 THE LANGUAGE INSTINCT\n\n\nIt makes one wonder the more about other inductions, where what\nis sought is a generalization not about our neighbor's verbal behavior but about the harsh impersonal world. It is reasonable that our\n\n[mental] quality space should match our neighbor's, we being birds\nof a feather; and so the general trustworthiness of induction in the\n. . . learning of words was a put-up job. To trust induction as a way\nof access to the truths of nature, on the other hand, is to suppose,\nmore nearly, that our quality space matches that of the cosmos....\n\n[But] why does our innate subjective spacing of qualities accord so\nwell with the functionally relevant groupings in nature as to make\nour inductions tend to come out right? Why should our subjective\nspacing of qualities have a special purchase on nature and a lien on\nthe future?\n\nThere is some encouragement in Darwin. If people's innate spacing of qualities is a gene-linked trait, then the spacing that has made\nfor the most successful inductions will have tended to predominate\nthrough natural selection. Creatures inveterately wrong in their inductions have a pathetic but praiseworthy tendency to die before\nreproducing their kind."
    },
    {
        "document_id": "0",
        "parent_id": 626,
        "parent_text": "There is some encouragement in Darwin. If people's innate spacing of qualities is a gene-linked trait, then the spacing that has made\nfor the most successful inductions will have tended to predominate\nthrough natural selection. Creatures inveterately wrong in their inductions have a pathetic but praiseworthy tendency to die before\nreproducing their kind.\n\n\nQuite right, though the cosmos is heterogeneous, and thus the\ncomputations of similarity that allow our generalizations to harmonize\nwith it must be heterogeneous, too. Qualities that make two utterances\nequivalent in terms of learning the grammar, such as being composed\nof the same sequence of nouns and verbs, should not make them equivalent in terms of scaring away animals, such as being a certain loudness.\nQualities that should make bits of vegetation equivalent in terms of\ncausing or curing an illness, such as being different parts of a kind of\nplant, are not the qualities that should make them equivalent for nutrition, like sweetness; equivalent for feeding a fire, like dryness; equivalent\nfor insulating a shelter, like bulk; or equivalent for giving as a gift, like\nbeauty. The qualities that should classify people as potential allies, such\nas showing signs of affection, should not necessarily classify them as\npotential mates, such as showing signs of fertility and not being close\nblood relatives. There must be many similarity spaces, defined by different instincts or modules, allowing those modules to generalize intelligently in some domain of knowledge such as the physical world, the\nbiological world, or the social world.\n\nSince innate similarity spaces are inherent to the logic of learning,\n\n\nMind Design 419"
    },
    {
        "document_id": "0",
        "parent_id": 627,
        "parent_text": "Since innate similarity spaces are inherent to the logic of learning,\n\n\nMind Design 419\n\n\nit is not surprising that human-engineered learning systems in artificial\nintelligence are always innately designed to exploit the constraints in\nsome domain of knowledge. A computer program intended to learn\nthe rules of baseball is pre-programmed with the assumptions underlying competitive sports, so that it will not interpret players' motions\nas a choreographed dance or a religious ritual. A program designed\nto learn the past tense of English verbs is given only the verb's sound\nas its input; a program designed to learn a verb's dictionary entry is\ngiven only its meaning. This requirement is apparent in what the\ndesigners do, though not always in what they say. Working within\nthe assumptions of the Standard Social Science Model, the computer\nscientists often hype their programs as mere demos of powerful generalpurpose learning systems. But because no one would be so foolhardy\nas to try to model the entire human mind, the researchers can take\nadvantage of this allegedly practical limitation. They are free to handtailor their demo program to the kind of problem it is charged with\nsolving, and they can be a deus ex machina funneling just the right\ninputs to the program at just the right time. Which is not a criticism;\nthat's the way learning systems have to work!"
    },
    {
        "document_id": "0",
        "parent_id": 628,
        "parent_text": "So what are the modules of the human mind? A common academic\nparody of Chomsky has him proposing innate modules for bicycling,\nmatching ties with shirts, rebuilding carburetors, and so on. But the\nslope from language to carburetor repair is not that slippery. We\ncan avoid the skid with some obvious footholds. Using engineering\nanalyses, we can examine what a system would need, in principle, to\ndo the right kind of generalizing for the problem it is solving (for\nexample, in studying how humans perceive shapes, we can ask\nwhether a system that learns to recognize different kinds of furniture\ncan also recognize different faces, or whether it needs special shape\nanalyzers for faces). Using biological anthropology, we can look for\nevidence that a problem is one that our ancestors had to solve in the\nenvironments in which they evolved—so language and face recognition are at least candidates for innate modules, but reading and driving\nare not. Using data from psychology and ethnography, we can test\nthe following prediction: when children solve problems for which\nthey have mental modules, they should look like geniuses, knowing\nthings they have not been taught; when they solve problems that their\n\n\n420 THE LANGUAGE INSTINCT\n\n\nminds are not equipped for, it should be a long hard slog. Finally, if\na module for some problem is real, neuroscience should discover that\nthe brain tissue computing the problem has some kind of physiological cohesiveness, such as constituting a circuit or subsystem.\n\nBeing a bit foolhardy myself, I will venture a guess as to what kinds\nof modules, or families of instincts, might eventually pass these tests,\naside from language and perception (for justification, I refer you to a\nrecent compendium called _The Adapted Mind):_"
    },
    {
        "document_id": "0",
        "parent_id": 629,
        "parent_text": "Being a bit foolhardy myself, I will venture a guess as to what kinds\nof modules, or families of instincts, might eventually pass these tests,\naside from language and perception (for justification, I refer you to a\nrecent compendium called _The Adapted Mind):_\n\n\n1. Intuitive mechanics: knowledge of the motions, forces, and deformations that objects undergo.\n2. Intuitive biology: understanding of how plants and animals\nwork.\n3. Number.\n4. Mental maps for large territories.\n5. Habitat selection: seeking of safe, information-rich, productive\nenvironments, generally savannah-like.\n6. Danger, including the emotions of fear and caution, phobias for\nstimuli such as heights, confinement, risky social encounters,\nand venomous and predatory animals, and a motive to learn the\ncircumstances in which each is harmless.\n7. Food: what is good to eat.\n8. Contamination, including the emotion of disgust, reactions to\ncertain things that seem inherently disgusting, and intuitions\nabout contagion and disease.\n9. Monitoring of current well-being, including the emotions of\nhappiness and sadness, and moods of contentment and restlessness.\n10. Intuitive psychology: predicting other people's behavior from\ntheir beliefs and desires.\n11. A mental Rolodex: a database of individuals, with blanks for\nkinship, status or rank, history of exchange of favors, and inherent skills and strengths, plus criteria that valuate each trait.\n12. Self-concept: gathering and organizing information about one's\nvalue to other people, and packaging it for others.\n13. Justice: sense of rights, obligations, and deserts, including the\nemotions of anger and revenge.\n14. Kinship, including nepotism and allocations of parenting effort.\n15. Mating, including feelings of sexual attraction, love, and intentions of fidelity and desertion.\n\n\nMind Design 421"
    },
    {
        "document_id": "0",
        "parent_id": 630,
        "parent_text": "Mind Design 421\n\n\nTo see how far standard psychology is from this conception, just\nturn to the table of contents of any textbook. The chapters will\nbe: Physiological, Learning, Memory, Attention, Thinking, DecisionMaking, Intelligence, Motivation, Emotion, Social, Development,\nPersonality, Abnormal. I believe that with the exception of Perception\nand, of course, Language, not a single curriculum unit in psychology\ncorresponds to a cohesive chunk of the mind. Perhaps this explains\nthe syllabus-shock experienced by Introductory Psychology students.\nIt is like explaining how a car works by first discussing the steel parts,\nthen the aluminum parts, then the red parts, and so on, instead of\nthe electrical system, the transmission, the fuel system, and so on.\n(Interestingly, textbooks on the brain are more likely to be organized\naround what I think of as real modules. Mental maps, fear, rage,\nfeeding, maternal behavior, language, and sex are all common sections\nin neuroscience texts.)\n\n\nFor some readers, the preceding list will be the final proof that I\nhave lost my mind. An innate module for doing biology? Biology is\na recently invented academic discipline. Students struggle through it.\nThe person in the street, and tribes around the world, are fonts of\nsuperstition and misinformation. The idea seems only slightly less\nmad than the innate carburetor repair instinct."
    },
    {
        "document_id": "0",
        "parent_id": 631,
        "parent_text": "For some readers, the preceding list will be the final proof that I\nhave lost my mind. An innate module for doing biology? Biology is\na recently invented academic discipline. Students struggle through it.\nThe person in the street, and tribes around the world, are fonts of\nsuperstition and misinformation. The idea seems only slightly less\nmad than the innate carburetor repair instinct.\n\nBut recent evidence suggests otherwise; there may be an innate\n\"folk biology\" that gives people different basic intuitions about plants\nand animals than they have about other objects, like man-made artifacts. The study of folk biology is young compared with the study of\nlanguage, and the idea might be wrong. (Maybe we reason about\nliving things using two modules, one for plants and one for animals.\nMaybe we use a bigger module, one that embraces other natural kinds\nlike rocks and mountains. Or maybe we use an inappropriate module,\nlike folk psychology.) But the evidence so far is suggestive enough\nthat I can present folk biology as an example of a possible cognitive\nmodule other than language, giving you an idea of the kinds of things\nan instinct-populated mind might contain.\n\nTo begin with, as hard as it may be for a supermarket-jaded city\ndweller to believe, \"stone age\" hunter-gatherers are erudite botanists\nand zoologists. They typically have names for hundreds of wild plant\nand animal species, and copious knowledge of those species' life\n\n\n4 2 2 THE LANGUAGE INSTINCT\n\n\ncycles, ecology, and behavior, allowing them to make subtle and\nsophisticated inferences. They might observe the shape, freshness,\nand direction of an animal's tracks, the time of day and year, and the\ndetails of the local terrain to predict what kind of animal it is, where\nit has gone, and how old, hungry, tired, and scared it is likely to be.\nA flowering plant in the spring might be remembered through the\nsummer and returned to in the fall for its underground tuber. The\nuse of medicinal drugs, recall, is part of the lifestyle of the Universal\nPeople."
    },
    {
        "document_id": "0",
        "parent_id": 632,
        "parent_text": "What kind of psychology underlies this talent? How does our\nmental similarity space accord with this part of the cosmos? Plants\nand animals are special kinds of objects. For a mind to reason intelligently about them, it should treat them differently from rocks, islands,\nclouds, tools, machines, and money, among other things. Here are\nfour of the basic differences. First, organisms (at least, sexual organisms) belong to populations of interbreeding individuals adapted to\nan ecological niche; this makes them fall into species with a relatively\nunified structure and behavior. For example, all robins are more or\nless alike, but they are different from sparrows. Second, related species descended from a common ancestor by splitting off from a lineage; this makes them fall into non-overlapping, hierarchically\nincluded classes. For example, sparrows and robins are alike in being\nbirds, birds and mammals are alike in being vertebrates, vertebrates\nand insects are alike in being animals. Third, because an organism is\na complex, self-preserving system, it is governed by dynamic physiological processes that are lawful even when, hidden. For example, the\nbiochemical organization of an organism enables it to grow and move,\nand is lost when it dies. Fourth, because organisms have separate\ngenotypes and phenotypes, they have a hidden \"essence\" that is\nconserved as they grow, change form, and reproduce. For example,\na caterpillar, chrysalis, and butterfly are in a crucial sense the same\nanimal.\n\nRemarkably, people's unschooled intuition about living things\nseems to mesh with these core biological facts, including the intuitions of young children who cannot read and have not set foot in a\nbiology lab.\n\nThe anthropologists Brent Berlin and Scott Atran have studied folk\ntaxonomies of flora and fauna. They have found that, universally,\npeople group local plants and animals into kinds that correspond to\n\n\nMind Design 423"
    },
    {
        "document_id": "0",
        "parent_id": 633,
        "parent_text": "Remarkably, people's unschooled intuition about living things\nseems to mesh with these core biological facts, including the intuitions of young children who cannot read and have not set foot in a\nbiology lab.\n\nThe anthropologists Brent Berlin and Scott Atran have studied folk\ntaxonomies of flora and fauna. They have found that, universally,\npeople group local plants and animals into kinds that correspond to\n\n\nMind Design 423\n\n\nthe _genus_ level in the Linnaean classification system of professional\nbiology (species-genus-family-order-class-phylum-kingdom). Since\nmost locales contain a single species from any genus, these folk categories usually correspond to species as well. People also classify kinds\ninto higher-level life-forms, like tree, grass, moss, quadruped, bird,\nfish, and insect. Most of the life-form categories of animals coincide\nwith the biologist's level of _class._ Folk classifications, like professional\nbiologist's classifications, are strictly hierarchical: every plant or animal belongs to one and only one genus; every genus belongs to only\none life-form; every life-form is either a plant or an animal; plants\nand animals are living things, and every object is either a living thing\nor not. All this gives people's intuitive biological concepts a logical\nstructure that is different from the one that organizes their other\nconcepts, such as human-made artifacts. Whereas people everywhere\nsay that an animal cannot be both fish and fowl, they are perfectly\nhappy with saying, for example, that a wheelchair can be both furniture and vehicle, or that a piano can be both musical instrument\nand furniture. And this in turn makes reasoning about natural kinds\ndifferent from reasoning about artifacts. People can deduce that if a\ntrout is a kind of fish and a fish is a kind of animal, then a trout is a\nkind of animal. But they do not infer that if a car seat is a kind of\nchair and a chair is a kind of furniture, then a car seat is a kind of\nfurniture."
    },
    {
        "document_id": "0",
        "parent_id": 634,
        "parent_text": "Special intuitions about living things begin early in life. Recall that\nthe human infant is far from being a bag of reflexes, mewling and\npuking in the nurse's arms. Three-to six-month infants, well before\nthey can move about or even see very well, know about objects and\ntheir possible motions, how they causally impinge on one another,\ntheir properties like compressibility, and their number and how it\nchanges with addition and subtraction. The distinction between living\nand nonliving things is appreciated early, perhaps before the first\nbirthday. The cut initially takes the form of a difference between\ninanimate objects that move around according to the laws of billiardball physics and objects like people and animals that are self-propelled. For example, in an experiment by the psychologist Elizabeth\nSpelke, a baby is shown a ball rolling behind a screen and another\nball emerging from the other side, over and over again to the point\nof boredom. If the screen is removed and the infant sees the expected\nhidden event, one ball hitting the other and launching it on its way,\n\n\n424 THE LANGUAGE INSTINCT\n\n\nthe baby's interest is only momentarily revived; presumably this is\nwhat the baby had been imagining all along. But if the screen is\nremoved and the baby sees the magical event of one object stopping\ndead in its tracks without reaching the second ball, and the second\nball taking off mysteriously on its own, the baby stares for much\nlonger. Crucially, infants expect inanimate balls and animate people\nto move according to different laws. In another scenario, people, not\nballs, disappeared and appeared from behind the screen. After the\nscreen was removed, the infants showed little surprise when they saw\none person stop short and the other up and move; they were more\nsurprised by a collision."
    },
    {
        "document_id": "0",
        "parent_id": 635,
        "parent_text": "By the time children are of nursery school and kindergarten age,\nthey display a subtle understanding that living things fall into kinds\nwith hidden essences. The psychologist Frank Keil has challenged\nchildren with pixilated questions like these:\n\n\nDoctors took a raccoon [shows picture of a raccoon] and shaved\naway some of its fur. They dyed what was left all black. Then they\nbleached a single stripe all white down the center of its back. Then,\nwith surgery, they put in its body a sac of super smelly yucky stuff,\njust like a skunk has. When they were all done, the animal looked\nlike this [shows picture of skunk]. After the operation, was this a\nskunk or a raccoon?\n\nDoctors took a coffeepot that looked like this [shows picture of a\ncoffeepot]. They sawed off the handle, sealed the top, took off the\ntop knob, closed the spout, and sawed it off. They also sawed off\nthe base and attached a flat piece of metal. They attached a little\nstick, cut a window in it, and filled the metal container with birdfood. When they were done, it looked like this [shows picture of a\nbirdfeeder]. After the operation, was this a coffeepot or a birdfeeder?\n\nDoctors took this toy [shows picture of a wind-up bird]. You wind\nit up with a key, and its mouth opens and a little machine inside\nplays music. The doctors did an operation on it. They put on real\nfeathers to make it nice and soft and they gave it a better beak.\nThen they took off the wind-up key and put in a new machine so\nthat it flapped its wings and flew, and chirped [shows picture of a\nbird]. After the operation, was it a real bird or a toy bird?\n\n\nMind Design 425"
    },
    {
        "document_id": "0",
        "parent_id": 636,
        "parent_text": "Doctors took this toy [shows picture of a wind-up bird]. You wind\nit up with a key, and its mouth opens and a little machine inside\nplays music. The doctors did an operation on it. They put on real\nfeathers to make it nice and soft and they gave it a better beak.\nThen they took off the wind-up key and put in a new machine so\nthat it flapped its wings and flew, and chirped [shows picture of a\nbird]. After the operation, was it a real bird or a toy bird?\n\n\nMind Design 425\n\n\nFor artifacts like a coffeepot turning into a bird feeder (or a deck of\ncards turning into toilet paper), the children accepted the changes at\nface value: a birdfeeder is anything that is meant to feed birds, so\nthat thing is a birdfeeder. But for natural kinds like a raccoon turning\ninto a skunk (or a grapefruit turning into an orange), they were\nmore resistant; there was some invisible raccoonhood lingering in the\nskunk's clothing, and they were less likely to say that the new creature\nwas a skunk. And for violations of the boundary between artifacts\nand natural kinds, like a toy turning into a bird (or a porcupine\nturning into a hairbrush), they were adamant: a bird is a bird and a\ntoy is a toy. Keil also showed that children are uncomfortable with\nthe idea of a horse that has cow insides and cow parents and cow\nbabies, even though they have no problem with a key that is made of\nmelted-down pennies and is then melted down to make pennies again.\n\nAnd of course adults from other cultures have the same sorts of\nintuitions. Illiterate rural Nigerians were given the following kind of\nquestion:\n\n\nSome students took a pawpaw [shows picture of a pawpaw] and\nstuck some green, pointed leaves on the top. Then they put small,\nprickly patches all over it. Now it looks like this [shows picture of\na pineapple]—is it a pawpaw or a pineapple?\n\n\nA typical response was, \"It's a pawpaw, because a pawpaw has its\nown structure from heaven and a pineapple its own origin. One\ncannot turn into the other.\""
    },
    {
        "document_id": "0",
        "parent_id": 637,
        "parent_text": "Some students took a pawpaw [shows picture of a pawpaw] and\nstuck some green, pointed leaves on the top. Then they put small,\nprickly patches all over it. Now it looks like this [shows picture of\na pineapple]—is it a pawpaw or a pineapple?\n\n\nA typical response was, \"It's a pawpaw, because a pawpaw has its\nown structure from heaven and a pineapple its own origin. One\ncannot turn into the other.\"\n\nLittle children also sense that animal kinds fall into larger categories, and their generalizations follow the similarity defined by category\nmembership, not mere similarity of appearance. Susan Gelman and\nEllen Markman showed three-year-old children a picture of a flamingo, a picture of a bat, and a picture of a blackbird, which looked\na lot more like the bat than like the flamingo. They told the kids that\na flamingo feeds its babies mashed-up food but a bat feeds its babies\nmilk, and asked them what the blackbird feeds its babies. With no\nfurther information, children went by appearances and predicted\nmilk. But all it took was a mention that flamingos and blackbirds\nwere birds, and the children lumped them together and predicted\nmashed-up food.\n\n\n426 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 638,
        "parent_text": "426 THE LANGUAGE INSTINCT\n\n\nAnd if you really doubt that we have botany instincts, consider one\nof the oddest of human motives: looking at flowers. A huge industry\nspecializes in breeding and growing flowers for people to use in\ndecorating dwellings and parks. Some research shows that bringing\nflowers to hospital patients is more than a warm gesture; it may\nactually improve the patient's mood and recovery rate. Since people\nrarely eat flowers, this diversion of effort and resources seems inexplicably frivolous. But if we evolved as intuitive botanists, it makes some\nsense. A flower is a microfiche of botanical information. When plants\nare not in bloom, they blend into a sea of green. A flower is often the\nonly way to identify a plant species, even for a professional taxonomist. Flowers also signal seasons and terrains of expected bounty and\nthe exact locations of future fruits and seeds. A motive to pay attention\nto flowers, and to be where they are, would obviously have been\nuseful in environments where there were no year-round salad bars."
    },
    {
        "document_id": "0",
        "parent_id": 639,
        "parent_text": "Intuitive biology is, of course, very different from what professors\nof biology do in their laboratories. But professional biology may have\nintuitive biology at its foundation. Folk taxonomy was obviously the\npredecessor to Linnaean taxonomy, and even today, professional taxonomists rarely contradict indigenous tribes when they classify the\nlocal species. The intuitive conviction that living things have a hidden\nessence and are governed by hidden processes is clearly what impelled\nthe first professional biologists to try to understand the nature of\nplants and animals by bringing them into the laboratory and putting\nbits of them under a microscope. Anyone who announced he was\ntrying to understand the nature of chairs by bringing them into a\nlaboratory and putting bits of them under a microscope would surely\nbe dismissed as mad, not given a grant. Indeed, probably all of science\nand mathematics is driven by intuitions coming from innate modules\nlike number, mechanics, mental maps, even law. Physical analogies\n(heat is a fluid, electrons are particles), visual metaphors (linear function, rectangular matrix), and social and legal terminology (attraction,\nobeying laws) are used throughout science. And if you will allow me\nto sneak in one more offhand remark that really deserves a book of\nits own, I would guess that most other human \"cultural\" practices\n(competitive sports, narrative literature, landscape design, ballet), no\nmatter how much they seem like arbitrary outcomes of a Borgesian\nlottery, are clever technologies we have invented to exercise and\n\n\nMind Design 427\n\n\nstimulate mental modules that were originally designed for specific\nadaptive functions."
    },
    {
        "document_id": "0",
        "parent_id": 640,
        "parent_text": "Mind Design 427\n\n\nstimulate mental modules that were originally designed for specific\nadaptive functions.\n\n\nSo the language instinct suggests a mind of adapted computational\nmodules rather than the blank slate, lump of wax, or general-purpose\ncomputer of the Standard Social Science Model. But what does this\nview say about the secular ideology of equality and opportunity that\nthe model has provided us? If we abandon the SSSM, are we forced\nto repugnant doctrines like \"biological determinism\"?\n\nLet me begin with what I hope are obvious points. First, the human\nbrain works however it works. Wishing for it to work in some way\nas a shortcut to justifying some ethical principle undermines both the\nscience and the ethics (for what happens to the principle if the scientific facts turn out to go the other way?). Second, there is no foreseeable discovery in psychology that could bear on the self-evident truth\nthat ethically and politically, all people are created equal, that they\nare endowed with certain inalienable rights, and that among these are\nlife, liberty, and the pursuit of happiness. Finally, radical empiricism\nis not necessarily a progressive, humanitarian doctrine. A blank slate\nis a dictator's dream. Some psychology textbooks mention the \"fact\"\nthat Spartan and samurai mothers smiled upon hearing that their sons\nfell in battle. Since history is written by generals, not mothers, we can\ndismiss this incredible claim, but it is clear what purposes it must\nhave served.\n\nWith those points out of the way, I do want to point out some\nimplications of the theory of cognitive instincts for heredity and humankind, for they are the opposite of what many people expect. It is\na shame that the following two claims are so often confused:\n\n\nDifferences between people are innate.\nCommonalities among all people are innate."
    },
    {
        "document_id": "0",
        "parent_id": 641,
        "parent_text": "With those points out of the way, I do want to point out some\nimplications of the theory of cognitive instincts for heredity and humankind, for they are the opposite of what many people expect. It is\na shame that the following two claims are so often confused:\n\n\nDifferences between people are innate.\nCommonalities among all people are innate.\n\n\nThe two claims could not be more different. Take number of legs.\nThe reason that some people have fewer legs than others is 100%\ndue to the environment. The reason that all uninjured people have\nexactly two legs (rather than eight, or six, or none) is 100% due to\nheredity. But claims that a universal human nature is innate are often\n\n\n428 THE LANGUAGE INSTINCT\n\n\nrun together with claims that differences between individuals, sexes,\nor races are innate. One can see the misguided motive for running\nthem together: if _nothing_ in the mind is innate, then differences\nbetween people's minds cannot be innate; thus it would be good if\nthe mind had no structure because then decent egalitarians would\nhave nothing to worry about. But the logical inverse is false. Everyone\ncould be born with identical, richly structured minds, and all differences among them could be bits of acquired knowledge and minor\nperturbations that accumulate through people's history of life experiences. So even for people who, inadvisably in my view, like to conflate\nscience and ethics, there is no need for alarm at the search for innate\nmental structure, whatever the truth turns out to be."
    },
    {
        "document_id": "0",
        "parent_id": 642,
        "parent_text": "One reason innate commonalities and innate differences are so\neasy to confuse is that behavior geneticists (the scientists who study\ninherited deficits, identical and fraternal twins, adopted and biological\nchildren, and so on) have usurped the word \"heritable\" as a technical\nterm referring to the proportion of _variation_ in some trait that correlates with genetic differences within a species. This sense is different\nfrom the everyday term \"inherited\" (or genetic), which refers to traits\nwhose inherent structure or organization comes from information\nin the genes. Something can be ordinarily inherited but show zero\nheritability, like number of legs at birth or the basic structure of the\nmind. Conversely, something can be not inherited but have 100%\nheritability. Imagine a society where all and only the red-haired people\nwere made priests. Priesthood would be highly \"heritable,\" though\nof course not inherited in any biologically meaningful sense. For this\nreason, people are bound to be confused by claims like \"Intelligence\nis 70% heritable,\" especially when the newsmagazines report them\nin the same breath (as they inevitably do, alas) with research in\ncognitive science on the basic workings of the mind.\n\nAll claims about a language instinct and other mental modules are\nclaims about the commonalities among all normal people. They have\nvirtually nothing to do with possible genetic differences between\npeople. One reason is that, to a scientist interested in how complex\nbiological systems work, differences between individuals are so _boring!_\nImagine what a dreary science of language we would have if instead\nof trying to figure out how people put words together to express\ntheir thoughts, researchers had begun by developing a Language\nQuotient (LQ) scale, and busied themselves by measuring thousands\n\n\nMind Design 429"
    },
    {
        "document_id": "0",
        "parent_id": 643,
        "parent_text": "Mind Design 429\n\n\nof people's relative language skills. It would be like asking how lungs\nwork and being told that some people have better lungs than others,\nor asking how compact disks reproduce sound and being given a\nconsumer magazine that ranked them instead of an explanation of\ndigital sampling and lasers.\n\nBut emphasizing commonalities is not just a matter of scientific\ntaste. The design of any adaptive biological system—the explanation\nof how it works—is almost certain to be uniform across individuals in\na sexually reproducing species, because sexual recombination would\nfatally scramble the blueprints for qualitatively different designs.\nThere is, to be sure, a great deal of genetic diversity among individuals; each person is biochemically unique. But natural selection is a\nprocess that feeds on that variation, and (aside from functionally\nequivalent varieties of molecules) when natural selection creates adaptive designs, it does so by using the variation up: the variant genes\nthat specify more poorly designed organs disappear when their owners starve, get eaten, or die mateless. To the extent that mental modules are complex products of natural selection, genetic variation will\nbe limited to quantitative variations, not differences in basic design.\nGenetic differences among people, no matter how fascinating they\nare to us in love, biography, personnel, gossip, and politics, are of\nminor interest to us when we appreciate what makes minds intelligent\nat all."
    },
    {
        "document_id": "0",
        "parent_id": 644,
        "parent_text": "Similarly, an interest in mind design puts possible innate differences\nbetween sexes (as a psycholinguist I refuse to call them \"genders\")\nand races in a new light. With the exception of the maleness-determining gene on the Y-chromosome, every functioning gene in a man's\nbody is also found in a woman's and vice versa. The maleness gene\nis a developmental switch that can activate some suites of genes and\ndeactivate others, but the same blueprints are in both kinds of bodies,\nand the default condition is identity of design. There is some evidence\nthat the sexes depart from this default in the case of the psychology\nof reproduction and the adaptive problems directly and indirectly\nrelated to it, which is not surprising; it seems unlikely that peripherals\nas different as the male and female reproductive systems would come\nwith the same software. But the sexes face essentially similar demands\nfor most of the rest of cognition, including language, and I would be\nsurprised if there were differences in design between them.\n\nRace and ethnicity are the most minor differences of all. The human\n\n\n430 THE LANGUAGE INSTINCT"
    },
    {
        "document_id": "0",
        "parent_id": 645,
        "parent_text": "Race and ethnicity are the most minor differences of all. The human\n\n\n430 THE LANGUAGE INSTINCT\n\n\ngeneticists Walter Bodmer and Luca Cavalli-Sforza have noted a\nparadox about race. Among laypeople, race is lamentably salient, but\nfor biologists it is virtually invisible. Eighty-five percent of human\ngenetic variation consists of the differences between one person and\nanother within the same ethnic group, tribe, or nation. Another eight\npercent is between ethnic groups, and a mere seven percent is between\n\"races.\" In other words, the genetic difference between, say, two\nrandomly picked Swedes is about twelve times as large as the genetic\ndifference between the average of Swedes and the average of Apaches\nor Warlpiris. Bodmer and Cavalli-Sforza suggests that the illusion is\nthe result of an unfortunate coincidence. Many of the systematic\ndifferences among races are adaptations to climate: melanin protects\nskin against the tropical sun, eyelid folds insulate eyes from dry cold\nand snow. But the skin, the part of the body seen by the weather, is\nalso the part of the body seen by other people. Race is, quite literally,\nskin-deep, but to the extent that perceivers generalize from external\nto internal differences, nature has duped them into thinking that race\nis important. The X-ray vision of the molecular geneticist reveals the\nunity of our species."
    },
    {
        "document_id": "0",
        "parent_id": 646,
        "parent_text": "And so does the X-ray vision of the cognitive scientist. \"Not speaking the same language\" is a virtual synonym for incommensurability,\nbut to a psycholinguist, it is a superficial difference. Knowing about\nthe ubiquity of complex language across individuals and cultures and\nthe single mental design underlying them all, no speech seems foreign\nto me, even when I cannot understand a word. The banter among\nNew Guinean highlanders in the film of their first contact with the\nrest of the world, the motions of a sign language interpreter, the\nprattle of little girls in a Tokyo playground—I imagine seeing through\nthe rhythms to the structures underneath, and sense that we all have\nthe same minds."
    },
    {
        "document_id": "0",
        "parent_id": 647,
        "parent_text": "# Glossary\n\n**accusative.** The case of the object of a verb: _**I saw HIM**_ (not _**HE).**_\n**active.** See **voice.**\n**adjective.** One of the major syntactic categories, comprising words that\ntypically refer to a property or state: _**a HOT tin roof; He is AFRAID of his**_\n\n_**mother.**_\n**adjunct.** A phrase that comments on or adds parenthetical information to a\nconcept (as opposed to an argument): _**a man FROM CINCINNATI; I cut the**_\n\n_**bread WITH A KNIFE,**_ I have used the word **modifier** instead.\n**adverb.** One of the minor syntactic categories, comprising words that typically refer to the manner or time of an action: _**tread SOFTLY; BOLDLY go;**_\n\n_**He**_ _**will**_ _**leave**_ _**SOON.**_\n**affix.** A prefix or suffix.\n**agreement.** The process in which a word in a sentence is altered depending\non a property of some other word in the sentence; typically, the verb\nbeing altered to match the number, person, and gender of its subject or\nobject: _**He SMELLS**_ (not _**SMELL)**_ versus _**They SMELL**_ (not _**SMELLS).**_\nAI. Artificial Intelligence, the attempt to program computers to carry out\nintelligent, humanlike tasks such as learning, reasoning, recognizing objects, understanding speech and sentences, and moving arms and legs.\n**algorithm.** An explicit, step-by-step program or set of instructions for getting\nthe solution to some problem: \"To calculate a 15% tip, take the sales tax\nand multiply by three.\"\n**aphasia.** The loss or impairment of language abilities following brain damage.\n**argument.** One of the participants defining a state, event, or relationship:\n\n_**president**_ _**of THE**_ _**UNITED**_ _**STATES;**_ _**DICK gave**_ _**THE DIAMOND**_ _**to**_ _**LIZ,**_ _**the sum**_\n\n_**of THREE and FOUR.**_ I have used the term **role-player** instead.\n**article.** One of the minor syntactic categories, including the words _**a**_ and _**the.**_\n\n\n474 Glossary"
    },
    {
        "document_id": "0",
        "parent_id": 648,
        "parent_text": "_**president**_ _**of THE**_ _**UNITED**_ _**STATES;**_ _**DICK gave**_ _**THE DIAMOND**_ _**to**_ _**LIZ,**_ _**the sum**_\n\n_**of THREE and FOUR.**_ I have used the term **role-player** instead.\n**article.** One of the minor syntactic categories, including the words _**a**_ and _**the.**_\n\n\n474 Glossary\n\n\nUsually subsumed in the category determiner in contemporary theories\nof grammar.\n**ASL.** American Sign Language, the primary sign language of the deaf in the\nUnited States.\n**aspect.** The way an event is spread out over time: whether it is instantaneous\n\n_( s w a t_ _a fly),_ continuous _(run_ _around all day),_ terminating _(draw a_ _circle),_\nhabitual _(mows the grass_ _e v e r y Sunday),_ or a timeless state _(knows how to_\n\n_s w i m ) ._ In English, aspect is involved in the inflectional distinction between\n\n_He eats_ and _He is eating,_ and between _He ate, He was eating,_ and _He has_\n\n\n_eaten._\n**auxiliary.** A special kind of verb used to express concepts related to the truth\nof the sentence, such as tense, negation, question/statement, necessary/\n\npossible: _He_ _MIGHT_ _quibble;_ _He_ _WILL_ _quibble;_ _He_ _HAS_ _quibbled;_ _He_ _IS_"
    },
    {
        "document_id": "0",
        "parent_id": 649,
        "parent_text": "_eaten._\n**auxiliary.** A special kind of verb used to express concepts related to the truth\nof the sentence, such as tense, negation, question/statement, necessary/\n\npossible: _He_ _MIGHT_ _quibble;_ _He_ _WILL_ _quibble;_ _He_ _HAS_ _quibbled;_ _He_ _IS_\n\n\n_quibbling;_ _He_ _DOESN'T_ _quibble;_ _DOES_ _he_ _quibble?_\n**axon.** The long fiber extending from a neuron that carries a signal to other\nneurons.\n**behaviorism.** A school of psychology, influential from the 1920s to the 1960s,\nthat rejected the study of the mind as unscientific, and sought to explain\nthe behavior of organisms (including humans) with laws of stimulusresponse conditioning.\n**bottom-up.** Perceptual processing that relies on extracting information directly from the sensory signal (for example, the loudness, pitch, and\nfrequency components of a sound wave), as opposed to top-down processing, which uses knowledge and expectancies to guess, predict, or fill\nin the perceived event or message.\n**case** . A set of affixes, positions, or word forms that a language uses to\ndistinguish the different roles of the participants in some event or state.\nCases typically correspond to the subject, object, indirect object, and\nthe objects of various kinds of prepositions. In English, case is what\ndistinguishes between _I_, _he, she, we, they,_ which are used for subjects,\nand _me, him, her, us, them,_ which are used for objects of verbs, objects\nof prepositions, and everywhere else.\n**chain device.** See **finite-state device.**\n**chromosome.** A long strand of DNA, containing thousands of genes, in a\nprotective package. There are twenty-three chromosomes in a human\nsperm or egg; there are twenty-three pairs of chromosomes (one from the\nmother, one from the father) in all other human cells.\n**clause.** A kind of phrase that is generally the same thing as a sentence, except\nthat some kinds of clause can never occur on their own but only inside a\nbigger sentence: _THE CAT IS ON THE MAT; John arranged FOR MARY TO_"
    },
    {
        "document_id": "0",
        "parent_id": 650,
        "parent_text": "_GO;_ _The_ _spy_ _WHO_ _LOVED_ _ME_ _disappeared;_ _He_ _said_ _THAT_ _SHE_ _LEFT._\n**cognitive science.** The study of intelligence (reasoning, perception, language,\nmemory, control of movement), embracing parts of several academic disci\n\nGlossary 475\n\n\nplines: experimental psychology, linguistics, computer science, philosophy, neuroscience.\n**complement.** A phrase that appears together with a verb, completing its\n\nmeaning: _She ate AN_ _APPLE; It_ _darted_ _UNDER_ _THE_ _COUCH; I_ _thought_ _HE_\n\n\n_WAS_ _DEAD._\n**compound.** A word formed by joining together other words: _f r u i t - e a t e r ;_\n\n_superwoman;_ _laser_ _printer._\n**concord.** See agreement.\n**conjunction** . One of the minor syntactic categories, including _a n d, o r,_ and\n_but;_ also, the entire phrase made by conjoining two words or phrases:\n\n_Ernie_ _and_ _Bert;_ _the_ _naked_ _and_ _the_ _dead._\n**consonant.** A phoneme produced with a blockage or constriction of the\nvocal tract.\n**content words** . Nouns, verbs, adjectives, adverbs, and some prepositions,\nwhich typically express concepts particular to a given sentence, as opposed\nto function words (articles, conjunctions, auxiliaries, pronouns, and other\nprepositions), which are used to specify kinds of information, like tense\nor case, that are expressed in all or most sentences.\n**copula** . The verb _to be_ when it is used to link a subject and a predicate: _S h e_\n\n_WAS_ _H a p p y ;_ _Biff and Joe_ _ARE fools;_ _The_ _cat_ _is_ _on_ _the_ _mat._\n**cortex** . The thin surface of the cerebral hemispheres of the brain, visible as\ngray matter, containing the bodies of neurons and their synapses with\nother neurons; where the neural computation takes place in the cerebral\nhemispheres. The rest of the cerebral hemispheres consists of white matter, bundles of axons that connect one part of cortex with another.\n**dative.** A family of constructions typically used for giving or benefiting; _S h e_"
    },
    {
        "document_id": "0",
        "parent_id": 651,
        "parent_text": "_BAKED_ _ME_ _A_ _CAKE;_ _She BAKED A_ _CAKE FOR_ _ME;_ _He_ _GAVE_ _HER_ _A_ _PARTRIDGE;_\n_He GAVE A PARTRIDGE TO HER._ Also refers to the case of the beneficiary\nor recipient in this construction.\n**deep structure** (now **d-structure** ). The tree, formed by phrase structure rules,\ninto which words are plugged, in such a way as to satisfy the demands of\nthe words regarding their neighboring phrases. Contrary to popular belief,\nnot the same as Universal Grammar, the meaning of a sentence, or the\nabstract grammatical relationships underlying a sentence.\n**derivational morphology** . The component of grammar containing rules that\ncreate new words out of old ones: _break +_ _-able_ _—>_ _breakable;_ _sing_ _+_\n\n_-er_ _—>_ _singer;_ _super_ _+_ _woman_ _—>_ _superwoman._\n**determiner** . One of the minor syntactic categories, comprising the articles\n\nand similar words: _a,_ _the,_ _some,_ _more,_ _much,_ _many._\n**diphthong** . A vowel consisting of two vowels pronounced in quick succession: _bite_ _(pronounced_ _\"ba-eet\");_ _loud;_ _mAke._\n**discourse** . A succession of related sentences, as in a conversation or text.\n**dyslexia** . Difficulty in reading or learning to read, which may be caused by\n\n\n476 Glossary\n\n\nbrain damage, inherited factors, or unknown causes. Contrary to popular\nbelief, it is not the habit of mirror-reversing letters,\n**ellipsis.** Omission of a phrase, usually one that was previously mentioned or"
    },
    {
        "document_id": "0",
        "parent_id": 652,
        "parent_text": "can be inferred: _Yes,_ _**I**_ _can (_ _); Where are you going? (_ _) To the_\n_store._\n**empiricism.** The approach to studying mind and behavior that emphasizes\nlearning and environmental influence over innate structure; the claim that\nthere is nothing in the mind that was not first in the senses. A second\nsense, not used in this book, is the approach to science that emphasizes\nexperimentation and observation over theory.\n**finite-state device.** A device that can produce or recognize ordered sequences\nof behavior (like sentences), by selecting an output item (like a word)\nfrom a list, going to some other list and selecting an item from it, and so\non, possibly looping back to earlier lists. I have used the term **chaining**\n**device** instead.\n**function word.** See **content word.**\n**gender.** A set of mutually exclusive kinds into which a language categorizes\nits nouns and pronouns. In many languages, the genders of pronouns\ncorrespond to the sexes _(he_ versus _she),_ and the genders of nouns are\ndetermined by their sounds (words ending in _o_ are one gender, words\nending in _a_ are the other) or are simply put in two or three arbitrary lists.\nIn other languages, gender can correspond to human versus nonhuman,\nanimate versus inanimate, long versus round versus flat, and other distinctions.\n**gene.** (1) A stretch (or set of stretches) of DNA that carries the information\nnecessary for building one kind of protein molecule. (2) A stretch of DNA\nthat is long enough to survive intact across many generations of sexual\nrecombination. (3) A stretch of DNA that, in comparison with alternative\nstretches that could sit at that location on the chromosome, contributes\nto the specification of some trait of the organism (e.g., \"a gene for blue\neyes\").\n**generative grammar.** See **grammar.**\n**generative linguistics.** The school of linguistics, associated with Noam\nChomsky, that tries to discover the generative grammars of languages and\nthe universal grammar underlying them."
    },
    {
        "document_id": "0",
        "parent_id": 653,
        "parent_text": "recombination. (3) A stretch of DNA that, in comparison with alternative\nstretches that could sit at that location on the chromosome, contributes\nto the specification of some trait of the organism (e.g., \"a gene for blue\neyes\").\n**generative grammar.** See **grammar.**\n**generative linguistics.** The school of linguistics, associated with Noam\nChomsky, that tries to discover the generative grammars of languages and\nthe universal grammar underlying them.\n**gerund.** The noun formed out of a verb by adding _-ing: his incessant_ _**HUM-**_"
    },
    {
        "document_id": "0",
        "parent_id": 654,
        "parent_text": "_**MING.**_\n**grammar.** A **generative grammar** is a set of rules that determines the form\nand meaning of words and sentences in a particular language as it is\nspoken in some community. A **mental grammar** is the hypothetical generative grammar stored unconsciously in a person's brain. Neither should be\nconfused with a **prescriptive** or **stylistic** grammar taught in school and\n\n\nGlossary 477\n\n\nexplained in style manuals, the guidelines for how one \"ought\" to speak\nin a prestige or written dialect,\n**gyrus** . The outward, visible portion of a wrinkle of the brain. The plural is\n\n_gyri._\n**head** . The single word in a phrase, or single morpheme in a word, that\n\ndetermines the meaning and properties of the whole: _the MAN in the_\n_pinstriped_ _suit;_ _ruby-throated_ _hummingBiRD._\n**indirect object** . In a dative construction with two objects, the first one,\n\nreferring to the recipient or beneficiary: _Bake ME a cake; Give THE DOG_\n_a bone._\n**Indo-European** . The group of language families that includes most of the\nlanguages of Europe, southwestern Asia, and northern India; thought to\nbe descended from a language, Proto-Indo-European, which was spoken\nby a prehistoric people.\n**induction** . Uncertain or probabilistic inference (as opposed to deduction),\nespecially a generalization from instances: \"This raven is black; that ravenis black; therefore all ravens are black.\"\n**infinitive** . The generic form of a verb, lacking tense: _He tried TO LEAVE; S h e_"
    },
    {
        "document_id": "0",
        "parent_id": 655,
        "parent_text": "_may_ _LEAVE._\n**INFL** . In post-1970s Chomskyan theory, a syntactic category comprising the\nauxiliary elements and tense inflections, which serves as the head of the\nsentence.\n**inflecting language** . A language, like Latin, Russian, Warlpiri, or ASL, that\nrelies heavily on inflectional morphology to convey information, as opposed\nto an isolating language like Chinese that leaves the forms of words alone\nand orders the words within phrases and sentences to convey information.\nEnglish does both, but is considered more isolating than inflecting.\n**inflectional morphology** . The modification of the form of a word to fit its\nrole in the sentence, usually by adding an inflection: _I conquerED; I'm_\n_thinklNG;_ _Speed_ _kills;_ _two_ _turtle_ _doves._\nintonation. The melody or pitch contour of speech.\nintransitive. A verb that may appear without an object: _We DINED; S h e_\n\n_THOUGHT that he was single;_ as opposed to a transitive verb, that may\nappear with one: _He DEVOURED the steak; I TOLD him to go._\n**inversion** . Flipping the position of the subject and the auxiliary: _I am blue_\n\n_—> Am I blue?;_ _What you will do_ —> _What will you do?_\nirregular. A word with an idiosyncratic inflected form instead of the one\nusually created by a rule of grammar: _brought_ (not _bringed); mice_ (not\n_mouses);_ as opposed to regular words, which simply obey the rule _(walk_\n_+ -ed—> walked, rat + -s —> rats)._\n**isolating language** . See inflecting language.\n**larynx** . The valve near the top of the windpipe, used to seal the lungs during\n\n\n478 Glossary"
    },
    {
        "document_id": "0",
        "parent_id": 656,
        "parent_text": "_—> Am I blue?;_ _What you will do_ —> _What will you do?_\nirregular. A word with an idiosyncratic inflected form instead of the one\nusually created by a rule of grammar: _brought_ (not _bringed); mice_ (not\n_mouses);_ as opposed to regular words, which simply obey the rule _(walk_\n_+ -ed—> walked, rat + -s —> rats)._\n**isolating language** . See inflecting language.\n**larynx** . The valve near the top of the windpipe, used to seal the lungs during\n\n\n478 Glossary\n\n\nexertion and to produce voiced sounds. Its parts include the vocal cords\ninside and the Adam's apple in front,\n**lexical entry.** The information about a particular word (its sound, meaning,\nsyntactic category, and special restrictions) stored in a person's mental\ndictionary.\n**lexicon.** A dictionary, especially the \"mental dictionary\" consisting of a\nperson's intuitive knowledge of words and their meanings.\n**linguist.** A scholar or scientist who studies how languages work. Does not\nrefer here to a person who speaks many languages.\n**listeme.** An uncommon but useful term corresponding to one of the senses\nof \"word,\" it refers to an element of language that must be memorized\nbecause its sound or meaning does not conform to some general rule. All\nword roots, irregular forms, and idioms are listemes.\n**main verb.** A verb that is not the auxiliary: _I might_ _**STUDY**_ _Latin; He is_"
    },
    {
        "document_id": "0",
        "parent_id": 657,
        "parent_text": "_**COMPLAINING**_ _again._\n**Markov model.** A finite-state device that, when faced with a choice between\ntwo or more lists, chooses among them according to prespecified probabilities (for example, a .7 chance of going to List A, a .3 chance of going to\nlist B).\n**mentalese.** The hypothetical \"language of thought,\" or representation of\nconcepts and propositions in the brain in which ideas, including the\nmeanings of words and sentences, are couched.\n**modal.** A kind of auxiliary: _can, should, could, will, ought, might._\n**modality.** Whether a clause is a statement, question, negation, or imperative;\nanother way of referring to some of the distinctions relevant to mood.\n**modifier.** See **adjunct.**\n**mood.** Whether a sentence is a statement _**(HE GOES),**_ imperative ( **GO** !), or\n\nsubjunctive _(It is important_ _**THAT HE GO).**_\n**morphemes.** The smallest meaningful pieces into which words can be cut:\n\n_un-micro-wave-abil-ity._\n**morphology.** The component of grammar that builds words out of pieces\n\n(morphemes).\n**movement.** The principal kind of transformational rule in Chomsky's theory,\nit moves a phrase from its customary position in deep structure to some\nother, unfilled position, leaving behind a \"trace\": _Do you want what_ —>\n_What do you want_ (trace).\n**natural kind.** A category of objects as found in nature, like robins, animals,\ncrabgrass, carbon, and mountains; as opposed to artifacts (man-made\nobjects) and nominal kinds (categories specified by a precise definition,\nlike senators, bachelors, brothers, and provinces).\n**natural language.** A human language like English or Japanese, as opposed\nto a computer language, musical notation, formulas in logic, and so on.\n**neural network.** A kind of computer program or model, loosely inspired by\n\n\nGlossary 479"
    },
    {
        "document_id": "0",
        "parent_id": 658,
        "parent_text": "Glossary 479\n\n\nthe brain, consisting of interconnected processing units that send signals\nto one another and turn on or off depending on the sum of their incoming\nsignals.\n**neurons.** The information-processing cells of the nervous system, including\nbrain cells and the cells whose fibers make up the nerves and spinal cord.\n**nominative.** The case of the subject of the sentence: _**SHE**_ _loves you_ (not _**HER**_\n_loves_ _you)._\n**noun.** One of the major syntactic categories, comprising words that typically\n\nrefer to a thing or person: _dog, cabbage, John, country, hour._\n**number.** Singular versus plural: _duck_ versus _ducks._\n**object.** The argument adjacent to the verb, typically referring to the entity\nthat defines or is affected by the action: _break_ _**THE GLASS**_ _, draw_ _**A CIRCLE,**_\n_honor_ _**YOUR MOTHER.**_ Also, the argument of a preposition: _in_ _**THE HOUSE,**_\n_with_ _**A**_ _**MOUSE.**_\n**parameter.** One of the ways in which something can vary; in linguistics, one\nof the ways in which languages can vary from one another (for example,\nverb-object versus object-verb ordering).\n**parsing.** One of the mental processes involved in sentence comprehension,\nin which the listener determines the syntactic categories of words, joins\nthem up in a tree, and identifies the subject, object, and predicate; a\nprerequisite to determining who did what to whom from the information\nin the sentence.\n**part of speech.** The syntactic category of a word: noun, verb, adjective,\n\npreposition, adverb, conjunction,\n**participle.** A form of the verb that cannot stand by itself in a sentence but\n\nneeds to be with an auxiliary or other verb: _He has_ _**EATEN**_ _; It was_ _**SHOWN,**_\n_She is_ _**RUNNING**_ _; They kept_ _**OPENING**_ _the door._\n**passive.** A construction in which the usual object appears as the subject,"
    },
    {
        "document_id": "0",
        "parent_id": 659,
        "parent_text": "preposition, adverb, conjunction,\n**participle.** A form of the verb that cannot stand by itself in a sentence but\n\nneeds to be with an auxiliary or other verb: _He has_ _**EATEN**_ _; It was_ _**SHOWN,**_\n_She is_ _**RUNNING**_ _; They kept_ _**OPENING**_ _the door._\n**passive.** A construction in which the usual object appears as the subject,\n\nand the usual subject is the object of the preposition _by_ or absent altogether: _He was eaten by wolverines; I was robbed._\n**perisylvian.** Regions of the brain lining both sides and the end of the Sylvian\n\nfissure, the cleft between the temporal lobe and the rest of the brain.\nLanguage circuitry is thought to be concentrated in the left perisylvian\nareas.\n**person.** The difference between _I_ or _we_ (first person), _you_ (second person),\nand _he/she/they/it_ (third person).\n**philosopher.** A scholar who attempts to clarify difficult logical and conceptual questions, especially questions about the mind and about scientific\nknowledge. Does not refer here to a person who ruminates about the\nmeaning of life.\n**phoneme.** One of the units of sound that are strung together to form a\nmorpheme, roughly corresponding to the letters of the alphabet: _b-a-t;_\n_b-ea-t; s-t-ou-t._\n\n\n480 Glossary"
    },
    {
        "document_id": "0",
        "parent_id": 660,
        "parent_text": "**phonetics.** How the sounds of language are articulated and perceived.\n**phonology.** The component of grammar that determines the sound pattern\nof a language, including its inventory of phonemes, how they may be\ncombined to form natural-sounding words, how the phonemes must be\nadjusted depending on their neighbors, and patterns of intonation, timing,\nand stress.\n**phrase.** A group of words that behaves as a unit in a sentence and which\ntypically has some coherent meaning: _in the dark; the man in the gray suit;_\n_dancing in the dark; afraid of the wolf._\n**phrase structure.** The information about the syntactic categories of the words\nin a sentence, how the words are grouped into phrases, and how the\nphrases are grouped into larger phrases; usually diagrammed as a tree.\n**phrase structure grammar.** A generative grammar consisting only of rules\nthat define phrase structures.\n**polysynthetic language.** An inflecting language in which a word may be\ncomposed of a long string of prefixes, roots, and suffixes.\n**pragmatics.** How language is used in a social context, including how sentences are made to fit in with the flow of a conversation, how unspoken\npremises are inferred, and how degrees of formality and politeness are\nsignaled.\n**predicate.** A state, event, or relationship, usually involving one or more\nparticipants (arguments). Sometimes the predicate is identified with the\nverb phrase of a sentence _(The baby_ _**ATE THE SLUG),**_ and the subject is\nconsidered its sole argument; at other times it is identified with the verb\nalone, and the subject, object, and other complements are all considered\nto be its arguments. The contradiction can be resolved by saying that the\nverb is a simple predicate, which combines with its complements to form\na complex predicate.\n**preposition.** One of the major syntactic categories, comprising words that\ntypically refer to a spatial or temporal relationship: _in, on, at, near, by,_\n_for, under, before, after._"
    },
    {
        "document_id": "0",
        "parent_id": 661,
        "parent_text": "considered its sole argument; at other times it is identified with the verb\nalone, and the subject, object, and other complements are all considered\nto be its arguments. The contradiction can be resolved by saying that the\nverb is a simple predicate, which combines with its complements to form\na complex predicate.\n**preposition.** One of the major syntactic categories, comprising words that\ntypically refer to a spatial or temporal relationship: _in, on, at, near, by,_\n_for, under, before, after._\n**pronoun.** A word that stands for a whole noun phrase: I, _me, my, you, your,_\n_he, him, his, she, her, it, its, we, us, our, they, them, their, who, whom,_\n_whose._\n**proposition.** A statement or assertion, consisting of a predicate and a set of\narguments.\n**prosody.** The overall sound contour with which a word or sentence is\npronounced: its melody (intonation) and rhythm (stress and timing).\n**psycholinguist.** A scientist, usually a psychologist by training, who studies\nhow people understand, produce, or learn language.\n**psychologist.** A scientist who studies how the mind works, usually via the\nanalysis of experimental or observational data on people's behavior. Does"
    },
    {
        "document_id": "0",
        "parent_id": 662,
        "parent_text": "Glossary 481\n\n\nnot refer here to psychotherapist or to a clinician who treats mental\ndisorders.\n**recursion.** A procedure that invokes an instance of itself, and thus can be\napplied repeatedly to create or analyze entities of any size: \"How to put\nwords _**in alphabetical order:**_ sort the words so their first letters are in the\nsame order as in the alphabet; then for each group of words beginning\nwith the same letter, ignore that first letter and put the remaining parts\n_**in alphabetical order.\"**_ _\"A_ _**verb phrase**_ can consist of a verb followed by a\nnoun phrase followed by a _**verb phrase.\"**_\n**regular.** See **irregular.**\n**relative clause.** A clause modifying a noun, usually containing a trace corresponding to that noun: _**the spy**_ _**WHO LOVED ME; the land THAT TIME**_"
    },
    {
        "document_id": "0",
        "parent_id": 663,
        "parent_text": "_**FORGOT; violet eyes**_ _**TO DIE FOR.**_\n**role-player.** See **argument.**\n**root.** The most basic morpheme in a word or family of related words,\nconsisting of an irreducible, arbitrary sound-meaning pairing: _**ELECTRicity,**_\n_**ELECTRical, ELECTRIC, ELECTRlfy, ELECTROn.**_\n**semantics.** The parts of rules and lexical entries that specify the meaning of\na morpheme, word, phrase, or sentence. Does not refer here to haggling\nover exact definitions.\n**sexual recombination.** The process that makes organisms capable of generating an immense number of distinct possible offspring. When a sperm or\negg is formed, the twenty-three pairs of chromosomes ordinarily found in\na human cell (one chromosome in each pair from the mother, one from\nthe father) have to be cut down to twenty-three single chromosomes. This\nis done in two steps. First, within each pair, a few random cuts are made\nin identical positions in each chromosome, pieces are exchanged, and the\nnew chromosomes are glued back together. Then, one member of each\npair is chosen at random, and put into the egg or sperm. During fertilization, each chromosome from the egg is paired up with its counterpart\nfrom the sperm, restoring the genome to twenty-three pairs.\nSLI. Specific Language Impairment, any syndrome in which a person fails\nto develop language properly and the blame cannot be pinned on hearing\ndeficits, low intelligence, social problems, or difficulty controlling the\nspeech muscles.\n**specifier.** A specific position at the periphery of a phrase, generally where\none finds the subject. For many years the specifier position of a noun\nphrase was thought to contain the determiner (article), but the current\nconsensus in Chomskyan theory puts the determiner in a phrase of its\nown (a determiner phrase).\n**stem.** The main portion of a word, the one that prefixes and suffixes are\nstuck onto: _**WALKS, BREAKable, ensLAVE.**_\n\n\n482 Glossary\n\n\n**stop consonant.** A consonant in which the airflow is completely blocked for"
    },
    {
        "document_id": "0",
        "parent_id": 664,
        "parent_text": "482 Glossary\n\n\n**stop consonant.** A consonant in which the airflow is completely blocked for\n\na moment: _p, t, k, b d, g._\n**strong verb.** The verbs in Germanic languages (including English), now all\n\nirregular, that form the past tense by changing the vowel: _break-broke,_\n_sing-sang,_ _fly-flew,_ _bind-bound,_ _bear-bore._\n**subject.** One of the arguments of a verb, typically used for the agent or actor"
    },
    {
        "document_id": "0",
        "parent_id": 665,
        "parent_text": "when the verb refers to an action: _**BELIVEAU**_ _scores;_ _**THE HIPPIE**_ _touched_\n_the_ _debutante._\n**surface structure** (now **s-structure).** The phrase structure tree formed when\nmovement transformations are applied to a deep structure. Thanks to\ntraces, it contains all the information necessary to determine the meaning\nof the sentence. Aside from certain minor adjustments (executed by \"stylistic\" and phonological rules), it corresponds to the actual order of words\nthat a person utters.\n**syllable.** A vowel or other continuous voiced sound, together with one or\nmore consonants preceding or following it, that are pronounced as **a** unit:\n_simple,_ _a-lone,_ _en-cy-clo-pe-di-a._\n**syntactic atom.** One of the senses of \"word,\" defined as an entity that the\nrules of syntax cannot separate or rearrange.\n**syntactic category.** See **part of speech.**\n**syntax.** The component of grammar that arranges words into phrases and\nsentences.\n**tense.** Relative time of occurrence of the event described by the sentence,\nthe moment at which the speaker utters the sentence, and, often, some\nthird reference point: present _(he eats),_ past _(he ate),_ future _(he will_\n_eat)._ Other so-called tenses such as the perfect _(He has eaten)_ involve **a**\ncombination of tense and aspect.\n**top-down.** See **bottom-up.**\n**trace.** A silent or \"understood\" element in a sentence, corresponding to the\ndeep-structure position of a moved phrase: _What did be put (_ _**TRACE**_ _) in_\n_the garage?_ (the trace corresponds to _what); Boggs was grazed (_ _**TRACE**_ _) by_\n_a fastball_ (the trace corresponds to _Boggs)._\n**transformational grammar.** A grammar composed of a set of phrase structure\nrules, which build a deep-structure tree, and one or more transformational\nrules, which move the phrases in the deep structure to yield a surfacestructure tree.\n**transitive.** See **intransitive.**\n**Turing machine.** A design for a simple computer consisting of a potentially"
    },
    {
        "document_id": "0",
        "parent_id": 666,
        "parent_text": "_the garage?_ (the trace corresponds to _what); Boggs was grazed (_ _**TRACE**_ _) by_\n_a fastball_ (the trace corresponds to _Boggs)._\n**transformational grammar.** A grammar composed of a set of phrase structure\nrules, which build a deep-structure tree, and one or more transformational\nrules, which move the phrases in the deep structure to yield a surfacestructure tree.\n**transitive.** See **intransitive.**\n**Turing machine.** A design for a simple computer consisting of a potentially\ninfinite strip of paper, and a processor that can move along the paper and\nprint or erase symbols on it in a sequence that depends on which symbol\nthe processor is currently reading and which of several states it is in.\nThough too clumsy for practical use, a Turing machine is thought to be"
    },
    {
        "document_id": "0",
        "parent_id": 667,
        "parent_text": "Glossary 483\n\n\ncapable of computing anything that any digital computer, past, present,\nor future, can compute.\n**Universal Grammar** . The basic design underlying the grammars of all human\n\nlanguages; also refers to the circuitry in children's brains that allows them\nto learn the grammar of their parents' language,\n**verb** . One of the major syntactic categories, comprising words that typically\n\nrefer to an action or state: _bit, break, run, know,_ _s e e m ._\n**voice** . The difference between the active and passive constructions: _D o g_\n\n_bites_ _man_ versus _Man_ _is_ _bitten_ _by_ _dog._\n**voicing** . Vibration of the vocal folds in the larynx simultaneous with the\n\narticulation of a consonant; the difference between _b, d, g, z, v_ (voiced)\nand _p, t, k, s, f_ (unvoiced).\n**vowel.** A phoneme pronounced without any constriction of the airway.\n**white matter** . See cortex.\n**word** . See listeme, morphology, syntactic atom.\n**X-bar** . The smallest kind of phrase, consisting of a head and its non-subject\narguments (role-players): _The_ _Romans'_ _DESTRUCTION_ _OF THE_ _CITY; She_\n\n_WENT_ _TO_ _SCHOOL_ _on_ _foot;_ _He_ _is_ _very_ _PROUD_ _OF_ _HIS_ _SON._\n**X-bar theory; X-bar phrase structure** . The particular kind of phrase structure rules thought to be used in human languages, according to which all\nthe phrases in all languages conform to a single plan. In that plan, the\nproperties of the whole phrase are determined by the properties of a single\nelement, the head, inside the phrase."
    }
]